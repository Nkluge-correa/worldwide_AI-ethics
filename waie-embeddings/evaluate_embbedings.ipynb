{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Analysis\n",
    "\n",
    "Return to the [index](https://github.com/Nkluge-correa/worldwide_AI-ethics).\n",
    "\n",
    "Use this notebook to create the 3D scatter plot of the principles in the WAIE dataset.\n",
    "\n",
    "> Note: The embedding vectors were generated via OpenAI's [`text-embedding-ada-002`](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings) API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 151 nearest neighbors...\n",
      "[t-SNE] Indexed 1456 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 1456 samples in 0.116s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1456\n",
      "[t-SNE] Computed conditional probabilities for sample 1456 / 1456\n",
      "[t-SNE] Mean sigma: 0.153985\n",
      "[t-SNE] KL divergence after 50 iterations with early exaggeration: 66.817604\n",
      "[t-SNE] KL divergence after 950 iterations: 1.328897\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "Accountability",
           " <i>Declaration on Ethics and Data Protection in Artifical Intelligence</i>",
           " 2018",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " Belgium",
           " Accountability",
           " <i>artificial intelligence systems should be ensured, promoting accountability of<br>all relevant stakeholders to individuals, supervisory authorities, and other<br>third parties as appropriate, including through the realization of audit,<br>continuous monitoring, and impact assessment of artificial intelligence systems,<br>and periodic review of oversight mechanisms.</i>"
          ],
          [
           "Accountability",
           " <i>Intel’s AI Privacy Policy White Paper: Protecting individuals’ privacy and data<br>in the artificial intelligence world</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Accountability",
           " <i>Responsible risk management practices require that organizations hold themselves<br>accountable to put in place appropriate technical and organizational measures<br>for addressing privacy and data protection concerns of customers, business<br>partners, and society.</i>"
          ],
          [
           "Accountability",
           " <i>AI Policies and Principles</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Industrial Association",
           " North America",
           " United States of America",
           " Accountability",
           " <i>We recognize our responsibility to integrate principles into the design of AI<br>technologies, beyond compliance with existing laws. AI researchers, subject<br>matter experts, and stakeholders should spend a great deal of time working to<br>ensure the responsible design and deployment of AI systems. Acknowledging<br>existing legal and regulatory frameworks, we are committed to partnering with<br>relevant stakeholders to inform a reasonable accountability framework for all<br>entities in the context of autonomous systems.</i>"
          ],
          [
           "Accountability",
           " <i>Artificial Intelligence and Machine Learning: Policy Paper</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Accountability",
           " <i>Legal accountability has to be ensured when human agency is replaced by<br>decisions of AI agents.</i>"
          ],
          [
           "Accountability",
           " <i>Everyday Ethics for Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Accountability",
           " <i>Given that humans write algorithms and define the success and failures of AI<br>outcomes, everyone involved in the development of AI should be accountable for<br>how AI affects the world. This includes technology developers and the companies<br>that invest in AI development.</i>"
          ],
          [
           "Accountability",
           " <i>Responsible AI: A Global Policy Framework</i>",
           " 2021",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization, Professional Association",
           " North America",
           " United States of America",
           " Accountability",
           " <i>Organisations that develop, make available, or use AI systems ought to be<br>accountable for the consequences of their actions and shall designate an<br>individual or individuals who are accountable for the organization’s compliance<br>with the principles of the Policy Framework for Responsible AI or other adopted<br>principles (including analogous principles that may be developed for a specific<br>industry) to keep humans behind the machines and AI Human-centric.</i>"
          ],
          [
           "Accountability",
           " <i>The Japanese Society for Artificial Intelligence Ethical Guidelines</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Academic",
           " Eastern Asia",
           " Japan",
           " Accountability",
           " <i>Members of the JSAI (Japanese Society for Artificial Intelligence) must respect<br>laws and regulations relating to research and development, intellectual<br>property, as well as any other relevant contractual agreements.</i>"
          ],
          [
           "Accountability",
           " <i>Hambach Declaration on Artificial Intelligence(Hambacher Erklärung zur<br>Künstlichen Intelligenz)</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Germany",
           " Accountability",
           " <i>The parties involved in the use of an AI system must identify and communicate<br>responsibility and each take the necessary measures to ensure lawful processing,<br>data subjects' rights, security of processing, and controllability of the AI<br>system. The controller must ensure that the principles set out in Article 5 of<br>the General Data Protection Regulation (GDPR) are complied with. AI may only be<br>used for constitutionally legitimized purposes and may not override the purpose<br>limitation requirement. It also applies to AI systems that may only be used for<br>constitutionally legitimized purposes.</i>"
          ],
          [
           "Accountability",
           " <i>Directive on Automated Decision-Making</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Accountability",
           " <i>The Assistant Deputy Minister responsible for the program using the Automated<br>Decision System, or any other person named by the Deputy Head, is responsible<br>for: Consulting with the institution’s legal services, from the concept stage of<br>a project, to ensure that the use of the Automated Decision System is compliant<br>with applicable legal requirements.</i>"
          ],
          [
           "Accountability",
           " <i>Ethics Guidelines for Trustworthy AI</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Accountability",
           " <i>It necessitates that mechanisms be put in place to ensure responsibility and<br>accountability for AI systems and their outcomes, both before and after their<br>development, deployment, and use.</i>"
          ],
          [
           "Accountability",
           " <i>Declaration of Ethical Principles for AI in Latin America (Declaración de<br>Principios Éticos para la IA de Latinoamérica)</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Latin America",
           " Unspecified",
           " Accountability",
           " <i>AI developers are responsible for their projects and must take into<br>consideration the impact that each project may have on society. We will work to<br>prevent potentially harmful or abusive applications. As we develop and implement<br>AI technologies, we will assess likely uses in light of the following factors:<br>Purpose, Nature, and Impact. The development of AI technologies and their<br>effects must always be following current legislation and respect local cultural<br>and social norms.</i>"
          ],
          [
           "Accountability",
           " <i>China’s Artificial Intelligence Industry Alliance Self-discipline Convention</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Accountability",
           " <i>Make clear the rights and obligations at each stage in artificial intelligence<br>research and development (R&D), design, manufacturing, operation, services,<br>etc., to be able to determine the responsible party promptly when harm occurs.<br>Advocate for relevant enterprises and organizations to innovate in insurance<br>mechanisms under the existing legal framework, to distribute the social risks<br>brought about by the development of the artificial intelligence industry.</i>"
          ],
          [
           "Accountability",
           " <i>Mid- to Long-Term Master Plan in Preparation for the Intelligent Information<br>Society Managing the Fourth Industrial Revolution</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " South Korea",
           " Accountability",
           " <i>Reform and improve the entire legal system to grant rights and responsibilities<br>to “electronic persons” in preparation for the dissemination of AI and self-<br>learning machines.</i>"
          ],
          [
           "Accountability",
           " <i>Charlevoix Common Vision for the Future of Artificial Intelligence</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " International Organization",
           " Intergovernmental Organization",
           " G7",
           " Accountability",
           " <i>We, the leaders of the G7, commit to safeguarding privacy including through the<br>development of appropriate legal regimes;</i>"
          ],
          [
           "Accountability",
           " <i>Governance Recommendations - Use of Artificial Intelligence by Public<br>Authorities</i>",
           " 2021",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Latin America",
           " Brazil",
           " Accountability",
           " <i>Accountability is a necessary guarantee to enable the exercise of civilian<br>oversight of Artificial Intelligence tools employed by public authorities,<br>minimizing risks of fundamental rights violation.</i>"
          ],
          [
           "Accountability",
           " <i>The Ethics of Artificial Intelligence</i>",
           " Unspecified",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Accountability",
           " <i>Another important social criterion for dealing with organizations is being able<br>to find the person responsible for getting something done. When does an AI<br>system fail at its assigned task, who takes the blame? The programmers? The end-<br>users? Modern bureaucrats often take refuge in established procedures that<br>distribute responsibility so widely that no one person can be identified to<br>blame for the catastrophes that result.</i>"
          ],
          [
           "Accountability",
           " <i>Next-Generation AI Governance Principles - Develop responsible artificial<br>intelligence</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Accountability",
           " <i>AI developers, users, and other interested parties should possess a strong sense<br>of social responsibility and self-discipline, and strictly abide by laws,<br>regulations, ethics, morals, standards, and norms. Establish an AI<br>accountability mechanism to clarify the responsibilities of developers, users,<br>beneficiaries, etc. The AI application process should ensure the human right to<br>know and give notice of possible risks and impacts. Prevent the use of AI for<br>illegal activities.</i>"
          ],
          [
           "Accountability",
           " <i>Draft AI R&D Guidelines for International Discussions</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Accountability",
           " <i>AI designers must ensure that they are accountable to their stakeholders and<br>users to gain their trust. In this way, AI designers must ensure that they<br>provide all the information and explanation about their systems to users.</i>"
          ],
          [
           "Accountability",
           " <i>Responsible bots: 10 guidelines for developers of conversational AI</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Accountability",
           " <i>Accept responsibility; Developers are accountable for the bots they deploy.</i>"
          ],
          [
           "Accountability",
           " <i>Toward a G20 Framework for Artificial Intelligence in the Workplace</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " Canada",
           " Accountability",
           " <i>People and corporations who design and deploy AI systems must be accountable for<br>how their systems are designed and operated. The development of AI must be<br>responsible, safe, and useful. AI must maintain the legal status of tools, and<br>legal persons need to retain control over, and responsibility for, these tools<br>at all times.</i>"
          ],
          [
           "Accountability",
           " <i>The Future Computed – Artificial intelligence and its role in society</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Accountability",
           " <i>The people who design and deploy AI systems must be accountable for how their<br>systems operate. To establish accountability norms for AI, we should draw upon<br>experience and practices in other areas, including healthcare and privacy.<br>Governments must also balance support for innovation with the need to ensure<br>consumer safety by holding the makers of AI systems responsible for harm caused<br>by unreasonable practices.</i>"
          ],
          [
           "Accountability",
           " <i>How Can Humans Keep The Upper Hand? The Ethical Matters Raised By Algorithms And<br>Artificial Intelligence</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Accountability",
           " <i>To end, introducing an obligation in terms of accountability or organizing<br>liability could be a way of addressing the phenomenon of diminishing<br>accountability which algorithms and AI are tending to encourage. The idea would<br>be that the roll-out of an algorithmic system systematically must give rise to a<br>clear attribution of the liabilities that should be assumed in its operation.</i>"
          ],
          [
           "Accountability",
           " <i>Statement on Algorithmic Transparency and Accountability</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Accountability",
           " <i>Institutions should be held responsible for decisions made by the algorithms<br>that they use, even if it is not feasible to explain in detail how the<br>algorithms produce their results.</i>"
          ],
          [
           "Accountability",
           " <i>Responsible AI - Microsoft AI principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Accountability",
           " <i>People should be accountable for AI systems.</i>"
          ],
          [
           "Accountability",
           " <i>For a meaningful Artificial Intelligence - Towards a French and European<br>strategy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Accountability",
           " <i>We need to ensure that organizations that deploy and utilize these systems<br>remain legally responsible for any damages caused.</i>"
          ],
          [
           "Accountability",
           " <i>Principles to Promote Fairness, Ethics, Accountability and Transparency (FEAT)<br>in the Use of Artificial Intelligence and Data Analytics in Singapore’s<br>Financial Sector</i>",
           " 2018",
           " Recommendation",
           " Governmental Institution",
           " Southeast Asia",
           " Singapore",
           " Accountability",
           " <i>Firms using AIDA should be accountable for both internally developed and<br>externally sourced AIDA models.</i>"
          ],
          [
           "Accountability",
           " <i>It’s Time to Do Something: Mitigating the Negative Impacts of Computing Through<br>a Change to the Peer Review Process</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " Eastern Asia, Central Europe",
           " Turkey, Turkey",
           " Accountability",
           " <i>An initial threshold for a “reasonable technology” might emerge from the nature<br>of recommendation as a means of making computing research more accountable to<br>the public.</i>"
          ],
          [
           "Accountability",
           " <i>Digital Technology and Healthcare which ethical issues for which regulations?</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " France",
           " Accountability",
           " <i>The implementation of a flexible normative system of regulation at the European<br>level will require a strong initiative on the part of governments to support the<br>joint construction of regulatory tools appropriate to national needs.</i>"
          ],
          [
           "Accountability",
           " <i>Business Ethics and Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " Western Europe",
           " United Kingdom",
           " Accountability",
           " <i>Companies must ensure that they establish a line of responsibility for actions<br>and who has to answer for the consequences of their AI systems. Companies must<br>take responsibility for the outcome of the decision-making process of their AI<br>systems since machines are not moral agents and cannot be held responsible for<br>their actions.</i>"
          ],
          [
           "Accountability",
           " <i>Model AI Governance Framework</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " Southeast Asia",
           " Singapore",
           " Accountability",
           " <i>Responsibility for and oversight of the various stages and activities involved<br>in AI deployment should be allocated to the appropriate personnel and/or<br>departments.</i>"
          ],
          [
           "Accountability",
           " <i>Data, Responsibly (Vol. 1) Mirror, Mirror</i>",
           " 2020",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Accountability",
           " <i>We need to agree on how to go about regulating technology, and so we must start<br>educating ourselves and partake in this lofty enterprise in good faith.</i>"
          ],
          [
           "Accountability",
           " <i>Asilomar AI Principles</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Accountability",
           " <i>Designers and builders of advanced AI systems are stakeholders in the moral<br>implications of their use, misuse, and actions, with a responsibility and<br>opportunity to shape those implications.</i>"
          ],
          [
           "Accountability",
           " <i>G20 Ministerial Statement on Trade and Digital Economy</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " G20",
           " Accountability",
           " <i>AI actors should be accountable for the proper functioning of AI systems and the<br>respect of the above principles, based on their roles, the context, and<br>consistent with the state of art.</i>"
          ],
          [
           "Accountability",
           " <i>AI 4People 's Ethical Framework for a Good AI Society: Opportunities, Risks,<br>Principles, and Recommendations</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Accountability",
           " <i>Those developing AI should assume responsibility for their creations.<br>Stakeholders should develop appropriate legal procedures and improve the IT<br>infrastructure of the justice system to permit the scrutiny of algorithmic<br>decisions in court.</i>"
          ],
          [
           "Accountability",
           " <i>AI & Data Topical Guide Series</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Southern Africa",
           " South Africa",
           " Accountability",
           " <i>In developing South Africa’s national strategy on AI, specific attention should<br>be paid to developing strong accountability mechanisms for the use of AI in line<br>with the principles of governance set out in the Constitution and, for<br>businesses, under the King Codes.</i>"
          ],
          [
           "Accountability",
           " <i>Rome Call for AI Ethics</i>",
           " 2020",
           " Recommendation",
           " Religious Institution",
           " Southern Europe",
           " Vatican City State",
           " Accountability",
           " <i>Those who design and deploy the use of AI must proceed with responsibility and<br>transparency.  There must always be someone who takes responsibility for what a<br>machine does.</i>"
          ],
          [
           "Accountability",
           " <i>A practical guide to Responsible Artificial Intelligence (AI)</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Accountability",
           " <i>Organizations should strive to develop, implement, and use AI solutions that are<br>both morally responsible and also legal and ethically defensible. Organizations<br>also must monitor the regulatory environment in which they operate and<br>understand how emerging regulations will shape future business practices.</i>"
          ],
          [
           "Accountability",
           " <i>Ethical Guidelines of the German Informatics Society</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization, Professional Association",
           " Western Europe",
           " Germany",
           " Accountability",
           " <i>GI members are familiar with and observant of pertinent legal regulations<br>concerning the design, manufacture, operation, and use of IT systems. GI<br>members, in conjunction with their expertise and professional competencies,<br>participate actively in drafting legislative regulations.</i>"
          ],
          [
           "Accountability",
           " <i>Ethically Aligned Design: A Vision for Prioritizing Human Well-being with<br>Autonomous and Intelligent Systems, Version 2</i>",
           " 2017",
           " Recommendation",
           " Professional Association",
           " North America",
           " United States of America",
           " Accountability",
           " <i>Legislatures/courts should clarify issues of responsibility, culpability,<br>liability, and accountability for A/IS where possible during development and<br>deployment (so that manufacturers and users understand their rights and<br>obligations).</i>"
          ],
          [
           "Accountability",
           " <i>Privacy and Freedom of Expression In the Age of Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " Western Europe",
           " United Kingdom",
           " Accountability",
           " <i>Different types of AI and different domains of application raise specific<br>ethical and regulatory human rights issues. To ensure that they protect<br>individuals from the risks posed by AI, existing laws must be reviewed, and if<br>necessary amended, to address the effects of new and emerging threats to privacy<br>and freedom of expression.</i>"
          ],
          [
           "Accountability",
           " <i>Užupis Principles for Trustworthy AI Design</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Europe",
           " Lithuania",
           " Accountability",
           " <i>I promise to make everybody happy again if my AI made somebody sad for any<br>reason.</i>"
          ],
          [
           "Accountability",
           " <i>The Ethics of Code: Developing AI for Business with Five Core Principles</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Accountability",
           " <i>AI must be held to account—and so must users. AI needs to be held accountable<br>for its actions and decisions, just like humans. Technology should not be<br>allowed to become too clever to be accountable.</i>"
          ],
          [
           "Accountability",
           " <i>Code of conduct for data-driven health and care technology</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Accountability",
           " <i>Ensure that the product meets all relevant regulatory requirements. Establish if<br>the data-driven technology that is being developed falls under the definition of<br>a medical device or in vitro diagnostic tool and follow the required regulatory<br>conformance route required to place the product on the market (currently CE<br>marking, soon to change to UKCA). Software that meets the definition of a<br>medical device will be regulated as such by the MHRA). The Care Quality<br>Commission (CQC) regulates providers of clinical services, defined by 14<br>regulated activities. Any organization using its products in a way that<br>constitutes carrying out any of these regulated activities must register with<br>CQC. Organizations using products involved in the delivery of pharmacy services<br>should register with the General Pharmaceutical Council (GPhC).</i>"
          ],
          [
           "Accountability",
           " <i>Digital Ethics Guidelines on AI</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Accountability",
           " <i>The human always remains responsible. Our solutions come with a clear definition<br>of who is responsible for which AI system or feature. We are in charge of our<br>products and services. And, we know who is in charge of partner or third-party<br>solutions.</i>"
          ],
          [
           "Accountability",
           " <i>Ethics Framework - Responsible AI</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Accountability",
           " <i>Care must be taken to operate within the company’s areas of competence, and to<br>actively engage with third-party evaluation and questions. Things can go wrong,<br>despite best efforts. Companies should put in place procedures to report,<br>investigate, take responsibility for, and resolve issues. Help should be<br>accessible and timely.</i>"
          ],
          [
           "Accountability",
           " <i>AI Ethics Principles & Guidelines</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Middle East",
           " United Arab Emirates",
           " Accountability",
           " <i>Accountability for the outcomes of an AI system lies not with the system itself<br>but is apportioned between those who design, develop and deploy it.</i>"
          ],
          [
           "Accountability",
           " <i>Data for the Benefit of the People: Recommendations from the Danish Expert Group<br>on Data Ethics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Denmark",
           " Accountability",
           " <i>Responsibility is a company's “due diligence” about data collection and<br>processing. Responsibility and co-responsibility must therefore exist in all<br>links of the data processing chain. This includes co-responsibility from<br>business partners and third-party processing and any future data storage. Every<br>year, companies should declare their data ethics policy in accordance with the<br>Danish Financial Statements Act.</i>"
          ],
          [
           "Accountability",
           " <i>Principles of Robotics</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Accountability",
           " <i>The person with legal responsibility for a robot should be attributed.</i>"
          ],
          [
           "Accountability",
           " <i>Algo.Rules: Rules for the Design of Algorithmic Systems</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Private Corporation",
           " Western Europe",
           " Germany",
           " Accountability",
           " <i>A natural or legal person must always be held responsible for the effects<br>involved with the use of an algorithmic system. Accountability must be assigned.<br>The accountable person must be aware of the responsibilities associated with<br>their tasks. This also applies to responsibilities that are shared by several<br>people or organizations. The allocation of responsibility must be fully<br>documented and transparent for internal and external parties. Responsibility may<br>not be transferred to the algorithmic system itself, users, or people who are<br>affected by the system.</i>"
          ],
          [
           "Accountability",
           " <i>From Principles to Practice: An interdisciplinary framework to operationalise AI<br>ethics</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Professional Association",
           " Western Europe",
           " Germany",
           " Accountability",
           " <i>The value of accountability refers to problems that arise in connection with the<br>complex allocation or clarification of responsibility relationships in the use<br>of AI. The various dimensions of accountability range from retrospective to<br>prospective organizational measures for assigning responsibilities. They also<br>include technical means or specific ways of dealing with organizational and<br>technical errors.</i>"
          ],
          [
           "Accountability",
           " <i>Beijing AI Principles</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Eastern Asia",
           " China",
           " Accountability",
           " <i>Researchers and developers of AI should have sufficient considerations for the<br>potential ethical, legal, and social impacts and risks brought in by their<br>products and take concrete actions to reduce and avoid them.</i>"
          ],
          [
           "Accountability",
           " <i>Artificial Intelligence: opportunities, risks and recommendations for the<br>financial sector</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Luxembourg",
           " Accountability",
           " <i>Institutions should assume clear responsibility and accountability for the<br>actions and decisions taken by automated AI//ML systems and processes. Ultimate<br>responsibility should rely on senior management of the institution which<br>integrates the AI/ML logic into its business processes. Whenever off-the-shelf<br>packages are acquired, clear liability provisions should be defined at the<br>contractual level.</i>"
          ],
          [
           "Accountability",
           " <i>Data protection and Big Data (Datenschutz und Big Data)</i>",
           " 2017",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Accountability",
           " <i>It must be made clear in a declaration of consent who is responsible for the<br>collection of the data. The complete name of the company as the \"responsible<br>party\" within the meaning of the BDSG and its address must be stated. As a<br>matter of principle, a declaration of consent must be made in writing and bear a<br>handwritten signature, see Section 4a (1) sentence 3 BDSG. Therefore,<br>declarations by e-mail, copy, or scan are not sufficient.</i>"
          ],
          [
           "Accountability",
           " <i>Responsible Artificial Intelligence in the Government of Canada (whitepaper)</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Accountability",
           " <i>Organizations are accountable for the actions of AI systems, and should build<br>auditable systems.</i>"
          ],
          [
           "Accountability",
           " <i>Artificial Intelligence in Healthcare</i>",
           " 2019",
           " Recommendation",
           " Academic",
           " Western Europe",
           " United Kingdom",
           " Accountability",
           " <i>Joined up-regulation is key to making sure that AI is introduced safely, as<br>currently there is too much uncertainty about accountability, responsibility,<br>and the wider legal implications of the use of this technology.</i>"
          ],
          [
           "Accountability",
           " <i>Universal principles of data ethics: 12 guidelines for developing ethics codes</i>",
           " 2016",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Accountability",
           " <i>Always follow the law, but understand that the law is often a minimum bar. To<br>excel in data ethics, leaders must define their own compliance frameworks that<br>outperform legislated requirements. Data professionals should develop practices<br>for holding themselves and peers accountable to shared standards</i>"
          ],
          [
           "Accountability",
           " <i>Artificial Intelligence: Australia’s Ethics Framework - A Discussion Paper</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Oceania",
           " Australia",
           " Accountability",
           " <i>The AI system must comply with all relevant international, Australian Local,<br>State/Territory, and Federal government obligations, regulations, and laws.<br>People and organizations responsible for the creation and implementation of AI<br>algorithms should be identifiable and accountable for the impacts of that<br>algorithm, even if the impacts are unintended.</i>"
          ],
          [
           "Accountability",
           " <i>Universal Guidelines for Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Belgium",
           " Accountability",
           " <i>An AI system should be deployed only after an adequate evaluation of its purpose<br>and objectives, its benefits, as well as its risks. Institutions must be<br>responsible for decisions made by an AI system.</i>"
          ],
          [
           "Accountability",
           " <i>The Future Society, Law & Society Initiative, Principles for the Governance of<br>AI</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Accountability",
           " <i>Manufacturers and operators of AI shall be accountable. Accountability means the<br>ability to assign responsibility for the effects caused by AI or its operators.</i>"
          ],
          [
           "Accountability",
           " <i>Principles for the safe and effective use of data and analytics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Oceania",
           " New Zealand",
           " Accountability",
           " <i>To ensure accountability, decisions based on analytical methods or automated<br>processes affecting people should be openly disclosed, and appropriate review<br>and feedback mechanisms developed to preserve fundamental rights and freedoms.<br>Transparency supports collaboration, partnership, and shared responsibility, and<br>is essential for accountability. This includes ensuring New Zealanders know what<br>data is held about them; how it’s kept secure; who has access to it; and how<br>it’s used.</i>"
          ],
          [
           "Accountability",
           " <i>Recommendations for the responsible use of AI and automated decision-making -<br>Corporate Digital Responsibility and Decision Making (Empfehlungen für den<br>verantwortlichen Einsatz von KI und automatisierten Entscheidungen - Corporate<br>Digital Responsibility and Decision Making)</i>",
           " 2018",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Accountability",
           " <i>The development of internal company and industry-specific guidelines for the<br>fair and ethical use of algorithms and AI should be increasingly promoted.<br>Guidelines are valuable aids that both facilitate the analysis of processes and<br>provide a framework for action. A process should be established that also<br>regularly adapts existing guidelines to new technologies and the associated<br>issues.</i>"
          ],
          [
           "Accountability",
           " <i>Code of Ethics for Data-Based Value Creation</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Switzerland",
           " Accountability",
           " <i>You should define clear responsibilities for the handling of data and take<br>responsibility in case of violations of rules. This is particularly intended to<br>counteract the tendency for responsibilities to become blurred and unclear in<br>the course of the digitization of processes.</i>"
          ],
          [
           "Accountability",
           " <i>Guidelines for the responsible use of artificial intelligence and other digital<br>technologies in human resources work</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Accountability",
           " <i>Organizations that use AI solutions are accountable for the results of their<br>use.</i>"
          ],
          [
           "Accountability",
           " <i>Automated and connected automated driving (Automatisiertes und Vernetztes<br>Fahren)</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Germany",
           " Accountability",
           " <i>In hazardous situations that prove to be unavoidable despite all technical<br>precautions, the protection of human life has the highest priority in a weighing<br>of legal interests. Programming must therefore be designed within the bounds of<br>what is technically feasible. The operator must be prepared to accept damage to<br>animals or property in the event of a conflict if the personal injury can be<br>prevented. It must be clearly distinguishable whether a driverless system is<br>used or a driver with the possibility of \"overruling\" retains responsibility. In<br>the case of non-driverless systems, the human/machine interface must be designed<br>in such a way that it is clearly regulated and recognizable at all times which<br>responsibilities lie on which side, in particular on which side the control<br>lies.</i>"
          ],
          [
           "Accountability",
           " <i>Telia Company Guiding Principles on trusted AI ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Sweden",
           " Accountability",
           " <i>We always remain responsible. Our solutions come with a clear definition of who<br>is responsible for which AI solution. We are in charge of our products and<br>services. And, we know who is in charge of partner or third-party solutions.</i>"
          ],
          [
           "Accountability",
           " <i>Responsible AI and robotics: An ethical framework</i>",
           " Unspecified",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Accountability",
           " <i>It must be clear where liability lies when systems make mistakes. General<br>principles should guide accountability.</i>"
          ],
          [
           "Accountability",
           " <i>AI Now Report 2018</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Accountability",
           " <i>Governments need to regulate AI by expanding the powers of sector-specific<br>agencies to oversee, audit, and monitor these technologies by domain. The AI<br>industry urgently needs new approaches to governance. As this report<br>demonstrates, internal governance structures at most technology companies are<br>failing to ensure accountability for AI systems</i>"
          ],
          [
           "Accountability",
           " <i>Report on Artificial Intelligence and Human Society</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Accountability",
           " <i>Determining the locus of responsibility for accidents involving AI technology<br>along with preparing insurance for probabilistic risks contributes to social<br>acceptance and helps users understand the risks of utilizing AI technologies.<br>In-depth analysis and basic research (e.g., social sciences) play an important<br>role in reconsidering fundamental concepts, such as human responsibilities, that<br>the modern law is based on.</i>"
          ],
          [
           "Accountability",
           " <i>Understanding artificial intelligence ethics and safety: A guide for the<br>responsible design and implementation of AI systems in the public sector</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Western Europe",
           " United Kingdom",
           " Accountability",
           " <i>All AI systems must be designed to facilitate end-to-end answerability and<br>audibility. This requires both responsible humans-in-the-loop across the entire<br>design, implementation, and activity monitoring of the system.</i>"
          ],
          [
           "Accountability",
           " <i>Data Ethics Framework</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Accountability",
           " <i>Accountability means that there are effective governance and oversight<br>mechanisms for any project. Public accountability means that the public or its<br>representatives are able to exercise effective oversight and control over the<br>decisions and actions taken by the government and its officials, in order to<br>guarantee that government initiatives meet their stated objectives and respond<br>to the needs of the communities they are designed to benefit.</i>"
          ],
          [
           "Accountability",
           " <i>Opinion of the Data Ethics Commission</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Accountability",
           " <i>Another vital aspect of self-determination is that people must not only be<br>allowed to assume responsibility but must do so and do justice to the task.<br>Responsibility always lies with a human – institutionally enshrined, if<br>necessary – never with a machine. Even if a technical system is used to apply<br>inferences based on automated evaluations (i.e. whether or not a loan should be<br>granted), the responsibility for developing and using this system in an<br>ethically sound manner must lie with humans.</i>"
          ],
          [
           "Accountability",
           " <i>Artificial Intelligence and Data Protection</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Accountability",
           " <i>AI developers, manufacturers, and service providers should adopt forms of<br>algorithm vigilance that promote the accountability of all relevant stakeholders<br>throughout the entire life cycle of these applications, to ensure compliance<br>with data protection and human rights law and principles.</i>"
          ],
          [
           "Accountability",
           " <i>Statement on Artificial Intelligence, Robotics and 'Autonomous‘ Systems</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Accountability",
           " <i>Rule of law, access to justice and the right to redress and a fair trial provide<br>the necessary framework for ensuring the observance of human rights standards<br>and potential AI-specific regulations. Governments and international<br>organizations ought to increase their efforts in clarifying with whom<br>liabilities lie for damages caused by undesired behavior of ‘autonomous’<br>systems. Moreover, effective harm mitigation systems should be in place.</i>"
          ],
          [
           "Accountability",
           " <i>Report with recommendations to the Commission on Civil Law Rules on Robotics</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " European Union",
           " European Union",
           " Accountability",
           " <i>The European Parliament considers that the civil liability for damage caused by<br>robots is a crucial issue that also needs to be analyzed and addressed at the<br>Union level to ensure the same degree of efficiency, transparency, and<br>consistency in the implementation of legal certainty throughout the European<br>Union for the benefit of citizens, consumers and businesses alike. Robotics<br>engineers should remain accountable for the social, environmental, and human<br>health impacts that robotics may impose on present and future generations.</i>"
          ],
          [
           "Accountability",
           " <i>Preparing for the future of Artificial Intelligence</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Accountability",
           " <i>Agencies should draw on appropriate technical expertise at the senior level when<br>setting regulatory policy for AI-enabled products. Effective regulation of AI-<br>enabled products requires collaboration between agency leadership, staff<br>knowledgeable about the existing regulatory framework and regulatory practices<br>generally, and technical experts with knowledge of AI. Agency leadership should<br>take steps to recruit the necessary technical talent, or identify it in existing<br>agency staff, and should ensure that there are sufficient technical “seats at<br>the table” in regulatory policy discussions.</i>"
          ],
          [
           "Accountability",
           " <i>Vienna Manifesto on Digital Humanism</i>",
           " 2019",
           " Recommendation",
           " Academic",
           " Central Europe",
           " Austria",
           " Accountability",
           " <i>Effective regulations, rules, and laws, based on a broad public discourse, must<br>be established. They should ensure prediction accuracy, fairness and equality,<br>accountability, and transparency of software programs and algorithms.</i>"
          ],
          [
           "Accountability",
           " <i>Principles for Accountable Algorithms and a Social Impact Statement for<br>Algorithms</i>",
           " Unspecified",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Unspecified",
           " Unspecified",
           " Accountability",
           " <i>Make available externally visible avenues of redress for adverse individual or<br>societal effects of an algorithmic decision system, and designate an internal<br>role for the person who is responsible for the timely remedy of such issues.</i>"
          ],
          [
           "Accountability",
           " <i>Artificial Intelligence: Economic importance, social challenges, human<br>responsibility</i>",
           " 2017",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Accountability",
           " <i>The use of algorithms and self-learning systems must be ethically evaluated.<br>Recommendations for legislators, regulators, the economy, and the public sector<br>must be developed. This also includes guidelines on which AI applications are<br>desired and which are not accepted. These challenges should be addressed by<br>policymakers. At the EU level, clarification should be given as to which AI<br>areas are approved and which are not, so that individual countries do not suffer<br>from location disadvantages.</i>"
          ],
          [
           "Accountability",
           " <i>Guidance for Regulation of Artificial Intelligence Applications</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Accountability",
           " <i>Consistent with law, agencies should take into consideration the following<br>principles when formulating regulatory and non-regulatory approaches to the<br>design, development, deployment, and operation of AI applications, both general<br>and sector-specific. These principles, many of which are interrelated, reflect<br>the goals and principles in Executive Order 13859. When developing regulatory<br>and non-regulatory approaches, agencies should pursue performance-based and<br>flexible approaches that can adapt to rapid changes and updates to AI<br>applications. Rigid, design-based regulations that attempt to prescribe the<br>technical specifications of AI applications will in most cases be impractical<br>and ineffective, given the anticipated pace with which AI will evolve and the<br>resulting need for agencies to react to new information and evidence.</i>"
          ],
          [
           "Accountability",
           " <i>A guide to using artificial intelligence in the public sector</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Accountability",
           " <i>With an AI project you should consider several factors, including AI ethics and<br>safety. hese factors span safety, ethical, legal and administrative concerns and<br>include: accountability - consider who is responsible for each element of the<br>model’s output and how the designers and implementers of AI systems will be held<br>accountable.</i>"
          ],
          [
           "Accountability",
           " <i>AI in the UK: ready, willing and able?</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Accountability",
           " <i>We recommend that the Law Commission consider the adequacy of existing<br>legislation to address the legal liability issues of AI and, where appropriate,<br>recommend to Government appropriate remedies to ensure that the law is clear in<br>this area.</i>"
          ],
          [
           "Accountability",
           " <i>Preliminary Study on the Ethics of Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Accountability",
           " <i>Developers and companies should take into consideration ethics when developing<br>autonomous intelligent systems. Arrangements should be developed that will make<br>it possible to attribute accountability for AI-driven decisions and the behavior<br>of AI systems.</i>"
          ],
          [
           "Accountability",
           " <i>Report of COMEST on robotics ethics</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Accountability",
           " <i>Deterministic robots, and even sophisticated cognitive robots, cannot take any<br>ethical responsibility, which lies with the designer, manufacturer, seller,<br>user, and the State. Therefore, human beings should always be in the loop and<br>find ways to control robots by different means (e.g., traceability, off switch,<br>etc.) to maintain human moral and legal responsibility.</i>"
          ],
          [
           "Accountability",
           " <i>Top 10 Principles for Ethical Artificial Intelligence</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " Switzerland",
           " Accountability",
           " <i>An absolute precondition is that the development of AI must be responsible,<br>safe, and useful, where machines maintain the legal status of tools, and legal<br>persons retain control over, and responsibility for, these machines at all<br>times. UNI Global Union asserts that legal responsibility for a robot should be<br>attributed to a person. Robots are not responsible parties under the law.</i>"
          ],
          [
           "Accountability",
           " <i>Montréal declaration for a responsible development of artificial intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " Canada",
           " Accountability",
           " <i>The development and use of AI must not contribute to lessening the<br>responsibility of human beings when decisions must be made. Only human beings<br>can be held responsible for decisions stemming from recommendations made by AI,<br>and the actions that proceed therefrom.</i>"
          ],
          [
           "Accountability",
           " <i>Ethical Framework for Artificial Intelligence in Colombia (Marco Ético para la<br>Inteligencia Artificial en Colombia)</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Latin America",
           " Colombia",
           " Accountability",
           " <i>The people who design an algorithm are responsible for the results it generates<br>and the criteria used to arrive at certain answers. Those involved in the<br>development of this technology must establish clear responsibilities in the<br>design, production, and implementation chain.</i>"
          ],
          [
           "Accountability",
           " <i>fAIr LAC: Responsible and Widespread Adoption of Artificial Intelligence in<br>Latin America and the Caribbean</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Latin America",
           " Unspecified",
           " Accountability",
           " <i>AI actors should be accountable for the proper functioning of AI systems and<br>respect the above principles, based on their roles, the context, and consistent<br>with the state of art.</i>"
          ],
          [
           "Accountability",
           " <i>Artificial Intelligence for Children: Beijing Principles</i>",
           " 2020",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Accountability",
           " <i>AI development policies and ethical norms to protect children's rights and<br>interests should be studied and formulated. Research on the potential impact of<br>AI on children should be strengthened, forward-looking codes of conduct, laws,<br>and regulations, technical specifications should be formulated, and long-term<br>follow-up studies and periodic assessment mechanisms should be established.<br>Stakeholders of AI should consciously and strictly abide by the code of conduct,<br>laws, regulations, and technical specifications related to children.</i>"
          ],
          [
           "Accountability",
           " <i>The Toronto Declaration</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " North America, Western Europe",
           " Canada, United Kingdom",
           " Accountability",
           " <i>States must ensure and require accountability and maximum possible transparency<br>around public sector use of machine learning systems. This must include<br>explainability and intelligibility in the use of these technologies so that the<br>impact on affected individuals and groups can be effectively scrutinized by<br>independent entities, responsibilities established, and actors held to account.<br>According to the UN Committee on Economic, Social and Cultural Rights, “States<br>parties must therefore adopt measures, which should include legislation, to<br>ensure that individuals and entities in the private sphere do not discriminate<br>on prohibited grounds”.</i>"
          ],
          [
           "Accountability",
           " <i>Position on Robotics and Artificial Intelligence</i>",
           " 2016",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Accountability",
           " <i>Humans, not robots, are responsible agents. Lawmakers should make sure that the<br>development and commercial use of emerging technologies comply with existing<br>laws and fundamental rights. The person with legal responsibility for a robot<br>should be attributed. Regarding safety and security, producers shall be held<br>responsible despite non-liability clauses in user agreements that may exist.</i>"
          ],
          [
           "Accountability",
           " <i>DataEthics: Principles and Guidelines for Companies, Authorities & Organisations</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " Northern Europe",
           " Denmark",
           " Accountability",
           " <i>Accountability is an organization’s reflective, reasonable and systematic use<br>and protection of personal data. Accountability is an integral part of all<br>aspects of data processing, and efforts are being made to reduce the risks for<br>the individual and mitigate social and ethical implications. Sustainable<br>personal data processing is embedded throughout the organization and ensures<br>ethical accountability in the short, medium, and long term. An organization’s<br>accountability should also apply to subcontractors’ and partners’ processing of<br>data.</i>"
          ],
          [
           "Accountability",
           " <i>Principles of Artificial Intelligence Ethics for the Intelligence Community</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Accountability",
           " <i>Our use of AI will fully comply with applicable legal authorities and with<br>policies and procedures that protect privacy, civil rights, and civil liberties.<br>We will develop and employ mechanisms to identify responsibilities and provide<br>accountability for the use of AI and its outcomes.</i>"
          ],
          [
           "Accountability",
           " <i>oston Dynamics Ethical Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Accountability",
           " <i>We support the establishment of laws and regulations that promote the safe and<br>responsible use of robots. We will use our leadership position in robotics to<br>help the public, lawmakers, government and commercial customers clearly<br>understand the capabilities and limitations of current robotic technology. We<br>will support and encourage a mix of stakeholders including academia, industry<br>associations, NGOs, and policymakers to debate and align on the benefits and<br>risks of this nascent technology. We will engage with lawmakers to promote<br>legislation around the safe use and deployment of robots.</i>"
          ],
          [
           "Accountability",
           " <i>Augmented Intelligence in Health Care H-480.940</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Professional Association",
           " North America",
           " United States of America",
           " Accountability",
           " <i>AMA will seek to explore the legal implications of health care AI, such as<br>issues of liability or intellectual property, and advocate for appropriate<br>professional and governmental oversight for safe, effective, and equitable use<br>of and access to health care AI.</i>"
          ],
          [
           "Accountability",
           " <i>WLiAI Report 2019: 10 Principles of Responsible AI</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " United Kingdom",
           " Accountability",
           " <i>Recommendation - Introduce a regulatory approach governing the deployment of AI<br>which mirrors that used for the pharmaceutical sector.</i>"
          ],
          [
           "Accountability",
           " <i>The Ethical Norms for the New Generation Artificial Intelligence, China</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Accountability",
           " <i>Various activities of AI shall abide by the following fundamental ethical norms,<br>like Adhere that human beings are the ultimately liable subjects. Clarify the<br>responsibilities of all relevant stakeholders, comprehensively enhance the<br>awareness of responsibility, introspection, and self-discipline in the entire<br>life cycle of AI. Establish an accountability mechanism in AI-related<br>activities, and do not evade liability reviews and do not escape from<br>responsibilities.</i>"
          ],
          [
           "Accountability",
           " <i>Work in the age of artificial intelligence: Four perspectives on the economy,<br>employment, skills and ethics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Finland",
           " Accountability",
           " <i>Responsibility means that decision-making based on artificial intelligence does<br>not pose a threat to anyone’s health or safety. This requirement applies to an<br>individual’s physical and psychological health as well as data protection and<br>protection of privacy. However, the point of departure in all cases is that<br>humans assume ultimate legal and moral responsibility for the decisions.</i>"
          ],
          [
           "Accountability",
           " <i>A Framework for Responsible Limits on Facial RecognitionUse Case: Flow<br>Management</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization",
           " Western Europe",
           " Switzerland",
           " Accountability",
           " <i>Organizations using facial recognition systems should ensure a culture of<br>accountability internally and across third-party service providers or business<br>partners. To this end, they should establish and publicly disclose the<br>governance principles that guide the design and use of their systems.</i>"
          ],
          [
           "Accountability",
           " <i>A Code of Ethics for the Human-Robot Interaction Profession</i>",
           " 2014",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Accountability",
           " <i>A robot’s decision paths must be re-constructible for the purposes of litigation<br>and dispute resolution. Human informed consent to HRI is to be facilitated to<br>the greatest extent possible consistent with reasonable design objectives</i>"
          ],
          [
           "Accountability",
           " <i>How to Prevent Discriminatory Outcomes in Machine Learning</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization",
           " Western Europe",
           " Switzerland",
           " Accountability",
           " <i>Leaders, designers, and developers of ML systems are responsible for identifying<br>the potential negative human rights impacts of their systems. They must make<br>visible avenues for redress for those affected by disparate impacts, and<br>establish processes for the timely redress of any discriminatory outputs.</i>"
          ],
          [
           "Accountability",
           " <i>The National Artificial Intelligence Research and Development Strategic Plan:<br>2019 Update</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Accountability",
           " <i>Understand and address the ethical, legal, and societal implications of AI.<br>Research AI systems that incorporate ethical, legal, and societal concerns<br>through technical mechanisms.</i>"
          ],
          [
           "Accountability",
           " <i>OECD, Recommendation of the Council on Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " France",
           " Accountability",
           " <i>AI actors should be accountable for the proper functioning of AI systems and for<br>the respect of the above principles, based on their roles, the context, and<br>consistent with the state of art.</i>"
          ],
          [
           "Accountability",
           " <i>OP Financial Group’s Ethical Guidelines for Artificial Intelligence</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Finland",
           " Accountability",
           " <i>We assign owners to the principles that guide our operations and the algorithms<br>we develop and ensure the ethics of artificial intelligence throughout its<br>lifecycle.</i>"
          ],
          [
           "Accountability",
           " <i>Oxford Munich Code of Conduct</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Accountability",
           " <i>The Data Scientist will always act following the law, developing a full<br>knowledge of, and ensuring compliance with, all relevant regulatory regimes.<br>Employers should take steps to raise their data scientists’ awareness and<br>knowledge of such issues. The Data Scientist shall behave as if she/he would be<br>liable for the accuracy and usage of her/his model. Moreover, a data scientist<br>shall write Terms and conditions for her/his work.</i>"
          ],
          [
           "Accountability",
           " <i>Partnership on AI Tenets</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization",
           " Unspecified",
           " Unspecified",
           " Accountability",
           " <i>We believe that AI research and development efforts need to be actively engaged<br>with and accountable to a broad range of stakeholders. We will engage with and<br>have representation from stakeholders in the business community to help ensure<br>that domain-specific concerns and opportunities are understood and addressed.</i>"
          ],
          [
           "Accountability",
           " <i>UNESCO Recommendation on the Ethics of Artificial Intelligence</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Accountability",
           " <i>Member States should ensure that it is always possible to attribute ethical and<br>legal responsibility for any stage of the life cycle of AI systems, as well as<br>in cases of remedy related to AI systems, to physical persons, or to existing<br>legal entities. Human oversight refers thus not only to individual human<br>oversight but to inclusive public oversight, as appropriate. The ethical<br>responsibility and liability for the decisions and actions based in any way on<br>an AI system should always ultimately be attributable to AI actors corresponding<br>to their role in the life cycle of the AI system.</i>"
          ],
          [
           "Accountability",
           " <i>AI Principles: Recommendations on the Ethical Use of Artificial Intelligence by<br>the Department of Defense - Defense Innovation Board</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Accountability",
           " <i>Human beings should exercise appropriate levels of judgment and remain<br>responsible for the development, deployment, use, and outcomes of DoD AI<br>systems.</i>"
          ],
          [
           "Accountability",
           " <i>Megvii's Artificial Intelligence Application Guidelines</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " China",
           " Accountability",
           " <i>AI solutions should be auditable and accountable. Errors, flaws, biases, or<br>other negative effects of AI solutions should be recognized immediately and<br>addressed aggressively as soon as they are discovered.</i>"
          ],
          [
           "Accountability",
           " <i>Policy guidance on AI for children</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution, International Organization",
           " Northern Europe, Intergovernmental Organization",
           " Finland, United Nations",
           " Accountability",
           " <i>Provide transparency, explainability, and accountability for children. I need to<br>know how AI impacts me. You need to be accountable for that.</i>"
          ],
          [
           "Accountability",
           " <i>Ethics & Governance of Artificial Intelligence for Health</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Accountability",
           " <i>Human warranty requires the application of regulatory principles upstream and<br>downstream of the algorithm by establishing points of human supervision. If<br>something goes wrong with AI technology, there should be accountability.<br>Appropriate mechanisms should be available for questioning and for redress for<br>individuals and groups that are adversely affected by decisions based on<br>algorithms.</i>"
          ],
          [
           "Accountability",
           " <i>HPE AI Ethics and Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Accountability",
           " <i>Be designed to enable responsible and accountable use, allow an understanding of<br>AI, and for outcomes to be challenged.</i>"
          ],
          [
           "Accountability",
           " <i>Thomson Reuters AI principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " Canada",
           " Accountability",
           " <i>Thomson Reuters will maintain appropriate accountability measures for our AI<br>products and services.</i>"
          ],
          [
           "Accountability",
           " <i>Defense Innovation Unit Responsible AI Guidelines in Practice: Lessons Learned<br>from the DIU Portfolio</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Accountability",
           " <i>DoD personnel will exercise appropriate levels of judgment and care while<br>remaining responsible for the development, deployment, and use of AI<br>capabilities.</i>"
          ],
          [
           "Accountability",
           " <i>DoD Ethical Principles for Artificial Intelligence</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Accountability",
           " <i>DoD personnel will exercise appropriate levels of judgment and care while<br>remaining responsible for the development, deployment, and use of AI<br>capabilities.</i>"
          ],
          [
           "Accountability",
           " <i>Alpha Principles for the Ethical Use of AI and Data Driven Technologies in<br>Ontario</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Accountability",
           " <i>Organizations and individuals developing, deploying, or operating AI systems<br>should be held accountable for their ongoing proper functioning in line with the<br>above principles. Algorithmic systems should be periodically peer-reviewed or<br>audited to ensure that unwanted biases have not inadvertently crept in overtime.<br>Where AI is used to make decisions about individuals there needs to be a process<br>for redress to better understand how a given decision was made.</i>"
          ],
          [
           "Accountability",
           " <i>Integrate’s AI principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " Canada",
           " Accountability",
           " <i>We are responsible for the products we design and their outputs. For a user of<br>our products to make responsible decisions within their organizations, we need<br>to understand how and why a prediction was made. This is one reason why our<br>models must be explainable. In other words, we can understand how and why a<br>prediction was made. So, transparency is essential. We build products that<br>complement and enhance your decision-making abilities. Not products that replace<br>them. At the end of the day, because we take responsibility for the things we<br>build, we’ll never create tools that can be misused or abused in any way.</i>"
          ],
          [
           "Accountability",
           " <i>National Association of Insurance Commissioners (NAIC) Principles on Artificial<br>Intelligence (AI)</i>",
           " 2020",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Accountability",
           " <i>AI actors should be accountable for ensuring that AI systems operate in<br>compliance with these principles consistent with the actors’ roles, within the<br>appropriate context and evolving technologies. Any AI system should be compliant<br>with legal requirements governing its use of data and algorithms during its<br>phase of the insurance life cycle. Data supporting the outcome of an AI<br>application should be retained and be able to be produced following applicable<br>insurance laws and regulations in each jurisdiction. AI actors should be<br>responsible for the creation, implementation, and impacts of any AI system, even<br>if the impacts are unintended.</i>"
          ],
          [
           "Accountability",
           " <i>Samsung Principles for AI Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " South Korea",
           " Accountability",
           " <i>The company will strive to apply the principles of social and ethical<br>responsibility to AI system.</i>"
          ],
          [
           "Accountability",
           " <i>Linux Foundation AI Principles</i>",
           " 2020",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Accountability",
           " <i>Accountability requires AI and the people behind the AI to explain, justify, and<br>take responsibility for any decision and action made by the AI. Mechanisms, such<br>as governance and tools, are necessary to achieve accountability.</i>"
          ],
          [
           "Accountability",
           " <i>Ethical Aspects of Autonomous and Intelligent Systems</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Accountability",
           " <i>A/IS should be designed and operated in a manner that permits production of an<br>unambiguous rationale for the decisions made by the system.</i>"
          ],
          [
           "Accountability",
           " <i>IEEE Position Statement - Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Accountability",
           " <i>To ensure that artificial intelligence serves the interests of society, IEEE<br>urges governments to adopt policies that create an appropriate mechanism to<br>determine how AI technology should be coordinated and regulated. This mechanism<br>can take different organizational forms, such as an intergovernmental task force<br>or a special commission. However constituted, the body should seek input from a<br>range of expert stakeholders, including academia, industry, civil society, and<br>government, as it considers questions related to the governance and safe<br>deployment of AI. It should consider societal implications; public engagement;<br>appropriate levels of public investment; economic and national security impacts;<br>transparency, accountability, and explainability; trust and safety assurance;<br>ethical principles; and legal and regulatory compliance.</i>"
          ],
          [
           "Accountability",
           " <i>Adobe’s Commitment to AI Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Accountability",
           " <i>We take ownership over the outcomes of our AI-assisted tools. We will have<br>processes and resources dedicated to receiving and responding to concerns about<br>our AI and taking corrective action as appropriate. Accountability also entails<br>testing for and anticipating potential harms, taking preemptive steps to<br>mitigate such harms, and maintaining systems to respond to unanticipated harmful<br>outcomes.</i>"
          ],
          [
           "Accountability",
           " <i>Artificial intelligence - Common good as a benchmark, good work as a principle</i>",
           " 2019",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Accountability",
           " <i>This requires clear accountability as well. Independent regulations of an<br>employee data protection law are just as necessary as the liability of companies<br>that sell or use artificial intelligence.</i>"
          ],
          [
           "Accountability",
           " <i>Algorithmic Decision-making for the Benefit of Consumers</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization",
           " Western Europe",
           " Germany",
           " Accountability",
           " <i>Operators of relevant ADM systems need to be held strictly liable for harm or<br>damage that occurs when a system has been used as intended by the consumer. When<br>the product liability directive will be updated, it must cover harm and damage<br>caused by ADM systems. The provisions in product liability legislation that<br>govern attribution and burden of proof have to be amended in order to take into<br>account that consumers can hardly prove an error or malfunctioning of complex,<br>intransparent ADM systems.</i>"
          ],
          [
           "Accountability",
           " <i>Draft - AI Utilization Principles</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Accountability",
           " <i>Users should make efforts to utilize AI systems or AI services in a proper scope<br>and manner, under the proper assignment of roles between humans and AI systems,<br>or among users. AI service providers and business users should make efforts to<br>fulfill their accountability to the stakeholders including consumer users and<br>indirect users.</i>"
          ],
          [
           "Accountability",
           " <i>The Code of Ethics in the Field of Artificial Intelligence</i>",
           " 2022",
           " Recommendation",
           " Unspecified",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Accountability",
           " <i>AI Actors must know and comply with the provisions of the legislation of the<br>Russian Federation in all areas of their activities and at all stages of<br>creation, integration, and use of AI technologies, i.e., in the sphere of legal<br>responsibility of AI Actors.</i>"
          ],
          [
           "Accountability",
           " <i>Shanghai Initiative for Safe and Secure AI Development</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Asia",
           " China",
           " Accountability",
           " <i>AI must be developed with a well-established security accountability framework.<br>A mechanism for ascertaining and sharing AI security responsibilities should be<br>established for different scenarios of AI application and in accordance with<br>laws and ethical norms.</i>"
          ],
          [
           "Accountability",
           " <i>Trustworthy AI in Aotearoa: AI Principles</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " Oceania",
           " New Zealand",
           " Accountability",
           " <i>Designers, developers, and users of AI systems (AI stakeholders) must respect<br>applicable laws in New Zealand and other relevant jurisdictions. Technologies<br>capable of harming individuals or groups should not be deployed until<br>stakeholders have determined appropriate accountability and liability.</i>"
          ],
          [
           "Accountability",
           " <i>Harmonious Artificial Intelligence Principles</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Accountability",
           " <i>AI needs to obey legal constraints for humans to be part of society. Humans are<br>responsible for continuous checking and verification of evolved AI to keep its<br>harmony with legal humans and legal AI. Legal Constraints on how humans should<br>interact with AI should be gradually set up for a harmonious Human-AI society<br>with a common destiny.</i>"
          ],
          [
           "Accountability",
           " <i>\"ARCC\": An Ethical Framework for Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " Eastern Asia",
           " China",
           " Accountability",
           " <i>Recommendation - To build trust in AI, we need a spectrum of rules, ethics is<br>just the beginning.</i>"
          ],
          [
           "Accountability",
           " <i>Human rights in the robot age: Challenges arising from the use of robotics,<br>artificial intelligence, and virtual and augmented reality</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Western Europe",
           " Netherlands",
           " Accountability",
           " <i>Recommendation - The Council of Europe could offer guidelines on how to<br>apportion liability with regard to robotics.</i>"
          ],
          [
           "Accountability",
           " <i>Technological convergence, artificial intelligence and human rights</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Accountability",
           " <i>Moreover, the Assembly proposes that guidelines be drawn upon the following<br>issues: strengthening transparency, regulation by public authorities, and<br>operators’ accountability concerning the fact that responsibility and<br>accountability of an act lie with the human being, no matter what the<br>circumstances may be. References to independent decision-making by artificial<br>intelligence systems cannot exempt the creators, owners, and managers of these<br>systems from accountability for human rights violations committed with the use<br>of these systems, even in cases where an act causing damage was not directly<br>ordered by a responsible human commander or operator.</i>"
          ],
          [
           "Accountability",
           " <i>Decree of the President of the Russian Federation on the Development of<br>Artificial Intelligence in the Russian Federation</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Accountability",
           " <i>To stimulate the development and use of artificial intelligence technologies,<br>the adaptation of statutory regulations relating to human interaction with<br>artificial intelligence is needed, together with the formulation of the<br>appropriate ethical standards. The primary directions of the creation of an<br>integrated system for regulating the social relations arising in line with the<br>development and introduction of artificial intelligence technologies shall<br>consist of: creating legal conditions and establishing procedures for the<br>simplified testing and introduction of technological solutions developed based<br>on artificial intelligence; creating unified systems for the standardization and<br>assessment of the compliance of technological solutions developed based on<br>artificial intelligence; formulating ethical rules for human interaction with<br>artificial intelligence.</i>"
          ],
          [
           "Accountability",
           " <i>Allen Institute for Artificial Intelligence Core Values</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Academic, Non-profit Organization",
           " North America",
           " United States of America",
           " Accountability",
           " <i>We take an efficient, results-oriented approach to our work. We define<br>ambitious, timely goals and continually measure our success against them.</i>"
          ]
         ],
         "hovertemplate": "<b>Document ID </b>=%{customdata[1]}<br><b>Year of Publication </b>=%{customdata[2]}<br><b>Reguation Type </b>=%{customdata[3]}<br><b>Institution Type </b>=%{customdata[4]}<br><b>World Region </b>=%{customdata[5]}<br><b>Country </b>=%{customdata[6]}<br><b>Principle </b>=%{customdata[7]}<br><b>Description </b>=%{customdata[8]}<extra></extra>",
         "legendgroup": "Accountability",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Accountability",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          -11.365994,
          -16.035093,
          -4.9840646,
          -14.2024975,
          -8.638193,
          -6.435278,
          4.9048715,
          -6.9516673,
          -28.446327,
          -10.45774,
          -1.4468914,
          -1.0730305,
          0.3910616,
          25.7528,
          -13.064998,
          -10.727676,
          -0.76969033,
          -6.489527,
          -12.48674,
          -7.61454,
          -9.274037,
          -11.011604,
          -2.98818,
          -12.55591,
          -19.095545,
          -15.184685,
          16.233496,
          2.7072723,
          -8.69285,
          -14.981939,
          19.431013,
          -2.4613879,
          -5.5118003,
          -4.013136,
          14.124516,
          -7.17159,
          -0.01723709,
          25.305496,
          -20.181087,
          2.185097,
          -8.001477,
          -14.609129,
          8.55227,
          -8.113499,
          -21.709614,
          -9.81269,
          -16.347483,
          -14.906743,
          -10.421294,
          -13.052605,
          -1.3662531,
          -7.1563797,
          -11.43003,
          -12.106809,
          -4.085763,
          -15.313211,
          -5.2387743,
          -8.13379,
          -10.654381,
          -12.21454,
          3.4897597,
          -15.684748,
          -10.438777,
          -25.68453,
          -6.9577136,
          -18.080717,
          7.2060494,
          -7.8115916,
          -10.841512,
          -17.519678,
          -12.976081,
          0.5052796,
          -0.89815265,
          3.1341257,
          -7.7181926,
          -1.6351895,
          1.1013757,
          3.829702,
          -10.434562,
          -20.364025,
          -2.5747182,
          -2.6328425,
          -13.90987,
          -13.175039,
          -11.179962,
          -10.36143,
          -4.0926075,
          1.8645548,
          -8.705658,
          -12.796706,
          -17.541897,
          -4.3295074,
          -7.347776,
          -3.3093674,
          8.021597,
          0.5640592,
          -15.827894,
          3.6738224,
          -12.102066,
          -0.010545302,
          0.56739134,
          -5.200339,
          -1.6805178,
          -4.258076,
          5.4913807,
          -8.843315,
          -15.004288,
          -15.655546,
          -17.367271,
          -9.080824,
          -6.265942,
          -2.627206,
          -14.402118,
          -15.503517,
          -9.011187,
          -13.843945,
          -7.6921244,
          0.26567316,
          -12.3335495,
          -25.379908,
          7.145667,
          -11.407873,
          -18.792624,
          -21.962523,
          -8.042974,
          -3.7292242,
          -12.204684,
          5.509623,
          -5.598678,
          9.51039,
          3.5301597,
          -14.493784,
          3.9263296,
          5.1932497
         ],
         "y": [
          -4.5814238,
          14.857872,
          -7.6954556,
          -8.57716,
          -12.888814,
          -5.27402,
          16.820751,
          13.948404,
          -2.184862,
          -8.186008,
          -13.10514,
          -6.4564476,
          -10.077053,
          3.8600862,
          -6.983453,
          -11.150933,
          -7.3621035,
          -8.706771,
          -14.401872,
          -7.770194,
          -6.850659,
          -11.946104,
          3.9910266,
          -11.544699,
          -6.645032,
          15.7829275,
          1.3735319,
          -4.123123,
          -9.523124,
          -16.15867,
          6.1278996,
          -9.751001,
          -2.5522225,
          -9.413469,
          -17.709972,
          -11.361184,
          -10.0455885,
          13.085833,
          -9.949265,
          -6.9618974,
          -16.255962,
          -11.263403,
          3.2749288,
          -16.802776,
          0.17410852,
          -10.042118,
          14.696758,
          -1.9100614,
          -13.8360615,
          -11.32296,
          -10.166881,
          -9.354022,
          17.882147,
          -10.982461,
          -12.860097,
          20.296736,
          -6.4549046,
          -6.8897033,
          -11.211456,
          5.537617,
          -8.947325,
          14.540972,
          -12.350441,
          2.1358817,
          -16.982378,
          -8.167879,
          -7.9622827,
          -10.360802,
          -7.6548495,
          5.2835293,
          8.616543,
          1.4745343,
          4.1293945,
          -6.020826,
          -24.590448,
          4.9369216,
          1.6733813,
          -7.2997303,
          -24.721594,
          -3.0922332,
          -9.078497,
          -8.73943,
          -4.941773,
          -1.7784376,
          4.2898483,
          -15.462901,
          -3.283502,
          4.7727585,
          5.4476852,
          -2.4473155,
          13.940522,
          3.4955218,
          -8.050323,
          -27.843618,
          -5.843556,
          -5.362546,
          3.95163,
          14.234077,
          1.6628706,
          6.50568,
          -11.062533,
          -4.0364375,
          -15.851957,
          21.256113,
          -16.30259,
          -6.4257545,
          -14.8019,
          -7.9499207,
          -10.289574,
          -3.0722501,
          -11.300839,
          -20.28957,
          -16.773207,
          -16.690186,
          -5.0352974,
          -1.4447595,
          -3.6600106,
          -15.194412,
          -8.9658985,
          -7.774647,
          -7.4478,
          -8.70028,
          9.599613,
          -6.970633,
          -0.23915963,
          -2.6097689,
          -5.253077,
          0.21843745,
          -1.9034728,
          -9.678316,
          -4.639772,
          4.579946,
          -6.6843805,
          -19.00231
         ],
         "z": [
          -5.6573195,
          -5.9935875,
          -1.5944744,
          -6.7146645,
          -5.494922,
          -2.5850544,
          17.839329,
          -2.8169222,
          -5.805336,
          -5.140036,
          1.6079979,
          -3.3275726,
          6.291974,
          -9.033223,
          -5.131968,
          2.8491924,
          -0.9007813,
          -15.988793,
          -6.72363,
          -2.869575,
          -2.4106278,
          -0.39060584,
          -18.37018,
          -6.4106593,
          -5.686686,
          -18.462648,
          -21.02562,
          30.557701,
          -3.659065,
          -2.5988672,
          9.357578,
          2.0020869,
          1.1821806,
          -3.8298063,
          -12.658721,
          -3.0685203,
          -3.6329923,
          6.374168,
          -6.2075357,
          -2.8752956,
          10.373423,
          -5.3454123,
          -25.547771,
          -6.9302545,
          -7.996392,
          -6.5317435,
          -9.687628,
          18.645206,
          -2.197299,
          -1.8061043,
          -0.85711706,
          -5.316961,
          -10.009362,
          -8.116316,
          -6.514772,
          -7.8120646,
          -4.673335,
          -6.0111732,
          -3.5379066,
          -15.140057,
          -12.42313,
          -11.383688,
          -8.503046,
          6.0995555,
          -6.9394493,
          -7.943442,
          -9.251898,
          1.3184772,
          -8.135945,
          -15.270231,
          11.668173,
          -3.0828817,
          -0.34512502,
          25.233776,
          -6.7439895,
          -22.291094,
          -19.019129,
          -10.628834,
          -7.9127693,
          13.265065,
          -6.1932592,
          -0.048173126,
          17.972385,
          16.603088,
          12.113526,
          -2.8976262,
          1.4388198,
          25.614698,
          -13.302249,
          18.63114,
          -7.9865847,
          -3.0117662,
          21.8162,
          1.0915521,
          -11.847067,
          1.0997773,
          11.393033,
          -7.7683754,
          22.588964,
          -7.598955,
          -1.684564,
          0.5196061,
          -3.061122,
          -15.7188,
          -1.8782094,
          1.3923833,
          1.6585699,
          -2.746978,
          -13.035677,
          -3.3811288,
          -9.103953,
          -11.757934,
          1.6044611,
          1.0059818,
          -4.0305624,
          -22.157808,
          0.19090462,
          -2.5762525,
          -4.063912,
          -0.8878507,
          -7.0188212,
          -1.683574,
          -9.366001,
          -8.1079645,
          0.21312957,
          4.4936523,
          -2.1615198,
          4.59929,
          7.299487,
          -14.430555,
          26.804268,
          15.894622,
          -6.13715,
          -8.093331
         ]
        },
        {
         "customdata": [
          [
           "Autonomy",
           " <i>Declaration on Ethics and Data Protection in Artifical Intelligence</i>",
           " 2018",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " Belgium",
           " Autonomy",
           " <i>empowerment of every individual should be promoted, and the exercise of<br>individuals’ rights should be encouraged, as well as the creation of<br>opportunities for public engagement, recognizing that the right to object or<br>appeal applies to technologies that influence personal development or opinions<br>and guaranteeing, where applicable, individuals’ right not to be subject to a<br>decision based solely on automated processing if it significantly affects them<br>and, where not applicable, guaranteeing individuals’ right to challenge such<br>decision.</i>"
          ],
          [
           "Autonomy",
           " <i>Artificial Intelligence and Machine Learning: Policy Paper</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>Any autonomous system must allow for a human to interrupt an activity or shut<br>down the system (an “off-switch”). There may also be a need to incorporate human<br>checks on new decision-making strategies in AI system design, especially where<br>the risk to human life and safety is great.</i>"
          ],
          [
           "Autonomy",
           " <i>Responsible AI: A Global Policy Framework</i>",
           " 2021",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization, Professional Association",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>Organisations that develop make available, or use AI systems that surveil human<br>behavior shall put in place appropriate safeguards to promote the right to be<br>let alone (the right not to be subject to arbitrary interference with on” IoT<br>devices (such as personal assistants and smart home devices) shall, to the<br>greatest extent possible, securely store such data, in an encrypted format, only<br>locally on the device in a manner that allows for the maximal level of autonomy<br>and control over the data by the individual(s) to whom it relates.</i>"
          ],
          [
           "Autonomy",
           " <i>Hambach Declaration on Artificial Intelligence(Hambacher Erklärung zur<br>Künstlichen Intelligenz)</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Germany",
           " Autonomy",
           " <i>Only if the protection of fundamental rights and data protection keep pace with<br>the process of digitalization is a future possible in which people, and not<br>machines, ultimately make decisions about people. Data subjects also have the<br>right to the intervention of a person (intervenability), to the presentation of<br>their point of view and to challenge a decision when AI systems are used.</i>"
          ],
          [
           "Autonomy",
           " <i>KI Seal of Approval</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Autonomy",
           " <i>In human-machine interactions, humans always can intervene or always can stop or<br>interrupt a system.</i>"
          ],
          [
           "Autonomy",
           " <i>AI at Google: our principles</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>We will design AI systems that provide appropriate opportunities for feedback,<br>relevant explanations, and appeal. Our AI technologies will be subject to<br>appropriate human direction and control.</i>"
          ],
          [
           "Autonomy",
           " <i>Directive on Automated Decision-Making</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Autonomy",
           " <i>The Assistant Deputy Minister responsible for the program using the Automated<br>Decision System, or any other person named by the Deputy Head, is responsible<br>for: Ensuring that an Automated Decision System allows for human intervention,<br>when appropriate.</i>"
          ],
          [
           "Autonomy",
           " <i>10 ethical guidelines for the digitalisation of companies (10 ethische<br>Leitlinien für die Digitalisierung von Unternehmen)</i>",
           " 2017",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Autonomy",
           " <i>To prevent automated decisions from paternalistic effects occurring, which<br>restrict the freedom of action of humans, there is a need for constant system<br>control and the possibility to intervene in the system.</i>"
          ],
          [
           "Autonomy",
           " <i>Ethics Guidelines for Trustworthy AI</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Autonomy",
           " <i>Freedom of the individual. Human beings should remain free to make life<br>decisions for themselves. AI systems should serve to maintain and foster<br>democratic processes and respect the plurality of values and life choices of<br>individuals. AI systems should not unjustifiably subordinate, coerce, deceive,<br>manipulate, condition, or herd humans. Instead, they should be designed to<br>augment, complement and empower human cognitive, social, and cultural skills.</i>"
          ],
          [
           "Autonomy",
           " <i>Declaration of Ethical Principles for AI in Latin America (Declaración de<br>Principios Éticos para la IA de Latinoamérica)</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Latin America",
           " Unspecified",
           " Autonomy",
           " <i>Ensure the development of an AI at the service of individuals and society.<br>Developed AI technology must obey its creators, as long as they do not conflict<br>with human autonomy, the individual good, and the common good.</i>"
          ],
          [
           "Autonomy",
           " <i>Mid- to Long-Term Master Plan in Preparation for the Intelligent Information<br>Society Managing the Fourth Industrial Revolution</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " South Korea",
           " Autonomy",
           " <i>It may be necessary to establish a systemic process through which people may<br>raise formal objections to the evaluations made by AI systems and have AI-based<br>decisions reviewed and tested.</i>"
          ],
          [
           "Autonomy",
           " <i>Charlevoix Common Vision for the Future of Artificial Intelligence</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " International Organization",
           " Intergovernmental Organization",
           " G7",
           " Autonomy",
           " <i>We, the leaders of the G7, commit to fostering initiatives that promote safety<br>and transparency and guide human intervention in AI decision-making processes.</i>"
          ],
          [
           "Autonomy",
           " <i>Governance Recommendations - Use of Artificial Intelligence by Public<br>Authorities</i>",
           " 2021",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Latin America",
           " Brazil",
           " Autonomy",
           " <i>This constraint is a challenge to ensure safeguards on the obligation for human<br>revision in automated decisions, because if interpreted in an extremely<br>restrictive way, it may impair the fundamental right of individuals to control<br>how their data are used and the impacts they may have in their lives.</i>"
          ],
          [
           "Autonomy",
           " <i>Facial recognition: It’s time for action</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>We will encourage and help our customers to deploy facial recognition technology<br>in a manner that ensures an appropriate level of human control for uses that may<br>affect people in consequential ways. We will advocate for safeguards for<br>people’s democratic freedoms in law enforcement surveillance scenarios, and will<br>not deploy facial recognition technology in scenarios that we believe will put<br>these freedoms at risk.</i>"
          ],
          [
           "Autonomy",
           " <i>Toward a G20 Framework for Artificial Intelligence in the Workplace</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " Canada",
           " Autonomy",
           " <i>Employees and contractors should be fully informed when either internal or<br>external data (or both) has been used in a decision affecting their career. Any<br>data processing of present or prospective employees’ or contractors’ data should<br>be transparent and the PII (personally identifiable information) available for<br>their review. The right to understand and appeal against both the rationale<br>employed and the data used to achieve that rationale is essential to safeguard<br>present or prospective workers against poor or inaccurate input data or<br>discriminative decisions. Human control of AI should be mandatory and testable<br>by regulators.</i>"
          ],
          [
           "Autonomy",
           " <i>The Future Computed – Artificial intelligence and its role in society</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>AI system should seek human input during critical situations, and how a system<br>controlled by AI should transfer control to a human in a manner that is<br>meaningful and intelligible.</i>"
          ],
          [
           "Autonomy",
           " <i>How Can Humans Keep The Upper Hand? The Ethical Matters Raised By Algorithms And<br>Artificial Intelligence</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Autonomy",
           " <i>Improve the design of algorithmic systems in the interests of human freedom. We<br>need to be promoting a design conducive to empowering individuals with more<br>autonomy and scope to think; a design to righting the imbalance that algorithms<br>can create to our detriment; overall a design that enables us to make clear and<br>informed decisions.</i>"
          ],
          [
           "Autonomy",
           " <i>Statement on Algorithmic Transparency and Accountability</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>Regulators should encourage the adoption of mechanisms that enable questioning<br>and redress for individuals and groups that are adversely affected by<br>algorithmically informed decisions.</i>"
          ],
          [
           "Autonomy",
           " <i>For a meaningful Artificial Intelligence - Towards a French and European<br>strategy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Autonomy",
           " <i>The protection of our rights and freedoms needs to be adapted to accommodate the<br>potential for abuse involved in the use of machine learning systems.</i>"
          ],
          [
           "Autonomy",
           " <i>Principles to Promote Fairness, Ethics, Accountability and Transparency (FEAT)<br>in the Use of Artificial Intelligence and Data Analytics in Singapore’s<br>Financial Sector</i>",
           " 2018",
           " Recommendation",
           " Governmental Institution",
           " Southeast Asia",
           " Singapore",
           " Autonomy",
           " <i>Data subjects should be provided with channels to enquire about, submit appeals<br>for, and request reviews of AIDA-driven decisions that affect them.</i>"
          ],
          [
           "Autonomy",
           " <i>Facebook and Google: This is What an Effective Ad Archive API Looks Like</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>In the spirit of upholding the EU Code of Practice on Disinformation, we expect<br>you to empower the research community by implementing open, functional APIs of<br>the quality outlined in this letter — just as we expect elected officials and<br>public authorities to fully support the release of such data in a privacy-<br>compliant fashion to enable independent research and inform public debate. Your<br>action on this is essential to ensuring the integrity of the upcoming European<br>Parliamentary elections — as well as elections happening all around the globe —<br>is upheld.</i>"
          ],
          [
           "Autonomy",
           " <i>Code of Practice on Disinformation</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " International Organization",
           " European Union",
           " European Union",
           " Autonomy",
           " <i>The Signatories of this Code commit to investing in products, technologies, and<br>programs to help people make informed decisions when they encounter online news<br>that may be false, including by supporting efforts to develop and implement<br>effective indicators of trustworthiness in collaboration with the news<br>ecosystem.</i>"
          ],
          [
           "Autonomy",
           " <i>It’s Time to Do Something: Mitigating the Negative Impacts of Computing Through<br>a Change to the Peer Review Process</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " Eastern Asia, Central Europe",
           " Turkey, Turkey",
           " Autonomy",
           " <i>Papers that advance generative models would be required to discuss the<br>potentially deleterious effects to democratic discourse.</i>"
          ],
          [
           "Autonomy",
           " <i>Digital Technology and Healthcare which ethical issues for which regulations?</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " France",
           " Autonomy",
           " <i>Concerning the next Bioethics Act, the fundamental principle of a Human Warranty<br>of digital technology in healthcare should be entrenched in law.</i>"
          ],
          [
           "Autonomy",
           " <i>Big Data, Artificial Intelligence, Machine Learning, and Data Protection</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Autonomy",
           " <i>If an organisation can identify potential benefits from using personal data in<br>big data analytics, it should be able to explain these to users and seek<br>consent, if that is the condition it chooses to rely on. Where possible, the<br>controller should be able to provide remote access to a secure system which<br>would provide the data subject with direct access to his or her personal data.</i>"
          ],
          [
           "Autonomy",
           " <i>Ethical, Social, and Political Challenges of Artificial Intelligence in Health</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " United Kingdom",
           " Autonomy",
           " <i>The issue of consent runs through the entirety of this work. This is<br>unsurprising given the crucial importance the concept of consent has in<br>biomedical ethics and its interaction with the central principle of personal<br>autonomy.</i>"
          ],
          [
           "Autonomy",
           " <i>Asilomar AI Principles</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>The application of AI to personal data must not unreasonably curtail people’s<br>real or perceived liberty. Humans should choose how and whether to delegate<br>decisions to AI systems, to accomplish human-chosen objectives. The power<br>conferred by control of highly advanced AI systems should respect and improve,<br>rather than subvert, the social and civic processes on which the health of<br>society depends.</i>"
          ],
          [
           "Autonomy",
           " <i>G20 Ministerial Statement on Trade and Digital Economy</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " G20",
           " Autonomy",
           " <i>AI actors should respect democratic values. AI actors should implement<br>mechanisms and safeguards, such as the capacity for human determination.</i>"
          ],
          [
           "Autonomy",
           " <i>Philips AI Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Netherlands",
           " Autonomy",
           " <i>We design AI-enabled solutions to augment and empower people, with appropriate<br>human supervision.</i>"
          ],
          [
           "Autonomy",
           " <i>AI 4People 's Ethical Framework for a Good AI Society: Opportunities, Risks,<br>Principles, and Recommendations</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Autonomy",
           " <i>autonomous systems must not impair [the] freedom of human beings to set their<br>own standards and norms and be able to live according to them. Humans should<br>choose how and whether to delegate decisions to AI systems, to accomplish human-<br>chosen objectives.</i>"
          ],
          [
           "Autonomy",
           " <i>Rome Call for AI Ethics</i>",
           " 2020",
           " Recommendation",
           " Religious Institution",
           " Southern Europe",
           " Vatican City State",
           " Autonomy",
           " <i>All human beings are born free and equal in dignity and rights. This fundamental<br>condition of freedom and dignity must also be protected and guaranteed when<br>producing and using AI systems.</i>"
          ],
          [
           "Autonomy",
           " <i>Ethical Guidelines of the German Informatics Society</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization, Professional Association",
           " Western Europe",
           " Germany",
           " Autonomy",
           " <i>GI members work toward ensuring that those people impacted by the usage and<br>conditions of use of IT systems are granted adequate opportunity to participate<br>in the design of these systems. This is especially pertinent with regard to<br>systems whose application involves the exerting influence over, monitoring, or<br>surveillance of said populations.</i>"
          ],
          [
           "Autonomy",
           " <i>Ethically Aligned Design: A Vision for Prioritizing Human Well-being with<br>Autonomous and Intelligent Systems, Version 2</i>",
           " 2017",
           " Recommendation",
           " Professional Association",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>For the foreseeable future, A/IS should not be granted rights and privileges<br>equal to human rights: A/IS should always be subordinate to human judgment and<br>control.</i>"
          ],
          [
           "Autonomy",
           " <i>The Ethics of Code: Developing AI for Business with Five Core Principles</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Autonomy",
           " <i>AI will replace, but it must also create. The best use case for AI is<br>automation, being very good at repetitive, mundane tasks, and in the long term,<br>is cheaper than humans. There will be new opportunities created by the<br>automation of tasks, and we need to train humans for these prospects—allowing<br>people to focus on what they are good at, building relationships, and caring for<br>customers. Never forgetting the need for human empathy in core professions like<br>law enforcement, nursing, caring, and complex decision-making.</i>"
          ],
          [
           "Autonomy",
           " <i>Artificial intelligence and Privacy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Norway",
           " Autonomy",
           " <i>When automated decisions are applied, measures must be implemented to protect<br>the data subject’s rights, freedoms, and rightful interests. The data subject<br>must be able to demand that a human being takes the final decision, and she must<br>have the right of appeal.</i>"
          ],
          [
           "Autonomy",
           " <i>Digital Ethics Guidelines on AI</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Autonomy",
           " <i>We act in tune with our company values. Our systems and solutions must be<br>subordinate to human-defined rules and laws. Therefore, in addition to our<br>technical requirements, our systems and solutions have to obey the rules and<br>laws that we as Deutsche Telekom, our employees – and human beings as such –<br>follow.</i>"
          ],
          [
           "Autonomy",
           " <i>Artificial intelligence and the work of tomorrow (Künstliche Intelligenz und die<br>Arbeit von Morgen)</i>",
           " 2019",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Autonomy",
           " <i>Employees and their interest groups must be involved in defining the objectives<br>and goals of AI systems that influence working conditions and employment<br>prospects as well as training and continuing education options. The same also<br>applies to the development, implementation, realization, and evaluation, in<br>which the dynamics of change of the learning systems, in particular, must be<br>taken into account. The guiding goal here must be that the machine supports the<br>human being. The final decision-making right must always lie with the<br>individual. In addition, the consequences for employees under labor law, which<br>could theoretically result from \"digital management\" or monitoring, must be<br>ruled out.</i>"
          ],
          [
           "Autonomy",
           " <i>AI Ethics Principles & Guidelines</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Middle East",
           " United Arab Emirates",
           " Autonomy",
           " <i>AI systems should have built-in appeals procedures whereby users can challenge<br>significant decisions. AGI and superintelligence, if developed, should serve<br>humanity as a whole. Humanity should retain the power to govern itself and make<br>the final decision, with AI in an assisting role.</i>"
          ],
          [
           "Autonomy",
           " <i>Data for the Benefit of the People: Recommendations from the Danish Expert Group<br>on Data Ethics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Denmark",
           " Autonomy",
           " <i>People's self-determination must be prioritized in all data processes. It is the<br>person who should have the ultimate control over what their data is used for and<br>in which contexts.</i>"
          ],
          [
           "Autonomy",
           " <i>Algo.Rules: Rules for the Design of Algorithmic Systems</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Private Corporation",
           " Western Europe",
           " Germany",
           " Autonomy",
           " <i>Those affected algorithmic systems must be able to request appropriate and<br>detailed information regarding a specific decision and the considerations that<br>have fed into it. If an algorithmic system results in a questionable decision or<br>a decision that affects an individual’s rights, it must be possible to request<br>an explanation and file a complaint.</i>"
          ],
          [
           "Autonomy",
           " <i>Beijing AI Principles</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Eastern Asia",
           " China",
           " Autonomy",
           " <i>Human privacy, dignity, freedom, autonomy, and rights should be sufficiently<br>respected.</i>"
          ],
          [
           "Autonomy",
           " <i>Artificial Intelligence: opportunities, risks and recommendations for the<br>financial sector</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Luxembourg",
           " Autonomy",
           " <i>Institutions should carefully review the integration of AI/ML into the business<br>process and establish controls performed by humans whenever there is a critical<br>decision step. Humans should be able to receive appropriate information to make<br>informed decisions. This analysis should also consider the need for<br>accountability, which cannot be delegated to a machine.</i>"
          ],
          [
           "Autonomy",
           " <i>Data protection and Big Data (Datenschutz und Big Data)</i>",
           " 2017",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Autonomy",
           " <i>The user must have the possibility to revoke a declared consent at any time. In<br>this case, you must immediately delete or block the personal data collected. If<br>stored personal data proves to be incorrect or incomplete, you must correct it<br>immediately following Section 35 (1) BDSG. You must also delete personal data<br>immediately if the collection or processing was not permissible, the processing<br>or use proves to be impermissible due to circumstances that have subsequently<br>arisen, or knowledge of the data is no longer necessary for the responsible<br>body.</i>"
          ],
          [
           "Autonomy",
           " <i>Responsible Artificial Intelligence in the Government of Canada (whitepaper)</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Autonomy",
           " <i>People should always be governed – and perceived to be governed – by people.</i>"
          ],
          [
           "Autonomy",
           " <i>People + AI Guidebook</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>When building your AI-powered feature or product, feedback and user control are<br>critical to developing communication and trust between your user and the system,<br>and for developing a product that fulfills your users’ needs consistently over<br>time.</i>"
          ],
          [
           "Autonomy",
           " <i>Artificial Intelligence at Google: Our Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>We believe that AI should be accountable to people. We will design AI systems<br>that provide appropriate opportunities for feedback, relevant explanations, and<br>appeal. Our AI technologies will be subject to appropriate human direction and<br>control.</i>"
          ],
          [
           "Autonomy",
           " <i>Artificial Intelligence: Australia’s Ethics Framework - A Discussion Paper</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Oceania",
           " Australia",
           " Autonomy",
           " <i>When an algorithm impacts a person there must be an efficient process to allow<br>that person to challenge the use or output of the algorithm.</i>"
          ],
          [
           "Autonomy",
           " <i>Universal Guidelines for Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Belgium",
           " Autonomy",
           " <i>All individuals have the right to a final determination made by a person. An<br>institution that has established an AI system has an affirmative obligation to<br>terminate the system if human control of the system is no longer possible.</i>"
          ],
          [
           "Autonomy",
           " <i>Principles for the safe and effective use of data and analytics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Oceania",
           " New Zealand",
           " Autonomy",
           " <i>Analytical processes are a tool to inform human decision-making and should never<br>entirely replace human oversight. Ensure significant decisions based on data<br>involve human judgment and evaluation, and that automated decision-making<br>processes are regularly reviewed to make sure they’re still fit for purpose.</i>"
          ],
          [
           "Autonomy",
           " <i>Recommendations for the responsible use of AI and automated decision-making -<br>Corporate Digital Responsibility and Decision Making (Empfehlungen für den<br>verantwortlichen Einsatz von KI und automatisierten Entscheidungen - Corporate<br>Digital Responsibility and Decision Making)</i>",
           " 2018",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Autonomy",
           " <i>Particularly responsible decision-making processes must be designed in such a<br>way that the ultimate decision-making authority remains with the human being<br>until the quality of control reaches a level accepted by all stakeholders.</i>"
          ],
          [
           "Autonomy",
           " <i>Code of Ethics for Data-Based Value Creation</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Switzerland",
           " Autonomy",
           " <i>You should enable individuals and communities to act in a self-determined<br>manner.</i>"
          ],
          [
           "Autonomy",
           " <i>Guidelines for the responsible use of artificial intelligence and other digital<br>technologies in human resources work</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Autonomy",
           " <i>Those who use AI solutions must ensure that the power of people to make<br>important personnel decisions is not restricted. Before or when using an AI<br>solution, the people affected by it must be informed about its use, its purpose,<br>its logic, the data collected, and the types of data used. No data may be<br>collected and used for use in AI solutions that are fundamentally beyond the<br>willful control of those affected.</i>"
          ],
          [
           "Autonomy",
           " <i>Automated and connected automated driving (Automatisiertes und Vernetztes<br>Fahren)</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Germany",
           " Autonomy",
           " <i>The autonomous decision of the individual is an expression of a society in which<br>the individual person with his or her claim to development and his or her need<br>for protection is at the center. Every state and political decision, therefore,<br>serves the free development and protection of the individual.</i>"
          ],
          [
           "Autonomy",
           " <i>Telia Company Guiding Principles on trusted AI ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Sweden",
           " Autonomy",
           " <i>We monitor AI solutions so that we are continuously ready to intervene into AI,<br>datasets, and algorithms, to identify needs for improvements and to prevent<br>and/or reduce damage.</i>"
          ],
          [
           "Autonomy",
           " <i>European ethical Charter on the use of Artificial Intelligence in judicial<br>systems and their environment</i>",
           " 2018",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Autonomy",
           " <i>preclude a prescriptive approach and ensure that users are informed actors and<br>in control of the choices made.</i>"
          ],
          [
           "Autonomy",
           " <i>AI Now Report 2018</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>Communities should have the right to reject the application of these<br>technologies in both public and private contexts. Mere public notice of their<br>use is not sufficient, and there should be a high threshold for any consent,<br>given the dangers of oppressive and continual mass surveillance.</i>"
          ],
          [
           "Autonomy",
           " <i>Report on Artificial Intelligence and Human Society</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Autonomy",
           " <i>A significant action is to consider the balance between human decisions and AI-<br>based decisions depending on the situations and objects to be judged. The<br>balance change causes the emergence of a new sense of ethics. If users confirm<br>AI services that enable them to manipulate someone's mind and/or to evaluate<br>people, discussions of ethics might especially be needed.</i>"
          ],
          [
           "Autonomy",
           " <i>Understanding artificial intelligence ethics and safety: A guide for the<br>responsible design and implementation of AI systems in the public sector</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Western Europe",
           " United Kingdom",
           " Autonomy",
           " <i>Respect the dignity of individual persons (i.e., ensure their abilities to make<br>free and informed decisions about their own lives).</i>"
          ],
          [
           "Autonomy",
           " <i>Safety First for Automated Driving – Proposed technical standards for the<br>development of Automated Driving</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Autonomy",
           " <i>Engaging and disengaging the automated driving system shall require an explicit<br>interaction from the vehicle operator, indicating high confidence of intent.</i>"
          ],
          [
           "Autonomy",
           " <i>Opinion of the Data Ethics Commission</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Autonomy",
           " <i>Acknowledging human dignity involves recognizing that humans must always be<br>“superior to technology”, i.e. that they must not be completely or irrevocably<br>subordinated to technical systems. The opportunities for configuration and<br>intervention may be localized at different levels in each specific application,<br>but the principle of human sovereignty of action must be upheld. Humans hold<br>responsibility in human/machine interactions, and must not be regarded as<br>defective beings that need to be optimized or perfected by the machine.</i>"
          ],
          [
           "Autonomy",
           " <i>Artificial Intelligence and Data Protection</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Autonomy",
           " <i>In line with the guidance on a risk assessment provided in the Guidelines on Big<br>Data, adopted by the Committee of Convention 108 in 2017, a wider view of the<br>possible outcomes of data processing should be adopted. This view should<br>consider not only human rights and fundamental freedoms but also the functioning<br>of democracies and social and ethical values. AI applications should allow<br>meaningful control by data subjects over the data processing and related effects<br>on individuals and society.</i>"
          ],
          [
           "Autonomy",
           " <i>Statement on Artificial Intelligence, Robotics and 'Autonomous‘ Systems</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Autonomy",
           " <i>The principle of autonomy implies the freedom of the human being. This<br>translates into human responsibility and thus control over and knowledge about<br>‘autonomous’ systems as they must not impair the freedom of human beings to set<br>their own standards and norms and be able to live according to them. All<br>‘autonomous’ technologies must, hence, honor the human ability to choose<br>whether, when, and how to delegate decisions and actions to them.</i>"
          ],
          [
           "Autonomy",
           " <i>Report with recommendations to the Commission on Civil Law Rules on Robotics</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " European Union",
           " European Union",
           " Autonomy",
           " <i>The European Parliament stresses that the development of robot technology should<br>focus on complementing human capabilities and not on replacing them. The<br>European Parliament considers it essential, in the development of robotics and<br>AI, to guarantee that humans have control over intelligent machines at all<br>times.</i>"
          ],
          [
           "Autonomy",
           " <i>Vienna Manifesto on Digital Humanism</i>",
           " 2019",
           " Recommendation",
           " Academic",
           " Central Europe",
           " Austria",
           " Autonomy",
           " <i>Decisions with consequences that have the potential to affect individual or<br>collective human rights must continue to be made by humans. Decision-makers must<br>be responsible and accountable for their decisions. Automated decision-making<br>systems should only support human decision-making, not replace it.</i>"
          ],
          [
           "Autonomy",
           " <i>Artificial Intelligence: Economic importance, social challenges, human<br>responsibility</i>",
           " 2017",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Autonomy",
           " <i>Particularly responsible decision-making processes ‒ e. g. autonomous driving or<br>in medical diagnostics ‒ should be designed in such a way that the ultimate<br>decision-making authority remains with the responsible actors until the quality<br>of the control system reaches a level that is accepted by all parties involved.<br>Regarding critical processes, the human being should be the ultimate decision-<br>making authority in case of doubt.</i>"
          ],
          [
           "Autonomy",
           " <i>Guidance for Regulation of Artificial Intelligence Applications</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>Consistent with law, agencies should take into consideration the following<br>principles when formulating regulatory and non-regulatory approaches to the<br>design, development, deployment, and operation of AI applications, both general<br>and sector-specific. These principles, many of which are interrelated, reflect<br>the goals and principles in Executive Order 13859. Agencies should provide ample<br>opportunities for the public to provide information and participate in all<br>stages of the rulemaking process, to the extent feasible and consistent with<br>legal requirements (including legal constraints on participation in certain<br>situations, for example, national security preventing imminent threat to or<br>responding to emergencies).</i>"
          ],
          [
           "Autonomy",
           " <i>AI in the UK: ready, willing and able?</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Autonomy",
           " <i>We recommend that the Government and Ofcom commission research into the possible<br>impact of AI on conventional and social media outlets, and investigate measures<br>that might counteract the use of AI to mislead or distort public opinion as a<br>matter of urgency.</i>"
          ],
          [
           "Autonomy",
           " <i>Preliminary Study on the Ethics of Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Autonomy",
           " <i>AI should respect human autonomy by requiring human control at all times.</i>"
          ],
          [
           "Autonomy",
           " <i>Report of COMEST on robotics ethics</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Autonomy",
           " <i>The recognition of human dignity implies that the value of autonomy does not<br>solely concern the respect for individual autonomy, which can go as far as to<br>refuse to be under the charge of a robot. The value of autonomy also expresses<br>the recognition of the interdependency of the relationship between humans,<br>between humans and animals, and between humans and the environment.</i>"
          ],
          [
           "Autonomy",
           " <i>Introducing Unity’s Guiding Principles for Ethical AI</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>Do not knowingly develop AI tools and experiences that interfere with normal,<br>functioning democratic systems of government.</i>"
          ],
          [
           "Autonomy",
           " <i>Montréal declaration for a responsible development of artificial intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " Canada",
           " Autonomy",
           " <i>AI must allow individuals to fulfill their moral objectives and their conception<br>of a life worth living. AI must not be developed or used to impose a particular<br>lifestyle on individuals, whether directly or indirectly, by implementing<br>oppressive surveillance and evaluation of incentive mechanisms. People must have<br>extensive control over information regarding their preferences. AI must not<br>create individual preference profiles to influence the behavior of the<br>individuals without their free and informed consent.</i>"
          ],
          [
           "Autonomy",
           " <i>Ethical Framework for Artificial Intelligence in Colombia (Marco Ético para la<br>Inteligencia Artificial en Colombia)</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Latin America",
           " Colombia",
           " Autonomy",
           " <i>Artificial intelligence systems should not be used to interact with the<br>citizenry without the control of a human being. Automated response and<br>conversation systems should have mechanisms for humans to intervene and<br>participate at any time. Human control must be proportional to the level of<br>risk. Technology applications with a higher probability and severity must have<br>greater human control than those with a lower risk. The most transcendental<br>decisions can only be taken by human beings, and, in any case, the algorithms<br>will serve as models to guide the decisions that humans make regarding the life<br>and integrity of others.</i>"
          ],
          [
           "Autonomy",
           " <i>fAIr LAC: Responsible and Widespread Adoption of Artificial Intelligence in<br>Latin America and the Caribbean</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Latin America",
           " Unspecified",
           " Autonomy",
           " <i>AI actors should respect the rule of law, human rights, and democratic values,<br>throughout the AI system lifecycle. These include freedom and autonomy. AI<br>actors should implement mechanisms and safeguards, such as the capacity for<br>human determination, that are appropriate to the context and consistent with the<br>state of art.</i>"
          ],
          [
           "Autonomy",
           " <i>Artificial Intelligence for Children: Beijing Principles</i>",
           " 2020",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Autonomy",
           " <i>The development of AI should help protect children's right to freely express<br>their opinions and wishes. Through appropriate channels, AI developers should<br>seriously listen to, value, and consider the opinions of children. Children<br>should be allowed to express their opinions and wishes freely when interacting<br>with AI. Parents, legal guardians, or other caregivers can help children<br>interact with AI while taking their wishes into account.</i>"
          ],
          [
           "Autonomy",
           " <i>Social Principles of Human-Centric AI</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia, Western Europe",
           " Japan, United Kingdom",
           " Autonomy",
           " <i>In a society making use of AI, we should introduce appropriate mechanisms for<br>literacy education and the promotion of proper use of AI so that people do not<br>become over-dependent on AI or misuse AI to manipulate other people's decision-<br>making.</i>"
          ],
          [
           "Autonomy",
           " <i>Position on Robotics and Artificial Intelligence</i>",
           " 2016",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Autonomy",
           " <i>In accordance with responsible research and innovation, it is imperative to<br>apply the precautionary principle and assess the long-term ethical implications<br>of new technologies in the early phase of their development. We demand respect<br>for the autonomy of persons; the right to information (linked to the right to<br>consent); the requirement for free and informed consent with a wide definition<br>of “intervention” including preventive care, diagnosis (including invasive<br>diagnostic acts), treatment, rehabilitation, and research; protection of persons<br>not able to consent. We believe a person's autonomy can only be fully respected<br>when their right to information and consent are protected, including the<br>protection of persons who are not able to consent.</i>"
          ],
          [
           "Autonomy",
           " <i>DataEthics: Principles and Guidelines for Companies, Authorities & Organisations</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " Northern Europe",
           " Denmark",
           " Autonomy",
           " <i>Humans should be in control of their data and empowered by their data. A<br>person’s self-determination should be prioritized in all data processes and the<br>person should be actively involved in regards to the data recorded about them.<br>The individual has the primary control over the usage of their data, the context<br>in which his/her data is processed, and how it is activated.</i>"
          ],
          [
           "Autonomy",
           " <i>AI Governance in Japan Ver. 1.1, Report from the expert group on how AI<br>principles should be implemented</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Autonomy",
           " <i>In a society making use of AI, we should introduce appropriate mechanisms for<br>literacy education and the promotion of proper use of AI so that people do not<br>become over-dependent on AI or misuse AI to manipulate other people's decision-<br>making.</i>"
          ],
          [
           "Autonomy",
           " <i>WLiAI Report 2019: 10 Principles of Responsible AI</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " United Kingdom",
           " Autonomy",
           " <i>We recommend the establishment of an official procedure for individuals to<br>challenge the outcomes or decisions devised by an AI system, including a<br>detailed list of what different information would have triggered a different<br>outcome.</i>"
          ],
          [
           "Autonomy",
           " <i>The Ethical Norms for the New Generation Artificial Intelligence, China</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Autonomy",
           " <i>Various activities of AI shall abide by the following fundamental ethical norms,<br>like ensuring that humans have the full power for decision-making, the right to<br>choose whether to accept the services provided by AI, the right to withdraw from<br>the interaction with AI at any time, and the rights to suspend the operation of<br>AI systems at any time and ensure that AI is always under meaningful human<br>control.</i>"
          ],
          [
           "Autonomy",
           " <i>Work in the age of artificial intelligence: Four perspectives on the economy,<br>employment, skills and ethics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Finland",
           " Autonomy",
           " <i>The Finnish artificial intelligence strategy should build on the existing<br>ethical value base of our society, which stresses trust and commonality.<br>Monopolistic and state-controlled practices, for example, should not be adopted.<br>The Finnish model relying on the European democratic tradition could serve as an<br>example of good practice in the EU and globally.</i>"
          ],
          [
           "Autonomy",
           " <i>A Framework for Responsible Limits on Facial RecognitionUse Case: Flow<br>Management</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization",
           " Western Europe",
           " Switzerland",
           " Autonomy",
           " <i>A manual review (human overseeing) should be conducted for any use that could<br>result in a consequential decision, such as causing a civil right infringement.<br>In the case of a fully automated system, a fallback system with a human in the<br>loop should always be in place in order to address exceptions and unexpected<br>errors. An alternative option to the use of facial recognition should always be<br>in place, and it should be a reasonable option.</i>"
          ],
          [
           "Autonomy",
           " <i>Advisory statement on human ethics in artificial intelligence and big data<br>research (2017)</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Autonomy",
           " <i>Ensure Discrete and Authentic Consent. Involve human participants and/or data<br>that is personally identifiable with them only through free and informed consent<br>(consent may be waived if all the conditions in TCPS 2 Article 5.5A are met).<br>Secure participant consent or consent for the use of personal information in a<br>way that is clearly given and separate from the acceptance of any form of<br>inducement, deprivation, or the exercise of control, or authority as cited in<br>the terms and conditions for the purchase of a product or service. Research that<br>relies exclusively on the secondary use of non-identifiable information does not<br>require participant consent but does require approval from the NRC-REB.</i>"
          ],
          [
           "Autonomy",
           " <i>The National Artificial Intelligence Research and Development Strategic Plan:<br>2019 Update</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>Make long-term investments in AI research. Prioritize investments in the next<br>generation of AI that will drive discovery and insight and enable the United<br>States to remain a world leader in AI.</i>"
          ],
          [
           "Autonomy",
           " <i>OECD, Recommendation of the Council on Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " France",
           " Autonomy",
           " <i>AI actors should implement mechanisms and safeguards, such as the capacity for<br>human determination, that is appropriate to the context and consistent with the<br>state of art.</i>"
          ],
          [
           "Autonomy",
           " <i>Oxford Munich Code of Conduct</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Autonomy",
           " <i>A data scientist shall be aware of the impact of changing geographical<br>aggregation units. A particular case is so-called “Gerrymandering”, consisting<br>of selecting different geographical units to influence the results of elections.<br>The Data Scientist shall not make use of any technique to create or assist in<br>the creation of manipulative evidence (e.g., psychometrics, social network<br>analysis, etc,)</i>"
          ],
          [
           "Autonomy",
           " <i>UNESCO Recommendation on the Ethics of Artificial Intelligence</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Autonomy",
           " <i>No human being or human community should be harmed or subordinated, whether<br>physically, economically, socially, politically, culturally, or mentally during<br>any phase of the life cycle of AI systems. Human rights and fundamental freedoms<br>must be respected, protected, and promoted, throughout the life cycle of AI<br>systems. In scenarios where decisions are understood to have an impact that is<br>irreversible or difficult to reverse or may involve life and death decisions, a<br>final human determination should apply. In particular, AI systems should not be<br>used for social scoring or mass surveillance purposes.</i>"
          ],
          [
           "Autonomy",
           " <i>AI Principles: Recommendations on the Ethical Use of Artificial Intelligence by<br>the Department of Defense - Defense Innovation Board</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>DoD AI systems should be designed and engineered to fulfill their intended<br>function while possessing the ability to detect and avoid unintended harm or<br>disruption and for human or automated disengagement or deactivation of deployed<br>systems that demonstrate unintended escalatory, or other, behavior.</i>"
          ],
          [
           "Autonomy",
           " <i>Megvii's Artificial Intelligence Application Guidelines</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " China",
           " Autonomy",
           " <i>AI should not surpass human autonomy. Humans should be able to oversee the<br>development of AI technology and the decisions of AI systems and intervene when<br>necessary.</i>"
          ],
          [
           "Autonomy",
           " <i>AI UX: 7 Principles of Designing Good AI Products</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Europe",
           " Hungary",
           " Autonomy",
           " <i>We should let people know if an algorithm has generated a piece of content so<br>they can decide for themselves whether to trust it or not.</i>"
          ],
          [
           "Autonomy",
           " <i>Ethics & Governance of Artificial Intelligence for Health</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Autonomy",
           " <i>The use of AI can lead to situations in which decision-making power could be<br>transferred to machines. The principle of autonomy requires that the use of AI<br>or other computational systems does not undermine human autonomy. In the context<br>of health care, this means that humans should remain in control of healthcare<br>systems and medical decisions. Respect for human autonomy also entails related<br>duties to ensure that providers have the information necessary to make safe,<br>effective use of AI systems and that people understand the role that such<br>systems play in their care.</i>"
          ],
          [
           "Autonomy",
           " <i>Ethical ML Institute Responsible Machine Learning Principles</i>",
           " Unspecified",
           " Recommendation",
           " Academic",
           " Western Europe",
           " United Kingdom",
           " Autonomy",
           " <i>Technologists should understand the consequences of incorrect predictions,<br>especially when automating critical processes that can have a significant impact<br>on human lives (e.g., justice, health, transport, etc). I commit to assessing<br>the impact of incorrect predictions and when reasonable, design systems with<br>human-in-the-loop review processes.</i>"
          ],
          [
           "Autonomy",
           " <i>HPE AI Ethics and Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>Respect human rights and be designed with mechanisms and safeguards, such as<br>human oversight to prevent misuse.</i>"
          ],
          [
           "Autonomy",
           " <i>Alpha Principles for the Ethical Use of AI and Data Driven Technologies in<br>Ontario</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Autonomy",
           " <i>Data-driven technologies should be designed in a way that respects the rule of<br>law, human rights, democratic values, and diversity, and they should include<br>appropriate safeguards to ensure a fair and just society. Designers,<br>policymakers, and developers should respect the rule of law, human rights, and<br>democratic values, throughout the AI system lifecycle. These include freedom,<br>dignity and autonomy, privacy and data protection, non-discrimination and<br>equality, diversity, fairness, social justice, and internationally recognized<br>labor rights.</i>"
          ],
          [
           "Autonomy",
           " <i>Transparency Guidelines for Data-Driven Technology in Government</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Autonomy",
           " <i>People have a right to think and act for themselves. Governments should not<br>limit a person’s ability to make important decisions for themselves, their<br>dependents, or their livelihoods. When the government makes decisions, they<br>should be done with people/stakeholders rather than on their behalf so the<br>outcomes can be more practical, appropriate, and trustworthy. Advice should<br>actively be sought from people contributing to any related data, designing any<br>AI elements, or affected by any impacts to ensure the use of any data-driven<br>technology is designed and implemented optimally for collective benefit.</i>"
          ],
          [
           "Autonomy",
           " <i>National Association of Insurance Commissioners (NAIC) Principles on Artificial<br>Intelligence (AI)</i>",
           " 2020",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>AI actors should implement mechanisms and safeguards consistent with the degree<br>and nature of the risks posed by AI to ensure all applicable laws and<br>regulations are followed, including ongoing (human or otherwise) monitoring and,<br>when appropriate, human intervention.</i>"
          ],
          [
           "Autonomy",
           " <i>ADP: Ethics in Artificial Intelligence</i>",
           " 2022",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>ADP believes that human oversight is essential to the reliable operation of ML<br>models and making proper use of their results. Our solutions provide<br>recommendations to human decision-makers, which they can then decide how to act<br>upon.</i>"
          ],
          [
           "Autonomy",
           " <i>Artificial intelligence - Common good as a benchmark, good work as a principle</i>",
           " 2019",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Autonomy",
           " <i>We demand a massive increase in control by democratic institutions in the<br>development and use of artificial intelligence, especially concerning the<br>opportunities that arise from this best use. Democracy and a fundamental rights-<br>compliant technical development, the basis of the dignity and the development<br>possibilities of human beings must be the basis.</i>"
          ],
          [
           "Autonomy",
           " <i>Draft - AI Utilization Principles</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Autonomy",
           " <i>Users should respect human dignity and individual autonomy in the utilization of<br>AI systems or AI services.</i>"
          ],
          [
           "Autonomy",
           " <i>The Code of Ethics in the Field of Artificial Intelligence</i>",
           " 2022",
           " Recommendation",
           " Unspecified",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Autonomy",
           " <i>AI Actors should take necessary measures to preserve the autonomy and free will<br>of humans in the process of decision-making, their right to choose, as well as<br>preserve human intellectual abilities in general as an intrinsic value, and a<br>system-forming factor of modern civilization.</i>"
          ],
          [
           "Autonomy",
           " <i>Chinese Young Scientists' Declaration on the Governance and Innovation of<br>Artificial Intelligence (Shanghai Declaration)</i>",
           " 2019",
           " Recommendation",
           " Academic, Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Asia",
           " China",
           " Autonomy",
           " <i>Artificial Intelligence should empower users to make their own decisions,<br>allowing users to join, monitor, or involve in the decision-making process.</i>"
          ],
          [
           "Autonomy",
           " <i>Trustworthy AI in Aotearoa: AI Principles</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " Oceania",
           " New Zealand",
           " Autonomy",
           " <i>Designers, developers, and users of AI systems (AI stakeholders) must respect<br>democratic values including the electoral process and informed public debate. AI<br>stakeholders should retain an appropriate level of human oversight of AI systems<br>and their outputs.</i>"
          ],
          [
           "Autonomy",
           " <i>Transparency and Trust in the Cognitive Era</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>The purpose of AI and cognitive systems developed and applied by the IBM company<br>is to augment human intelligence. Our technology, products, services, and<br>policies will be designed to enhance and extend human capability, expertise, and<br>potential. Our position is based not only on principle but also on science.<br>Cognitive systems will not realistically attain consciousness or independent<br>agency. Rather, they will increasingly be embedded in the processes, systems,<br>products, and services by which business and society function – all of which<br>will and should remain within human control.</i>"
          ],
          [
           "Autonomy",
           " <i>Civil Rights Principles for the Era of Big Data</i>",
           " 2014",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>Enhance Individual Control of Personal Information. Personal information that is<br>known to a corporation — such as the moment-to-moment record of a person’s<br>movements or communications — can easily be used by companies and the government<br>against vulnerable populations, including women, the formerly incarcerated,<br>immigrants, religious minorities, the LGBT community, and young people.<br>Individuals should have meaningful, flexible control over how a corporation<br>gathers data from them, and how it uses and shares that data. Non-public<br>information should not be disclosed to the government without judicial process.</i>"
          ],
          [
           "Autonomy",
           " <i>Technological convergence, artificial intelligence and human rights</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Autonomy",
           " <i>Moreover, the Assembly proposes that guidelines be drawn upon the following<br>issues: the need for any machine, any robot, or any artificial intelligence<br>artifact to remain under human control; insofar as the machine in question is<br>intelligent solely through its software, any power it is given must be able to<br>be withdrawn from it.</i>"
          ],
          [
           "Autonomy",
           " <i>Decree of the President of the Russian Federation on the Development of<br>Artificial Intelligence in the Russian Federation</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Autonomy",
           " <i>The basic principles of the development and use of artificial intelligence<br>technologies, the observance of which is obligatory during the implementation of<br>this Strategy, include: the assurance of the necessary level of Russian<br>Federation self-sufficiency in the field of artificial intelligence, including<br>that achieved through the predominant use of domestic artificial intelligence<br>technologies and technological solutions developed based on artificial<br>intelligence.</i>"
          ],
          [
           "Autonomy",
           " <i>Principles and Practices for the Responsible Application of Artificial<br>Intelligence at Motorola Solutions - White Paper</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Autonomy",
           " <i>Fundamentally, our approach is to augment human decision-making while never<br>displacing or disintermediating human judgment. In this sense, our systems are<br>advisory and will never take AI-generated consequential actions on their own. In<br>other words, there is always a “human in the loop” to make the final<br>determinations on substantial decisions. Studies indicate that the best results<br>are achieved with a combination of AI and human experts.</i>"
          ]
         ],
         "hovertemplate": "<b>Document ID </b>=%{customdata[1]}<br><b>Year of Publication </b>=%{customdata[2]}<br><b>Reguation Type </b>=%{customdata[3]}<br><b>Institution Type </b>=%{customdata[4]}<br><b>World Region </b>=%{customdata[5]}<br><b>Country </b>=%{customdata[6]}<br><b>Principle </b>=%{customdata[7]}<br><b>Description </b>=%{customdata[8]}<extra></extra>",
         "legendgroup": "Autonomy",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Autonomy",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          -4.057759,
          -9.501869,
          -10.568297,
          -4.3000765,
          -10.497004,
          -5.8476357,
          -28.582937,
          -10.289168,
          -5.5616803,
          -0.8206684,
          2.7681656,
          24.101967,
          -2.2046933,
          6.359561,
          -8.286011,
          -9.261466,
          1.7848988,
          1.0218385,
          -4.1377306,
          -11.000183,
          -1.8373778,
          -3.0868235,
          17.331175,
          3.5030768,
          -6.1918592,
          -6.3384595,
          -5.7120113,
          -3.7597816,
          1.4143956,
          -8.177085,
          1.0574924,
          25.590902,
          8.2856245,
          8.218261,
          -4.095878,
          6.7392154,
          12.269529,
          -6.4440365,
          -2.4649367,
          -1.4465082,
          -3.12667,
          -1.5095986,
          -9.578254,
          -3.467641,
          -7.102602,
          -5.7142696,
          -0.049562413,
          -10.125915,
          -1.1324694,
          -24.885082,
          -1.4084747,
          -10.893527,
          -8.189424,
          -6.358149,
          -21.584858,
          1.1805252,
          -1.4457388,
          -0.8897536,
          -28.033426,
          -3.6942427,
          -1.726872,
          -7.5270996,
          0.9279882,
          -11.991925,
          -25.367352,
          -11.75136,
          1.9312229,
          -8.311449,
          -4.4735537,
          1.2787663,
          -4.5398574,
          -9.063335,
          -1.5288131,
          3.0978093,
          14.502802,
          -4.518292,
          -3.624004,
          14.49946,
          1.7613951,
          -0.4091302,
          15.01249,
          0.60648876,
          -5.983399,
          14.309341,
          -5.7454786,
          -0.25771022,
          -6.04366,
          -18.376593,
          -7.8053017,
          -2.5441692,
          -6.2552595,
          -0.95683044,
          8.809983,
          1.3869135,
          -4.52618,
          -6.8285985,
          -1.9010496,
          2.63338,
          -3.7032664,
          -1.7611898,
          -6.147225,
          3.7378585,
          5.0708055,
          -7.268916,
          -13.966135,
          0.77897114,
          -0.13929847
         ],
         "y": [
          16.074724,
          9.610363,
          10.453689,
          14.466491,
          8.273448,
          -15.683463,
          -1.9427115,
          6.7446523,
          5.5725174,
          -0.006911002,
          -1.6226925,
          0.7622925,
          16.131966,
          17.865444,
          12.018604,
          -15.529913,
          10.338852,
          2.6058176,
          6.89478,
          16.55562,
          5.6169987,
          2.6562648,
          5.148289,
          17.625313,
          20.173363,
          25.979885,
          7.0790286,
          1.5222545,
          -15.9643345,
          8.297457,
          10.834508,
          11.406485,
          10.369657,
          -14.394678,
          15.663613,
          14.328301,
          -17.06649,
          3.9603684,
          20.081558,
          0.71026206,
          18.66366,
          1.8153777,
          20.405502,
          8.965072,
          -11.11826,
          -15.14,
          0.6429812,
          3.0980105,
          3.7471201,
          5.8128214,
          21.809038,
          12.899238,
          14.154744,
          -23.269138,
          2.3539407,
          18.651068,
          -6.860183,
          19.740837,
          2.9521976,
          12.465378,
          12.033172,
          11.151874,
          -9.394119,
          6.3042517,
          5.5156646,
          -23.349403,
          -3.6491551,
          2.3764548,
          15.046689,
          9.649919,
          1.460925,
          4.1875067,
          1.1548612,
          8.68765,
          -5.1207128,
          25.169931,
          19.762632,
          -5.8682566,
          -2.4566708,
          -4.6644588,
          -2.949222,
          11.745076,
          24.749435,
          -18.185848,
          -0.05783401,
          23.33182,
          4.2922254,
          -14.823616,
          3.6065369,
          -0.12798741,
          9.03505,
          7.75549,
          18.157299,
          7.6810937,
          8.011379,
          -1.2940913,
          4.8936887,
          4.06578,
          7.730705,
          4.152558,
          5.5819473,
          1.0856017,
          -19.59901,
          19.364264,
          3.4748003,
          -17.59309,
          -17.353897
         ],
         "z": [
          4.331122,
          15.343997,
          6.8579855,
          2.5728765,
          17.137424,
          0.14744952,
          -4.706141,
          14.934334,
          11.863936,
          13.282364,
          -20.083612,
          -7.077535,
          1.6317766,
          -1.8755096,
          -5.29694,
          1.8360047,
          5.198367,
          -20.486671,
          -5.6014614,
          -15.034502,
          -27.317114,
          -28.401562,
          -19.8005,
          11.059637,
          -6.7817154,
          1.4459808,
          12.376501,
          5.2441554,
          10.551185,
          12.440793,
          10.076207,
          7.0325627,
          13.549218,
          11.223634,
          0.40684366,
          2.1274335,
          12.424437,
          14.704889,
          -0.03987951,
          -19.231401,
          8.05637,
          -12.841726,
          -9.25134,
          15.955917,
          -19.317,
          -0.8949156,
          -21.691423,
          -9.4177065,
          -14.633445,
          -7.7736177,
          3.889348,
          -7.6435013,
          9.887437,
          1.0515424,
          -13.221954,
          -2.7206695,
          4.1689434,
          6.7812653,
          1.1770523,
          11.161677,
          1.4252875,
          11.0799,
          24.534435,
          12.255111,
          -6.695179,
          -8.994327,
          -8.083613,
          17.544012,
          10.424254,
          15.070872,
          12.835655,
          13.895723,
          5.158291,
          23.663942,
          7.9737864,
          0.4907423,
          -0.2382349,
          7.124867,
          -20.209593,
          3.504702,
          4.2275767,
          -9.367864,
          -3.5750427,
          -0.9092329,
          3.9173555,
          -16.080185,
          10.073251,
          3.224267,
          16.345102,
          -23.43489,
          10.520195,
          -15.156311,
          9.636204,
          2.3359277,
          14.351013,
          4.3750157,
          -10.783617,
          12.243762,
          8.029333,
          10.987595,
          17.367922,
          2.6502032,
          12.843772,
          2.0653517,
          17.015862,
          21.771776,
          12.436798
         ]
        },
        {
         "customdata": [
          [
           "Beneficence",
           " <i>Intel’s AI Privacy Policy White Paper: Protecting individuals’ privacy and data<br>in the artificial intelligence world</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>Minimize potential adverse impacts for citizens from automated decision-making.<br>Privacy requires that data is both reliable and that it will not be used to harm<br>individuals. Privacy aims to prevent unauthorized access, modification, and loss<br>of personal data. It requires respect for private and family life, home, and<br>confidentiality of communications.</i>"
          ],
          [
           "Beneficence",
           " <i>Icelander Institute for Intelligent Machine Ethics Policy</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization",
           " Northern Europe",
           " Iceland",
           " Beneficence",
           " <i>IIIM’s sincere goal is to focus its research towards topics and challenges of<br>obvious benefit to the general public, and for the betterment of society, human<br>livelihood, and life on Earth. IIIM aims to advance scientific understanding of<br>the world and to enable the application of this knowledge for the benefit and<br>betterment of humankind. IIIM will not undertake any project or activity<br>intended to cause bodily injury or severe emotional distress to any person.</i>"
          ],
          [
           "Beneficence",
           " <i>Responsible AI: A Global Policy Framework</i>",
           " 2021",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization, Professional Association",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>Organisations that develop, make available, or use AI systems and any national<br>laws or industry standards that govern such use should require the purposes of<br>such implementation to be identified and ensure that such purposes are<br>consistent with the overall ethical purposes of beneficence and non-maleficence,<br>as well as the other principles of the Policy Framework for Responsible AI.</i>"
          ],
          [
           "Beneficence",
           " <i>The Japanese Society for Artificial Intelligence Ethical Guidelines</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Academic",
           " Eastern Asia",
           " Japan",
           " Beneficence",
           " <i>Members of the JSAI will contribute to the peace, safety, welfare, and public<br>interest of humanity.</i>"
          ],
          [
           "Beneficence",
           " <i>Kakao Algorithm Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " South Korea",
           " Beneficence",
           " <i>Kakao's Algorithm Kakao makes all its efforts related to ensuring our algorithms<br>pursue the welfare and happiness of mankind.</i>"
          ],
          [
           "Beneficence",
           " <i>AI at Google: our principles</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>As we consider potential development and uses of AI technologies, we will take<br>into account a broad range of social and economic factors, and will proceed<br>where we believe that the overall likely benefits substantially exceed the<br>foreseeable risks and downsides.</i>"
          ],
          [
           "Beneficence",
           " <i>Ethics Guidelines for Trustworthy AI</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Beneficence",
           " <i>AI systems should neither cause nor exacerbate harm or otherwise adversely<br>affect human beings. This entails the protection of human dignity as well as<br>mental and physical integrity. AI systems and the environments in which they<br>operate must be safe and secure.</i>"
          ],
          [
           "Beneficence",
           " <i>China’s Artificial Intelligence Industry Alliance Self-discipline Convention</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Beneficence",
           " <i>The development of artificial intelligence should advance the progress of<br>society and human civilization, create more intelligent modes of working and<br>lifestyles, and enhance people's livelihood and well-being. (...) The<br>development of artificial intelligence should avoid harming the interests of<br>society and the public; existing dangers should not be aggravated, nor new<br>dangers caused, through the abuse of artificial intelligence.</i>"
          ],
          [
           "Beneficence",
           " <i>Mid- to Long-Term Master Plan in Preparation for the Intelligent Information<br>Society Managing the Fourth Industrial Revolution</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " South Korea",
           " Beneficence",
           " <i>Intelligent IT is expected to enhance consumer welfare by preventing diseases,<br>increasing the efficacy of healthcare, improving people’s living environments,<br>reducing accidents, and facilitating progress in other areas. It is also<br>necessary to raise public awareness of the negative impacts of technological<br>innovation, such as threats to privacy, socioeconomic polarization, and human<br>alienation, and establish a structure for broad public discourses on identifying<br>and managing these risks.</i>"
          ],
          [
           "Beneficence",
           " <i>Next-Generation AI Governance Principles - Develop responsible artificial<br>intelligence</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Beneficence",
           " <i>AI development should begin from the objective of enhancing the common well-<br>being of humanity; it should conform to human values, ethics, and morality,<br>promote human-machine harmony, and serve the progress of human civilization; it<br>should be based on the premise of safeguarding societal security and respecting<br>human rights, avoid misuse, and prohibit abuse and malicious application.</i>"
          ],
          [
           "Beneficence",
           " <i>Draft AI R&D Guidelines for International Discussions</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Beneficence",
           " <i>AI developers must ensure that their systems need not posit any harm to the<br>lives and properties of users.</i>"
          ],
          [
           "Beneficence",
           " <i>Responsible bots: 10 guidelines for developers of conversational AI</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>Before beginning design work, carefully specify how your bot will benefit the<br>user or the entity deploying the bot.</i>"
          ],
          [
           "Beneficence",
           " <i>It’s Time to Do Something: Mitigating the Negative Impacts of Computing Through<br>a Change to the Peer Review Process</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " Eastern Asia, Central Europe",
           " Turkey, Turkey",
           " Beneficence",
           " <i>The research community should more actively evaluate its members on their<br>ethical decision-making when it comes to research project selection.</i>"
          ],
          [
           "Beneficence",
           " <i>Digital Technology and Healthcare which ethical issues for which regulations?</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " France",
           " Beneficence",
           " <i>Given the potential scale of the issue in coming years, it would be desirable if<br>a framework specifically designed to cover injury caused by digital objects were<br>developed at least at the European level.</i>"
          ],
          [
           "Beneficence",
           " <i>Big Data, Artificial Intelligence, Machine Learning, and Data Protection</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Beneficence",
           " <i>Organisations should define the benefits of the analytics. They should not incur<br>the risks of big data analytics if the benefits could be achieved by less risky<br>means.</i>"
          ],
          [
           "Beneficence",
           " <i>Model AI Governance Framework</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " Southeast Asia",
           " Singapore",
           " Beneficence",
           " <i>As AI is used to amplify human capabilities, the protection of the interests of<br>human beings, including their well-being and safety, should be the primary<br>considerations in the design, development, and deployment of AI.</i>"
          ],
          [
           "Beneficence",
           " <i>Asilomar AI Principles</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>The goal of AI research should be to create not undirected intelligence, but<br>beneficial intelligence. An arms race in lethal autonomous weapons should be<br>avoided. Superintelligence should only be developed in the service of widely<br>shared ethical ideals, and for the benefit of all humanity rather than one state<br>or organization.</i>"
          ],
          [
           "Beneficence",
           " <i>Code of Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Professional Association",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>Software engineering managers and leaders shall subscribe to and promote an<br>ethical approach to the management of software development and maintenance.<br>Software engineers shall act consistently with the public interest. Software<br>engineers shall act in a manner that is in the best interests of their client<br>and employer consistent with the public interest.</i>"
          ],
          [
           "Beneficence",
           " <i>G20 Ministerial Statement on Trade and Digital Economy</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " G20",
           " Beneficence",
           " <i>Stakeholders should proactively engage in responsible stewardship of trustworthy<br>AI in pursuit of beneficial outcomes for people and the planet.</i>"
          ],
          [
           "Beneficence",
           " <i>Philips AI Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Netherlands",
           " Beneficence",
           " <i>We design our solutions to benefit the health and well-being of individuals and<br>to contribute to the sustainable development of society.</i>"
          ],
          [
           "Beneficence",
           " <i>  Philips Data Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Netherlands",
           " Beneficence",
           " <i>We aim to create innovative solutions that benefit our customers, patients, and<br>society as a whole. We use your personal data in line with your reasonable<br>expectations.</i>"
          ],
          [
           "Beneficence",
           " <i>AI 4People 's Ethical Framework for a Good AI Society: Opportunities, Risks,<br>Principles, and Recommendations</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Beneficence",
           " <i>The development of AI should ultimately promote the well-being of all sentient<br>creatures. AI should be developed for the common good and the benefit of<br>humanity. Stakeholders should assess the capacity of existing institutions, such<br>as national civil courts, to redress the mistakes made or harms inflicted by AI<br>systems.</i>"
          ],
          [
           "Beneficence",
           " <i>Rome Call for AI Ethics</i>",
           " 2020",
           " Recommendation",
           " Religious Institution",
           " Southern Europe",
           " Vatican City State",
           " Beneficence",
           " <i>The development of AI in the service of humankind and the planet must be<br>reflected in regulations and principles that protect people – particularly the<br>weak and the underprivileged – and natural environments.</i>"
          ],
          [
           "Beneficence",
           " <i>Ethically Aligned Design: A Vision for Prioritizing Human Well-being with<br>Autonomous and Intelligent Systems, Version 2</i>",
           " 2017",
           " Recommendation",
           " Professional Association",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>A/IS should prioritize human well-being as an outcome in all system designs,<br>using the best available, and widely accepted, well-being metrics as their<br>reference point.</i>"
          ],
          [
           "Beneficence",
           " <i>Užupis Principles for Trustworthy AI Design</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Europe",
           " Lithuania",
           " Beneficence",
           " <i>I trust myself that I will use AI to strive for the common good whenever<br>possible.</i>"
          ],
          [
           "Beneficence",
           " <i>Hippocratic Oath for Data Scientists</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization",
           " Western Europe",
           " France",
           " Beneficence",
           " <i>Ensure that the metrics to be optimized are relevant and do not lead the project<br>to have a negative social and environmental impact.</i>"
          ],
          [
           "Beneficence",
           " <i>Code of conduct for data-driven health and care technology</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Beneficence",
           " <i>Generate evidence that the product achieves clinical, social, economic, or<br>behavioral benefits. When building or developing the technology, consider what<br>function the product delivers – this will inform the evidence generation plan.<br>It’s advisable to consider the generation of evidence as something that happens<br>in parallel with the development of the product and builds throughout the<br>product’s life.</i>"
          ],
          [
           "Beneficence",
           " <i>Digital Ethics Guidelines on AI</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Beneficence",
           " <i>We take great care in the initial algorithm of our own AI solutions to prevent<br>so called 'Black Boxes' and to make sure that our systems shall not<br>unintentionally harm the users.</i>"
          ],
          [
           "Beneficence",
           " <i>Ethics Framework - Responsible AI</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Beneficence",
           " <i>Benefits should be clear, likely, and outweigh potential, reasonable risks. They<br>should be evaluated for different user groups and for any affected non-user<br>groups (especially when there are competing values or interests between these<br>groups) and with consideration of plausible future trends or changes (such as<br>greater compute capacity, a solution coming to dominate the market, etc).</i>"
          ],
          [
           "Beneficence",
           " <i>AI Ethics Principles & Guidelines</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Middle East",
           " United Arab Emirates",
           " Beneficence",
           " <i>Government will support the research of the beneficial use of AI.</i>"
          ],
          [
           "Beneficence",
           " <i>Principles of Robotics</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Beneficence",
           " <i>Robots should not be designed solely or primarily to kill or harm humans, except<br>in the interests of national security</i>"
          ],
          [
           "Beneficence",
           " <i>Beijing AI Principles</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Eastern Asia",
           " China",
           " Beneficence",
           " <i>AI should be designed and developed to promote the progress of society and human<br>civilization, to promote the sustainable development of nature and society, to<br>benefit all humankind and the environment, and to enhance the well-being of<br>society and ecology.  AI should not be used against, utilize or harm human<br>beings.</i>"
          ],
          [
           "Beneficence",
           " <i>Responsible Artificial Intelligence in the Government of Canada (whitepaper)</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Beneficence",
           " <i>The Treasury Board of Canada Secretariat actively encourages institutions to<br>explore this technology for the benefit of the populations that we serve.<br>Ethical and responsible design of these systems will drive a virtuous cycle of<br>acceptance, which in turn will drive further development.</i>"
          ],
          [
           "Beneficence",
           " <i>Artificial Intelligence at Google: Our Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>We believe that AI should be socially beneficial. As we consider potential<br>development and uses of AI technologies, we will take into account a broad range<br>of social and economic factors, and will proceed where we believe that the<br>overall likely benefits substantially exceed the foreseeable risks and<br>downsides. We will not pursue technologies that cause or are likely to cause<br>overall harm.</i>"
          ],
          [
           "Beneficence",
           " <i>Universal principles of data ethics: 12 guidelines for developing ethics codes</i>",
           " 2016",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Beneficence",
           " <i>The highest priority is to respect the persons behind the data. When insights<br>derived from data could impact the human condition, the potential harm to<br>individuals and communities should be the paramount consideration. Big data can<br>produce compelling insights about populations, but those same insights can be<br>used to unfairly limit an individual’s possibilities.</i>"
          ],
          [
           "Beneficence",
           " <i>Artificial Intelligence: Australia’s Ethics Framework - A Discussion Paper</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Oceania",
           " Australia",
           " Beneficence",
           " <i>The AI system must generate benefits for people that are greater than the costs.<br>Civilian AI systems must not be designed to harm or deceive people and should be<br>implemented in ways that minimize any negative outcomes.</i>"
          ],
          [
           "Beneficence",
           " <i>Sony Group AI Ethics Guidelines</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " Japan",
           " Beneficence",
           " <i>Through advancing its AI-related R&D and promoting the utilization of AI in a<br>manner harmonized with society, Sony aims to support the exploration of the<br>potential for each individual to empower their lives, and to contribute to the<br>enrichment of our culture and push our civilization forward by providing novel<br>and creative types of kando. Sony will be cognizant of the effects and impact of<br>products and services that utilize AI on society and will proactively work to<br>contribute to developing AI to create a better society and foster human talent<br>capable of shaping our collective bright future through R&D and/or utilization<br>of AI.</i>"
          ],
          [
           "Beneficence",
           " <i>Principles for the safe and effective use of data and analytics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Oceania",
           " New Zealand",
           " Beneficence",
           " <i>The use of data and analytics must have clear benefits for New Zealanders.</i>"
          ],
          [
           "Beneficence",
           " <i>Recommendations for the responsible use of AI and automated decision-making -<br>Corporate Digital Responsibility and Decision Making (Empfehlungen für den<br>verantwortlichen Einsatz von KI und automatisierten Entscheidungen - Corporate<br>Digital Responsibility and Decision Making)</i>",
           " 2018",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Beneficence",
           " <i>When decision-support technologies are used, the consequences for the user<br>should be examined in advance and compared with the benefits of their use.<br>Unreasonable disadvantages should be ruled out.</i>"
          ],
          [
           "Beneficence",
           " <i>Code of Ethics for Data-Based Value Creation</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Switzerland",
           " Beneficence",
           " <i>You should not harm individuals or communities.</i>"
          ],
          [
           "Beneficence",
           " <i>Automated and connected automated driving (Automatisiertes und Vernetztes<br>Fahren)</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Germany",
           " Beneficence",
           " <i>The protection of people takes precedence over all other utilitarian<br>considerations. The goal is to reduce harm up to and including complete<br>prevention. The approval of automated systems is only justifiable if, in<br>comparison with humans, the new system promises at least a reduction in damage<br>in the sense of a positive risk balance.</i>"
          ],
          [
           "Beneficence",
           " <i>Telia Company Guiding Principles on trusted AI ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Sweden",
           " Beneficence",
           " <i>Our mission is to create value for customers and other stakeholders with a<br>positive impact on society. We aspire to act with care and in a responsible way.<br>We explore opportunities in tandem with potential risks.</i>"
          ],
          [
           "Beneficence",
           " <i>Report on Artificial Intelligence and Human Society</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Beneficence",
           " <i>Advancing AI technologies that are beneficial for human society requires basic<br>sciences, including social sciences to study societal issues that may arise in<br>the future, observe the social acceptance of their stochastic behaviors such as<br>deep learning, and create an environment that supports open science to enhance<br>the diversity of AI technologies. Scientists and engineers should collaborate<br>with researchers in the humanities and social sciences for pursuing socially<br>beneficial AI technologies.</i>"
          ],
          [
           "Beneficence",
           " <i>Understanding artificial intelligence ethics and safety: A guide for the<br>responsible design and implementation of AI systems in the public sector</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Western Europe",
           " United Kingdom",
           " Beneficence",
           " <i>Care for the wellbeing of each and all (i.e., do no harm with these technologies<br>and minimize the risks of their misuse or abuse).</i>"
          ],
          [
           "Beneficence",
           " <i>Opinion of the Data Ethics Commission</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Beneficence",
           " <i>The Data Ethics Commission recommends that measures be taken against ethically<br>indefensible uses of data. Examples of these uses include total surveillance,<br>profiling that poses a threat to personal integrity, the targeted exploitation<br>of vulnerabilities, addictive designs and dark patterns, methods of influencing<br>political elections that are incompatible with the principle of democracy,<br>vendor lock-in, and systematic consumer detriment, and many practices that<br>involve trading in personal data.</i>"
          ],
          [
           "Beneficence",
           " <i>Statement on Artificial Intelligence, Robotics and 'Autonomous‘ Systems</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Beneficence",
           " <i>The principle of responsibility must be fundamental to AI research and<br>application. ‘Autonomous’ systems should only be developed and used in ways that<br>serve the global social and environmental good, as determined by outcomes of<br>deliberative democratic processes. This implies that they should be designed so<br>that their effects align with a plurality of fundamental human values and<br>rights.</i>"
          ],
          [
           "Beneficence",
           " <i>Report with recommendations to the Commission on Civil Law Rules on Robotics</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " European Union",
           " European Union",
           " Beneficence",
           " <i>The European Parliament points out that the guiding ethical framework should be<br>based on the principles of beneficence, non-maleficence. Beneficence – robots<br>should act in the best interests of humans; Non-maleficence – the doctrine of<br>‘first, do not harm’, whereby robots should not harm a human.</i>"
          ],
          [
           "Beneficence",
           " <i>Preparing for the future of Artificial Intelligence</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>Private and public institutions are encouraged to examine whether and how they<br>can responsibly leverage AI and machine learning in ways that will benefit<br>society. Social justice and public policy institutions that do not typically<br>engage with advanced technologies and data science in their work should consider<br>partnerships with AI researchers and practitioners that can help apply AI<br>tactics to the broad social problems these institutions already address in other<br>ways.</i>"
          ],
          [
           "Beneficence",
           " <i>Vienna Manifesto on Digital Humanism</i>",
           " 2019",
           " Recommendation",
           " Academic",
           " Central Europe",
           " Austria",
           " Beneficence",
           " <i>Practitioners everywhere ought to acknowledge their shared responsibility for<br>the impact of information technologies. They need to understand that no<br>technology is neutral and be sensitized to see both potential benefits and<br>possible downsides. Education on computer science/informatics and its societal<br>impact must start as early as possible. Students should learn to combine<br>information-technology skills with an awareness of the ethical and societal<br>issues at stake.</i>"
          ],
          [
           "Beneficence",
           " <i>Guidance for Regulation of Artificial Intelligence Applications</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>Consistent with law, agencies should take into consideration the following<br>principles when formulating regulatory and non-regulatory approaches to the<br>design, development, deployment, and operation of AI applications, both general<br>and sector-specific. These principles, many of which are interrelated, reflect<br>the goals and principles in Executive Order 13859. AI is expected to have a<br>positive impact across sectors of social and economic life, including<br>employment, transportation, education, finance, healthcare, personal security,<br>and manufacturing. At the same time, AI applications could pose risks to<br>privacy, individual rights, autonomy, and civil liberties that must be carefully<br>assessed and appropriately addressed.</i>"
          ],
          [
           "Beneficence",
           " <i>Tieto’s AI ethics guidelines</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Finland",
           " Beneficence",
           " <i>At Tieto, we are committed to harnessing AI for good, for the planet, and for<br>humankind.</i>"
          ],
          [
           "Beneficence",
           " <i>AI in the UK: ready, willing and able?</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Beneficence",
           " <i>Artificial intelligence should be developed for the common good and benefit of<br>humanity. The autonomous power to hurt, destroy or deceive human beings should<br>never be vested in artificial intelligence.</i>"
          ],
          [
           "Beneficence",
           " <i>Preliminary Study on the Ethics of Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Beneficence",
           " <i>AI should be developed to enhance the quality of life.</i>"
          ],
          [
           "Beneficence",
           " <i>Report of COMEST on robotics ethics</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Beneficence",
           " <i>‘Do not harm’ principle is a red line for robots. Like many technologies, a<br>robot has the potential for ‘dual-use’. Robots are usually designed for good and<br>useful purposes (to diminish the harmfulness of work for example), to help human<br>beings, not to harm or kill them. In this regard, Isaac Asimov’s formulation of<br>this principle (three laws) is still accurate (see paragraph 18. If we are<br>morally serious about this ethical principle, then we have to ask ourselves<br>whether armed drones and autonomous weapons should be banned.</i>"
          ],
          [
           "Beneficence",
           " <i>Top 10 Principles for Ethical Artificial Intelligence</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " Switzerland",
           " Beneficence",
           " <i>Lethal autonomous weapons, including cyber warfare, should be banned.</i>"
          ],
          [
           "Beneficence",
           " <i>ACM Code of Ethics and Professional Conduct</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>A computing professional should contribute to society and human well-being,<br>acknowledging that all people are stakeholders in computing.</i>"
          ],
          [
           "Beneficence",
           " <i>Montréal declaration for a responsible development of artificial intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " Canada",
           " Beneficence",
           " <i>AI must help individuals improve their living conditions, their health, and<br>their working conditions. AI must allow individuals to pursue their preferences,<br>so long as they do not cause harm to other sentient beings.</i>"
          ],
          [
           "Beneficence",
           " <i>Ethical Framework for Artificial Intelligence in Colombia (Marco Ético para la<br>Inteligencia Artificial en Colombia)</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Latin America",
           " Colombia",
           " Beneficence",
           " <i>Artificial intelligence systems must not affect the integrity and physical and<br>mental health of the human beings with whom they interact. Codes of conduct<br>should generate parameters to avoid activities that endanger the integrity and<br>physical safety of people. Artificial intelligence systems implemented in<br>Colombia must allow or be directly related to an activity that generates a clear<br>and determinable social benefit.</i>"
          ],
          [
           "Beneficence",
           " <i>fAIr LAC: Responsible and Widespread Adoption of Artificial Intelligence in<br>Latin America and the Caribbean</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Latin America",
           " Unspecified",
           " Beneficence",
           " <i>Stakeholders should proactively engage in responsible stewardship of trustworthy<br>AI in pursuit of beneficial outcomes for people and the planet, such as<br>augmenting human capabilities and enhancing creativity.</i>"
          ],
          [
           "Beneficence",
           " <i>Artificial Intelligence for Children: Beijing Principles</i>",
           " 2020",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Beneficence",
           " <i>The development of AI should help protect and promote children's physical and<br>mental safety. AI should help protect children from all forms of physical or<br>mental violence, injury or abuse, neglect or negligent treatment, maltreatment<br>or exploitation, including sexual abuse, and help combat child trafficking,<br>indecency, and other crimes. The development of AI should help protect and<br>promote children's physical and mental health.</i>"
          ],
          [
           "Beneficence",
           " <i>Position on Robotics and Artificial Intelligence</i>",
           " 2016",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Beneficence",
           " <i>We demand that research and technology are integrated to the maximum benefit of<br>all and avoid potential unintended social impacts, especially when talking about<br>emerging technologies like robotics and artificial intelligence. Robots should<br>not be designed to kill or harm humans.</i>"
          ],
          [
           "Beneficence",
           " <i>Governing Artificial Intelligence: Upholding human rights & dignity</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>In order for AI to benefit the common good, at the very least it's design and<br>deployment should avoid harm to fundamental human values. International human<br>rights provide a robust and global formulation of those values.</i>"
          ],
          [
           "Beneficence",
           " <i>DataEthics: Principles and Guidelines for Companies, Authorities & Organisations</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " Northern Europe",
           " Denmark",
           " Beneficence",
           " <i>Data processes should be designed as sustainable solutions benefitting first and<br>foremost humans.</i>"
          ],
          [
           "Beneficence",
           " <i>Artificial Intelligence at the service of the citizen (L’intelligenzia<br>artificiale al servizio del cittadino)</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Southern Europe",
           " Italy",
           " Beneficence",
           " <i>Articles of artificial intelligence should follow principles of benefit and not<br>harm to people. Always aiming for the good as a whole.</i>"
          ],
          [
           "Beneficence",
           " <i>oston Dynamics Ethical Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>We are motivated by curiosity and respect for humans and animals. We see this as<br>the next step in the human history of building machines to reduce the danger,<br>repetition, and physically difficult aspects of work. We will not weaponize our<br>robots. We will not authorize nor partner with those who wish to use our robots<br>as weapons or autonomous targeting systems. If our products are being used for<br>harm, we will take appropriate measures to mitigate that misuse.</i>"
          ],
          [
           "Beneficence",
           " <i>The Ethical Norms for the New Generation Artificial Intelligence, China</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Beneficence",
           " <i>Various activities of AI shall abide by the following fundamental ethical norms,<br>like enhancing the well-being of humankind, improving people’s livelihood, and<br>enhancing the sense of happiness.</i>"
          ],
          [
           "Beneficence",
           " <i>Work in the age of artificial intelligence: Four perspectives on the economy,<br>employment, skills and ethics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Finland",
           " Beneficence",
           " <i>Extensive societal benefits mean that AI-based solutions benefit all groups in<br>society. This value should be a key guideline informing all government support<br>for the development of AI technology and applications based on it.</i>"
          ],
          [
           "Beneficence",
           " <i>Discussion Paper: National Strategy for Artificial Intelligence</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " South Asia",
           " India",
           " Beneficence",
           " <i>Beyond just the headline numbers of economic impact, a disruptive technology<br>such as AI needs to be seen from the perspective of the transformative impact it<br>could have on the greater good – improving the quality of life and access of<br>choice to a large section of the country.</i>"
          ],
          [
           "Beneficence",
           " <i>The Holberton-Turing Oath</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Unspecified",
           " Unspecified",
           " Beneficence",
           " <i>As a member of the data science and artificial intelligence profession, I<br>solemnly pledge to dedicate my life to the service of Humanity. I will maintain<br>the utmost respect for human life.</i>"
          ],
          [
           "Beneficence",
           " <i>OECD, Recommendation of the Council on Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " France",
           " Beneficence",
           " <i>Stakeholders should proactively engage in responsible stewardship of trustworthy<br>AI in pursuit of beneficial outcomes for people and the planet, such as<br>augmenting human capabilities and enhancing creativity, advancing the inclusion<br>of underrepresented populations, reducing economic, social, gender, and other<br>inequalities, and protecting natural environments, thus invigorating inclusive<br>growth, sustainable development, and well-being.</i>"
          ],
          [
           "Beneficence",
           " <i>OP Financial Group’s Ethical Guidelines for Artificial Intelligence</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Finland",
           " Beneficence",
           " <i>We utilize data and artificial intelligence responsibly to promote the well-<br>being of our customers.</i>"
          ],
          [
           "Beneficence",
           " <i>OpenAI Charter</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization, Private Corporation",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>We commit to use any influence we obtain over AGI’s deployment to ensure it is<br>used for the benefit of all, and to avoid enabling uses of AI or AGI that harm<br>humanity or unduly concentrate power. Our primary fiduciary duty is to humanity.<br>We anticipate needing to marshal substantial resources to fulfill our mission,<br>but will always diligently act to minimize conflicts of interest among our<br>employees and stakeholders that could compromise broad benefit.</i>"
          ],
          [
           "Beneficence",
           " <i>Partnership on AI Tenets</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization",
           " Unspecified",
           " Unspecified",
           " Beneficence",
           " <i>We will seek to ensure that AI technologies benefit and empower as many people<br>as possible.</i>"
          ],
          [
           "Beneficence",
           " <i>UNESCO Recommendation on the Ethics of Artificial Intelligence</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Beneficence",
           " <i>AI actors should play a participative and enabling role to ensure peaceful and<br>just societies, which are based on an interconnected future for the benefit of<br>all, consistent with human rights and fundamental freedoms. The value of living<br>in peaceful and just societies points to the potential of AI systems to<br>contribute throughout their life cycle to the interconnectedness of all living<br>creatures with each other and with the natural environment.</i>"
          ],
          [
           "Beneficence",
           " <i>Megvii's Artificial Intelligence Application Guidelines</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " China",
           " Beneficence",
           " <i>Technology should be a positive force. We are committed to being a responsible<br>corporate citizen, complying with applicable laws and generally accepted ethical<br>principles, and promoting the well-being of society.</i>"
          ],
          [
           "Beneficence",
           " <i>Policy guidance on AI for children</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution, International Organization",
           " Northern Europe, Intergovernmental Organization",
           " Finland, United Nations",
           " Beneficence",
           " <i>The opportunities that AI systems bring to children of all ages and backgrounds<br>– such as to support their education, health care, and right to play – need to<br>be fully leveraged when, and this is critical, it is appropriate to use AI<br>systems. Children need to be protected from any harmful and discriminatory<br>impacts of AI systems and safely interact with them. AI systems should also be<br>leveraged to actively protect children from harm and exploitation.</i>"
          ],
          [
           "Beneficence",
           " <i>Ethics & Governance of Artificial Intelligence for Health</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Beneficence",
           " <i>AI technologies should not harm people. The designers of AI technologies should<br>satisfy regulatory requirements for safety, accuracy, and efficacy for well-<br>defined use cases or indications.</i>"
          ],
          [
           "Beneficence",
           " <i>Thomson Reuters AI principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " Canada",
           " Beneficence",
           " <i>Thomson Reuters aims to design, develop and deploy AI products and services that<br>are reliable and that help empower people to make efficient, informed, and<br>socially beneficial decisions.</i>"
          ],
          [
           "Beneficence",
           " <i>National Association of Insurance Commissioners (NAIC) Principles on Artificial<br>Intelligence (AI)</i>",
           " 2020",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>AI systems should not be designed to harm or deceive people and should be<br>implemented in a manner that avoids harmful or unintended consequences and<br>corrects and remediates such consequences when they occur.</i>"
          ],
          [
           "Beneficence",
           " <i>Samsung Principles for AI Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " South Korea",
           " Beneficence",
           " <i>The company will strive to benefit the society and promote the corporate<br>citizenship though AI system.</i>"
          ],
          [
           "Beneficence",
           " <i>Ethical Aspects of Autonomous and Intelligent Systems</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>A/IS developers should consider the impact on individual and societal well-being<br>as the central criterion in development.</i>"
          ],
          [
           "Beneficence",
           " <i>IEEE Policies - Code of Ethics</i>",
           " 2022",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>We, the members of the IEEE, o hereby commit ourselves to the highest ethical<br>and professional conduct and agree to hold paramount the safety, health, and<br>welfare of the public, to strive to comply with ethical design and sustainable<br>development practices, to protect the privacy of others, and to disclose<br>promptly factors that might endanger the public or the environment.</i>"
          ],
          [
           "Beneficence",
           " <i>Safe Face Pledge</i>",
           " 2021",
           " Recommendation",
           " Academic, Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>Do not contribute to applications that risk human life. By acknowledging that<br>decisions that foreseeably increase the risk to human life are too dangerous for<br>artificial intelligence, and by refraining from selling or providing facial<br>analysis technologies to locate or identify targets in operations where lethal<br>force may be used or is contemplated.</i>"
          ],
          [
           "Beneficence",
           " <i>Artificial intelligence - Common good as a benchmark, good work as a principle</i>",
           " 2019",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Beneficence",
           " <i>Common good requires the legislative and social partnership development of clear<br>criteria for the good design of working conditions that are affected by<br>artificial intelligence. This includes not only questions of work intensity,<br>mental stress, and illnesses, but also plans to deal with the consequences of<br>employment, for example reducing working hours and developing new fields of<br>employment.</i>"
          ],
          [
           "Beneficence",
           " <i>The Code of Ethics in the Field of Artificial Intelligence</i>",
           " 2022",
           " Recommendation",
           " Unspecified",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Beneficence",
           " <i>The key priority of ai technologies development is the protection of the<br>interests and rights of human beings at large and every person in particular. AI<br>Actors should not allow the use of AI technologies to cause harm to human life<br>and/or health, the property of citizens and legal entities, and the environment.<br>Any use, including the design, development, testing, integration, or operation<br>of an AI system capable of purposefully causing harm to the environment, human<br>life and/or health, the property of citizens, and legal entities, is prohibited.</i>"
          ],
          [
           "Beneficence",
           " <i>Chinese Young Scientists' Declaration on the Governance and Innovation of<br>Artificial Intelligence (Shanghai Declaration)</i>",
           " 2019",
           " Recommendation",
           " Academic, Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Asia",
           " China",
           " Beneficence",
           " <i>Artificial Intelligence should prioritize human well-being. We are committed to<br>highlighting people's livelihood through applied artificial intelligence<br>research and development, examining the digital wellbeing of users, and creating<br>a carefree and happy working and lifestyle.</i>"
          ],
          [
           "Beneficence",
           " <i>Trustworthy AI in Aotearoa: AI Principles</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " Oceania",
           " New Zealand",
           " Beneficence",
           " <i>Where appropriate, AI stakeholders should design, develop and use AI systems to<br>promote, as much as possible, the wellbeing of New Zealand’s people and<br>environment in areas such as health, education, employment, sustainability,<br>diversity, inclusion, and recognition of the unique values of Te Ao Māori.</i>"
          ],
          [
           "Beneficence",
           " <i>Harmonious Artificial Intelligence Principles</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Beneficence",
           " <i>AI needs to keep humans safe, on the basis that this safety consideration does<br>not, directly and indirectly, harm human society. What humans do not want AI to<br>do to a human, humans should not do unto AI.</i>"
          ],
          [
           "Beneficence",
           " <i>Fu Ying: Six Principles of Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Beneficence",
           " <i>The development of artificial intelligence should serve the common well-being<br>and interests of mankind. Artificial intelligence must not harm human beings.<br>Artificial intelligence technology must be used for peaceful purposes, and<br>efforts should be made to enhance transparency and confidence-building measures,<br>promote the peaceful use of artificial intelligence, and prevent an arms race of<br>lethal autonomous weapons.</i>"
          ],
          [
           "Beneficence",
           " <i>A Framework for the Ethical use of advanced Data Science Methodes in the<br>Humanitarian Sector</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe, Intergovernmental Organization",
           " Netherlands, United Nations",
           " Beneficence",
           " <i>The purpose of humanitarian action is to protect life and health and ensure<br>respect for human beings, and this should always be the priority over financial<br>or operational improvements. Ensuring dignity while reducing vulnerabilities<br>should not be at the cost of rendering affected communities as “test beds” or<br>“testing sites”. Technologies that would never be applied, nor allowed in<br>countries like the UK or US due to legal and regulatory barriers must not be<br>applied for piloting capacity through humanitarian actions.</i>"
          ],
          [
           "Beneficence",
           " <i>Unified Ethical Frame for Big Data Analysis</i>",
           " 2014",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>Both the discovery and application phases require an organization to define the<br>benefits that will be created by the analytics and should identify the parties<br>that gain tangible value from the effort. The act of big data analytics may<br>create risks for some individuals and benefits for others or society as a whole.<br>Those risks must be counter-balanced by the benefits created for individuals,<br>organizations, political entities, and society as a whole.</i>"
          ],
          [
           "Beneficence",
           " <i>Technological convergence, artificial intelligence and human rights</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Beneficence",
           " <i>The Assembly reiterates its call made in Resolution 2051 (2015) “Drones and<br>targeted killings: the need to uphold human rights and international law” to all<br>member States and observer States, as well as States whose parliaments have<br>observer status with the Assembly, to refrain from any automated (robotic)<br>procedures for selecting individuals for targeted killings or any sort of injury<br>based on communication patterns or other data collected through mass<br>surveillance techniques. This should be true not only for drones but also for<br>other combat equipment with artificial intelligence systems, as well as other<br>equipment and/or software that might potentially inflict damage on people,<br>property, personal data, or information databases, or interfere with privacy,<br>freedom of expression, or the right to equality and non-discrimination.</i>"
          ],
          [
           "Beneficence",
           " <i>Decree of the President of the Russian Federation on the Development of<br>Artificial Intelligence in the Russian Federation</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Beneficence",
           " <i>The basic principles of the development and use of artificial intelligence<br>technologies, the observance of which is obligatory during the implementation of<br>this Strategy, include: the impermissibility of the use of artificial<br>intelligence to intentionally inflict harm on individuals and legal entities.<br>The goals of the development of artificial intelligence in the Russian<br>Federation shall consist of ensuring the improvement of the well-being and<br>quality of life of its population, ensuring national security and rule of law,<br>and achieving the sustainable competitiveness of the Russian economy, including<br>leading positions the world over in the field of artificial intelligence.</i>"
          ],
          [
           "Beneficence",
           " <i>Allen Institute for Artificial Intelligence Core Values</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Academic, Non-profit Organization",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>Our mission is to build AI for the common good. We aim to produce breakthrough<br>research and tools that move the needle in AI, empower the research community,<br>and benefit society.</i>"
          ],
          [
           "Beneficence",
           " <i>Stanford's Human-Centered AI Initiative Values</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Academic",
           " North America",
           " United States of America",
           " Beneficence",
           " <i>We value the well-being of humans and humanity and are committed to ensuring<br>that the power of AI is used to improve the human condition, not diminish it. As<br>such, we focus on applications that augment and enhance human capabilities<br>rather than simply displacing or replacing them. In a time of increasing<br>automation, we aim to better understand its implications and find technical as<br>well as policy mechanisms to manage this transition. We study the global impact<br>of AI on the economy and society, in hopes of promoting positive outcomes and<br>mitigating the negative.</i>"
          ]
         ],
         "hovertemplate": "<b>Document ID </b>=%{customdata[1]}<br><b>Year of Publication </b>=%{customdata[2]}<br><b>Reguation Type </b>=%{customdata[3]}<br><b>Institution Type </b>=%{customdata[4]}<br><b>World Region </b>=%{customdata[5]}<br><b>Country </b>=%{customdata[6]}<br><b>Principle </b>=%{customdata[7]}<br><b>Description </b>=%{customdata[8]}<extra></extra>",
         "legendgroup": "Beneficence",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Beneficence",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          -8.521136,
          14.474954,
          -3.4426446,
          7.853884,
          -11.360066,
          -0.43015096,
          -7.306281,
          0.7173237,
          19.546314,
          3.6127298,
          -10.788626,
          -24.149096,
          12.069647,
          4.850466,
          -3.2788982,
          -0.96427345,
          -1.6355292,
          18.342999,
          6.480284,
          14.696809,
          14.142713,
          5.045444,
          5.984814,
          12.745231,
          -5.3994436,
          10.017061,
          9.426056,
          -8.254664,
          4.4027576,
          3.5810442,
          -6.5611224,
          3.5375242,
          19.064112,
          -0.17200994,
          -2.3336267,
          -6.3283706,
          0.89911133,
          -0.7402302,
          3.8146844,
          4.097048,
          -24.66754,
          15.804998,
          19.33794,
          4.522447,
          0.31866968,
          -5.106185,
          -3.0290685,
          14.413937,
          24.135128,
          -11.888561,
          4.0178556,
          -3.2047782,
          2.5343776,
          -4.3415956,
          -6.002135,
          20.346336,
          -3.5485775,
          -8.803559,
          5.0336437,
          0.294151,
          -6.591779,
          2.6636348,
          3.720098,
          -2.4747958,
          -6.178151,
          2.3654935,
          10.761674,
          8.733644,
          -1.1747236,
          5.8912826,
          -3.3102407,
          3.1900835,
          3.0984225,
          -0.5217099,
          17.306656,
          -0.44194588,
          -9.068028,
          -1.3509853,
          -8.146981,
          1.5756308,
          14.1777,
          15.693405,
          -11.078827,
          10.957094,
          -2.6159835,
          5.846356,
          11.774571,
          -5.901651,
          -1.0440884,
          9.115573,
          -2.9076405,
          -5.4140096,
          -0.99491405,
          5.213387,
          6.6083684
         ],
         "y": [
          16.732864,
          15.430121,
          -3.956216,
          15.37094,
          -22.901232,
          -16.241589,
          0.57289755,
          -1.1835874,
          -0.9879599,
          -1.1349177,
          -0.15160543,
          7.742369,
          1.3649626,
          -4.521339,
          14.911625,
          -2.6670334,
          -0.843167,
          18.584108,
          -15.015149,
          -11.123505,
          -10.354108,
          -8.568809,
          -3.203158,
          9.271533,
          -16.878588,
          14.567794,
          7.548862,
          -20.17909,
          8.379681,
          -14.055309,
          -4.608429,
          -2.1667864,
          -5.994941,
          -15.23972,
          17.549133,
          -3.9314332,
          -25.162256,
          14.227894,
          7.0454698,
          23.031866,
          2.204823,
          -9.877049,
          -4.597554,
          20.062206,
          21.71203,
          -7.950562,
          -6.3711147,
          -10.624159,
          -2.3797548,
          -24.553196,
          -26.134645,
          -1.3250638,
          -5.4065185,
          -5.460768,
          -1.4352921,
          11.333981,
          0.5192105,
          1.394084,
          -14.191298,
          4.83715,
          -6.1845675,
          -0.9301702,
          14.494964,
          -3.029043,
          -8.573701,
          -5.059094,
          -8.162625,
          -8.796515,
          16.392145,
          -12.110796,
          -20.240091,
          -22.374834,
          -17.372347,
          1.3798174,
          -8.089795,
          7.564653,
          -2.2187152,
          -21.141876,
          -2.8350697,
          -15.20171,
          9.106586,
          15.214222,
          1.8103232,
          -16.145903,
          -2.7626555,
          -8.225011,
          -1.0313538,
          -1.0039095,
          -0.52511907,
          24.705605,
          15.3565035,
          -0.21154736,
          -17.999634,
          -20.708921,
          -10.697018
         ],
         "z": [
          0.5154764,
          16.238945,
          -3.2930796,
          16.470242,
          7.9867773,
          2.090079,
          9.601847,
          16.429468,
          14.24504,
          14.658611,
          7.3119903,
          10.954269,
          -20.486902,
          28.487305,
          -16.624956,
          9.242619,
          18.797045,
          3.687073,
          1.0885106,
          -16.997576,
          -18.192831,
          5.2052703,
          12.368857,
          13.878046,
          11.884363,
          -19.645191,
          -21.85441,
          2.7335274,
          -22.135603,
          -7.562507,
          19.358246,
          16.81569,
          -14.011098,
          2.6953428,
          -10.021289,
          11.843392,
          10.545573,
          -20.293898,
          -21.810465,
          1.3777064,
          7.0468154,
          -15.131673,
          -0.5562025,
          5.2280426,
          -7.081379,
          1.1354411,
          23.152464,
          -6.22015,
          2.4408278,
          -5.6952014,
          -8.688827,
          16.438297,
          18.008886,
          21.229187,
          19.82884,
          1.1974595,
          12.49014,
          10.5415,
          2.688637,
          21.5918,
          18.875975,
          8.819573,
          -12.706548,
          14.56944,
          19.123337,
          5.6250525,
          4.672368,
          7.0976624,
          19.981903,
          3.1992366,
          -2.1794822,
          3.9869483,
          5.9787107,
          7.8234735,
          -14.399808,
          21.622398,
          9.558793,
          -14.970673,
          11.513866,
          -2.5123348,
          13.250968,
          8.888855,
          13.273967,
          15.658506,
          8.984922,
          13.50879,
          10.953297,
          10.366324,
          16.916937,
          -5.9581456,
          -14.879545,
          25.570349,
          20.527172,
          0.12520324,
          11.033326
         ]
        },
        {
         "customdata": [
          [
           "Children Rights",
           " <i>Kakao Algorithm Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " South Korea",
           " Children Rights",
           " <i>Kakao strives to help children and adolescents, the future of our society, grow<br>into healthy individuals in a clean and healthy digital world. Kakao will<br>dedicate constant attention and resources to creating an environment to protect<br>children and adolescents from information and risks that can be mentally and<br>physically harmful.</i>"
          ],
          [
           "Children Rights",
           " <i>10 ethical guidelines for the digitalisation of companies (10 ethische<br>Leitlinien für die Digitalisierung von Unternehmen)</i>",
           " 2017",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Children Rights",
           " <i>Online content, services, and offerings shall be designed and optimized in the<br>context of the responsibility to protect and optimize in such a way that<br>children, adolescents, and people with low digital sovereignty are not<br>endangered or deliberately exploited.</i>"
          ],
          [
           "Children Rights",
           " <i>Ethically Aligned Design: A Vision for Prioritizing Human Well-being with<br>Autonomous and Intelligent Systems, Version 2</i>",
           " 2017",
           " Recommendation",
           " Professional Association",
           " North America",
           " United States of America",
           " Children Rights",
           " <i>Additional protections must be put in place for vulnerable populations, such as<br>children, when informed consent cannot be obtained, or when it may not be a<br>sufficient safeguard.</i>"
          ],
          [
           "Children Rights",
           " <i>Telia Company Guiding Principles on trusted AI ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Sweden",
           " Children Rights",
           " <i>We aim to know and show how we respect human rights. We seek to identify,<br>prevent, mitigate and account for how we address our impacts on human rights and<br>how we manage human rights risks and opportunities, such as privacy, children’s<br>rights, and anti-discrimination.</i>"
          ],
          [
           "Children Rights",
           " <i>Opinion of the Data Ethics Commission</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Children Rights",
           " <i>The Data Ethics Commission calls for action against the significant enforcement<br>gap that exists with regard to the statutory protection of children and young<br>people in the digital sphere. Particular attention should be paid to the<br>development and mandatory provision of technologies (including effective<br>identity management) and default settings that not only guarantee reliable<br>protection of children and young people but that are also family-friendly, i.e.<br>that neither demand too much of parents or guardians nor allow or even encourage<br>excessive surveillance in the home environment.</i>"
          ],
          [
           "Children Rights",
           " <i>Report with recommendations to the Commission on Civil Law Rules on Robotics</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " European Union",
           " European Union",
           " Children Rights",
           " <i>The European Parliament underlines the need to address the psychological and<br>societal impact of human-robot interaction as well as the dual character of the<br>impact of technology on human capabilities, with special attention for<br>vulnerable groups, in particular children, to avoid creating harmful dependence<br>on robots, e.g., through the evocation of emotional response, or isolation of<br>these humans from reality.</i>"
          ],
          [
           "Children Rights",
           " <i>Ethical Framework for Artificial Intelligence in Colombia (Marco Ético para la<br>Inteligencia Artificial en Colombia)</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Latin America",
           " Colombia",
           " Children Rights",
           " <i>It is necessary to create guidelines that protect and materialize the best<br>interests of the child in this particular context. Artificial intelligence<br>systems must recognize, respect, and privilege the rights of children and<br>adolescents.</i>"
          ],
          [
           "Children Rights",
           " <i>Artificial Intelligence for Children: Beijing Principles</i>",
           " 2020",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Children Rights",
           " <i>The development of AI should protect and promote the benefits of children, avoid<br>depriving and harming children's rights, and help realize the healthy growth of<br>children. The development of AI should give priority to benefiting children. The<br>research, design, development, deployment, and use of AI should prioritize the<br>needs, rights, and interests of children, prioritize the adequate protection of<br>children, and prioritize the promotion of children's development.</i>"
          ],
          [
           "Children Rights",
           " <i>A Framework for Responsible Limits on Facial RecognitionUse Case: Flow<br>Management</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization",
           " Western Europe",
           " Switzerland",
           " Children Rights",
           " <i>Facial recognition should not exclude anyone and should always be accessible to<br>and usable by all groups of people, including elderly people and people with<br>disabilities. It is recognized that there may be some instances, such as infants<br>and children, in which an exception to this principle is appropriate and an<br>alternative to facial identification should be offered.</i>"
          ],
          [
           "Children Rights",
           " <i>Advisory statement on human ethics in artificial intelligence and big data<br>research (2017)</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Children Rights",
           " <i>Take particular measures to protect the rights of children and other vulnerable<br>individuals.</i>"
          ],
          [
           "Children Rights",
           " <i>UNESCO Recommendation on the Ethics of Artificial Intelligence</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Children Rights",
           " <i>Member States should ensure that the development and deployment of AI systems<br>related to health in general and mental health in particular, paying due<br>attention to children and youth, is regulated to the effect that they are safe,<br>effective, efficient, scientifically and medically proven and enable evidence-<br>based innovation and medical progress.</i>"
          ],
          [
           "Children Rights",
           " <i>Policy guidance on AI for children</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution, International Organization",
           " Northern Europe, Intergovernmental Organization",
           " Finland, United Nations",
           " Children Rights",
           " <i>Empower governments and businesses with knowledge of AI and children’s rights.<br>You must know what my rights are and uphold them.</i>"
          ]
         ],
         "hovertemplate": "<b>Document ID </b>=%{customdata[1]}<br><b>Year of Publication </b>=%{customdata[2]}<br><b>Reguation Type </b>=%{customdata[3]}<br><b>Institution Type </b>=%{customdata[4]}<br><b>World Region </b>=%{customdata[5]}<br><b>Country </b>=%{customdata[6]}<br><b>Principle </b>=%{customdata[7]}<br><b>Description </b>=%{customdata[8]}<extra></extra>",
         "legendgroup": "Children Rights",
         "marker": {
          "color": "#ab63fa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Children Rights",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          -10.054379,
          0.7752457,
          -2.1688814,
          6.715892,
          0.07295194,
          -1.0916853,
          0.73999155,
          1.6901052,
          11.2155695,
          -0.83987665,
          -2.139852,
          8.482012
         ],
         "y": [
          -24.812862,
          25.696735,
          26.015991,
          23.565079,
          23.77932,
          -9.023138,
          9.554036,
          6.423693,
          21.246765,
          26.664873,
          5.395861,
          6.73006
         ],
         "z": [
          8.698948,
          -5.5892587,
          -1.9395041,
          9.098222,
          -6.394309,
          23.873516,
          21.952356,
          21.95349,
          -0.26609844,
          -2.0687404,
          21.288208,
          21.125774
         ]
        },
        {
         "customdata": [
          [
           "Cooperation",
           " <i>Responsible AI: A Global Policy Framework</i>",
           " 2021",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization, Professional Association",
           " North America",
           " United States of America",
           " Cooperation",
           " <i>Organisations that develop make available, or use AI systems and any national<br>laws that regulate such use shall, without prejudice to normal rules of<br>intellectual property and privacy, foster open access and encourage open-source<br>frameworks and software for AI systems.</i>"
          ],
          [
           "Cooperation",
           " <i>AI at Google: our principles</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Cooperation",
           " <i>We will continue to thoughtfully evaluate when to make our technologies<br>available on a non-commercial basis.</i>"
          ],
          [
           "Cooperation",
           " <i>Responsible use of artificial intelligence (AI)</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Cooperation",
           " <i>To ensure the effective and ethical use of AI the government will: be as open as<br>we can by sharing source code, training data, and other relevant information,<br>all while protecting personal information, system integration, and national<br>security and defense.</i>"
          ],
          [
           "Cooperation",
           " <i>IBM’s Principles for Trust and Transparency</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Cooperation",
           " <i>IBM views the free movement of data across borders as essential to 21st century<br>commerce.</i>"
          ],
          [
           "Cooperation",
           " <i>China’s Artificial Intelligence Industry Alliance Self-discipline Convention</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Cooperation",
           " <i>Encourage open source and open resources such as platforms, tools, data, and<br>science and education; share artificial intelligence development dividends and<br>governance experience; strive to break data islands and platform monopolies;<br>continuously narrow the intelligence gap, and advance the deep integration of<br>artificial intelligence and the real economy.</i>"
          ],
          [
           "Cooperation",
           " <i>Mid- to Long-Term Master Plan in Preparation for the Intelligent Information<br>Society Managing the Fourth Industrial Revolution</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " South Korea",
           " Cooperation",
           " <i>Minimize the monopolistic and oligopolistic practices of platforms using the<br>networking effect by finding and fostering an appropriate environment of fair<br>competition.</i>"
          ],
          [
           "Cooperation",
           " <i>Charlevoix Common Vision for the Future of Artificial Intelligence</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " International Organization",
           " Intergovernmental Organization",
           " G7",
           " Cooperation",
           " <i>We, the leaders of the G7, commit to supporting an open and fair market<br>environment including the free flow of information while respecting applicable<br>frameworks for privacy and data protection for AI innovation by addressing<br>discriminatory trade practices, such as forced technology transfer.</i>"
          ],
          [
           "Cooperation",
           " <i>Next-Generation AI Governance Principles - Develop responsible artificial<br>intelligence</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Cooperation",
           " <i>Encourage exchanges and cooperation across disciplines, domains, regions, and<br>borders; promote coordination and interaction between international<br>organizations, government departments, research institutions, educational<br>institutions, enterprises, social organizations, and the public for the<br>development and governance of AI. Launch international dialogue and cooperation;<br>with full respect for each country's principles and practices for AI governance,<br>promote the formation of a broad consensus on an international AI governance<br>framework, standards, and norms.</i>"
          ],
          [
           "Cooperation",
           " <i>Draft AI R&D Guidelines for International Discussions</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Cooperation",
           " <i>AI developers are obliged to ensure interconnectivity and interoperability<br>between AI systems that have been developed and other AI systems.</i>"
          ],
          [
           "Cooperation",
           " <i>Toward a G20 Framework for Artificial Intelligence in the Workplace</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " Canada",
           " Cooperation",
           " <i>AI should benefit as many people as possible. Access to AI technologies should<br>be open to all countries. The wealth created by AI should benefit workers and<br>society as a whole, as well as the innovators.</i>"
          ],
          [
           "Cooperation",
           " <i>For a meaningful Artificial Intelligence - Towards a French and European<br>strategy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Cooperation",
           " <i>As regards questions of technological and economic sovereignty and questions of<br>efficiency and performance alike, it is essential to prioritize the use of open<br>technologies (“open source” and “open hardware”) as much as possible, so as not<br>to fall victim to close shop mindsets.</i>"
          ],
          [
           "Cooperation",
           " <i>Facebook and Google: This is What an Effective Ad Archive API Looks Like</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Cooperation",
           " <i>A functional, open API should have itself and any data collected from the API<br>should be accessible to and shareable with the general public.</i>"
          ],
          [
           "Cooperation",
           " <i>Digital Technology and Healthcare which ethical issues for which regulations?</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " France",
           " Cooperation",
           " <i>The sharing of research data according to ‘FAIR’ (findable, accessible,<br>interoperable, reusable) principles is a crucial factor for the development of<br>world-class scientific research in healthcare and in helping to guarantee the<br>reproducibility and validity of results.</i>"
          ],
          [
           "Cooperation",
           " <i>Business Ethics and Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " Western Europe",
           " United Kingdom",
           " Cooperation",
           " <i>Opening sourcing material in computer science, when appropriate, is an important<br>step. It helps the development community to understand better how AI works and<br>therefore be able to explain it more accurately to the public and the media.<br>This is particularly important as better information within the general public<br>improves trust and prevents unjustified fears. Moreover, the more people have<br>access to the code, the more likely it is that bugs and long-term opportunities<br>and risks can be worked out.</i>"
          ],
          [
           "Cooperation",
           " <i>Asilomar AI Principles</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Cooperation",
           " <i>A culture of cooperation, trust, and transparency should be fostered among<br>researchers and developers of AI. Teams developing AI systems should actively<br>cooperate to avoid corner-cutting on safety standards. AI technologies should<br>benefit and empower as many people as possible. The economic prosperity created<br>by AI should be shared broadly, to benefit all of humanity.</i>"
          ],
          [
           "Cooperation",
           " <i>Code of Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Professional Association",
           " North America",
           " United States of America",
           " Cooperation",
           " <i>Software engineers shall be fair to and supportive of their colleagues.</i>"
          ],
          [
           "Cooperation",
           " <i>AI 4People 's Ethical Framework for a Good AI Society: Opportunities, Risks,<br>Principles, and Recommendations</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Cooperation",
           " <i>AI developers should respect the interests of all parties that may be impacted<br>by AI advances. Stakeholders should incentivize financially cross-disciplinary<br>and cross-sectoral cooperation and debate concerning the intersections between<br>technology, social issues, legal studies, and ethics.</i>"
          ],
          [
           "Cooperation",
           " <i>AI & Data Topical Guide Series</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Southern Africa",
           " South Africa",
           " Cooperation",
           " <i>In developing South Africa’s national strategy on AI, specific attention should<br>be paid to how data and AI can be used to address South Africa’s socio-economic<br>inequalities, and economically empower disadvantaged individuals and<br>communities, which includes taking proactive measures against the economic<br>monopolization of data-driven technologies and enabling infrastructure, through<br>consultation with the Competition Commission.</i>"
          ],
          [
           "Cooperation",
           " <i>Ethically Aligned Design: A Vision for Prioritizing Human Well-being with<br>Autonomous and Intelligent Systems, Version 2</i>",
           " 2017",
           " Recommendation",
           " Professional Association",
           " North America",
           " United States of America",
           " Cooperation",
           " <i>Funding models and institutional incentive structures should be reviewed and<br>revised to prioritize projects with interdisciplinary ethics components to<br>encourage the integration of ethics into projects at all levels. Encourage<br>global standardization/ harmonization and open source software for A/IS.</i>"
          ],
          [
           "Cooperation",
           " <i>Privacy and Freedom of Expression In the Age of Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " Western Europe",
           " United Kingdom",
           " Cooperation",
           " <i>It is important to emphasize the need to develop knowledge-exchange programs and<br>facilitate joint-strategy development between civil society organizations. So<br>far, academia and industry have taken the lead in moving the debate on the<br>societal impact of AI forward. While civil society actors play a crucial role in<br>these debates, it is important to strengthen the voice of those working on<br>technology in the public interest.</i>"
          ],
          [
           "Cooperation",
           " <i>Artificial intelligence and the work of tomorrow (Künstliche Intelligenz und die<br>Arbeit von Morgen)</i>",
           " 2019",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Cooperation",
           " <i>Relevant stakeholders for these processes - developers as well as employers and<br>employees - should already work together at the beginning of the development of<br>AI systems to jointly agree on and document the optimization goals for<br>operational use, including work design. In this way, possible conflicting goals<br>should be explored at this early stage.</i>"
          ],
          [
           "Cooperation",
           " <i>Ethics Framework - Responsible AI</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Cooperation",
           " <i>The value exchange between those who provide the data (or label it), directly or<br>otherwise, and the company, should be considered for fairness. If data are used<br>from public sources (e.g., open data collected by a public body or NGO) the<br>company should consider whether it may contribute back or support the work of<br>ongoing data maintenance, perhaps by providing cleaned or corrected data.<br>Integrity and fair dealing should be an integral part of organizational culture.<br>Companies should consider what structures and processes are being employed to<br>drive revenue or other material value to the organization as certain business<br>models or pricing strategies can result in discrimination. Where possible and<br>appropriate, companies should consider whether part of the product, service, or<br>data can be made available to the public.</i>"
          ],
          [
           "Cooperation",
           " <i>AI Ethics Principles & Guidelines</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Middle East",
           " United Arab Emirates",
           " Cooperation",
           " <i>Nations should collaborate to avoid an arms race in lethal autonomous weapons,<br>and such weapons should be tightly controlled. Active cooperation should be<br>pursued to avoid corner-cutting on safety standards. Global cooperation should<br>be encouraged to ensure the safe governance of AI.</i>"
          ],
          [
           "Cooperation",
           " <i>Beijing AI Principles</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Eastern Asia",
           " China",
           " Cooperation",
           " <i>It is encouraged to establish AI open platforms to avoid data/platform<br>monopolies, to share the benefits of AI development to the greatest extent, and<br>to promote equal development opportunities for different regions and industries.<br>: Cooperation should be actively developed to establish an interdisciplinary,<br>cross-domain, cross-sectoral, cross-organizational, cross-regional, global, and<br>comprehensive AI governance ecosystem, to avoid malicious AI race, to share AI<br>governance experience, and to jointly cope with the impact of AI with the<br>philosophy of “Optimizing Symbiosis”.</i>"
          ],
          [
           "Cooperation",
           " <i>Artificial Intelligence in Healthcare</i>",
           " 2019",
           " Recommendation",
           " Academic",
           " Western Europe",
           " United Kingdom",
           " Cooperation",
           " <i>For those who meet information handling and governance standards, data should be<br>made more easily available across the private and public sectors.</i>"
          ],
          [
           "Cooperation",
           " <i>Code of Ethics for Data-Based Value Creation</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Switzerland",
           " Cooperation",
           " <i>You should consider a fair distribution of benefits and burdens. This basic<br>orientation includes, among other things, the value of solidarity (e.g., by<br>making data available to the public for collective use).</i>"
          ],
          [
           "Cooperation",
           " <i>Responsible AI and robotics: An ethical framework</i>",
           " Unspecified",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Cooperation",
           " <i>The government should encourage discussion on the ethics of AI, and ensure all<br>relevant parties are involved. Bringing together the private sector, consumer<br>groups, and academia would allow the development of an ethical code that keeps<br>up with technological, social, and political developments. Government efforts<br>should be collaborative with existing efforts to research and discuss ethics in<br>AI.</i>"
          ],
          [
           "Cooperation",
           " <i>AI Now Report 2018</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Cooperation",
           " <i>Vendors and developers who create AI and automated decision systems for use in<br>government should agree to waive any trade secrecy or other legal claim that<br>inhibits full auditing and understanding of their software.</i>"
          ],
          [
           "Cooperation",
           " <i>Tokyo Statement - Useful Artificial Intelligence- Beneficial AI -Cooperation for<br>Realization</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Asia",
           " Japan",
           " Cooperation",
           " <i>We urge you to address the challenges of ensuring the benefits of artificial<br>intelligence in a spirit of cooperation rather than competition. We should work<br>together to ensure that artificial intelligence contributes to the sustainable<br>prosperity of humankind around the world.  Collaboration must be global.<br>Artificial intelligence has a great impact on all cultures and nations.<br>Therefore, all cultures and nations should speak about how artificial<br>intelligence is developed and used. Artificial intelligence has the potential to<br>be one of the best achievements humanity can achieve. We must work together to<br>make it a reality.</i>"
          ],
          [
           "Cooperation",
           " <i>Opinion of the Data Ethics Commission</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Cooperation",
           " <i>In the world, as it stands today, access to digital resources via the Internet<br>is a fundamental requirement for digital and thus also social participation. As<br>part of its public provision remit, the State is obliged to ensure that its<br>citizens can access up-to-date Internet infrastructure anywhere in the country<br>and to an adequate extent, using either a fixed or a mobile connection. As part<br>of its educational remit, it must provide its citizens with the skills needed<br>for self-determined navigation of the digital world and for an accurate<br>appraisal of the opportunities and risks of Internet use.</i>"
          ],
          [
           "Cooperation",
           " <i>Artificial Intelligence and Data Protection</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Cooperation",
           " <i>AI developers, manufacturers, and service providers are encouraged to set up and<br>consult independent committees of experts from a range of fields, as well as<br>engage with independent academic institutions, which can contribute to designing<br>human rights-based and ethically and socially-oriented AI applications, and to<br>detecting potential bias. Such committees may play a particularly important role<br>in areas where transparency and stakeholder engagement can be more difficult due<br>to competing interests and rights, such as in the fields of predictive justice,<br>crime prevention, and detection. Individuals, groups, and other stakeholders<br>should be informed and actively involved in the debate on what role AI should<br>play in shaping social dynamics and in decision-making processes affecting them.</i>"
          ],
          [
           "Cooperation",
           " <i>Report with recommendations to the Commission on Civil Law Rules on Robotics</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " European Union",
           " European Union",
           " Cooperation",
           " <i>The European Parliament stresses the importance of measures to help small and<br>medium-sized enterprises and start-ups in the robotics sector that create new<br>market segments in this sector or make use of robots.</i>"
          ],
          [
           "Cooperation",
           " <i>Preparing for the future of Artificial Intelligence</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Cooperation",
           " <i>Federal agencies should prioritize open training data and open data standards in<br>AI. The government should emphasize the release of datasets that enable the use<br>of AI to address social challenges. Potential steps may include developing an<br>“Open Data for AI” initiative to release a significant number of government data<br>sets to accelerate AI research and galvanize the use of open data standards and<br>best practices across government, academia, and the private sector.</i>"
          ],
          [
           "Cooperation",
           " <i>Vienna Manifesto on Digital Humanism</i>",
           " 2019",
           " Recommendation",
           " Academic",
           " Central Europe",
           " Austria",
           " Cooperation",
           " <i>Regulators need to intervene with tech monopolies. It is necessary to restore<br>market competitiveness as tech monopolies concentrate market power and stifle<br>innovation. Governments should not leave all decisions to markets.</i>"
          ],
          [
           "Cooperation",
           " <i>Artificial Intelligence: Economic importance, social challenges, human<br>responsibility</i>",
           " 2017",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Cooperation",
           " <i>One focus should lay on interdisciplinary applied research. Domain-specific<br>knowledge from areas such as medicine, law, manufacturing technology, financial<br>services, logistics, etc. must be more closely connected with AI knowledge.<br>Cooperation between universities and the industry should be intensified to<br>develop practical training and education modules. To apply AI’s potential for<br>improving life in a digital society, we will require a digital ethics agenda,<br>for which policymakers should collaborate with scientists.</i>"
          ],
          [
           "Cooperation",
           " <i>Machine learning: the power and promise of computers that learn by example</i>",
           " 2017",
           " Recommendation",
           " Academic",
           " Western Europe",
           " United Kingdom",
           " Cooperation",
           " <i>Good progress in increasing the accessibility of public sector data has<br>positioned the UK as a leader in this area; continued efforts are needed in a<br>new wave of ‘open data for machine learning’ by Government to enhance the<br>availability and usability of public sector data while recognizing the value of<br>strategic datasets.</i>"
          ],
          [
           "Cooperation",
           " <i>Guidance for Regulation of Artificial Intelligence Applications</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Cooperation",
           " <i>Consistent with law, agencies should take into consideration the following<br>principles when formulating regulatory and non-regulatory approaches to the<br>design, development, deployment, and operation of AI applications, both general<br>and sector-specific. These principles, many of which are interrelated, reflect<br>the goals and principles in Executive Order 13859. Agencies should coordinate<br>with each other to share experiences and to ensure consistency and<br>predictability of AI-related policies that advance American innovation and<br>growth in AI, while appropriately protecting privacy, civil liberties, and<br>American values and allowing for the sector- and application-specific approaches<br>when appropriate.</i>"
          ],
          [
           "Cooperation",
           " <i>AI in the UK: ready, willing and able?</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Cooperation",
           " <i>We recommend that wherever possible and appropriate, and with regard to its<br>potential commercial value, publicly-held data be made available to AI<br>researchers and developers.</i>"
          ],
          [
           "Cooperation",
           " <i>Preliminary Study on the Ethics of Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Cooperation",
           " <i>AI should be integrated into national development policies and strategies by<br>drawing on endogenous cultures, values, and knowledge to develop African<br>economies.  To contribute to peace, AI could be used to obtain insights into the<br>drivers of conflict, and should never operate out of human control.</i>"
          ],
          [
           "Cooperation",
           " <i>Top 10 Principles for Ethical Artificial Intelligence</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " Switzerland",
           " Cooperation",
           " <i>AI technologies should benefit and empower as many people as possible. The<br>economic prosperity created by AI should be distributed broadly and equally, to<br>benefit all of humanity. Global as well as national policies aimed at bridging<br>the economic, technological, and social digital divide are therefore necessary.<br>UNI recommends the establishment of multi-stakeholder Decent Work and Ethical AI<br>governance bodies on global and regional levels. The bodies should include AI<br>designers, manufacturers, owners, developers, researchers, employers, lawyers,<br>CSOs, and trade unions. Whistleblowing mechanisms and monitoring procedures to<br>ensure the transition to, and implementation of, ethical AI must be established.</i>"
          ],
          [
           "Cooperation",
           " <i>Montréal declaration for a responsible development of artificial intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " Canada",
           " Cooperation",
           " <i>The development of AIS must be compatible with maintaining the bonds of<br>solidarity among people and generations. Artificial intelligence research should<br>remain open and accessible to all. We should support the development of commons<br>algorithms — and of open data needed to train them — and expand their use, as a<br>socially equitable objective.</i>"
          ],
          [
           "Cooperation",
           " <i>Artificial Intelligence for Children: Beijing Principles</i>",
           " 2020",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Cooperation",
           " <i>Children, parents, legal guardians, or other caregivers, as well as governments,<br>relevant companies, civil society, and people from all walks of life, should be<br>encouraged to participate in the discussion of the potential impact of AI on<br>children. A cross-regional, global, and comprehensive AI governance open<br>cooperation platform should be established to share governance experience and<br>methods of AI for children, to promote the common development of global<br>governance of AI for children, and to empower the healthy development of<br>children all over the world in the era of AI.</i>"
          ],
          [
           "Cooperation",
           " <i>Social Principles of Human-Centric AI</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia, Western Europe",
           " Japan, United Kingdom",
           " Cooperation",
           " <i>A fair competitive environment must be maintained to create new businesses and<br>services, maintain sustainable economic growth, and present solutions to social<br>challenges. Even if resources related to AI are concentrated in a specific<br>country, we must not have a society where unfair data collection and<br>infringement of sovereignty are performed under that country's dominant<br>position. To realize Society 5.0 and aim for continuous innovation that advances<br>as people evolve together with AI development, we should transcend boundaries<br>such as national borders, industries, academia, governments, race, gender,<br>nationality, age, political convictions, and religion.</i>"
          ],
          [
           "Cooperation",
           " <i>The Toronto Declaration</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " North America, Western Europe",
           " Canada, United Kingdom",
           " Cooperation",
           " <i>We call on states and private sector actors to work together and play an active<br>and committed role in protecting individuals and groups from discrimination.<br>When creating and deploying machine learning systems, they must take meaningful<br>measures to promote accountability and human rights, including, but not limited<br>to, the right to equality and non-discrimination, as per their obligations and<br>responsibilities under international human rights law and standards.</i>"
          ],
          [
           "Cooperation",
           " <i>Position on Robotics and Artificial Intelligence</i>",
           " 2016",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Cooperation",
           " <i>We demand that software and its source code needs to be accessible and freely<br>useable, at least to the owner of a device and their deputies. Given the -<br>possibly unprecedentedly far-reaching - risks inherent to software coding<br>impacting citizens’ future lives and body integrity, the exclusive rights on<br>computer programs should be subject to reinforced exceptions (such as reverse<br>engineering, not to be overridden by contract) taking into account the specific<br>risk of these AI programs, be it present, imminent or potential. Algorithms not<br>protected by copyright but protected otherwise, e.g., by trade secrets, should<br>be subject to the same possibility of reverse-engineering. We call for a<br>revision and modification of the copyright rules and other exclusive rights<br>norms in order to explicitly allow this. We promote an open environment, from<br>open standards and innovative licensing models, to open platforms and<br>transparency, in order to avoid vendor lock-in that restrains interoperability.</i>"
          ],
          [
           "Cooperation",
           " <i>Governing Artificial Intelligence: Upholding human rights & dignity</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Cooperation",
           " <i>Since human rights principles were not written as technical specifications,<br>human rights lawyers, policymakers, social scientists, computer scientists, and<br>engineers should work together to operationalize human rights into business<br>models, workflows, and product design. Academics should further examine the<br>value, limitations, and interactions between human rights law and human dignity<br>approaches, humanitarian law, and ethics concerning emerging AI technologies.<br>Human rights and legal scholars should work with other stakeholders on the<br>tradeoffs between rights when faced with specific AI risks and harms. Social<br>science researchers should empirically investigate the on-the-ground impact of<br>AI on human rights.</i>"
          ],
          [
           "Cooperation",
           " <i>AI Governance in Japan Ver. 1.1, Report from the expert group on how AI<br>principles should be implemented</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Cooperation",
           " <i>A fair competitive environment must be maintained to create new businesses and<br>services, maintain sustainable economic growth, and present solutions to social<br>challenges. Even if resources related to AI are concentrated in a specific<br>country, we must not have a society where unfair data collection and<br>infringement of sovereignty are performed under that country's dominant<br>position. To realize Society 5.0 and aim for continuous innovation that advances<br>as people evolve together with AI development, we should transcend boundaries<br>such as national borders, industries, academia, governments, race, gender,<br>nationality, age, political convictions, and religion.</i>"
          ],
          [
           "Cooperation",
           " <i>Vodafone Artificial Intelligence Framework</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Cooperation",
           " <i>Vodafone will proactively participate in the scientific community, industry<br>coalitions, and self-regulatory bodies working on research, laws, regulations,<br>and ethical guidelines for AI, such as the EU High-Level Expert Group on AI.</i>"
          ],
          [
           "Cooperation",
           " <i>Artificial Intelligence at the service of the citizen (L’intelligenzia<br>artificiale al servizio del cittadino)</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Southern Europe",
           " Italy",
           " Cooperation",
           " <i>Recommendation - Enable with new resources the computational linguistic systems<br>for the Italian language (such as digitized lexicons or annotated corpora) to be<br>distributed with open licenses, in order to favor the development of services<br>based on the treatment of natural language. Support the collaboration between<br>research, business accelerators, and innovation hubs, both public and private,<br>also at the European level, to promote the adoption of AI solutions in the<br>public sector. Establish a Trans-disciplinary Centre on AI.</i>"
          ],
          [
           "Cooperation",
           " <i>The Ethical Norms for the New Generation Artificial Intelligence, China</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Cooperation",
           " <i>Various activities of AI shall abide by the following fundamental ethical norms,<br>like encourage cross-disciplinary, cross-domain, cross-regional, and cross-<br>border exchanges and cooperation, and promote the formation of AI governance<br>frameworks, standards, and norms with broad consensus.</i>"
          ],
          [
           "Cooperation",
           " <i>Work in the age of artificial intelligence: Four perspectives on the economy,<br>employment, skills and ethics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Finland",
           " Cooperation",
           " <i>The scaling of AI technology makes the creation of monopolies possible. Any<br>abuses of dominant market power should be intervened through smart regulation<br>and competition oversight. The central government should encourage<br>multidisciplinary and versatile research with closer links to basic research<br>which also builds up cooperation between universities, companies, and public<br>organizations. The universities’ performance guidance and incentive scheme<br>should be updated to create clear incentives for participating in cooperation<br>and network projects and commercialization of research. Experience has shown<br>that R&D funding should be increased gradually through a multiannual program<br>requiring commitment.</i>"
          ],
          [
           "Cooperation",
           " <i>Discussion Paper: National Strategy for Artificial Intelligence</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " South Asia",
           " India",
           " Cooperation",
           " <i>AI is a highly collaborative domain, and any framework aimed at promoting AI<br>needs to be aligned accordingly. A multi-pronged approach, involving various<br>stakeholders and promoting a collaborative approach is required for promoting<br>the development of AI tools as well as the adoption of AI in different fields of<br>activity.  Opening up government datasets. Establish platforms for making<br>datasets in the area of the social sector (either collected during the<br>implementation of a scheme or in normal business processes) available for open<br>public use in a machine-readable form.</i>"
          ],
          [
           "Cooperation",
           " <i>The National Artificial Intelligence Research and Development Strategic Plan:<br>2019 Update</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Cooperation",
           " <i>Develop shared public datasets and environments for AI training and testing.<br>Develop and enable access to high-quality datasets and environments, as well as<br>to testing and training resources. Expand public-private partnerships to<br>accelerate advances in AI. Promote opportunities for sustained investment in AI<br>R&D and for transitioning advances into practical capabilities, in collaboration<br>with academia, industry, international partners, and other non-Federal entities.</i>"
          ],
          [
           "Cooperation",
           " <i>The Holberton-Turing Oath</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Unspecified",
           " Unspecified",
           " Cooperation",
           " <i>I will respect the hard-won scientific gains of those scientists and engineers<br>in whose steps I walk, and gladly share such knowledge as is mine with those who<br>are to follow. I will share my knowledge for the benefit of the people and for<br>the advancement of Data-Science and Artificial Intelligence.</i>"
          ],
          [
           "Cooperation",
           " <i>OECD, Recommendation of the Council on Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " France",
           " Cooperation",
           " <i>Governments should also consider public investment and encourage private<br>investment in open datasets that are representative and respect privacy and data<br>protection to support an environment for AI research and development that is<br>free of inappropriate bias and to improve interoperability and use of standards.<br>Governments, including developing countries and stakeholders, should actively<br>co-operate to advance these principles and to progress on responsible<br>stewardship of trustworthy AI.  Governments should work together in the OECD and<br>other global and regional fora to foster the sharing of AI knowledge, as<br>appropriate. They should encourage international, cross-sectoral, and open<br>multi-stakeholder initiatives to garner long-term expertise on AI.</i>"
          ],
          [
           "Cooperation",
           " <i>OpenAI Charter</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization, Private Corporation",
           " North America",
           " United States of America",
           " Cooperation",
           " <i>We are concerned about late-stage AGI development becoming a competitive race<br>without time for adequate safety precautions. Therefore, if a value-aligned,<br>safety-conscious project comes close to building AGI before we do, we commit to<br>stop competing with and start assisting this project. We will actively cooperate<br>with other research and policy institutions; we seek to create a global<br>community working together to address AGI’s global challenges.</i>"
          ],
          [
           "Cooperation",
           " <i>Partnership on AI Tenets</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization",
           " Unspecified",
           " Unspecified",
           " Cooperation",
           " <i>We are committed to open research and dialogue on the ethical, social, economic,<br>and legal implications of AI. We strive to create a culture of cooperation,<br>trust, and openness among AI scientists and engineers to help us all better<br>achieve these goals.</i>"
          ],
          [
           "Cooperation",
           " <i>UNESCO Recommendation on the Ethics of Artificial Intelligence</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Cooperation",
           " <i>Furthermore, efforts, including international cooperation, should be made to<br>overcome, and never take advantage of, the lack of necessary technological<br>infrastructure, education, and skills, as well as legal frameworks, particularly<br>in low-and middle-income countries, least developed countries, landlocked<br>developing countries, and small island developing States, affecting communities.<br>The notion of humans being interconnected is based on the knowledge that every<br>human belongs to a greater whole, which thrives when all its constituent parts<br>are enabled to thrive. Living in peaceful, just, and interconnected societies<br>requires an organic, immediate, uncalculated bond of solidarity, characterized<br>by a permanent search for peaceful relations, tending towards care for others<br>and the natural environment in the broadest sense of the term.</i>"
          ],
          [
           "Cooperation",
           " <i>The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and<br>Mitigation</i>",
           " 2018",
           " Recommendation",
           " Academic, Non-profit Organization, Private Corporation",
           " Western Europe, North America ",
           " United Kingdom, United States of America",
           " Cooperation",
           " <i>Recommendation - Policymakers should collaborate closely with technical<br>researchers to investigate, prevent, and mitigate potential malicious uses of<br>AI. Actively seek to expand the range of stakeholders and domain experts<br>involved in discussions of these challenges.</i>"
          ],
          [
           "Cooperation",
           " <i>IBM AI Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Cooperation",
           " <i>We believe that government data policies should be fair and equitable and<br>prioritize openness.</i>"
          ],
          [
           "Cooperation",
           " <i>Artificial intelligence - Common good as a benchmark, good work as a principle</i>",
           " 2019",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Cooperation",
           " <i>We see the promotion of open-source software as a common good as an attractive<br>and promising way to advance technological development in Europe that is geared<br>towards the common good.</i>"
          ],
          [
           "Cooperation",
           " <i>The Code of Ethics in the Field of Artificial Intelligence</i>",
           " 2022",
           " Recommendation",
           " Unspecified",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Cooperation",
           " <i>AI Actors are encouraged to cooperate within their community and among<br>developers in particular, i.a. through informing each other about the<br>identification of critical vulnerabilities in order to prevent them from<br>spreading, and make efforts to improve the quality and availability of resources<br>in the field of AI systems development, i.e., by creating conditions for the<br>formation of a national school of AI technologies development, including<br>publicly available national repositories of libraries and network models,<br>available national development tools, open national frameworks, etc.</i>"
          ],
          [
           "Cooperation",
           " <i>Shanghai Initiative for Safe and Secure AI Development</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Asia",
           " China",
           " Cooperation",
           " <i>Ai development calls for concerted efforts of all countries and all sectors.<br>Proactive efforts must be made to establish norms and standards for safe and<br>secure AI development worldwide and prevent security risks caused by technology<br>and policy incompatibility.</i>"
          ],
          [
           "Cooperation",
           " <i>Chinese Young Scientists' Declaration on the Governance and Innovation of<br>Artificial Intelligence (Shanghai Declaration)</i>",
           " 2019",
           " Recommendation",
           " Academic, Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Asia",
           " China",
           " Cooperation",
           " <i>Artificial intelligence should be transparent and interpretable. We are<br>committed to conducting open-source and interpretative research, reducing<br>research on blind black-box algorithms, and enhancing multi-layered<br>transparency, thus attesting to compliance with the proposed framework of<br>ethics.</i>"
          ],
          [
           "Cooperation",
           " <i>Harmonious Artificial Intelligence Principles</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Cooperation",
           " <i>Artificial Intelligence Models should be evolved to be with more Empathy and<br>Altruism to establish a more trustworthy, reliable, friendly, and harmonious<br>Human-AI Society. Humans and AI need to collaborate for the advancements and<br>long-term future of both sides.</i>"
          ],
          [
           "Cooperation",
           " <i>Fu Ying: Six Principles of Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Cooperation",
           " <i>Artificial intelligence should serve all human beings, and a reasonable<br>mechanism should be established to enable more people to benefit from the<br>development of artificial intelligence technology, enjoy convenience, and avoid<br>the emergence of the digital divide.  Countries around the world should promote<br>the technical exchange and talent exchange of artificial intelligence, and<br>promote and standardize the improvement of technology in an open environment.</i>"
          ],
          [
           "Cooperation",
           " <i>A Framework for the Ethical use of advanced Data Science Methodes in the<br>Humanitarian Sector</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe, Intergovernmental Organization",
           " Netherlands, United Nations",
           " Cooperation",
           " <i>Humanitarian organizations should also consider (where possible) regularly and<br>actively engaging human rights, data privacy specialists and ethics advisors,<br>and other organizational focal points who are actively involved in providing<br>advice or who have expertise related to safeguarding the rights and data of<br>affected populations.</i>"
          ],
          [
           "Cooperation",
           " <i>Technological convergence, artificial intelligence and human rights</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Cooperation",
           " <i>The Assembly calls for close cooperation with the institutions of the European<br>Union and the United Nations Educational, Scientific and Cultural Organization<br>(UNESCO) to ensure a consistent legal framework and effective supervisory<br>mechanisms at the international level.</i>"
          ],
          [
           "Cooperation",
           " <i>Decree of the President of the Russian Federation on the Development of<br>Artificial Intelligence in the Russian Federation</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Cooperation",
           " <i>The basic principles of the development and use of artificial intelligence<br>technologies, the observance of which is obligatory during the implementation of<br>this Strategy, include: the development of market relations and the<br>impermissibility of actions aimed at the restriction of competition between<br>Russian organizations that engage in activities in the field of artificial<br>intelligence.</i>"
          ],
          [
           "Cooperation",
           " <i>Allen Institute for Artificial Intelligence Core Values</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Academic, Non-profit Organization",
           " North America",
           " United States of America",
           " Cooperation",
           " <i>We proactively develop diverse teams with a wide range of perspectives and<br>skills to cultivate the best possible ideas. We build relationships with outside<br>research groups and organizations to collectively elevate the field of AI and<br>achieve the broadest possible impact.</i>"
          ]
         ],
         "hovertemplate": "<b>Document ID </b>=%{customdata[1]}<br><b>Year of Publication </b>=%{customdata[2]}<br><b>Reguation Type </b>=%{customdata[3]}<br><b>Institution Type </b>=%{customdata[4]}<br><b>World Region </b>=%{customdata[5]}<br><b>Country </b>=%{customdata[6]}<br><b>Principle </b>=%{customdata[7]}<br><b>Description </b>=%{customdata[8]}<extra></extra>",
         "legendgroup": "Cooperation",
         "marker": {
          "color": "#FFA15A",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Cooperation",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          -2.8876371,
          -1.882491,
          3.566489,
          -11.970317,
          15.956837,
          20.430649,
          22.854012,
          14.078989,
          -7.595461,
          10.620404,
          25.985151,
          -6.1193175,
          -7.8293977,
          -3.345181,
          8.677552,
          17.916311,
          8.65404,
          17.846811,
          26.301895,
          12.471135,
          -0.16922295,
          3.7498202,
          -3.0086067,
          14.519965,
          -5.72616,
          5.593848,
          10.596705,
          -7.0788136,
          7.8285484,
          20.266272,
          7.632245,
          1.0862818,
          13.343548,
          20.222149,
          18.967703,
          -4.710951,
          -10.58305,
          -5.3157983,
          3.7673821,
          11.022018,
          10.231795,
          4.0903916,
          14.080109,
          1.2695701,
          -4.316268,
          1.6870993,
          14.81302,
          11.455026,
          18.282812,
          4.1057434,
          16.160496,
          12.738038,
          15.467695,
          -1.7868809,
          12.217849,
          4.9605246,
          2.8480687,
          18.047754,
          11.2092905,
          -3.9047344,
          26.94645,
          -5.7612143,
          -4.3455434,
          -13.000393,
          -0.10901815,
          9.971046,
          7.0870557,
          0.22623882,
          0.47043172,
          16.703753
         ],
         "y": [
          -0.97805697,
          -20.449484,
          -11.102086,
          9.197725,
          -4.88854,
          5.491399,
          3.1052516,
          -4.8113756,
          -8.598456,
          -6.1370096,
          3.3434455,
          8.071316,
          10.636276,
          -5.4317455,
          -6.555531,
          17.25193,
          -8.836815,
          -0.23571233,
          -4.8676767,
          -12.37949,
          -13.428938,
          15.86241,
          -0.24127682,
          -5.6649623,
          10.332178,
          18.5162,
          -9.0751295,
          2.6225119,
          -5.420546,
          -3.7386613,
          -7.784632,
          -8.807204,
          -6.7735395,
          5.793466,
          -8.329898,
          12.961159,
          -23.21341,
          10.037986,
          -0.8197703,
          -5.4593716,
          -1.5793628,
          6.546382,
          -4.296233,
          8.867272,
          2.6241257,
          6.1592827,
          -3.658975,
          -21.300648,
          -4.9403906,
          -3.5889807,
          -7.550661,
          -5.132198,
          -6.023905,
          17.844467,
          -7.2870426,
          -24.60083,
          -18.238552,
          -5.692517,
          -11.858155,
          9.636428,
          3.3573184,
          -6.6143084,
          -9.769647,
          -2.0514936,
          -10.642256,
          -4.2359695,
          21.40135,
          -3.11294,
          -19.37273,
          -0.53143215
         ],
         "z": [
          -5.3074713,
          1.482803,
          -8.644561,
          -10.561439,
          -6.4957843,
          4.4397855,
          -8.329731,
          -3.2914708,
          5.7799983,
          4.778911,
          6.3658895,
          -25.468962,
          -22.926329,
          -14.116118,
          2.273522,
          1.603878,
          -0.3445343,
          4.1763616,
          -1.3916765,
          -2.399861,
          -14.739399,
          -17.696064,
          20.466543,
          -5.0055323,
          -21.736158,
          -18.33782,
          -5.131735,
          -6.461512,
          3.8606799,
          9.428903,
          -1.774561,
          27.472471,
          -9.1424,
          6.09205,
          -1.5778506,
          -22.203775,
          -6.33777,
          -25.910152,
          19.766106,
          2.2288678,
          2.5677161,
          25.889791,
          2.2239258,
          -4.3227677,
          -7.1153765,
          -0.6114288,
          1.6721929,
          -6.1798444,
          -6.39248,
          2.144734,
          -4.147742,
          -6.056991,
          -8.775528,
          19.556973,
          -7.3882456,
          2.60643,
          0.66567755,
          11.685212,
          -9.700393,
          -21.377638,
          7.2463903,
          6.447853,
          9.033624,
          -11.912629,
          11.957974,
          4.4159117,
          -8.503686,
          30.205807,
          20.840164,
          -6.3069263
         ]
        },
        {
         "customdata": [
          [
           "Dignity",
           " <i>Declaration on Ethics and Data Protection in Artifical Intelligence</i>",
           " 2018",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " Belgium",
           " Dignity",
           " <i>The 40th International Conference of Data Protection and Privacy Commissioners<br>considers that any creation, development, and use of artificial intelligence<br>systems shall fully respect human rights, particularly the rights to the<br>protection of personal data and to privacy, as well as human dignity, non-<br>discrimination, and fundamental values, and shall provide solutions to allow<br>individuals to maintain control and understanding of artificial intelligence<br>systems.</i>"
          ],
          [
           "Dignity",
           " <i>AI Policies and Principles</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Industrial Association",
           " North America",
           " United States of America",
           " Dignity",
           " <i>AI systems designed and deployed must be consistent with the international<br>convention that ensures and preserve human dignity, rights, and freedom.</i>"
          ],
          [
           "Dignity",
           " <i>Icelander Institute for Intelligent Machine Ethics Policy</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization",
           " Northern Europe",
           " Iceland",
           " Dignity",
           " <i>One of the ethical policies of IIIM is to ensure that its project does not cause<br>bodily or emotional distress to any person by, as stipulated in the United<br>Nations Declaration of Human Rights.</i>"
          ],
          [
           "Dignity",
           " <i>Responsible AI: A Global Policy Framework</i>",
           " 2021",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization, Professional Association",
           " North America",
           " United States of America",
           " Dignity",
           " <i>Organisations that develop, deploy or use AI systems should do so in a manner<br>compatible with human agency and respect for fundamental human rights.</i>"
          ],
          [
           "Dignity",
           " <i>The Japanese Society for Artificial Intelligence Ethical Guidelines</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Academic",
           " Eastern Asia",
           " Japan",
           " Dignity",
           " <i>Members of the JSAI protect basic human rights and will respect cultural<br>diversity.</i>"
          ],
          [
           "Dignity",
           " <i>Hambach Declaration on Artificial Intelligence(Hambacher Erklärung zur<br>Künstlichen Intelligenz)</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Germany",
           " Dignity",
           " <i>The guarantee of human dignity (Article 1 (1) of the Basic Law, Article 1 of the<br>Charter of Fundamental Rights) requires that, especially in the case of state<br>action utilizing AI, the individual is not turned into an object. Fully<br>automated decisions or profiling by AI systems are only permitted to a limited<br>extent.</i>"
          ],
          [
           "Dignity",
           " <i>KI Seal of Approval</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Dignity",
           " <i>Artificial intelligence should lead to more freedom, equality, justice,<br>solidarity, tolerance, and pluralism to ensure that it is not used for<br>discrimination, or against democracy or human rights.</i>"
          ],
          [
           "Dignity",
           " <i>10 ethical guidelines for the digitalisation of companies (10 ethische<br>Leitlinien für die Digitalisierung von Unternehmen)</i>",
           " 2017",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Dignity",
           " <i>Artificial intelligence should be designed in a value-oriented way. Intelligent<br>systems should be designed in such a way that the fundamental rights of people<br>are rights and enable them to lead a good and successful life.</i>"
          ],
          [
           "Dignity",
           " <i>Ethics Guidelines for Trustworthy AI</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Dignity",
           " <i>AI systems should hence be developed in a manner that respects, serves, and<br>protects humans’ physical and mental integrity, personal and cultural sense of<br>identity, and satisfaction of their essential needs. Moreover, mechanisms should<br>be put into place to receive external feedback regarding AI systems that<br>potentially infringe on fundamental rights.</i>"
          ],
          [
           "Dignity",
           " <i>China’s Artificial Intelligence Industry Alliance Self-discipline Convention</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Dignity",
           " <i>The development of artificial intelligence should uphold basic rights such as<br>human freedom and dignity, follow the principle of human-centeredness, and<br>prevent artificial intelligence from weakening and replacing humanity's<br>position.</i>"
          ],
          [
           "Dignity",
           " <i>Draft AI R&D Guidelines for International Discussions</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Dignity",
           " <i>AI developers must ensure that they respect their users’ dignity and individual<br>autonomy. Developers must avoid unfair discrimination resulting from prejudices<br>through AI data learning. AI must not infringe human values and must be made to<br>respect the International Human Rights Law.</i>"
          ],
          [
           "Dignity",
           " <i>For a meaningful Artificial Intelligence - Towards a French and European<br>strategy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Dignity",
           " <i>AI must first and foremost help us to promote our fundamental rights, improve<br>social cohesion, and strengthen solidarity.</i>"
          ],
          [
           "Dignity",
           " <i>Model AI Governance Framework</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " Southeast Asia",
           " Singapore",
           " Dignity",
           " <i>Ensure that the design, development, and implementation of technologies do not<br>infringe internationally recognized human rights.</i>"
          ],
          [
           "Dignity",
           " <i>Asilomar AI Principles</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Dignity",
           " <i>AI systems should be designed and operated to be compatible with ideals of human<br>dignity, rights, freedoms, and cultural diversity.</i>"
          ],
          [
           "Dignity",
           " <i>G20 Ministerial Statement on Trade and Digital Economy</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " G20",
           " Dignity",
           " <i>AI actors should respect human rights.</i>"
          ],
          [
           "Dignity",
           " <i>Rome Call for AI Ethics</i>",
           " 2020",
           " Recommendation",
           " Religious Institution",
           " Southern Europe",
           " Vatican City State",
           " Dignity",
           " <i>All human beings are born free and equal in dignity and rights. This fundamental<br>condition of freedom and dignity must also be protected and guaranteed when<br>producing and using AI systems.</i>"
          ],
          [
           "Dignity",
           " <i>Ethical Guidelines of the German Informatics Society</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization, Professional Association",
           " Western Europe",
           " Germany",
           " Dignity",
           " <i>To assess the consequences of IT systems in the application environment and to<br>propose suitable solutions, there must be a willingness to understand and take<br>into account the rights, needs, and interests of those parties who are impacted<br>by them. GI members staunchly advocate for the protection and safeguarding of<br>human dignity, even when this is not explicitly mandated by laws, contracts or<br>other norms, or when these stand in direct opposition to the protection and<br>safeguarding of human dignity.</i>"
          ],
          [
           "Dignity",
           " <i>Ethically Aligned Design: A Vision for Prioritizing Human Well-being with<br>Autonomous and Intelligent Systems, Version 2</i>",
           " 2017",
           " Recommendation",
           " Professional Association",
           " North America",
           " United States of America",
           " Dignity",
           " <i>A/IS should be designed and operated in a way that both respects and fulfills<br>human rights, freedoms, human dignity, and cultural diversity.</i>"
          ],
          [
           "Dignity",
           " <i>Privacy and Freedom of Expression In the Age of Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " Western Europe",
           " United Kingdom",
           " Dignity",
           " <i>The development, use, research, and development of AI must be subject to the<br>minimum requirement of respecting, promoting, and protecting international human<br>rights standards.</i>"
          ],
          [
           "Dignity",
           " <i>Artificial intelligence and Privacy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Norway",
           " Dignity",
           " <i>Ensure that you have good systems for protecting the rights of data subjects,<br>such as the right to information, access, and deletion. If consent is the legal<br>basis of processing, the system must also include functionality enabling consent<br>to be given and to be withdrawn.</i>"
          ],
          [
           "Dignity",
           " <i>AI Ethics Principles & Guidelines</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Middle East",
           " United Arab Emirates",
           " Dignity",
           " <i>AI systems should conform to international norms and standards with respect to<br>human values and people's rights and acceptable behavior. Surveillance or other<br>AI-driven technologies should not be deployed to the extent of violating<br>internationally and/or UAE’s accepted standards of privacy and human dignity and<br>people's rights.</i>"
          ],
          [
           "Dignity",
           " <i>Data for the Benefit of the People: Recommendations from the Danish Expert Group<br>on Data Ethics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Denmark",
           " Dignity",
           " <i>Human dignity must be respected in all data processes, i.e. data should not be<br>used to exploit knowledge against the user's long-term interests. This includes,<br>for example, the use of the latest new technology and encryption methods to<br>protect privacy data from leaks and misuse, and organizational processes and<br>data analysis and correlation that protect people from discrimination and misuse<br>of their data.</i>"
          ],
          [
           "Dignity",
           " <i>Principles of Robotics</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Dignity",
           " <i>Humans, not robots, are responsible agents. Robots should be designed; operated<br>as far as is practicable to comply with existing laws & fundamental rights &<br>freedoms, including privacy.</i>"
          ],
          [
           "Dignity",
           " <i>Beijing AI Principles</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Eastern Asia",
           " China",
           " Dignity",
           " <i>Human privacy, dignity, freedom, autonomy, and rights should be sufficiently<br>respected.</i>"
          ],
          [
           "Dignity",
           " <i>Responsible Artificial Intelligence in the Government of Canada (whitepaper)</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Dignity",
           " <i>As these agents grow to operate in increasingly sophisticated spaces, they act<br>on behalf of the Crown, and should be subject to similar values, ethics, and<br>laws as public servants and adherence to international human rights obligations.</i>"
          ],
          [
           "Dignity",
           " <i>SAP’s guiding principles for Artificial Intelligence</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Dignity",
           " <i>In developing AI software, we will remain true to our human rights commitment<br>statement, the UN guiding principles on business and human rights, laws, and<br>widely accepted international norms.</i>"
          ],
          [
           "Dignity",
           " <i>Artificial Intelligence at Google: Our Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Dignity",
           " <i>We will not pursue Technologies whose purpose contravenes widely accepted<br>principles of international law and human rights.</i>"
          ],
          [
           "Dignity",
           " <i>Artificial Intelligence: Australia’s Ethics Framework - A Discussion Paper</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Oceania",
           " Australia",
           " Dignity",
           " <i>Under Australia’s Human Rights (Parliamentary Scrutiny) Act 2011, new bills must<br>be accompanied by a statement of compatibility that demonstrates how they align<br>with the seven aforementioned human rights agreements. The Parliamentary Joint<br>Committee on Human Rights scrutinizes laws to confirm they are compatible with<br>Australia’s human rights obligations. Any future Australian legislation will<br>need to abide by these principles amid change occurring due to AI.</i>"
          ],
          [
           "Dignity",
           " <i>Code of Ethics for Data-Based Value Creation</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Switzerland",
           " Dignity",
           " <i>You should enable individuals and communities to act in a self-determined<br>manner. This basic orientation includes, among other things, the value of<br>dignity (e.g., through information practices taking the customer seriously).</i>"
          ],
          [
           "Dignity",
           " <i>Telefónica´s Approach to the Responsible Use of AI (Enfoque de Telefónica para<br>un uso responsable de la IA)</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Spain",
           " Dignity",
           " <i>Telefonica is strongly committed to respecting Human Rights, as is stated in its<br>Business Principles and Human Rights Policy. AI used in products and services<br>should in no way lead to a negative impact on human rights or the achievement of<br>the UN’s Sustainable Development Goals.</i>"
          ],
          [
           "Dignity",
           " <i>Telia Company Guiding Principles on trusted AI ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Sweden",
           " Dignity",
           " <i>We aim to know and show how we respect human rights. We seek to identify,<br>prevent, mitigate and account for how we address our impacts on human rights and<br>how we manage human rights risks and opportunities, such as privacy, children’s<br>rights, and anti-discrimination.</i>"
          ],
          [
           "Dignity",
           " <i>European ethical Charter on the use of Artificial Intelligence in judicial<br>systems and their environment</i>",
           " 2018",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Dignity",
           " <i>ensure that the design and implementation of artificial intelligence tools and<br>services are compatible with fundamental rights.</i>"
          ],
          [
           "Dignity",
           " <i>Opinion of the Data Ethics Commission</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Dignity",
           " <i>Human dignity, which from an ethical viewpoint is synonymous with the<br>unconditional value of every human being and which is enshrined as a<br>“fundamental constitutional principle” in the constitutional order, is of<br>foundational and supreme importance. It follows from the principle of human<br>dignity that every individual merits respect, regardless of his or her<br>attributes and achievements. As far as possible, a culture of “incorporating”<br>the basic principles of democracy, the rule of law, and fundamental rights into<br>the system architecture should be established for the process of designing<br>technology.</i>"
          ],
          [
           "Dignity",
           " <i>Artificial Intelligence and Data Protection</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Dignity",
           " <i>The protection of human dignity and safeguarding of human rights and fundamental<br>freedoms, in particular the right to the protection of personal data, are<br>essential when developing and adopting AI applications that may have<br>consequences on individuals and society. This is especially important when AI<br>applications are used in decision-making processes.</i>"
          ],
          [
           "Dignity",
           " <i>Statement on Artificial Intelligence, Robotics and 'Autonomous‘ Systems</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Dignity",
           " <i>The principle of human dignity, understood as the recognition of the inherent<br>human state of being worthy of respect, must not be violated by ‘autonomous’<br>technologies. This means, for instance, that there are limits to determinations<br>and classifications concerning persons, made based on algorithms and<br>‘autonomous’ systems, especially when those affected by them are not informed<br>about them. It also implies that there have to be (legal) limits to how people<br>can be led to believe that they are dealing with human beings while they are<br>dealing with algorithms and smart machines.</i>"
          ],
          [
           "Dignity",
           " <i>Report with recommendations to the Commission on Civil Law Rules on Robotics</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " European Union",
           " European Union",
           " Dignity",
           " <i>The European Parliament notes that the potential for empowerment through the use<br>of robotics is nuanced by a set of tensions or risks and should be seriously<br>assessed from the point of view of integrity, dignity, and on the principles and<br>values enshrined in Article 2 of the Treaty on European Union and the Charter of<br>Fundamental Rights.</i>"
          ],
          [
           "Dignity",
           " <i>Preparing for the future of Artificial Intelligence</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Dignity",
           " <i>The U.S. Government should complete the development of a single, government-wide<br>policy, consistent with international humanitarian law, on autonomous and semi-<br>autonomous weapons.</i>"
          ],
          [
           "Dignity",
           " <i>Guidance for Regulation of Artificial Intelligence Applications</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Dignity",
           " <i>A regulatory analysis should begin with a clear explanation of the need for the<br>regulatory action, including a description of the problem that the agency seeks<br>to address. The analysis of these alternatives should also evaluate, where<br>relevant and appropriate, and consistent with Executive Order 13859, impacts to<br>equity, human dignity, fairness, potential distributive impacts, privacy, civil<br>liberties, and personal freedom. The agency’s analysis should be based on the<br>best available scientific, technical, and economic information.</i>"
          ],
          [
           "Dignity",
           " <i>Tieto’s AI ethics guidelines</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Finland",
           " Dignity",
           " <i>At Tieto, we are committed to ensuring the freedom and liberty of people to<br>serve the social good.</i>"
          ],
          [
           "Dignity",
           " <i>Preliminary Study on the Ethics of Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Dignity",
           " <i>AI should be developed and implemented in accordance with international human<br>rights standards. AI should be developed, implemented, and used in line with<br>democratic principles.</i>"
          ],
          [
           "Dignity",
           " <i>Report of COMEST on robotics ethics</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Dignity",
           " <i>Human dignity is a core value related to the Universal Declaration of Human<br>Rights (UN, 1948). It recognizes that being free and equal, all human beings<br>“are endowed with reason and conscience and should act towards one another in a<br>spirit of brotherhood” (Art. 1). Dignity is inherent to human beings, not to<br>machines or robots. Therefore, robots and humans are not to be confused even if<br>an android robot has the seductive appearance of a human, or if a powerful<br>cognitive robot has a learning capacity that exceeds individual human cognition.<br>Robots are not humans – they are the result of human creativity and they still<br>need a technical support system and maintenance to be effective and efficient<br>tools or mediators.</i>"
          ],
          [
           "Dignity",
           " <i>Top 10 Principles for Ethical Artificial Intelligence</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " Switzerland",
           " Dignity",
           " <i>Throughout their entire operational process, AI systems remain compatible and<br>increase the principles of human dignity, integrity, freedom, privacy, and<br>cultural and gender diversity, as well as fundamental human rights.</i>"
          ],
          [
           "Dignity",
           " <i>Introducing Unity’s Guiding Principles for Ethical AI</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Dignity",
           " <i>Do not develop AI tools aimed at the suppression of human rights, as defined by<br>the Universal Declaration of Human Rights, such as the right to free expression.</i>"
          ],
          [
           "Dignity",
           " <i>fAIr LAC: Responsible and Widespread Adoption of Artificial Intelligence in<br>Latin America and the Caribbean</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Latin America",
           " Unspecified",
           " Dignity",
           " <i>AI actors should respect the rule of law, human rights, and democratic values,<br>throughout the AI system lifecycle.</i>"
          ],
          [
           "Dignity",
           " <i>Artificial Intelligence for Children: Beijing Principles</i>",
           " 2020",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Dignity",
           " <i>The development of AI should safeguard children's dignity. The development of AI<br>should value and respect children's own thoughts, wishes, emotions, interests,<br>self-esteem, etc., and should avoid harm to their personal dignity.</i>"
          ],
          [
           "Dignity",
           " <i>Social Principles of Human-Centric AI</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia, Western Europe",
           " Japan, United Kingdom",
           " Dignity",
           " <i>We should not build a society where humans are overly dependent on AI or where<br>AI is used to control human behavior through the excessive pursuit of efficiency<br>and convenience. We need to construct a society where human dignity is respected<br>and, by using AI as a tool, a society where people can better demonstrate their<br>various human abilities, show greater creativity, engage in challenging work,<br>and live richer lives both physically and mentally.</i>"
          ],
          [
           "Dignity",
           " <i>The Toronto Declaration</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " North America, Western Europe",
           " Canada, United Kingdom",
           " Dignity",
           " <i>Human rights law sets standards and provides mechanisms to hold public and<br>private sector actors accountable where they fail to fulfill their respective<br>obligations and responsibilities to protect and respect rights. It also requires<br>that everyone must be able to obtain effective remedy and redress where their<br>rights have been denied or violated. States bear the primary duty to promote,<br>protect, respect, and fulfill human rights. Under international law, states must<br>not engage in or support discriminatory or otherwise rights-violating actions or<br>practices when designing or implementing machine learning systems in a public<br>context or through public-private partnerships. States must refrain altogether<br>from using or requiring the private sector to use tools that discriminate, lead<br>to discriminatory outcomes, or otherwise harm human rights. Private sector<br>actors have a responsibility to respect human rights; this responsibility exists<br>independently of state obligations.</i>"
          ],
          [
           "Dignity",
           " <i>Position on Robotics and Artificial Intelligence</i>",
           " 2016",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Dignity",
           " <i>The use and implementation of emerging technologies must take place according to<br>guaranteed individual rights and fundamental freedoms and in particular human<br>integrity (physical and mental integrity), human dignity, and identity. We<br>underline the primacy of the human being over the sole interest of science or<br>society.</i>"
          ],
          [
           "Dignity",
           " <i>Governing Artificial Intelligence: Upholding human rights & dignity</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Dignity",
           " <i>Technology companies should find effective channels of communication with local<br>civil society groups and researchers, particularly in geographic areas where<br>human rights concerns are high, to identify and respond to risks related to AI<br>deployments. Governments should acknowledge their human rights obligations and<br>incorporate a duty to protect fundamental rights in national AI policies,<br>guidelines, and possible regulations. Governments can play a more active role in<br>multilateral institutions, like the UN, to advocate for AI development that<br>respects human rights.</i>"
          ],
          [
           "Dignity",
           " <i>AI Governance in Japan Ver. 1.1, Report from the expert group on how AI<br>principles should be implemented</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Dignity",
           " <i>We should not build a society where humans are overly dependent on AI or where<br>AI is used to control human behavior through the excessive pursuit of efficiency<br>and convenience. We need to construct a society where human dignity is respected<br>and, by using AI as a tool, a society where people can better demonstrate their<br>various human abilities, show greater creativity, engage in challenging work,<br>and live richer lives both physically and mentally.</i>"
          ],
          [
           "Dignity",
           " <i>Principles of Artificial Intelligence Ethics for the Intelligence Community</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Dignity",
           " <i>We will employ AI in a manner that respects human dignity, rights, and freedoms.</i>"
          ],
          [
           "Dignity",
           " <i>Vodafone Artificial Intelligence Framework</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Dignity",
           " <i>We will act responsibly and follow technology industry best practices to<br>minimize the risks of our systems being unlawfully used to the detriment of<br>people’s human rights.</i>"
          ],
          [
           "Dignity",
           " <i>oston Dynamics Ethical Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Dignity",
           " <i>We believe robotic use must comply with privacy and civil rights laws. We will<br>not authorize nor partner with those who wish to use our robots in a way that<br>violates privacy and civil rights laws. We understand that emerging artificial<br>intelligence technologies including computer vision and personal identification<br>algorithms raise questions about the ethics, legality, and potential for bias<br>around their use in the public sphere.</i>"
          ],
          [
           "Dignity",
           " <i>WLiAI Report 2019: 10 Principles of Responsible AI</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " United Kingdom",
           " Dignity",
           " <i>We recommend risk to individuals or groups should be determined within the UN<br>Universal Declaration of Human Rights (UDHR) to balance any variance in cultural<br>norms with regard to fairness and bias.</i>"
          ],
          [
           "Dignity",
           " <i>The Ethical Norms for the New Generation Artificial Intelligence, China</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Dignity",
           " <i>Various activities of AI shall abide by the following fundamental ethical norms,<br>like respect for human rights and the fundamental interests of humankind.</i>"
          ],
          [
           "Dignity",
           " <i>A Code of Ethics for the Human-Robot Interaction Profession</i>",
           " 2014",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Dignity",
           " <i>All HRI research, development, and marketing should heed the overall principle<br>of respect for human persons, including respect for human autonomy, respect for<br>human bodily and mental integrity, and the affordance of all rights and<br>protections ordinarily assumed in human-human interactions. The robot actor is<br>expected to behave in a manner at least as respectful of human personhood as<br>human actors to the extent feasible. Human frailty is always to be respected,<br>both physical and psychological. The emotional needs of humans are always to be<br>respected. All relevant laws and regulations concerning individuals’ rights and<br>protections (e.g., FDA, HIPPA, and FTC) are to be respected.</i>"
          ],
          [
           "Dignity",
           " <i>How to Prevent Discriminatory Outcomes in Machine Learning</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization",
           " Western Europe",
           " Switzerland",
           " Dignity",
           " <i>Companies developing and using ML systems must integrate these principles of<br>non-discrimination into their human rights due diligence – a process by which<br>businesses take ongoing, proactive, and reactive steps to ensure that they<br>uphold people’s dignity and do not cause or contribute to human rights abuses.<br>This responsibility lies not only with the engineers building ML models: the<br>goal of leadership should be to steer ML technology to uphold human rights.</i>"
          ],
          [
           "Dignity",
           " <i>Discussion Paper: National Strategy for Artificial Intelligence</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " South Asia",
           " India",
           " Dignity",
           " <i>Recommendation - Address and implement a data protection framework, which<br>protects human rights and privacy without stifling innovation in India.</i>"
          ],
          [
           "Dignity",
           " <i>Advisory statement on human ethics in artificial intelligence and big data<br>research (2017)</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Dignity",
           " <i>Preserve Human and Legal Rights. Ensure that the consent to use personal data or<br>otherwise participate in research is not conditional upon and does not include<br>any statement to the effect that, by consenting, participants waive basic human<br>rights or any rights to legal recourse in the event of research-related harm.</i>"
          ],
          [
           "Dignity",
           " <i>The Holberton-Turing Oath</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Unspecified",
           " Unspecified",
           " Dignity",
           " <i>I will not use my knowledge to violate human rights and civil liberties, even<br>under threat. I will remember that I am not encountering dry data, mere zeros,<br>and ones, but human beings, whose interactions with my Artificial Intelligence<br>software may affect the person’s freedom, family, or economic stability.</i>"
          ],
          [
           "Dignity",
           " <i>OECD, Recommendation of the Council on Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " France",
           " Dignity",
           " <i>AI actors should respect the rule of law, human rights, and democratic values,<br>throughout the AI system lifecycle. These include freedom, dignity and autonomy,<br>privacy and data protection, nondiscrimination and equality, diversity,<br>fairness, social justice, and internationally recognized labor rights.</i>"
          ],
          [
           "Dignity",
           " <i>Oxford Munich Code of Conduct</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Dignity",
           " <i>Data scientists shall not create inferred evidence that violates fundamental<br>principles, such as the presumption of innocence, etc.</i>"
          ],
          [
           "Dignity",
           " <i>Partnership on AI Tenets</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization",
           " Unspecified",
           " Unspecified",
           " Dignity",
           " <i>We will work to maximize the benefits and address the potential challenges of AI<br>technologies, by opposing the development and use of AI technologies that would<br>violate international conventions or human rights and promoting safeguards and<br>technologies that do not harm.</i>"
          ],
          [
           "Dignity",
           " <i>UNESCO Recommendation on the Ethics of Artificial Intelligence</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Dignity",
           " <i>The inviolable and inherent dignity of every human constitutes the foundation<br>for the universal, indivisible, inalienable, interdependent, and interrelated<br>system of human rights and fundamental freedoms. Therefore, respect, protection,<br>and promotion of human dignity and rights as established by international law,<br>including international human rights law, is essential throughout the life cycle<br>of AI systems. Human dignity relates to the recognition of the intrinsic and<br>equal worth of each human being, regardless of race, color, descent, gender,<br>age, language, religion, political opinion, national origin, ethnic origin,<br>social origin, the economic or social condition of birth, or disability and any<br>other grounds.</i>"
          ],
          [
           "Dignity",
           " <i>Ethics & Governance of Artificial Intelligence for Health</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Dignity",
           " <i>For AI to have a beneficial impact on public health and medicine, ethical<br>considerations and human rights must be placed at the center of the design,<br>development, and deployment of AI technologies for health.</i>"
          ],
          [
           "Dignity",
           " <i>HPE AI Ethics and Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Dignity",
           " <i>Respect human rights and be designed with mechanisms and safeguards, such as<br>human oversight to prevent misuse.</i>"
          ],
          [
           "Dignity",
           " <i>Alpha Principles for the Ethical Use of AI and Data Driven Technologies in<br>Ontario</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Dignity",
           " <i>Data-driven technologies should be designed in a way that respects the rule of<br>law, human rights, democratic values, and diversity, and they should include<br>appropriate safeguards to ensure a fair and just society. Designers,<br>policymakers, and developers should respect the rule of law, human rights, and<br>democratic values, throughout the AI system lifecycle. These include freedom,<br>dignity and autonomy, privacy and data protection, non-discrimination and<br>equality, diversity, fairness, social justice, and internationally recognized<br>labor rights.</i>"
          ],
          [
           "Dignity",
           " <i>Ethical Aspects of Autonomous and Intelligent Systems</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Dignity",
           " <i>A/IS should be developed and operated in a manner that respects internationally<br>recognized human rights.</i>"
          ],
          [
           "Dignity",
           " <i>IEEE Position Statement - Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Dignity",
           " <i>To ensure that artificial intelligence serves the interests of society, IEEE<br>urges governments to adopt policies that ensure that AI regulations always<br>comply with human rights laws and prioritize the protection of personal data<br>relating to the individuals coming into contact with AI systems or algorithms.</i>"
          ],
          [
           "Dignity",
           " <i>Safe Face Pledge</i>",
           " 2021",
           " Recommendation",
           " Academic, Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Dignity",
           " <i>Modify legal documents to reflect value for human life, dignity, and rights. By<br>updating vendor contracts, partner agreements, and terms of service to reflect<br>commitments associated with lethal, secret government surveillance, and law<br>enforcement applications, including terms that obligate compliance with these<br>commitments and require the cessation of use of the technology in the event of<br>any discovered non-compliance.</i>"
          ],
          [
           "Dignity",
           " <i>Artificial intelligence - Common good as a benchmark, good work as a principle</i>",
           " 2019",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Dignity",
           " <i>Human dignity and self-determination must take precedence over the autonomy of<br>the systems. We welcome the Federal Government's move to design artificial<br>intelligence based on fundamental rights.</i>"
          ],
          [
           "Dignity",
           " <i>Draft - AI Utilization Principles</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Dignity",
           " <i>Users should respect human dignity and individual autonomy in the utilization of<br>AI systems or AI services.</i>"
          ],
          [
           "Dignity",
           " <i>The Code of Ethics in the Field of Artificial Intelligence</i>",
           " 2022",
           " Recommendation",
           " Unspecified",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Dignity",
           " <i>Human rights and freedoms and the human as such must be treated as the greatest<br>value in the process of AI technologies development.</i>"
          ],
          [
           "Dignity",
           " <i>Trustworthy AI in Aotearoa: AI Principles</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " Oceania",
           " New Zealand",
           " Dignity",
           " <i>Designers, developers, and users of AI systems (AI stakeholders) must respect<br>human rights recognized under domestic and international law.</i>"
          ],
          [
           "Dignity",
           " <i>\"ARCC\": An Ethical Framework for Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " Eastern Asia",
           " China",
           " Dignity",
           " <i>Recommendation - Respect human dignity, rights and freedoms, and cultural<br>diversity.</i>"
          ],
          [
           "Dignity",
           " <i>Fu Ying: Six Principles of Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Dignity",
           " <i>The application of artificial intelligence technology should conform to the<br>purposes of the UN Charter and the basic principles of modern international law,<br>such as the sovereign equality of all countries, the peaceful settlement of<br>disputes, the prohibition of the use of force, and non-interference in internal<br>affairs.</i>"
          ],
          [
           "Dignity",
           " <i>A Framework for the Ethical use of advanced Data Science Methodes in the<br>Humanitarian Sector</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe, Intergovernmental Organization",
           " Netherlands, United Nations",
           " Dignity",
           " <i>While efficiency and technological development are valuable, those responsible<br>for human lives should not pursue innovation at the expense of fairness,<br>accountability, and oversight. Fundamental human rights must hold a central<br>place in this discussion.</i>"
          ],
          [
           "Dignity",
           " <i>Civil Rights Principles for the Era of Big Data</i>",
           " 2014",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Dignity",
           " <i>Recommendation - Preserve Constitutional Principles. Search warrants and other<br>independent oversight of law enforcement are particularly important for<br>communities of color and for religious and ethnic minorities, who often face<br>disproportionate scrutiny. Government databases must not be allowed to undermine<br>core legal protections, including those of privacy and freedom of association.</i>"
          ],
          [
           "Dignity",
           " <i>Human rights in the robot age: Challenges arising from the use of robotics,<br>artificial intelligence, and virtual and augmented reality</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Western Europe",
           " Netherlands",
           " Dignity",
           " <i>Recommendation - In order to safeguard human rights in the robot age, we<br>recommend that PACE calls for the preparation of a convention on robot ethics,<br>or, even better, safeguarding human rights in the robot age, which would create<br>common guiding principles to preserve human dignity in the way humans apply<br>innovations in the field of the Internet of Things, including the Internet,<br>robotics, AI, and virtual and augmented reality.</i>"
          ],
          [
           "Dignity",
           " <i>Technological convergence, artificial intelligence and human rights</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Dignity",
           " <i>In the light of the above, the Assembly urges the Committee of Ministers to<br>instruct the relevant bodies of the Council of Europe to consider how<br>intelligent artifacts and/or connected devices and, more generally,<br>technological convergence and its social and ethical consequences related to the<br>field of genetics and genomics, neurosciences and big data, challenge the<br>different dimensions of human rights.</i>"
          ],
          [
           "Dignity",
           " <i>Decree of the President of the Russian Federation on the Development of<br>Artificial Intelligence in the Russian Federation</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Dignity",
           " <i>The basic principles of the development and use of artificial intelligence<br>technologies, the observance of which is obligatory during the implementation of<br>this Strategy, include: the protection of human rights and liberties: ensuring<br>the protection of the human rights and liberties guaranteed by Russian and<br>international laws.</i>"
          ]
         ],
         "hovertemplate": "<b>Document ID </b>=%{customdata[1]}<br><b>Year of Publication </b>=%{customdata[2]}<br><b>Reguation Type </b>=%{customdata[3]}<br><b>Institution Type </b>=%{customdata[4]}<br><b>World Region </b>=%{customdata[5]}<br><b>Country </b>=%{customdata[6]}<br><b>Principle </b>=%{customdata[7]}<br><b>Description </b>=%{customdata[8]}<extra></extra>",
         "legendgroup": "Dignity",
         "marker": {
          "color": "#19d3f3",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Dignity",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          -4.656827,
          4.5279584,
          13.274826,
          4.390168,
          6.465096,
          -3.218082,
          4.2114115,
          0.9270756,
          -6.4757557,
          1.2290726,
          3.192852,
          9.109237,
          6.7485356,
          6.867101,
          -4.5248284,
          0.3818146,
          25.911167,
          10.775366,
          3.5726776,
          -8.241894,
          2.3890548,
          -2.0897117,
          -11.60938,
          -2.272694,
          5.880076,
          7.278669,
          8.260425,
          -0.95109355,
          -2.652027,
          9.207508,
          6.006335,
          5.0206738,
          -0.16956384,
          -3.8007329,
          -3.5475483,
          -0.3880616,
          -5.226849,
          -12.142217,
          6.6153526,
          2.3650575,
          -2.4567242,
          7.397406,
          2.5654645,
          -2.0360868,
          3.6444092,
          5.4378114,
          0.17998222,
          3.0239635,
          4.774031,
          4.820094,
          6.1392403,
          7.3436456,
          -9.1190405,
          12.652993,
          1.4018207,
          -11.2824135,
          1.0661496,
          -13.833476,
          -6.249171,
          -2.6688735,
          0.6141825,
          -2.4146078,
          0.3003029,
          -0.46409652,
          0.5062696,
          9.391346,
          3.0008097,
          10.10246,
          5.9887104,
          3.1039248,
          -0.9376338,
          -2.6136394,
          2.162446,
          4.623544,
          0.9446266,
          -0.4864375,
          5.5612884,
          3.4890716,
          -1.0905461,
          -0.74648535,
          0.64575773
         ],
         "y": [
          10.709145,
          5.7495737,
          15.571831,
          3.8883376,
          15.516347,
          12.182651,
          3.56137,
          -1.9395777,
          1.687686,
          1.9380436,
          4.1708612,
          4.926802,
          17.529224,
          5.6955433,
          4.539073,
          10.668454,
          9.898763,
          9.81766,
          1.6197504,
          21.911724,
          6.3248315,
          18.692354,
          -2.2810647,
          19.40599,
          9.943885,
          0.97707427,
          17.798996,
          6.8844204,
          20.78037,
          0.6981225,
          24.530241,
          6.1163855,
          15.31692,
          12.491763,
          12.4747305,
          -6.022753,
          0.35435188,
          -20.867205,
          -26.225452,
          2.932866,
          14.728977,
          3.5187073,
          8.523859,
          3.8084702,
          7.1940346,
          -7.146596,
          8.96193,
          16.467403,
          -1.4693207,
          -6.2633524,
          2.439881,
          18.230043,
          -6.40943,
          18.573446,
          -3.824974,
          0.5385926,
          6.563983,
          25.045912,
          23.346207,
          14.657756,
          2.893602,
          24.457695,
          -19.940374,
          13.658464,
          -3.1298575,
          17.220175,
          7.698962,
          10.688168,
          -4.8196483,
          18.233503,
          8.653434,
          8.129719,
          7.4054785,
          1.8984979,
          21.185724,
          1.9888344,
          15.632845,
          20.629068,
          -2.3922503,
          -2.195814,
          -16.99514
         ],
         "z": [
          3.1114936,
          8.66472,
          14.354106,
          6.3216653,
          15.377802,
          6.329152,
          15.597802,
          11.914309,
          8.736209,
          13.193725,
          2.9116957,
          14.073406,
          6.0107756,
          8.917434,
          4.1464214,
          9.111659,
          6.5545664,
          12.118715,
          7.9098296,
          -3.2223103,
          7.9293103,
          -7.1513214,
          19.62048,
          9.237382,
          10.043548,
          11.854635,
          4.7102323,
          -1.2146881,
          3.813666,
          14.021925,
          8.002326,
          5.2495427,
          10.859695,
          3.498745,
          9.043472,
          23.994957,
          20.977755,
          -9.849907,
          -8.996538,
          9.341694,
          10.827926,
          8.591448,
          14.201481,
          5.719062,
          22.018045,
          9.657261,
          -2.4815247,
          8.785211,
          -4.36692,
          9.281826,
          11.43589,
          2.7014916,
          23.714975,
          -8.677196,
          4.3798714,
          21.494356,
          -6.555122,
          -6.5479436,
          -2.589457,
          17.935686,
          5.5442047,
          -13.898045,
          6.1200776,
          10.101342,
          8.265349,
          9.368646,
          2.0525293,
          12.790036,
          -5.0924687,
          1.3014437,
          11.094627,
          7.851324,
          11.331473,
          5.6963534,
          9.48413,
          16.93322,
          8.300358,
          -2.8684888,
          24.099924,
          27.877804,
          19.853695
         ]
        },
        {
         "customdata": [
          [
           "Diversity",
           " <i>An Open Letter to the Global South: Bring the 'rest' in (Uma Carta Aberta ao Sul<br>Global: Tragam o “resto” para dentro)</i>",
           " 2021",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Latin America",
           " Brazil",
           " Diversity",
           " <i>The valuing of the different ways in which the human entity can come to express<br>itself by whatever group or identity it wishes. AI systems must be developed in<br>a way that protects and values our diversity. The embracing and welcoming of all<br>the ways that the human entity can come to express itself, regardless of<br>specific affiliations, groups, and identities. AI systems should be developed in<br>such a way as to \"include,\" not exclude.</i>"
          ],
          [
           "Diversity",
           " <i>AI Policies and Principles</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Industrial Association",
           " North America",
           " United States of America",
           " Diversity",
           " <i>AI systems designers must ensure that they prioritize diversity and inclusion in<br>their systems. AI systems need to leverage large datasets, and the availability<br>of robust and representative data for building and improving AI and machine<br>learning systems is of utmost importance.</i>"
          ],
          [
           "Diversity",
           " <i>Artificial Intelligence and Machine Learning: Policy Paper</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Diversity",
           " <i>The ability of various stakeholders, whether civil society, government, private<br>sector or academia, and the technical community, to inform and participate in<br>the governance of AI is crucial for its safe deployment.</i>"
          ],
          [
           "Diversity",
           " <i>Everyday Ethics for Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Diversity",
           " <i>The approach to right and wrong is context-laden; different contexts understand<br>right and wrong differently. AI developers must ensure that they take the<br>diversity of cultural and societal norms seriously. Care is vital to ensure<br>sensitivity towards a wide rand of cultural norms and values.</i>"
          ],
          [
           "Diversity",
           " <i>The Japanese Society for Artificial Intelligence Ethical Guidelines</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Academic",
           " Eastern Asia",
           " Japan",
           " Diversity",
           " <i>AI researchers must listen attentively to the diverse views of society and learn<br>from them with humility. Members of the JSAI understand that there are diverse<br>views of AI within society and will earnestly learn from them. They will<br>strengthen their understanding of society and maintain consistent and effective<br>communication with them, to contribute to the overall peace and happiness of all<br>of humanity.</i>"
          ],
          [
           "Diversity",
           " <i>Kakao Algorithm Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " South Korea",
           " Diversity",
           " <i>Kakao aims for a future where all members of our society can rejoice together<br>through our technologies and services. Algorithms can lead to unintended social<br>alienation due to their inherent nature. Kakao is not only sensitive to these<br>dysfunctions but also pays attention to ways our algorithms can be used to<br>enhance the benefits and happiness of the socially vulnerable.</i>"
          ],
          [
           "Diversity",
           " <i>10 ethical guidelines for the digitalisation of companies (10 ethische<br>Leitlinien für die Digitalisierung von Unternehmen)</i>",
           " 2017",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Diversity",
           " <i>The exclusion of people with low online affinity and of offline users is to be,<br>as far as possible, irrespective of the technical capabilities of the<br>individual.</i>"
          ],
          [
           "Diversity",
           " <i>Ethics Guidelines for Trustworthy AI</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Diversity",
           " <i>Pay particular attention to situations involving more vulnerable groups such as<br>children, persons with disabilities, and others that have historically been<br>disadvantaged or are at risk of exclusion, and to situations that are<br>characterized by asymmetries of power or information, such as between employers<br>and workers, or between businesses and consumers. AI systems should not have a<br>one-size-fits-all approach and should consider Universal Design principles<br>addressing the widest possible range of users, following relevant accessibility<br>standards.</i>"
          ],
          [
           "Diversity",
           " <i>China’s Artificial Intelligence Industry Alliance Self-discipline Convention</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Diversity",
           " <i>Promote the inclusiveness, diversity, and universality of artificial<br>intelligence systems. Strengthen cross-domain, interdisciplinary, and cross-<br>border cooperation and exchange, and solidify an artificial intelligence<br>governance consensus. Strive to achieve diversification of R&D personnel and<br>comprehensive training data for artificial intelligence systems. Continually<br>test and validate algorithms, so that they do not discriminate against users<br>based on race, gender, nationality, age, religious beliefs, etc.</i>"
          ],
          [
           "Diversity",
           " <i>Mid- to Long-Term Master Plan in Preparation for the Intelligent Information<br>Society Managing the Fourth Industrial Revolution</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " South Korea",
           " Diversity",
           " <i>Channel technological innovation toward supporting and assisting human<br>activities (eating, using the bathroom, moving about, etc.) to solve many of the<br>daily problems and difficulties faced by the elderly and people with<br>disabilities.</i>"
          ],
          [
           "Diversity",
           " <i>Charlevoix Common Vision for the Future of Artificial Intelligence</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " International Organization",
           " Intergovernmental Organization",
           " G7",
           " Diversity",
           " <i>We, the leaders of the G7, commit to supporting and involving women,<br>underrepresented populations, and marginalized individuals as creators,<br>stakeholders, leaders, and decision-makers at all stages of the development and<br>implementation of AI applications.</i>"
          ],
          [
           "Diversity",
           " <i>Next-Generation AI Governance Principles - Develop responsible artificial<br>intelligence</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Diversity",
           " <i>AI development should improve the adaptability of disadvantaged groups, and<br>strive to erase the digital divid</i>"
          ],
          [
           "Diversity",
           " <i>Responsible bots: 10 guidelines for developers of conversational AI</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Diversity",
           " <i>Design your bot so that it respects relevant cultural norms and guards against<br>misuse; Strive for diversity amongst your development team. If you are<br>developing a bot, consider how your bot complies with commonly used<br>accessibility standards; Have people with disabilities test your bots; Design<br>bots to respect the full range of human abilities.</i>"
          ],
          [
           "Diversity",
           " <i>Toward a G20 Framework for Artificial Intelligence in the Workplace</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " Canada",
           " Diversity",
           " <i>AI should adopt inclusive design efforts to anticipate any potential deployment<br>issues that could unintentionally exclude people.</i>"
          ],
          [
           "Diversity",
           " <i>Digital ethics: a guide for professionals of the digital age</i>",
           " 2018",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " France",
           " Diversity",
           " <i>Draw up an HR (Human Resources) policy ensuring social and gender diversity in<br>the workplace. By default, design solutions that are accessible for people with<br>disabilities.</i>"
          ],
          [
           "Diversity",
           " <i>The Future Computed – Artificial intelligence and its role in society</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Diversity",
           " <i>AI systems should empower everyone and engage people. People around the world<br>can benefit from AI — but only if AI technologies are available for them. We<br>believe that the people designing AI systems should reflect the diversity of the<br>world in which we live.</i>"
          ],
          [
           "Diversity",
           " <i>How Can Humans Keep The Upper Hand? The Ethical Matters Raised By Algorithms And<br>Artificial Intelligence</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Diversity",
           " <i>If we are to guarantee that artificial intelligence does not foster forms of<br>ethnocentrism, it is vital to encourage cultural, social, and gender<br>diversification in the occupations involved in designing algorithms.</i>"
          ],
          [
           "Diversity",
           " <i>Responsible AI - Microsoft AI principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Diversity",
           " <i>AI systems should empower everyone and engage people.</i>"
          ],
          [
           "Diversity",
           " <i>For a meaningful Artificial Intelligence - Towards a French and European<br>strategy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Diversity",
           " <i>We must support investment efforts focused on AI projects within the sphere of<br>dependence and disability. Given the important nature of the ethical questions<br>that confront future developments in AI, it would be prudent to create a<br>genuinely diverse and inclusive social forum for discussion, to enable us to<br>democratically determine which forms of AI are appropriate for our society.<br>Given the extent of future AI-led transformation, we have a collective<br>responsibility to ensure that no one gets left behind.</i>"
          ],
          [
           "Diversity",
           " <i>It’s Time to Do Something: Mitigating the Negative Impacts of Computing Through<br>a Change to the Peer Review Process</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " Eastern Asia, Central Europe",
           " Turkey, Turkey",
           " Diversity",
           " <i>The researcher who develops any technology would be required under our<br>recommendations to include benefits to accessibility.</i>"
          ],
          [
           "Diversity",
           " <i>Ethical, Social, and Political Challenges of Artificial Intelligence in Health</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " United Kingdom",
           " Diversity",
           " <i>Research focusing on these ethical, social, and political challenges must be<br>multidisciplinary, drawing on the expertise of those who develop AI tools, those<br>who will use and be impacted by these tools, and those who have knowledge and<br>experience of addressing other major ethical, social and political challenges in<br>health. Most importantly, it is vital that the voices of patients and their<br>relatives are heard, and that their needs - clinical, pastoral, spiritual, and<br>more - are kept in mind at all stages of such research.</i>"
          ],
          [
           "Diversity",
           " <i>Model AI Governance Framework</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " Southeast Asia",
           " Singapore",
           " Diversity",
           " <i>Ensure that AI is accessible to all.</i>"
          ],
          [
           "Diversity",
           " <i>Data, Responsibly (Vol. 1) Mirror, Mirror</i>",
           " 2020",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Diversity",
           " <i>In our reality, digital accessibility is focused on making sure web platforms<br>are easily navigable and usable for people with any kind of disability.<br>Accessibility needs to be a fundamental design principle for building websites<br>and software. We should focus on harnessing the power of Learning Technologies<br>to positively impact people. And not one, affluent, highly influential<br>demographic of persons, but truly all persons, of all social strata, classes,<br>genders, and races.</i>"
          ],
          [
           "Diversity",
           " <i>Asilomar AI Principles</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Diversity",
           " <i>AI systems should be designed and operated to be compatible with ideals of human<br>dignity, rights, freedoms, and cultural diversity.</i>"
          ],
          [
           "Diversity",
           " <i>G20 Ministerial Statement on Trade and Digital Economy</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " G20",
           " Diversity",
           " <i>Stakeholders should proactively engage in responsible stewardship of trustworthy<br>AI in pursuit of beneficial outcomes for people and the planet, such as<br>advancing the inclusion of underrepresented populations.</i>"
          ],
          [
           "Diversity",
           " <i>AI & Data Topical Guide Series</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Southern Africa",
           " South Africa",
           " Diversity",
           " <i>Universities and research institutions should seek to develop engagement<br>processes that enroll diverse participants and perspectives as part of AI and<br>data research projects, and carefully consider how industry partnerships may<br>lead to conflicting commercial and ethical interests. The private sector,<br>government, and academic organizations can increase public engagement with and<br>awareness of data-driven technologies and AI, particularly insofar as it can<br>affect and shape the lives of individuals and communities.</i>"
          ],
          [
           "Diversity",
           " <i>Rome Call for AI Ethics</i>",
           " 2020",
           " Recommendation",
           " Religious Institution",
           " Southern Europe",
           " Vatican City State",
           " Diversity",
           " <i>The needs of all human beings must be taken into consideration so that everyone<br>can benefit and all individuals can be offered the best possible conditions to<br>express themselves and develop. These systems must not discriminate against<br>anyone because every human being has equal dignity.</i>"
          ],
          [
           "Diversity",
           " <i>Ethically Aligned Design: A Vision for Prioritizing Human Well-being with<br>Autonomous and Intelligent Systems, Version 2</i>",
           " 2017",
           " Recommendation",
           " Professional Association",
           " North America",
           " United States of America",
           " Diversity",
           " <i>Designers and developers of A/IS should remain aware of, and take into account<br>when relevant, the diversity of existing cultural norms among the groups of<br>users of these A/IS.</i>"
          ],
          [
           "Diversity",
           " <i>Užupis Principles for Trustworthy AI Design</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Europe",
           " Lithuania",
           " Diversity",
           " <i>I promise to discuss my opinion about what is common good with the various<br>groups affected by my AI.</i>"
          ],
          [
           "Diversity",
           " <i>The Ethics of Code: Developing AI for Business with Five Core Principles</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Diversity",
           " <i>AI should level the playing field. AI should reflect the diversity of the users<br>it serves. We need to create innately diverse AI.</i>"
          ],
          [
           "Diversity",
           " <i>Artificial intelligence and Privacy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Norway",
           " Diversity",
           " <i>Adopt a multidisciplinary approach. AI is more than just technology. It is<br>important to put together multi-disciplinary teams that can consider the<br>consequences for society of the systems developed.</i>"
          ],
          [
           "Diversity",
           " <i>Code of conduct for data-driven health and care technology</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Diversity",
           " <i>Health and care services are for everyone, including people with different<br>physical, mental health, social, cultural, or learning needs. Health technology<br>designers should consider the needs of a diverse set of users to ensure the<br>product is accessible to as many people as possible.</i>"
          ],
          [
           "Diversity",
           " <i>Artificial intelligence and the work of tomorrow (Künstliche Intelligenz und die<br>Arbeit von Morgen)</i>",
           " 2019",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Diversity",
           " <i>A prerequisite for good design is a broad participation process that begins with<br>the definition of the objectives for AI and its application and includes an<br>impact assessment. Employees and their interest groups must be involved.</i>"
          ],
          [
           "Diversity",
           " <i>Ethics Framework - Responsible AI</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Diversity",
           " <i>Companies should consider the impact and utility of their product for<br>individuals, larger groups, and society as a whole, including its impact on<br>widening or narrowing inequality, enabling or constraining discrimination, and<br>other political, cultural and environmental factors.</i>"
          ],
          [
           "Diversity",
           " <i>AI Ethics Principles & Guidelines</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Middle East",
           " United Arab Emirates",
           " Diversity",
           " <i>Data ingested should, where possible, be representative of the affected<br>population.</i>"
          ],
          [
           "Diversity",
           " <i>Data for the Benefit of the People: Recommendations from the Danish Expert Group<br>on Data Ethics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Denmark",
           " Diversity",
           " <i>Diversity (demographic and professional) in teams working with data systems is<br>essential. Diversity helps ensure a mix of skills, beyond the purely technical,<br>for identifying and tackling the social and ethical consequences of data<br>processing and to ensure that a representative section of the needs, values, and<br>interests of population groups in society is taken into account right from the<br>start when data systems are designed.</i>"
          ],
          [
           "Diversity",
           " <i>Beijing AI Principles</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Eastern Asia",
           " China",
           " Diversity",
           " <i>Te development of AI should reflect diversity and inclusiveness, and be designed<br>to benefit as many people as possible, especially those who would otherwise be<br>easily neglected or underrepresented in AI applications.</i>"
          ],
          [
           "Diversity",
           " <i>Responsible Artificial Intelligence in the Government of Canada (whitepaper)</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Diversity",
           " <i>AI systems should be developed in a diverse team that includes individuals<br>capable of assessing the ethical and socioeconomic implications of the system.</i>"
          ],
          [
           "Diversity",
           " <i>SAP’s guiding principles for Artificial Intelligence</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Diversity",
           " <i>We strive to create AI software systems that are inclusive and that seek to<br>empower and augment the talents of our diverse users.</i>"
          ],
          [
           "Diversity",
           " <i>People + AI Guidebook</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Diversity",
           " <i>Your training data should reflect the diversity and cultural context of the<br>people who will use it. Use tools like Facets and WIT to explore your dataset<br>and better understand its biases.</i>"
          ],
          [
           "Diversity",
           " <i>Responsible AI practices</i>",
           " Unspecified",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Diversity",
           " <i>Design your model using concrete goals for fairness and inclusion. Engage with<br>social scientists, humanists, and other relevant experts for your product to<br>understand and account for various perspectives. Consider how the technology and<br>its development over time will impact different use cases: Whose views are<br>represented? What types of data are represented? What’s being left out? What<br>outcomes does this technology enable and how do these compare for different<br>users and communities? What biases, negative experiences, or discriminatory<br>outcomes might occur?</i>"
          ],
          [
           "Diversity",
           " <i>Artificial Intelligence: Australia’s Ethics Framework - A Discussion Paper</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Oceania",
           " Australia",
           " Diversity",
           " <i>The Government has recognized that Australia must have a deeper STEM talent pool<br>and this is why it has supported the development of a Decadal Plan for Women in<br>STEM to provide a roadmap for sustained increases in women’s participation in<br>STEM over the next decade. The benefits of greater diversity in the ICT<br>workforce will be felt across many dimensions of the Australian economy,<br>including AI.</i>"
          ],
          [
           "Diversity",
           " <i>The Future Society, Law & Society Initiative, Principles for the Governance of<br>AI</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Diversity",
           " <i>The norms of the delegation of decisions to AI systems shall be codified through<br>thoughtful, inclusive dialogue with civil society.</i>"
          ],
          [
           "Diversity",
           " <i>Sony Group AI Ethics Guidelines</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " Japan",
           " Diversity",
           " <i>To solve the challenges arising from the use of AI while striving for better AI<br>utilization, Sony will seriously consider the interests and concerns of various<br>stakeholders including its customers and creators, and proactively advance<br>dialogue with related industries, organizations, academic communities, and more.</i>"
          ],
          [
           "Diversity",
           " <i>Principles for the safe and effective use of data and analytics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Oceania",
           " New Zealand",
           " Diversity",
           " <i>Data and data analytics are tools that support decision-making and it’s<br>essential that in collecting and using public data, government agencies<br>consider, and can demonstrate positive public benefits. This includes:<br>considering the views of all relevant stakeholders; embedding a te ao Māori<br>perspective through a Treaty-based partnership approach.</i>"
          ],
          [
           "Diversity",
           " <i>Telefónica´s Approach to the Responsible Use of AI (Enfoque de Telefónica para<br>un uso responsable de la IA)</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Spain",
           " Diversity",
           " <i>Technology should contribute to making society more inclusive and offer better<br>opportunities for all, and AI can contribute to these goals.</i>"
          ],
          [
           "Diversity",
           " <i>AI Now Report 2018</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Diversity",
           " <i>Technology companies and the AI field as a whole have focused on the “pipeline<br>model,” looking to train and hire more diverse employees. While this is<br>important, it overlooks what happens once people are hired into workplaces that<br>exclude, harass, or systemically undervalue people based on gender, race,<br>sexuality, or disability.</i>"
          ],
          [
           "Diversity",
           " <i>Report on Artificial Intelligence and Human Society</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Diversity",
           " <i>There is a need to create space for dialogue among people with different visions<br>and ideas and to consider common, fundamental social values. The government<br>needs to promote basic sciences and create an environment that supports open<br>science to enhance R&D in AI technology diversity. This will contribute to the<br>advancement, robustness, and safety of AI technologies. Such technological<br>diversity seems suited for social diversity</i>"
          ],
          [
           "Diversity",
           " <i>Understanding artificial intelligence ethics and safety: A guide for the<br>responsible design and implementation of AI systems in the public sector</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Western Europe",
           " United Kingdom",
           " Diversity",
           " <i>Connect with each other sincerely, openly, and inclusively (i.e., prioritize<br>diversity, participation, and inclusion at all points in the design,<br>development, and deployment processes of AI innovation).</i>"
          ],
          [
           "Diversity",
           " <i>Opinion of the Data Ethics Commission</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Diversity",
           " <i>It must be ensured by means of a wide range of different measures, which may<br>also and in particular involve inclusion and participation in the development of<br>algorithmic systems.</i>"
          ],
          [
           "Diversity",
           " <i>Statement on Artificial Intelligence, Robotics and 'Autonomous‘ Systems</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Diversity",
           " <i>Key decisions on the regulation of AI development and application should be the<br>result of democratic debate and public engagement. A spirit of global<br>cooperation and public dialogue on the issue will ensure that they are taken in<br>an inclusive, informed, and farsighted manner. The right to receive education or<br>access information on new technologies and their ethical implications will<br>facilitate that everyone understands risks and opportunities and is empowered to<br>participate in decisional processes that crucially shape our future.</i>"
          ],
          [
           "Diversity",
           " <i>Report with recommendations to the Commission on Civil Law Rules on Robotics</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " European Union",
           " European Union",
           " Diversity",
           " <i>Robotics engineers guarantee transparency and respect for the legitimate right<br>of access to information by all stakeholders. Inclusiveness allows for<br>participation in decision-making processes by all stakeholders involved in or<br>concerned by robotics research activities.</i>"
          ],
          [
           "Diversity",
           " <i>Preparing for the future of Artificial Intelligence</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Diversity",
           " <i>The NSTC Subcommittees on MLAI and NITRD, in conjunction with the NSTC Committee<br>on Science, Technology, Engineering, and Education (CoSTEM), should initiate a<br>study on the AI workforce pipeline to develop actions that ensure an appropriate<br>increase in the size, quality, and diversity of the workforce, including AI<br>researchers, specialists, and users. NSF and the Department of Education are<br>working with the private sector and across government to advance education<br>quality, flexibility, and domain impact, to address goals such as sustained<br>economic development, increased inclusion and diversity, and improved outcome<br>measures.</i>"
          ],
          [
           "Diversity",
           " <i>Vienna Manifesto on Digital Humanism</i>",
           " 2019",
           " Recommendation",
           " Academic",
           " Central Europe",
           " Austria",
           " Diversity",
           " <i>Digital technologies should be designed to promote democracy and inclusion. This<br>will require special efforts to overcome current inequalities and to use the<br>emancipatory potential of digital technologies to make our societies more<br>inclusive.</i>"
          ],
          [
           "Diversity",
           " <i>Tieto’s AI ethics guidelines</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Finland",
           " Diversity",
           " <i>At Tieto, we are committed to unbiased, fair, and inclusive AI fostering<br>diversity and equality among people.</i>"
          ],
          [
           "Diversity",
           " <i>AI in the UK: ready, willing and able?</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Diversity",
           " <i>We recommend that a specific challenge be established within the Industrial<br>Strategy Challenge Fund to stimulate the creation of authoritative tools and<br>systems for auditing and testing training datasets to ensure they are<br>representative of diverse populations, and to ensure that when used to train AI<br>systems they are unlikely to lead to prejudicial decisions.</i>"
          ],
          [
           "Diversity",
           " <i>Preliminary Study on the Ethics of Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Diversity",
           " <i>AI should foster cultural diversity, inclusiveness, and the flourishing of human<br>experience, avoiding a deepening of the digital divide. A multilingual approach<br>should be promoted.</i>"
          ],
          [
           "Diversity",
           " <i>Report of COMEST on robotics ethics</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Diversity",
           " <i>A greater sensitivity to cultural and gender issues should drive research and<br>innovation in robotics. Due to the diversity of cultures, robots – especially<br>social robots – may be accepted in certain settings and not in others.</i>"
          ],
          [
           "Diversity",
           " <i>Introducing Unity’s Guiding Principles for Ethical AI</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Diversity",
           " <i>Design AI tools to complement the human experience in a positive way. Consider<br>all types of human experiences in this pursuit. Diversity of perspective will<br>lead to AI complementing experiences for everybody, as opposed to a select few.</i>"
          ],
          [
           "Diversity",
           " <i>Montréal declaration for a responsible development of artificial intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " Canada",
           " Diversity",
           " <i>The development and use of AI must be compatible with maintaining social and<br>cultural diversity and must not restrict the scope of lifestyle choices or<br>personal experiences. From the moment algorithms are conceived, AIS development<br>and deployment must take into consideration the multitude of expressions of<br>social and cultural diversity present in society.</i>"
          ],
          [
           "Diversity",
           " <i>Ethical Framework for Artificial Intelligence in Colombia (Marco Ético para la<br>Inteligencia Artificial en Colombia)</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Latin America",
           " Colombia",
           " Diversity",
           " <i>The State must use artificial intelligence systems that have complied with<br>inclusion criteria and respond to the specific needs of historically<br>marginalized and diverse populations.</i>"
          ],
          [
           "Diversity",
           " <i>fAIr LAC: Responsible and Widespread Adoption of Artificial Intelligence in<br>Latin America and the Caribbean</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Latin America",
           " Unspecified",
           " Diversity",
           " <i>Stakeholders should proactively engage in advancing the inclusion of<br>underrepresented populations, reducing economic, social, gender, and other<br>inequalities.</i>"
          ],
          [
           "Diversity",
           " <i>Social Principles of Human-Centric AI</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia, Western Europe",
           " Japan, United Kingdom",
           " Diversity",
           " <i>It is preferred that the use of AI will create an environment in which many<br>people can engage in highly creative and productive work. To that end, it is<br>expected that a diverse range of people will acquire the ability to realize<br>their dreams and ideas with AI's support despite many differences in origin,<br>culture, taste, and so on.</i>"
          ],
          [
           "Diversity",
           " <i>The Toronto Declaration</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " North America, Western Europe",
           " Canada, United Kingdom",
           " Diversity",
           " <i>This Declaration underlines that inclusion, diversity, and equity are key<br>components of protecting and upholding the right to equality and non-<br>discrimination. All must be considered in the development and deployment of<br>machine learning systems to prevent discrimination, particularly against<br>marginalized groups. Additional protection must extend to those groups,<br>including protections for sensitive data. States should proactively adopt<br>diverse hiring practices and engage in consultations to assure diverse<br>perspectives so that those involved in the design, implementation, and review of<br>machine learning represent a range of backgrounds and identities.</i>"
          ],
          [
           "Diversity",
           " <i>Position on Robotics and Artificial Intelligence</i>",
           " 2016",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Diversity",
           " <i>Nobody is to judge whether a technological self-modification is useful or<br>necessary except for the individuals themselves. Inclusion and diversity must be<br>the highest priority of our societies. The dignity of persons with or without<br>disabilities is inviolable.</i>"
          ],
          [
           "Diversity",
           " <i>AI Governance in Japan Ver. 1.1, Report from the expert group on how AI<br>principles should be implemented</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Diversity",
           " <i>It is preferred that the use of AI will create an environment in which many<br>people can engage in highly creative and productive work. To that end, it is<br>expected that a diverse range of people will acquire the ability to realize<br>their dreams and ideas with AI's support despite many differences in origin,<br>culture, taste, and so on.</i>"
          ],
          [
           "Diversity",
           " <i>Vodafone Artificial Intelligence Framework</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Diversity",
           " <i>Vodafone will seek to reduce any digital divide that occurs in our markets<br>because of differential access to AI-based technologies. Vodafone will<br>proactively engage with industry peers and other relevant experts (e.g.<br>academics and civil society) in consultation exercises to ensure that AI-based<br>systems are human-centric and foster diversity and inclusivity. We will strive<br>to ensure that our AI teams – in line with all other teams in Vodafone – are<br>diverse</i>"
          ],
          [
           "Diversity",
           " <i>Artificial Intelligence at the service of the citizen (L’intelligenzia<br>artificiale al servizio del cittadino)</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Southern Europe",
           " Italy",
           " Diversity",
           " <i>AI needs to defend people with disabilities, and not let prejudice against them<br>occur. AI articles should care about diversity and inclusion, without using<br>prejudice between races, ethnicities, gender.</i>"
          ],
          [
           "Diversity",
           " <i>Artificial Intelligence: open questions about gender inclusion</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Latin America",
           " Argentina",
           " Diversity",
           " <i>Women need to have an active role in shaping the next generation of<br>technologies, so stereotypes are not reproduced and diversity is considered.<br>Countries need to take proactive steps towards the inclusion of women in the<br>coding and the design of machine learning and AI technologies. We Recommend that<br>G20 governments, in close collaboration with the Education Ministries,<br>Universities, and the private sector, take proactive steps towards the inclusion<br>of more women in the workforce that design AI systems.</i>"
          ],
          [
           "Diversity",
           " <i>WLiAI Report 2019: 10 Principles of Responsible AI</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " United Kingdom",
           " Diversity",
           " <i>We recommend the set up of a solid, courageous, and rigorous program to<br>encourage young women and other underrepresented groups into technology.</i>"
          ],
          [
           "Diversity",
           " <i>The Ethical Norms for the New Generation Artificial Intelligence, China</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Diversity",
           " <i>Various activities of AI shall abide by the following fundamental ethical norms,<br>like Adhere to shared benefits and inclusivity, effectively protecting the<br>legitimate rights and interests of all relevant stakeholders. When providing AI<br>products and services, we should fully respect and help vulnerable groups and<br>underrepresented groups, and provide corresponding alternatives as needed.</i>"
          ],
          [
           "Diversity",
           " <i>Work in the age of artificial intelligence: Four perspectives on the economy,<br>employment, skills and ethics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Finland",
           " Diversity",
           " <i>In the development and use of AI technology, attention should be paid to<br>societal heterogeneity and participation. Diversity should be promoted –<br>including different educational backgrounds, linguistic and ethnic groups,<br>genders, and age groups – among AI developers. It should also be ensured that<br>citizens have capabilities for participating in a broad-based discussion on the<br>artificial intelligence society. A general understanding of the potential<br>generated and challenges created by artificial intelligence should be built up.</i>"
          ],
          [
           "Diversity",
           " <i>A Framework for Responsible Limits on Facial RecognitionUse Case: Flow<br>Management</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization",
           " Western Europe",
           " Switzerland",
           " Diversity",
           " <i>Facial recognition should not exclude anyone and should always be accessible to<br>and usable by all groups of people, including elderly people and people with<br>disabilities.</i>"
          ],
          [
           "Diversity",
           " <i>How to Prevent Discriminatory Outcomes in Machine Learning</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization",
           " Western Europe",
           " Switzerland",
           " Diversity",
           " <i>The development and design of ML applications must actively seek a diversity of<br>input, especially of the norms and values of specific populations affected by<br>the output of AI systems.</i>"
          ],
          [
           "Diversity",
           " <i>Advisory statement on human ethics in artificial intelligence and big data<br>research (2017)</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Diversity",
           " <i>Respect the rights of involved communities as a whole when, for example, data<br>and information studied has implications for a specific community such as<br>Indigenous People.</i>"
          ],
          [
           "Diversity",
           " <i>The Holberton-Turing Oath</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Unspecified",
           " Unspecified",
           " Diversity",
           " <i>I will not permit considerations of age, disease or disability, creed, ethnic<br>origin, gender, nationality, political affiliation, religious beliefs, race,<br>sexual orientation, social standing, or any other factor to intervene in duty.</i>"
          ],
          [
           "Diversity",
           " <i>OECD, Recommendation of the Council on Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " France",
           " Diversity",
           " <i>Stakeholders should proactively engage in responsible stewardship of trustworthy<br>AI in pursuit of beneficial outcomes for people and the planet, such as<br>augmenting human capabilities and enhancing creativity, advancing the inclusion<br>of underrepresented populations, reducing economic, social, gender, and other<br>inequalities, and protecting natural environments, thus invigorating inclusive<br>growth, sustainable development, and well-being.</i>"
          ],
          [
           "Diversity",
           " <i>Partnership on AI Tenets</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization",
           " Unspecified",
           " Unspecified",
           " Diversity",
           " <i>We will work to maximize the benefits and address the potential challenges of AI<br>technologies, by striving to understand and respect the interests of all parties<br>that may be impacted by AI advances.</i>"
          ],
          [
           "Diversity",
           " <i>UNESCO Recommendation on the Ethics of Artificial Intelligence</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Diversity",
           " <i>Respect, protection, and promotion of diversity and inclusiveness should be<br>ensured throughout the life cycle of AI systems, consistent with international<br>law, including human rights law. This may be done by promoting active<br>participation of all individuals or groups regardless of race, color, descent,<br>gender, age, language, religion, political opinion, national origin, ethnic<br>origin, social origin, the economic or social condition of birth, or disability<br>and any other grounds.</i>"
          ],
          [
           "Diversity",
           " <i>Megvii's Artificial Intelligence Application Guidelines</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " China",
           " Diversity",
           " <i>AI solutions should be accessible to all regardless of age, gender, ethnicity or<br>other characteristics.</i>"
          ],
          [
           "Diversity",
           " <i>Policy guidance on AI for children</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution, International Organization",
           " Northern Europe, Intergovernmental Organization",
           " Finland, United Nations",
           " Diversity",
           " <i>Ensure inclusion of and for children. Include me and those around me. All<br>children should be empowered by AI and play a leading role in designing a<br>responsible digital future for all.</i>"
          ],
          [
           "Diversity",
           " <i>Ethics & Governance of Artificial Intelligence for Health</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Diversity",
           " <i>Inclusiveness requires that AI for health be designed to encourage the widest<br>possible appropriate, equitable use and access, irrespective of age, sex,<br>gender, income, race, ethnicity, sexual orientation, ability, or other<br>characteristics protected under human rights codes. AI technology, like any<br>other technology, should be shared as widely as possible.</i>"
          ],
          [
           "Diversity",
           " <i>HPE AI Ethics and Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Diversity",
           " <i>Be inclusive, minimize harmful bias, and ensure fair and equal treatment and<br>access for individuals.</i>"
          ],
          [
           "Diversity",
           " <i>Alpha Principles for the Ethical Use of AI and Data Driven Technologies in<br>Ontario</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Diversity",
           " <i>Data-driven technologies should be designed in a way that respects the rule of<br>law, human rights, democratic values, and diversity, and they should include<br>appropriate safeguards to ensure a fair and just society. Designers,<br>policymakers, and developers should respect the rule of law, human rights, and<br>democratic values, throughout the AI system lifecycle. These include freedom,<br>dignity and autonomy, privacy and data protection, non-discrimination and<br>equality, diversity, fairness, social justice, and internationally recognized<br>labor rights.</i>"
          ],
          [
           "Diversity",
           " <i>Transparency Guidelines for Data-Driven Technology in Government</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Diversity",
           " <i>Keep People in Focus and the Loop - Be aware of who will benefit most and who<br>will be impacted both directly and indirectly as a result of using the data-<br>driven technology. Development activities from design, to implementation, need<br>to reflect multiple perspectives to assess and address potential and perceived<br>risks.</i>"
          ],
          [
           "Diversity",
           " <i>Samsung Principles for AI Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " South Korea",
           " Diversity",
           " <i>The company will strive to provide easy access to all users.</i>"
          ],
          [
           "Diversity",
           " <i>ADP: Ethics in Artificial Intelligence</i>",
           " 2022",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Diversity",
           " <i>We are committed to having diverse teams design and develop our ML models, to<br>ensure a wide variety of perspectives and experiences are considered. After all,<br>ML models impact humans, and human experience should inform that impact.</i>"
          ],
          [
           "Diversity",
           " <i>Adobe’s Commitment to AI Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Diversity",
           " <i>We will ensure that we design for inclusiveness and assess the impact of<br>potentially unfair, discriminatory, or inaccurate results, which might<br>perpetuate harmful biases and stereotypes.</i>"
          ],
          [
           "Diversity",
           " <i>Artificial intelligence - Common good as a benchmark, good work as a principle</i>",
           " 2019",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Diversity",
           " <i>The potential of artificial intelligence for social inclusion being able to use<br>it, softening language barriers, compensating for cognitive and motor<br>impairments, and thus enabling participation is a promising perspective. The<br>development of artificial intelligence systems must be easily accessible,<br>verifiable and to be understandable.</i>"
          ],
          [
           "Diversity",
           " <i>The Code of Ethics in the Field of Artificial Intelligence</i>",
           " 2022",
           " Recommendation",
           " Unspecified",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Diversity",
           " <i>AI Actors should regard core values such as the preservation and development of<br>human cognitive abilities and creative potential; the preservation of moral,<br>spiritual, and cultural values; the promotion of cultural and linguistic<br>diversity and identity; and the preservation of traditions and the foundations<br>of nations, peoples, ethnic and social groups.</i>"
          ],
          [
           "Diversity",
           " <i>Chinese Young Scientists' Declaration on the Governance and Innovation of<br>Artificial Intelligence (Shanghai Declaration)</i>",
           " 2019",
           " Recommendation",
           " Academic, Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Asia",
           " China",
           " Diversity",
           " <i>We aim to initiate from the disciplined approach of system engineering, and to<br>construct the AI system with diverse data and unbiased algorithms, thus<br>improving the fairness of user experience.</i>"
          ],
          [
           "Diversity",
           " <i>Trustworthy AI in Aotearoa: AI Principles</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " Oceania",
           " New Zealand",
           " Diversity",
           " <i>Designers, developers, and users of AI systems (AI stakeholders) must respect<br>the rights of Māori articulated in Te Tiriti o Waitangi.</i>"
          ],
          [
           "Diversity",
           " <i>\"ARCC\": An Ethical Framework for Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " Eastern Asia",
           " China",
           " Diversity",
           " <i>Recommendation - AI should be available. Ensure AI is available to as many<br>people as possible, to achieve inclusive and broadly-shared development, and<br>avoid a technology gap.</i>"
          ],
          [
           "Diversity",
           " <i>Technological convergence, artificial intelligence and human rights</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Diversity",
           " <i>The Assembly calls on the Committee of Ministers to define the framework for the<br>use of care robots and assistive technologies in the Council of Europe<br>Disability Strategy 2017-2023 in the framework of its objective to achieve<br>equality, dignity, and equal opportunities for people with disabilities.</i>"
          ],
          [
           "Diversity",
           " <i>Stanford's Human-Centered AI Initiative Values</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Academic",
           " North America",
           " United States of America",
           " Diversity",
           " <i>We believe the quality of any intellectual endeavor is improved when<br>participants reflect diversity in the broadest sense, including gender, ethnic<br>and socioeconomic background, but also intellectual, cultural, and political<br>perspectives. We recognize that the field of AI, and academia in general, do not<br>yet reflect this diversity and that changing such systemic issues will take<br>time, but we aim to decrease the disparity. We are committed to seeking the<br>insights, experiences, and concerns of people across ethnicities, genders,<br>cultures, and socio-economic groups, as well as those from multiple disciplines<br>and with divergent political views.</i>"
          ],
          [
           "Diversity",
           " <i>Principles and Practices for the Responsible Application of Artificial<br>Intelligence at Motorola Solutions - White Paper</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Diversity",
           " <i>Motorola Solutions thoroughly evaluates the data employed in training our AI<br>algorithms to ensure that sufficient quantity, quality, and diversity exist<br>across the dataset to properly train the algorithm for its intended purpose and<br>operating environment.</i>"
          ]
         ],
         "hovertemplate": "<b>Document ID </b>=%{customdata[1]}<br><b>Year of Publication </b>=%{customdata[2]}<br><b>Reguation Type </b>=%{customdata[3]}<br><b>Institution Type </b>=%{customdata[4]}<br><b>World Region </b>=%{customdata[5]}<br><b>Country </b>=%{customdata[6]}<br><b>Principle </b>=%{customdata[7]}<br><b>Description </b>=%{customdata[8]}<extra></extra>",
         "legendgroup": "Diversity",
         "marker": {
          "color": "#FF6692",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Diversity",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          9.041437,
          13.967182,
          11.667759,
          1.1294622,
          7.015725,
          -10.364954,
          12.798436,
          7.7977996,
          15.576594,
          18.996792,
          22.344751,
          15.3243265,
          -21.975416,
          14.199304,
          15.229642,
          8.706995,
          16.71974,
          9.582324,
          12.068457,
          17.009829,
          4.635686,
          12.131971,
          20.78332,
          6.9128666,
          5.2695312,
          13.08544,
          2.176033,
          12.252655,
          -5.3844604,
          14.735792,
          7.5655513,
          19.722355,
          -0.19042227,
          14.089223,
          8.24618,
          1.6698179,
          13.957791,
          7.341306,
          3.6171796,
          9.36391,
          9.926841,
          20.844536,
          13.318568,
          -0.7563024,
          0.20549612,
          9.861979,
          17.356955,
          17.763107,
          13.742222,
          17.286436,
          12.023808,
          -12.473973,
          20.597204,
          22.125105,
          5.182025,
          9.366781,
          13.467936,
          -5.4201884,
          3.4013326,
          10.264101,
          13.935736,
          6.2901254,
          6.73105,
          2.7795434,
          1.7156368,
          7.645624,
          11.63412,
          11.741205,
          19.855938,
          21.333551,
          1.6377294,
          12.869017,
          11.738502,
          15.104543,
          6.390632,
          17.125128,
          4.3753023,
          1.0022115,
          8.69782,
          12.015298,
          7.069797,
          10.997086,
          13.8139925,
          2.038908,
          1.0270162,
          18.239414,
          16.761662,
          13.444489,
          9.99462,
          -1.2892518,
          12.097589,
          6.837673,
          12.111787,
          -1.5107602,
          16.141117,
          -22.302757
         ],
         "y": [
          4.1753197,
          3.3219843,
          -14.084801,
          -8.725231,
          14.303203,
          -23.54109,
          14.757756,
          6.716063,
          -3.5883398,
          1.5233097,
          0.75738525,
          1.8547455,
          8.144262,
          2.9822543,
          18.050869,
          -3.1125119,
          2.1161377,
          -2.1265638,
          -2.479766,
          1.3471807,
          -8.276981,
          0.51555336,
          0.41453448,
          5.7121634,
          -13.435741,
          -9.973774,
          12.9092245,
          9.034982,
          -18.250912,
          6.278421,
          -4.309214,
          1.428024,
          -11.895703,
          12.228825,
          14.115197,
          18.137362,
          2.4699786,
          -2.9353187,
          -15.970122,
          10.953137,
          7.8975325,
          -13.760347,
          -16.455994,
          -24.900978,
          12.7284775,
          -6.6685796,
          6.3918653,
          -3.4481719,
          -0.19081779,
          6.3296824,
          -8.39205,
          -13.007263,
          -14.418836,
          -1.5403851,
          -24.03871,
          -0.78902346,
          3.5809352,
          -12.695395,
          -13.301223,
          -0.36429328,
          7.6066384,
          -12.308778,
          -13.073805,
          8.37307,
          15.982426,
          -12.807493,
          -22.316038,
          5.8853574,
          1.8442676,
          1.8048557,
          -3.560492,
          0.15401642,
          20.29394,
          4.0933933,
          17.654928,
          13.546056,
          -12.208424,
          -18.515022,
          3.6991699,
          2.660692,
          5.099317,
          2.516067,
          15.962301,
          8.906042,
          12.972322,
          -1.3085934,
          2.3466,
          12.301014,
          -8.125609,
          4.405033,
          0.61644727,
          0.738182,
          -1.0497508,
          -5.432844,
          0.05828913,
          -5.0176682
         ],
         "z": [
          4.7183423,
          -2.620835,
          -3.587052,
          0.67274773,
          19.085545,
          6.813264,
          1.2139452,
          1.4727715,
          -3.33958,
          12.222419,
          -5.2006755,
          8.09727,
          10.900299,
          3.534377,
          -3.8986409,
          7.515788,
          -1.4142281,
          8.0546055,
          -0.2638864,
          -18.608028,
          -1.4020157,
          6.17756,
          7.8188562,
          7.738177,
          0.15398729,
          -4.719294,
          8.485704,
          10.097821,
          11.399076,
          3.2554812,
          -0.9376661,
          9.405735,
          -16.456259,
          -17.234695,
          -13.420012,
          -13.359043,
          1.1247588,
          0.043931775,
          7.735738,
          -16.274172,
          -19.605387,
          0.44418207,
          -5.979188,
          8.05102,
          -19.811457,
          7.532498,
          -5.062662,
          -0.512799,
          -3.3825173,
          -0.13922724,
          -1.3122296,
          16.153254,
          -2.241607,
          8.767477,
          -8.773443,
          -12.706513,
          9.333825,
          23.400864,
          13.088844,
          1.4767083,
          -0.50276285,
          -2.1962047,
          14.920877,
          -4.6435456,
          6.758216,
          14.308259,
          -3.9522858,
          2.1360948,
          -2.2356951,
          -0.41213647,
          1.9858483,
          0.46069482,
          0.2186812,
          0.017101228,
          -11.71798,
          -7.7667456,
          1.9246863,
          4.6471243,
          2.595779,
          6.0006013,
          23.444674,
          2.7330945,
          -4.407434,
          1.4895729,
          -13.850661,
          -17.442358,
          -6.1598024,
          -12.039975,
          10.389709,
          9.588059,
          -9.037484,
          6.381702,
          5.690932,
          27.648045,
          -1.1280607,
          -16.689026
         ]
        },
        {
         "customdata": [
          [
           "Fairness",
           " <i>Declaration on Ethics and Data Protection in Artifical Intelligence</i>",
           " 2018",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " Belgium",
           " Fairness",
           " <i>unlawful biases or discriminations that may result from the use of data in<br>artificial intelligence should be reduced and mitigated, ensuring the respect of<br>international legal instruments on human rights and non-discrimination.</i>"
          ],
          [
           "Fairness",
           " <i>AI Policies and Principles</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Industrial Association",
           " North America",
           " United States of America",
           " Fairness",
           " <i>To promote the responsible use of data and ensure its integrity at every stage,<br>the industry has a responsibility to understand the parameters and<br>characteristics of the data, to demonstrate the recognition of potentially<br>harmful bias, and to test for potential bias before and throughout the<br>deployment of AI systems. We are committed to partnering with others across<br>government, private industry, academia, and civil society to find ways to<br>mitigate bias, inequity, and other potential harms in automated decision-making<br>systems.</i>"
          ],
          [
           "Fairness",
           " <i>Artificial Intelligence and Machine Learning: Policy Paper</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Fairness",
           " <i>Stakeholders should shape an environment where AI provides socio-economic<br>opportunities for all.</i>"
          ],
          [
           "Fairness",
           " <i>Everyday Ethics for Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Fairness",
           " <i>AI must be developed to minimize bias and promote inclusive representation.<br>Designers of AI must ensure that algorithm bias is minimized by collecting data<br>from diverse populations.</i>"
          ],
          [
           "Fairness",
           " <i>Responsible AI: A Global Policy Framework</i>",
           " 2021",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization, Professional Association",
           " North America",
           " United States of America",
           " Fairness",
           " <i>Organisations that develop make available, or use AI systems, and any national<br>laws that regulate such use shall ensure the non-discrimination of AI outcomes<br>and shall promote appropriate and effective measures to safeguard fairness in AI<br>use.</i>"
          ],
          [
           "Fairness",
           " <i>Trusted AI</i>",
           " Unspecified",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Fairness",
           " <i>IBM has engaged in several projects such as AI Fairness 360 (a toolkit to check<br>for unwanted biases in datasets and machine learning and state-of-the-art<br>algorithms to minimize unnecessary biases).</i>"
          ],
          [
           "Fairness",
           " <i>The Japanese Society for Artificial Intelligence Ethical Guidelines</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Academic",
           " Eastern Asia",
           " Japan",
           " Fairness",
           " <i>Members of the JSAI will, to the best of their ability, ensure that AI is<br>developed as a resource that can be used by humanity in a fair and equal manner.</i>"
          ],
          [
           "Fairness",
           " <i>Kakao Algorithm Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " South Korea",
           " Fairness",
           " <i>Kakao aims for a society where diverse values ​​coexist. We will do our best to<br>ensure that the results implemented by our algorithms do not bias specific<br>values ​​or reinforce social discrimination.</i>"
          ],
          [
           "Fairness",
           " <i>Hambach Declaration on Artificial Intelligence(Hambacher Erklärung zur<br>Künstlichen Intelligenz)</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Germany",
           " Fairness",
           " <i>Discriminatory processing operations constitute a violation of the rights and<br>freedoms of data subjects. Among other things, they violate certain requirements<br>of the GDPR, such as the principle of fairness, the linking of processing to<br>legitimate purposes, or the adequacy of the processing.</i>"
          ],
          [
           "Fairness",
           " <i>KI Seal of Approval</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Fairness",
           " <i>Artificial intelligence should lead to more freedom, equality, justice,<br>solidarity, tolerance, and pluralism to ensure that it is not used for<br>discrimination or against democracy or human rights.</i>"
          ],
          [
           "Fairness",
           " <i>AI at Google: our principles</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Fairness",
           " <i>We will seek to avoid unjust impacts on people, particularly those related to<br>sensitive characteristics such as race, ethnicity, gender, nationality, income,<br>sexual orientation, ability, and political or religious belief.</i>"
          ],
          [
           "Fairness",
           " <i>Directive on Automated Decision-Making</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Fairness",
           " <i>The expected results of this Directive are as follows: Decisions made by federal<br>government departments are data-driven, responsible, and comply with procedural<br>fairness and due process requirements.</i>"
          ],
          [
           "Fairness",
           " <i>10 ethical guidelines for the digitalisation of companies (10 ethische<br>Leitlinien für die Digitalisierung von Unternehmen)</i>",
           " 2017",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Fairness",
           " <i>Equal opportunities should be promoted and discrimination avoided. The principle<br>of equal opportunity applies equally to online and offline users.</i>"
          ],
          [
           "Fairness",
           " <i>Ethics Guidelines for Trustworthy AI</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Fairness",
           " <i>To achieve Trustworthy AI, we must enable inclusion and diversity throughout the<br>entire AI system’s life cycle. Besides the consideration and involvement of all<br>affected stakeholders throughout the process, this also entails ensuring equal<br>access through inclusive design processes as well as equal treatment. This<br>requirement is closely linked with the principle of fairness.</i>"
          ],
          [
           "Fairness",
           " <i>Declaration of Ethical Principles for AI in Latin America (Declaración de<br>Principios Éticos para la IA de Latinoamérica)</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Latin America",
           " Unspecified",
           " Fairness",
           " <i>Avoid bias and unfair impacts on people, particularly those related to sensitive<br>characteristics such as race, ethnicity, gender, nationality, income, sexual<br>orientation, ability, and political or religious beliefs.</i>"
          ],
          [
           "Fairness",
           " <i>Mid- to Long-Term Master Plan in Preparation for the Intelligent Information<br>Society Managing the Fourth Industrial Revolution</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " South Korea",
           " Fairness",
           " <i>Apply Intelligent IT to people’s daily lives to achieve an open, discrimination-<br>free society in which everyone can enjoy the benefits of technological<br>innovation and maintain stable livelihoods despite job losses or transitions and<br>the rising cost of healthcare.</i>"
          ],
          [
           "Fairness",
           " <i>Charlevoix Common Vision for the Future of Artificial Intelligence</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " International Organization",
           " Intergovernmental Organization",
           " G7",
           " Fairness",
           " <i>We, the leaders of the G7, encourage industry to invest in developing and<br>deploying AI that supports economic growth and women’s economic empowerment<br>while addressing issues related to accountability, assurance, liability,<br>security, safety, gender, and other biases and potential misuse.</i>"
          ],
          [
           "Fairness",
           " <i>Governance Recommendations - Use of Artificial Intelligence by Public<br>Authorities</i>",
           " 2021",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Latin America",
           " Brazil",
           " Fairness",
           " <i>During data collection, it is important to ensure the data selected for training<br>the algorithms is representative of the groups and populations affected by them.<br>It is also important to check for subtle discriminations embedded in data<br>creation that might replicate discriminatory patterns further down the line.</i>"
          ],
          [
           "Fairness",
           " <i>Next-Generation AI Governance Principles - Develop responsible artificial<br>intelligence</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Fairness",
           " <i>AI development should promote fairness and justice, protect the rights and<br>interests of stakeholders, and promote equality of opportunity. Through<br>continuously raising the level of technology and improving management methods,<br>eliminate bias and discrimination in the process of data acquisition, algorithm<br>design, technology development, product R&D, and application.</i>"
          ],
          [
           "Fairness",
           " <i>Responsible bots: 10 guidelines for developers of conversational AI</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Fairness",
           " <i>Ensure your bot treats people fairly; Systematically assess the data used for<br>training your bot.</i>"
          ],
          [
           "Fairness",
           " <i>Facial recognition: It’s time for action</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Fairness",
           " <i>We will work to develop and deploy facial recognition technology in a manner<br>that strives to treat all people fairly. We will prohibit in our terms of<br>service the use of facial recognition technology to engage in unlawful<br>discrimination.</i>"
          ],
          [
           "Fairness",
           " <i>Toward a G20 Framework for Artificial Intelligence in the Workplace</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " Canada",
           " Fairness",
           " <i>Employers should be required to test AI in the workplace regularly to ensure<br>that the system is built for purpose and is not harmfully influenced by biases<br>of any kind — gender, race, sexual orientation, age, religion, income, family<br>status and so on. Workplace AI should be tested to ensure that it does not<br>discriminate against vulnerable individuals or communities. In particular, the<br>impact of overlapping AI systems toward profiling and marginalization should be<br>identified and countered</i>"
          ],
          [
           "Fairness",
           " <i>Digital ethics: a guide for professionals of the digital age</i>",
           " 2018",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " France",
           " Fairness",
           " <i>Carry out a DIA (discrimination impact assessment) as suggested in the Villani<br>report (p.148), inspired by the PIA (privacy impact assessment) introduced with<br>the GDPR, to analyze the possible design-induced discriminatory impacts of<br>algorithms. Put in place checks and balances at each stage of development to<br>ensure there is no bias in the results.</i>"
          ],
          [
           "Fairness",
           " <i>The Future Computed – Artificial intelligence and its role in society</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Fairness",
           " <i>AI systems should treat everyone in a fair and balanced manner and not affect<br>similarly situated groups of people in different ways.</i>"
          ],
          [
           "Fairness",
           " <i>How Can Humans Keep The Upper Hand? The Ethical Matters Raised By Algorithms And<br>Artificial Intelligence</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Fairness",
           " <i>A fair algorithm should not end up generating, replicating, or aggravating any<br>form of discrimination, even if this were to happen without its designers being<br>aware.</i>"
          ],
          [
           "Fairness",
           " <i>Statement on Algorithmic Transparency and Accountability</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Fairness",
           " <i>Owners, designers, builders, users, and other stakeholders of analytic systems<br>should be aware of the possible biases involved in their design, implementation,<br>and use and the potential harm that biases can cause to individuals and society.</i>"
          ],
          [
           "Fairness",
           " <i>Responsible AI - Microsoft AI principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Fairness",
           " <i>AI systems should treat all people fairly.</i>"
          ],
          [
           "Fairness",
           " <i>For a meaningful Artificial Intelligence - Towards a French and European<br>strategy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Fairness",
           " <i>In a world marked by inequality, artificial intelligence should not end up<br>reinforcing the problems of exclusion and the concentration of wealth and<br>resources. The development of this technology does not contribute to an increase<br>in social and economic inequality and using AI to help genuinely reduce these<br>problems.</i>"
          ],
          [
           "Fairness",
           " <i>Principles to Promote Fairness, Ethics, Accountability and Transparency (FEAT)<br>in the Use of Artificial Intelligence and Data Analytics in Singapore’s<br>Financial Sector</i>",
           " 2018",
           " Recommendation",
           " Governmental Institution",
           " Southeast Asia",
           " Singapore",
           " Fairness",
           " <i>Individuals or groups of individuals should not be systematically disadvantaged<br>through AIDA-driven decisions unless these decisions can be justified. Data and<br>models used for AIDA-driven decisions should be regularly reviewed and validated<br>for accuracy and relevance, and to minimize unintentional bias.</i>"
          ],
          [
           "Fairness",
           " <i>It’s Time to Do Something: Mitigating the Negative Impacts of Computing Through<br>a Change to the Peer Review Process</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " Eastern Asia, Central Europe",
           " Turkey, Turkey",
           " Fairness",
           " <i>For a technology with greater societal benefit, the researchers could be<br>incentivized to change the technologies they create to tilt the scales towards<br>more positive outcomes. A paper would need to acknowledge and discuss its<br>potential impact on privacy, security, and discrimination in a rigorous fashion.</i>"
          ],
          [
           "Fairness",
           " <i>Digital Technology and Healthcare which ethical issues for which regulations?</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " France",
           " Fairness",
           " <i>The uptake of digital technology in healthcare can have potentially significant<br>effects on health inequalities, both reducing and, in certain cases,<br>exacerbating them. It is therefore indispensable to monitor the implementation<br>of digital technology in healthcare in order to ensure that its adoption<br>contributes to reducing these inequalities.</i>"
          ],
          [
           "Fairness",
           " <i>Business Ethics and Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " Western Europe",
           " United Kingdom",
           " Fairness",
           " <i>Justice and fairness should be considered paramount when dealing with AI. This<br>includes fairness to the public and the stakeholders. Designers of AI systems<br>must ensure that their algorithms are free from systematic errors and biases.</i>"
          ],
          [
           "Fairness",
           " <i>Digital Decisions</i>",
           " Unspecified",
           " Recommendation",
           " Non-profit Organization",
           " Western Europe, North America",
           " Belgium, United States of America",
           " Fairness",
           " <i>In the case of algorithms, we must acknowledge and draw from civil rights<br>traditions to develop an adequate definition of fair. A fair system or design is<br>demonstrably not biased against individuals or groups of people.</i>"
          ],
          [
           "Fairness",
           " <i>Big Data, Artificial Intelligence, Machine Learning, and Data Protection</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Fairness",
           " <i>The data controller should use “appropriate mathematical or statistical<br>procedures for the profiling” and take measures to prevent discrimination based<br>on race or ethnic origin, political opinions, religion or beliefs, trade union<br>membership, genetic or health status or sexual orientation.</i>"
          ],
          [
           "Fairness",
           " <i>Model AI Governance Framework</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " Southeast Asia",
           " Singapore",
           " Fairness",
           " <i>There are many types of bias relevant to AI. The Model Framework focuses on<br>inherent bias in datasets, which may lead to undesired outcomes such as<br>unintended discriminatory decisions. Organizations should be aware that the data<br>which they provide to AI systems could contain inherent biases and are<br>encouraged to take steps to mitigate such bias.</i>"
          ],
          [
           "Fairness",
           " <i>Unfairness by Algorithm: Distilling the Harms of Automated Decision-making</i>",
           " 2017",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Fairness",
           " <i>Recent discussions have highlighted legal and ethical issues raised by the use<br>of sensitive data for hiring, policing, benefits determinations, marketing, and<br>other purposes. These conversations can become mired in definitional challenges<br>that make progress towards solutions difficult. There are few easy ways to<br>navigate these issues, but if stakeholders hold frank discussions, we can do<br>more to promote fairness, encourage responsible data use, and combat<br>discrimination.</i>"
          ],
          [
           "Fairness",
           " <i>G20 Ministerial Statement on Trade and Digital Economy</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " G20",
           " Fairness",
           " <i>Stakeholders should proactively engage in responsible stewardship of trustworthy<br>AI in pursuit of beneficial outcomes for people and the planet, such as reducing<br>economic, social, gender, and other inequalities.</i>"
          ],
          [
           "Fairness",
           " <i>Philips AI Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Netherlands",
           " Fairness",
           " <i>We develop and validate solutions using data that is representative of the<br>target group for the intended use, and we aim to avoid bias or discrimination.</i>"
          ],
          [
           "Fairness",
           " <i>AI 4People 's Ethical Framework for a Good AI Society: Opportunities, Risks,<br>Principles, and Recommendations</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Fairness",
           " <i>The development of AI should promote justice and seek to eliminate all types of<br>discrimination. Stakeholders should develop auditing mechanisms for AI systems<br>to identify unwanted consequences, such as unfair bias, and (for instance, in<br>cooperation with the insurance sector) a solidarity mechanism to deal with<br>severe risks in AIintensive sectors.</i>"
          ],
          [
           "Fairness",
           " <i>AI & Data Topical Guide Series</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Southern Africa",
           " South Africa",
           " Fairness",
           " <i>In developing South Africa’s national strategy on AI, specific attention should<br>be paid to the ways in which, and literature around how AI and data use can<br>reinforce discriminatory social categories and produce unfair biases that have a<br>material effect on how people chose to live their lives.</i>"
          ],
          [
           "Fairness",
           " <i>Rome Call for AI Ethics</i>",
           " 2020",
           " Recommendation",
           " Religious Institution",
           " Southern Europe",
           " Vatican City State",
           " Fairness",
           " <i>Do not create or act according to bias, thus safeguarding fairness and human<br>dignity. AI systems must not follow or create biases.</i>"
          ],
          [
           "Fairness",
           " <i>A practical guide to Responsible Artificial Intelligence (AI)</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Fairness",
           " <i>Bias is often identified as one of the biggest risks associated with AI.<br>However, it is possible to tune AI systems to mitigate bias and enable decisions<br>that are as fair as possible and adhere to an organization’s corporate code of<br>ethics, as well as follow anti-discrimination regulations.</i>"
          ],
          [
           "Fairness",
           " <i>Ethical Guidelines of the German Informatics Society</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization, Professional Association",
           " Western Europe",
           " Germany",
           " Fairness",
           " <i>GI members advocate for organizational structures which foster and facilitate<br>socially equitable contractual agreements concerning terms of employment.</i>"
          ],
          [
           "Fairness",
           " <i>Ethically Aligned Design: A Vision for Prioritizing Human Well-being with<br>Autonomous and Intelligent Systems, Version 2</i>",
           " 2017",
           " Recommendation",
           " Professional Association",
           " North America",
           " United States of America",
           " Fairness",
           " <i>Evaluation of A/IS must carefully assess potential biases in the system’s<br>performance that disadvantage specific social groups. The evaluation process<br>should integrate members of potentially disadvantaged groups to diagnose and<br>correct such biases.</i>"
          ],
          [
           "Fairness",
           " <i>The Ethics of Code: Developing AI for Business with Five Core Principles</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Fairness",
           " <i>As an industry and tech community, we must develop effective mechanisms to<br>filter our bias as well as any negative sentiment in the data that AI learns<br>from and ensure AI does not perpetuate stereotypes. Unless we build AI using<br>diverse teams, data sets, and design, we are at risk of repeating the inequality<br>of previous revolutions.</i>"
          ],
          [
           "Fairness",
           " <i>Hippocratic Oath for Data Scientists</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization",
           " Western Europe",
           " France",
           " Fairness",
           " <i>Be careful, when eliminating or imputing missing or outlying values, not to<br>introduce additional biases that would lead to partial or false results. Do not<br>create characteristic data (“features”) which would amount to sensitive personal<br>data if their use can lead to illegal or illegitimate discriminatory effects.<br>Measure bias and variance to control the accuracy and dispersion of the result<br>and document the error metrics retained.</i>"
          ],
          [
           "Fairness",
           " <i>Artificial intelligence and Privacy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Norway",
           " Fairness",
           " <i>The principle also requires the data controller to implement measures to prevent<br>the arbitrary discriminatory treatment of individual persons.</i>"
          ],
          [
           "Fairness",
           " <i>Code of conduct for data-driven health and care technology</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Fairness",
           " <i>It is crucial to eliminate your project’s potential to have unintended<br>discriminatory effects on individuals and social groups. You should aim to<br>mitigate biases that may influence your model’s outcome and ensure that the<br>project and its outcomes respect the dignity of individuals, are just,<br>nondiscriminatory, and consistent with the public interest, including human<br>rights and democratic values.</i>"
          ],
          [
           "Fairness",
           " <i>Digital Ethics Guidelines on AI</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Fairness",
           " <i>We take responsibility for a diverse and appropriate data input. In case of<br>inconsistencies, we rather stop the AI system than pursue with potentially<br>manipulated data. We are also able to “reset” our AI systems to remove false or<br>biased data. By this, we install a lever to reduce (unintended) unsuitable<br>decisions or actions to a minimum.</i>"
          ],
          [
           "Fairness",
           " <i>Ethics Framework - Responsible AI</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Fairness",
           " <i>Other considerations arise from data-driven products, such as the aptness of<br>data for use in situations that were not encountered in the training data, or<br>whether data contains unfair biases, that must be taken into account when<br>assessing the ethical implications of an AI product or service.</i>"
          ],
          [
           "Fairness",
           " <i>AI Ethics Principles & Guidelines</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Middle East",
           " United Arab Emirates",
           " Fairness",
           " <i>Algorithms should avoid non-operational bias. Steps should be taken to mitigate<br>and disclose the biases inherent in datasets. Significant decisions should be<br>provably fair.</i>"
          ],
          [
           "Fairness",
           " <i>Data for the Benefit of the People: Recommendations from the Danish Expert Group<br>on Data Ethics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Denmark",
           " Fairness",
           " <i>Strive for a fair balance in the data processing. When using machine learning<br>and algorithms for processing data, active work is being done to prevent<br>undesired bias in data (such as when manually sorting and tidying data), as well<br>as to work towards designs that avoid categorization that discriminates between<br>e.g. population groups. In regard to this, the rationale and criteria for<br>methods that reduce bias and discrimination will always be explicit and open to<br>revision.</i>"
          ],
          [
           "Fairness",
           " <i>Algo.Rules: Rules for the Design of Algorithmic Systems</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Private Corporation",
           " Western Europe",
           " Germany",
           " Fairness",
           " <i>The risk of discrimination and other consequences affecting individuals and the<br>common good must be taken into consideration.</i>"
          ],
          [
           "Fairness",
           " <i>From Principles to Practice: An interdisciplinary framework to operationalise AI<br>ethics</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Professional Association",
           " Western Europe",
           " Germany",
           " Fairness",
           " <i>The criteria subsumed under the value of justice in this example pertain to<br>classic aspects of algorithmic fairness such as bias prevention and assessment<br>but emphasize a process perspective to include a broader set of ethical<br>considerations. These aspects are, for example, inclusion, represented by<br>criteria such as participatory procedures, or social justice considerations, and<br>a criterion for the assessment of trade-offs generated by the employment of the<br>AI system in question. In this sense, justice refers to a broader set of ethical<br>considerations than the often-used term fairness, which mostly focuses on<br>algorithmic outcomes themselves.</i>"
          ],
          [
           "Fairness",
           " <i>Beijing AI Principles</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Eastern Asia",
           " China",
           " Fairness",
           " <i>AI R&D should take ethical design approaches to make the system trustworthy.<br>This may include, but is not limited to: making the system as fair as possible,<br>reducing possible discrimination and biases, improving its transparency,<br>explainability, and predictability, and making the system more traceable,<br>auditable, and accountable.</i>"
          ],
          [
           "Fairness",
           " <i>Artificial Intelligence: opportunities, risks and recommendations for the<br>financial sector</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Luxembourg",
           " Fairness",
           " <i>Institutions should aim at building systems respecting the principle of fairness<br>and nondiscrimination.</i>"
          ],
          [
           "Fairness",
           " <i>Responsible Artificial Intelligence in the Government of Canada (whitepaper)</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Fairness",
           " <i>AI needs to be trained with datasets and oriented towards preferable outcomes.<br>Both the training process and the selection of preferable outcomes carry with it<br>the bias of the humans that collected and tagged the data, as well as the<br>programmers that designed the algorithm.</i>"
          ],
          [
           "Fairness",
           " <i>Artificial Intelligence in Healthcare</i>",
           " 2019",
           " Recommendation",
           " Academic",
           " Western Europe",
           " United Kingdom",
           " Fairness",
           " <i>Artificial intelligence should be used to reduce, not increase, health<br>inequality – geographically, economically, and socially.</i>"
          ],
          [
           "Fairness",
           " <i>SAP’s guiding principles for Artificial Intelligence</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Fairness",
           " <i>We seek to increase the diversity and inter­disciplinarity of our teams, and we<br>are investigating new technical methods for mitigating biases. We are also<br>deeply committed to supporting our customers in building even more diverse<br>businesses by leveraging AI to build products that help move businesses beyond<br>bias.</i>"
          ],
          [
           "Fairness",
           " <i>People + AI Guidebook</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Fairness",
           " <i>It is important to identify whether or not machine learning can help provide an<br>adequate solution to the specific problem at hand. If it can, just as there is<br>no single “correct” model for all ML tasks, there is no single technique that<br>ensures fairness in every situation. In practice, researchers and developers<br>should consider using a variety of approaches to iterate and improve. Before<br>using an existing dataset, take the time to thoroughly explore it using tools<br>like Facets to better understand any gaps or biases. Real data is often messy,<br>so you should expect to spend a fair amount of time cleaning it up.</i>"
          ],
          [
           "Fairness",
           " <i>Responsible AI practices</i>",
           " Unspecified",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Fairness",
           " <i>Design your model using concrete goals for fairness and inclusion. Set goals for<br>your system to work fairly across anticipated use cases: for example, in X<br>different languages, or to Y different age groups. Monitor these goals over time<br>and expand as appropriate. Design your algorithms and objective function to<br>reflect fairness goals.</i>"
          ],
          [
           "Fairness",
           " <i>Artificial Intelligence at Google: Our Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Fairness",
           " <i>We believe that AI should avoid creating or reinforcing unfair bias. We will<br>seek to avoid unjust impacts on people, particularly those related to sensitive<br>characteristics such as race, ethnicity, gender, nationality, income, sexual<br>orientation, ability, and political or religious beliefs.</i>"
          ],
          [
           "Fairness",
           " <i>Universal principles of data ethics: 12 guidelines for developing ethics codes</i>",
           " 2016",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Fairness",
           " <i>Data professionals should strive to mitigate the disparate impacts of their<br>products and listen to the concerns of affected communities.</i>"
          ],
          [
           "Fairness",
           " <i>Artificial Intelligence: Australia’s Ethics Framework - A Discussion Paper</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Oceania",
           " Australia",
           " Fairness",
           " <i>The development or use of the AI system must not result in unfair discrimination<br>against individuals, communities, or groups.</i>"
          ],
          [
           "Fairness",
           " <i>Universal Guidelines for Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Belgium",
           " Fairness",
           " <i>Institutions must ensure that AI systems do not reflect unfair bias or make<br>impermissible discriminatory decisions.</i>"
          ],
          [
           "Fairness",
           " <i>The Future Society, Law & Society Initiative, Principles for the Governance of<br>AI</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Fairness",
           " <i>AI shall not impair, and, where possible, shall advance the equality in rights,<br>dignity, and freedom to flourish of all humans.</i>"
          ],
          [
           "Fairness",
           " <i>Sony Group AI Ethics Guidelines</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " Japan",
           " Fairness",
           " <i>In its utilization of AI, Sony will respect the diversity and human rights of<br>its customers and other stakeholders without any discrimination while striving<br>to contribute to the resolution of social problems through its activities in its<br>own and related industries.</i>"
          ],
          [
           "Fairness",
           " <i>Principles for the safe and effective use of data and analytics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Oceania",
           " New Zealand",
           " Fairness",
           " <i>Data and data analytics are tools that support decision-making and it’s<br>essential that in collecting and using public data, government agencies<br>consider, and can demonstrate positive public benefits. This includes: ensuring<br>all associated policies and decisions have been evaluated for fairness and<br>potential bias and have a solid grounding in law.</i>"
          ],
          [
           "Fairness",
           " <i>Recommendations for the responsible use of AI and automated decision-making -<br>Corporate Digital Responsibility and Decision Making (Empfehlungen für den<br>verantwortlichen Einsatz von KI und automatisierten Entscheidungen - Corporate<br>Digital Responsibility and Decision Making)</i>",
           " 2018",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Fairness",
           " <i>Companies should sensitize and train their employees to address and reduce<br>susceptibility to machine bias. Particular attention should also be paid to the<br>data feed. Here, for example, internal and external testing processes can be<br>developed to detect patterns of discrimination.</i>"
          ],
          [
           "Fairness",
           " <i>Code of Ethics for Data-Based Value Creation</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Switzerland",
           " Fairness",
           " <i>You should consider a fair distribution of benefits and burdens. This basic<br>orientation includes, among other things, the values of equality (e.g.,<br>protection against discrimination) and fairness (e.g., by giving something in<br>return for collecting customer data).</i>"
          ],
          [
           "Fairness",
           " <i>Guidelines for the responsible use of artificial intelligence and other digital<br>technologies in human resources work</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Fairness",
           " <i>Anyone who develops or uses AI solutions must ensure that the underlying data<br>have a high quality and system-related discriminations are excluded.</i>"
          ],
          [
           "Fairness",
           " <i>Telefónica´s Approach to the Responsible Use of AI (Enfoque de Telefónica para<br>un uso responsable de la IA)</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Spain",
           " Fairness",
           " <i>Fair AI seeks to ensure that the applications of AI technology lead to fair<br>results. This means that they should not lead to discriminatory impacts on<br>people concerning race, ethnic origin, religion, gender, sexual orientation,<br>disability, or any other personal condition. When optimizing a machine learning<br>algorithm, we must take into account not only the performance in terms of error<br>optimization but also the impact of the algorithm in the specific domain.</i>"
          ],
          [
           "Fairness",
           " <i>Automated and connected automated driving (Automatisiertes und Vernetztes<br>Fahren)</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Germany",
           " Fairness",
           " <i>In unavoidable accident situations, any qualification according to personal<br>characteristics (age, sex, physical or mental constitution) is strictly<br>prohibited. Offsetting of victims is prohibited. General programming to minimize<br>the number of personal injuries may be justifiable.</i>"
          ],
          [
           "Fairness",
           " <i>Telia Company Guiding Principles on trusted AI ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Sweden",
           " Fairness",
           " <i>We aspire to embed the principles of fairness and equality in datasets and<br>algorithms - applied in all phases of AI design, implementation, testing, and<br>usage – fostering fairness and diversity and avoiding unfair bias both at the<br>input and output levels of AI.</i>"
          ],
          [
           "Fairness",
           " <i>Responsible AI and robotics: An ethical framework</i>",
           " Unspecified",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Fairness",
           " <i>Steps must be made to stop systemic bias. Core values such as equality,<br>diversity, and lack of discrimination must be promoted. The codes should<br>confront what obligations rest on actors who deploy AI to mitigate the social<br>dislocation that results.</i>"
          ],
          [
           "Fairness",
           " <i>European ethical Charter on the use of Artificial Intelligence in judicial<br>systems and their environment</i>",
           " 2018",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Fairness",
           " <i>specifically prevent the development or intensification of any discrimination<br>between individuals or groups of individuals.</i>"
          ],
          [
           "Fairness",
           " <i>AI Now Report 2018</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Fairness",
           " <i>Technology companies must go beyond the “pipeline model” and commit to<br>addressing the practices of exclusion and discrimination in their workplaces.</i>"
          ],
          [
           "Fairness",
           " <i>Report on Artificial Intelligence and Human Society</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Fairness",
           " <i>One of the fundamental issues is the need to facilitate provisions against the<br>\"AI divide,\" unbalanced social costs relative to AI, and discrimination that<br>occurs because of the technologies’ procession. Continuous assessments of social<br>pathology, conflict, and dependence on AI technologies will offer solutions to<br>these issues. Potential discrimination based on the output of personal profiling<br>by AI technologies must be prevented</i>"
          ],
          [
           "Fairness",
           " <i>Understanding artificial intelligence ethics and safety: A guide for the<br>responsible design and implementation of AI systems in the public sector</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Western Europe",
           " United Kingdom",
           " Fairness",
           " <i>Protect the priorities of social values, justice, and the public interest (i.e.,<br>treat all individuals equally and protect social equity). All AI systems that<br>process social or demographic data about features of human subjects must be<br>designed to meet a minimum threshold of discriminatory non-harm.</i>"
          ],
          [
           "Fairness",
           " <i>Data Ethics Framework</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Fairness",
           " <i>It is crucial to eliminate your project’s potential to have unintended<br>discriminatory effects on individuals and social groups. You should aim to<br>mitigate biases that may influence your model’s outcome and ensure that the<br>project and its outcomes respect the dignity of individuals, are just,<br>nondiscriminatory, and consistent with the public interest, including human<br>rights and democratic values.</i>"
          ],
          [
           "Fairness",
           " <i>Opinion of the Data Ethics Commission</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Fairness",
           " <i>Protecting human dignity also rules out the use of algorithmic systems to<br>discriminate systematically against individuals or groups, for example by<br>“downgrading” them, preventing them from using certain services for ethically<br>untenable reasons, or systematically misleading them as they participate in the<br>democratic discourse. A key aim in regulating algorithmic systems is to ensure<br>that the decision-making patterns upon which the algorithmic systems are based<br>do not have any systematic distortions (bias) leading to discriminatory and<br>unfair decisions.</i>"
          ],
          [
           "Fairness",
           " <i>Artificial Intelligence and Data Protection</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Fairness",
           " <i>In all phases of the processing, including data collection, AI developers,<br>manufacturers, and service providers should adopt a human rights by-design<br>approach and avoid any potential biases, including unintentional or hidden, and<br>the risk of discrimination or other adverse impacts on the human rights and<br>fundamental freedoms of data subjects.</i>"
          ],
          [
           "Fairness",
           " <i>Statement on Artificial Intelligence, Robotics and 'Autonomous‘ Systems</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Fairness",
           " <i>AI should contribute to global justice and equal access to the benefits and<br>advantages that AI, robotics, and ‘autonomous’ systems can bring. Discriminatory<br>biases in data sets used to train and run AI systems should be prevented or<br>detected, reported, and neutralized at the earliest stage possible.</i>"
          ],
          [
           "Fairness",
           " <i>Report with recommendations to the Commission on Civil Law Rules on Robotics</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " European Union",
           " European Union",
           " Fairness",
           " <i>The European Parliament notes that the potential for empowerment through the use<br>of robotics is nuanced by a set of tensions or risks and should be seriously<br>assessed from the point of view of non-discrimination. Justice – the fair<br>distribution of the benefits associated with robotics and affordability of home<br>care and healthcare robots in particular.</i>"
          ],
          [
           "Fairness",
           " <i>Preparing for the future of Artificial Intelligence</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Fairness",
           " <i>Federal agencies that use AI-based systems to make or provide decision support<br>for consequential decisions about individuals should take extra care to ensure<br>the efficacy and fairness of those systems, based on evidence-based verification<br>and validation.</i>"
          ],
          [
           "Fairness",
           " <i>Principles for Accountable Algorithms and a Social Impact Statement for<br>Algorithms</i>",
           " Unspecified",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Unspecified",
           " Unspecified",
           " Fairness",
           " <i>Ensure that algorithmic decisions do not create discriminatory or unjust impacts<br>when comparing across different demographics (e.g. race, sex, etc).</i>"
          ],
          [
           "Fairness",
           " <i>Guidance for Regulation of Artificial Intelligence Applications</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Fairness",
           " <i>Consistent with law, agencies should take into consideration the following<br>principles when formulating regulatory and non-regulatory approaches to the<br>design, development, deployment, and operation of AI applications, both general<br>and sector-specific. These principles, many of which are interrelated, reflect<br>the goals and principles in Executive Order 13859. Agencies should consider, in<br>accordance with the law, issues of fairness and non-discrimination with respect<br>to outcomes and decisions produced by the AI application at issue, as well as<br>whether the AI application at issue may reduce levels of unlawful, unfair, or<br>otherwise unintended discrimination as compared to existing processes.</i>"
          ],
          [
           "Fairness",
           " <i>Tieto’s AI ethics guidelines</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Finland",
           " Fairness",
           " <i>At Tieto, we are committed to unbiased, fair, and inclusive AI fostering<br>diversity and equality among people.</i>"
          ],
          [
           "Fairness",
           " <i>A guide to using artificial intelligence in the public sector</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Fairness",
           " <i>With an AI project you should consider several factors, including AI ethics and<br>safety. hese factors span safety, ethical, legal and administrative concerns and<br>include: fairness - are the models trained and tested on relevant, accurate, and<br>generalisable datasets and is the AI system deployed by users trained to<br>implement them responsibly and without bias.</i>"
          ],
          [
           "Fairness",
           " <i>AI in the UK: ready, willing and able?</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Fairness",
           " <i>Artificial intelligence should operate on principles of intelligibility and<br>fairness. The Government must outline its plans to tackle any potential societal<br>or regional inequality caused by AI, and this must be explicitly addressed as<br>part of the implementation of the Industrial Strategy</i>"
          ],
          [
           "Fairness",
           " <i>Preliminary Study on the Ethics of Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Fairness",
           " <i>AI should be inclusive, aiming to avoid bias and allowing for diversity, and<br>avoiding a new digital divide. Gender bias should be avoided in the development<br>of algorithms, in the datasets used for their training, and in their use in<br>decision-making.</i>"
          ],
          [
           "Fairness",
           " <i>Report of COMEST on robotics ethics</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Fairness",
           " <i>The value of justice is also related to non-discrimination. Roboticists should<br>be sensitized to the reproduction of gender bias and sexual stereotypes in<br>robots. The issue of discrimination and stigmatization through data mining<br>collected by robots is not trivial. Adequate measures need to be taken by<br>States. Particular attention should be paid to gender issues and stereotyping<br>concerning all types of robots described in this report, and in particular, toy<br>robots, sex companions, and job replacements.</i>"
          ],
          [
           "Fairness",
           " <i>Top 10 Principles for Ethical Artificial Intelligence</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " Switzerland",
           " Fairness",
           " <i>In the design and maintenance of AI, it is vital that the system is controlled<br>for harmful human-bias, and that any bias—be it gender, race, sexual<br>orientation, age, etc.—is identified and is not propagated by the system.</i>"
          ],
          [
           "Fairness",
           " <i>ACM Code of Ethics and Professional Conduct</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Fairness",
           " <i>A computing professional should be fair and take action not to discriminate.<br>Computing professionals should foster the fair participation of all people,<br>including those of underrepresented groups. Prejudicial discrimination based on<br>age, color, disability, ethnicity, family status, gender identity, labor union<br>membership, military status, nationality, race, religion or belief, sex, sexual<br>orientation, or any other inappropriate factor is an explicit violation of the<br>Code. Harassment, including sexual harassment, bullying, and other abuses of<br>power and authority, is a form of discrimination that, amongst other harms,<br>limits fair access to the virtual and physical spaces where such harassment<br>takes place.</i>"
          ],
          [
           "Fairness",
           " <i>Montréal declaration for a responsible development of artificial intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " Canada",
           " Fairness",
           " <i>The development and use of AI must contribute to the creation of a just and<br>equitable society. AI must be designed and trained so as not to create,<br>reinforce, or reproduce discrimination based on — among other things — social,<br>sexual, ethnic, cultural, or religious differences. AI development must help<br>eliminate relationships of domination between groups and people based on<br>differences in power, wealth, or knowledge.</i>"
          ],
          [
           "Fairness",
           " <i>Ethical Framework for Artificial Intelligence in Colombia (Marco Ético para la<br>Inteligencia Artificial en Colombia)</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Latin America",
           " Colombia",
           " Fairness",
           " <i>Artificial intelligence systems cannot have results or responses that undermine<br>the welfare of a specific group or limit the rights of historically marginalized<br>populations. There must be a constant analysis of this impact and even consider<br>mechanisms for immediately withdrawing systems that have discriminatory effects.</i>"
          ],
          [
           "Fairness",
           " <i>fAIr LAC: Responsible and Widespread Adoption of Artificial Intelligence in<br>Latin America and the Caribbean</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Latin America",
           " Unspecified",
           " Fairness",
           " <i>AI actors should respect the rule of law, human rights, and democratic values,<br>throughout the AI system lifecycle. These include non-discrimination and<br>equality.</i>"
          ],
          [
           "Fairness",
           " <i>Artificial Intelligence for Children: Beijing Principles</i>",
           " 2020",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Fairness",
           " <i>The development of AI should treat and serve all children fairly and should not<br>cause discrimination or harm to any child. The research and application of AI<br>shall not make any distinction as to the child's, his or her parent's, legal<br>guardians, or other caregivers' race, color, gender, language, religion,<br>political or other opinions, nationality, or social origin, property,<br>disability, birth or another status, as far as the fundamental rights of the<br>child are concerned.</i>"
          ],
          [
           "Fairness",
           " <i>Social Principles of Human-Centric AI</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia, Western Europe",
           " Japan, United Kingdom",
           " Fairness",
           " <i>Under AI's design concept, all people are treated fairly without unjustified<br>discrimination on the grounds of diverse backgrounds such as race, gender,<br>nationality, age, political beliefs, religion, and so on.</i>"
          ],
          [
           "Fairness",
           " <i>The Toronto Declaration</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " North America, Western Europe",
           " Canada, United Kingdom",
           " Fairness",
           " <i>Discrimination is defined under international law as “any distinction,<br>exclusion, restriction or preference which is based on any ground such as race,<br>color, sex, language, religion, political or other opinions, national or social<br>origin, property, birth or another status, and which has the purpose or effect<br>of nullifying or impairing the recognition, enjoyment or exercise by all<br>persons, on an equal footing, of all rights and freedoms.” This list is non-<br>exhaustive as the United Nations High Commissioner for Human Rights has<br>recognized the necessity of preventing discrimination against additional<br>classes. Governments have obligations and private sector actors have<br>responsibilities to proactively prevent discrimination to comply with existing<br>human rights laws and standards. When prevention is not sufficient or<br>satisfactory, and discrimination arises, a system should be interrogated and<br>harm addressed immediately. All actors, public and private, must prevent and<br>mitigate discrimination risks in the design, development, and application of<br>machine learning technologies. They must also ensure that there are mechanisms<br>allowing for access to an effective remedy in place before deployment and<br>throughout a system’s lifecycle.</i>"
          ],
          [
           "Fairness",
           " <i>DataEthics: Principles and Guidelines for Companies, Authorities & Organisations</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " Northern Europe",
           " Denmark",
           " Fairness",
           " <i>Democratic data processing is based on an awareness of the societal power<br>relations that data systems sustain, reproduce or create. When processing data,<br>special attention should be paid to vulnerable people, who are particularly<br>vulnerable to profiling that may adversely affect their self-determination and<br>control or expose them to discrimination or stigmatization, for example, due to<br>their financial, social, or health-related conditions. Paying attention to<br>vulnerable people also involves working actively to reduce bias in the<br>development of self-learning algorithms.</i>"
          ],
          [
           "Fairness",
           " <i>AI Governance in Japan Ver. 1.1, Report from the expert group on how AI<br>principles should be implemented</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Fairness",
           " <i>Under AI's design concept, all people are treated fairly without unjustified<br>discrimination on the grounds of diverse backgrounds such as race, gender,<br>nationality, age, political beliefs, religion, and so on.</i>"
          ],
          [
           "Fairness",
           " <i>Principles of Artificial Intelligence Ethics for the Intelligence Community</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Fairness",
           " <i>Consistent with our commitment to providing objective intelligence, we will take<br>affirmative steps to identify and mitigate bias.</i>"
          ],
          [
           "Fairness",
           " <i>Vodafone Artificial Intelligence Framework</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Fairness",
           " <i>All our AI experts and data scientists are subject to our Code of Conduct, which<br>includes explicit provisions for nondiscrimination and fair treatment.</i>"
          ],
          [
           "Fairness",
           " <i>Artificial Intelligence at the service of the citizen (L’intelligenzia<br>artificiale al servizio del cittadino)</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Southern Europe",
           " Italy",
           " Fairness",
           " <i>Artificial intelligence should be used to reduce, not increase, health<br>inequality – geographically, economically, and socially. Recommendation -<br>Promote a national platform dedicated to the development of AI solutions in<br>order to organize and convey tests openly before the release of AI systems used<br>in the PA in order to evaluate their behavior and limit the anomalies and the<br>amplification of the bias.</i>"
          ],
          [
           "Fairness",
           " <i>Artificial Intelligence: open questions about gender inclusion</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Latin America",
           " Argentina",
           " Fairness",
           " <i>We Recommend that G20 countries explore the adoption of algorithmic equitable<br>actions to correct real-life biases and barriers that prevent women from<br>achieving full participation and equal enjoyment of rights.</i>"
          ],
          [
           "Fairness",
           " <i>Augmented Intelligence in Health Care H-480.940</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Professional Association",
           " North America",
           " United States of America",
           " Fairness",
           " <i>AMA will seek to promote the development of thoughtfully designed, high-quality,<br>clinically validated healthcare AI that identifies and takes steps to address<br>bias and avoids introducing or exacerbating health care disparities including<br>when testing or deploying new AI tools on vulnerable populations.</i>"
          ],
          [
           "Fairness",
           " <i>WLiAI Report 2019: 10 Principles of Responsible AI</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " United Kingdom",
           " Fairness",
           " <i>Recommendation - Introduce a new ‘Certificate of Fairness for AI systems’<br>alongside a ‘kite mark’ type scheme to display it. Criteria are to be defined at<br>the industry level, similarly to food labeling regulations. Introduce a ‘reduced<br>liability’ incentive for companies that have obtained a Certificate of Fairness<br>to foster innovation and competitiveness.</i>"
          ],
          [
           "Fairness",
           " <i>The Ethical Norms for the New Generation Artificial Intelligence, China</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Fairness",
           " <i>Various activities of AI shall abide by the following fundamental ethical norms,<br>like promoting fair sharing of the benefits of AI in the whole society,<br>promoting social fairness and justice, and equal opportunities. During the<br>process of data collection and algorithm development, strengthen ethics review,<br>fully consider the diversity of demands, avoid potential data and algorithmic<br>bias, and strive to achieve inclusivity, fairness, and non-discrimination in AI<br>systems.</i>"
          ],
          [
           "Fairness",
           " <i>A Framework for Responsible Limits on Facial RecognitionUse Case: Flow<br>Management</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization",
           " Western Europe",
           " Switzerland",
           " Fairness",
           " <i>Organizations using facial recognition systems should take appropriate steps to<br>ensure that unfair bias or outcomes can be detected, identified, and mitigated<br>to the greatest extent possible. While acknowledging that the complete removal<br>of bias represents one of the biggest challenges in AI research, organizations<br>must allocate appropriate resources to the implementation of tools and processes<br>that minimize unfair bias or outcomes.</i>"
          ],
          [
           "Fairness",
           " <i>A Code of Ethics for the Human-Robot Interaction Profession</i>",
           " 2014",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Fairness",
           " <i>Avoid racist, sexist, and ableist morphologies and behaviors in robot design.</i>"
          ],
          [
           "Fairness",
           " <i>How to Prevent Discriminatory Outcomes in Machine Learning</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization",
           " Western Europe",
           " Switzerland",
           " Fairness",
           " <i>People involved in conceptualizing, developing, and implementing machine<br>learning systems should consider which definition of fairness best applies to<br>their context and application, and prioritize it in the architecture of the<br>machine learning system and its evaluation metrics.</i>"
          ],
          [
           "Fairness",
           " <i>Discussion Paper: National Strategy for Artificial Intelligence</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " South Asia",
           " India",
           " Fairness",
           " <i>Based on the premise that a large set of well-diversified data may be an<br>accurate description of the world, most of the developer community takes a<br>technocratic attitude that data-driven decision making is good and algorithms<br>are neutral. However, this argument does not recognize the fact that the<br>existing data may have biases, which may have got reinforced over time. The<br>issue of fairness is at the forefront of discussion in academic, research, and<br>policy fora, and merits a combined dialogue and sustained research to come to an<br>acceptable resolution. One possible way to approach this would be to identify<br>the in-built biases and assess their impact, and in turn, find ways to reduce<br>the bias.</i>"
          ],
          [
           "Fairness",
           " <i>The National Artificial Intelligence Research and Development Strategic Plan:<br>2019 Update</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Fairness",
           " <i>Scientists must also study to what extent justice and fairness considerations<br>can be designed into the system, and how to accomplish this within the bounds of<br>current engineering techniques.</i>"
          ],
          [
           "Fairness",
           " <i>The Holberton-Turing Oath</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Unspecified",
           " Unspecified",
           " Fairness",
           " <i>I will consider the impact of my work on fairness both in perpetuating<br>historical biases, which are caused by the blind extrapolation from past data to<br>future predictions, and in creating new conditions that increase economic or<br>other inequality</i>"
          ],
          [
           "Fairness",
           " <i>OECD, Recommendation of the Council on Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " France",
           " Fairness",
           " <i>AI actors should respect the rule of law, human rights, and democratic values,<br>throughout the AI system lifecycle. These include freedom, dignity and autonomy,<br>privacy and data protection, nondiscrimination and equality, diversity,<br>fairness, social justice, and internationally recognized labor rights.</i>"
          ],
          [
           "Fairness",
           " <i>Oxford Munich Code of Conduct</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Fairness",
           " <i>The Data Scientist has a duty not to break gender, race, ethnicity, marital<br>status, religion, belief, disability, or age equality legislation. In<br>particular, such attributes should not place individuals at any disadvantage<br>within models or any automated decisions. The Data Scientist is supposed to<br>analyze and document potential bias present in the data and assess how this bias<br>might affect the results and the usage of the models. he Data Scientist is<br>responsible for detecting and flagging features that might be surrogates to<br>other features that violate fundamental equality rights (gender, race, religion,<br>etc). In general, proxy features need to always be checked against social<br>discriminating features.</i>"
          ],
          [
           "Fairness",
           " <i>UNESCO Recommendation on the Ethics of Artificial Intelligence</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Fairness",
           " <i>AI actors should promote social justice and safeguard fairness and non-<br>discrimination of any kind in compliance with international law. This implies an<br>inclusive approach to ensuring that the benefits of AI technologies are<br>available and accessible to all, taking into consideration the specific needs of<br>different age groups, cultural systems, different language groups, persons with<br>disabilities, girls and women, and disadvantaged, marginalized and vulnerable<br>people or people in vulnerable situations.</i>"
          ],
          [
           "Fairness",
           " <i>AI Principles: Recommendations on the Ethical Use of Artificial Intelligence by<br>the Department of Defense - Defense Innovation Board</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Fairness",
           " <i>DoD should take deliberate steps to avoid unintended bias in the development and<br>deployment of combat or non-combat AI systems that would inadvertently cause<br>harm to persons.</i>"
          ],
          [
           "Fairness",
           " <i>Megvii's Artificial Intelligence Application Guidelines</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " China",
           " Fairness",
           " <i>Developers of AI technologies should minimize the systematic bias in AI<br>solutions that may arise from biases inherent in the data and algorithms used to<br>develop the solutions.</i>"
          ],
          [
           "Fairness",
           " <i>Policy guidance on AI for children</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution, International Organization",
           " Northern Europe, Intergovernmental Organization",
           " Finland, United Nations",
           " Fairness",
           " <i>Prioritize fairness and non-discrimination for children. AI must be for all<br>children.</i>"
          ],
          [
           "Fairness",
           " <i>Ethics & Governance of Artificial Intelligence for Health</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Fairness",
           " <i>. AI technologies should not encode biases to the disadvantage of identifiable<br>groups, especially groups that are already marginalized. Bias is a threat to<br>inclusiveness and equity, as it can result in a departure, often arbitrary, from<br>equal treatment. AI technologies should minimize inevitable disparities in power<br>that arise between providers and patients, between policy-makers and people, and<br>between companies and governments that create and deploy AI technologies and<br>those that use or rely on them. No technology, AI or otherwise, should sustain<br>or worsen existing forms of bias and discrimination.</i>"
          ],
          [
           "Fairness",
           " <i>Ethical ML Institute Responsible Machine Learning Principles</i>",
           " Unspecified",
           " Recommendation",
           " Academic",
           " Western Europe",
           " United Kingdom",
           " Fairness",
           " <i>Technologists should focus on building processes & methods to identify &<br>document the inherent bias in the data, features, and inference results, and<br>subsequently the implications of this bias. I commit to continue developing<br>processes that allow me to understand, document, and monitor bias in development<br>and production.</i>"
          ],
          [
           "Fairness",
           " <i>HPE AI Ethics and Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Fairness",
           " <i>Be inclusive, minimize harmful bias, and ensure fair and equal treatment and<br>access for individuals.</i>"
          ],
          [
           "Fairness",
           " <i>Thomson Reuters AI principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " Canada",
           " Fairness",
           " <i>Thomson Reuters will strive to maintain a human-centric approach and will strive<br>to design, develop and deploy AI products and services that treat people fairly.</i>"
          ],
          [
           "Fairness",
           " <i>Defense Innovation Unit Responsible AI Guidelines in Practice: Lessons Learned<br>from the DIU Portfolio</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Fairness",
           " <i>The Department will take deliberate steps to minimize unintended bias in AI<br>capabilities.</i>"
          ],
          [
           "Fairness",
           " <i>DoD Ethical Principles for Artificial Intelligence</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Fairness",
           " <i>The Department will take deliberate steps to minimize unintended bias in AI<br>capabilities.</i>"
          ],
          [
           "Fairness",
           " <i>Transparency Guidelines for Data-Driven Technology in Government</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Fairness",
           " <i>Data used to train machines needs to be assessed for bias continually and steps<br>need to be taken to flag and minimize different biases during the entire<br>lifecycle of use.</i>"
          ],
          [
           "Fairness",
           " <i>Integrate’s AI principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " Canada",
           " Fairness",
           " <i>Bias varies across cultures and contexts. This is something we readily<br>acknowledge and attempt to mitigate in the datasets we use and the models we<br>build. We don’t knowingly introduce bias, appeal to relativistic definitions of<br>fairness, or allow fairness to be used as a tradeoff for revenue. We believe our<br>systems should reflect the best that humans can be and not the preexisting<br>biases we have already fallen prey to.</i>"
          ],
          [
           "Fairness",
           " <i>National Association of Insurance Commissioners (NAIC) Principles on Artificial<br>Intelligence (AI)</i>",
           " 2020",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Fairness",
           " <i>AI actors should respect the rule of law throughout the AI life cycle. This<br>includes, but is not limited to, insurance laws and regulations, such as those<br>relating to trade practices, unfair discrimination, access to insurance,<br>underwriting, privacy, consumer protection and eligibility practices, ratemaking<br>standards, advertising decisions, claims practices, and solvency.</i>"
          ],
          [
           "Fairness",
           " <i>Samsung Principles for AI Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " South Korea",
           " Fairness",
           " <i>The company will strive to apply the values of equality and diversity in  AI<br>systems throughout its entire lifecycle. The company will strive not to<br>reinforce nor propagate negative or unfair bias.</i>"
          ],
          [
           "Fairness",
           " <i>IBM AI Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Fairness",
           " <i>At IBM, we believe AI should make all of us better at our jobs, and that the<br>benefits of the AI era should touch the many, not just the elite few.</i>"
          ],
          [
           "Fairness",
           " <i>Linux Foundation AI Principles</i>",
           " 2020",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Fairness",
           " <i>Equitability for AI and the people behind AI should take deliberate steps – in<br>the AI life-cycle – to avoid intended or unintended bias and unfairness that<br>would inadvertently cause harm.</i>"
          ],
          [
           "Fairness",
           " <i>ADP: Ethics in Artificial Intelligence</i>",
           " 2022",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Fairness",
           " <i>Included in this approach is the isolation of unintended bias. Bias in the world<br>of work—that is, favoring or disfavoring one group compared with another—is<br>caused by a variety of factors. Ethically, anyone developing ML technologies<br>should be vigilant not to reproduce such bias in any ML-enabled product or<br>service. Even when accounting for potential unintentional bias in the source<br>data, coding, or use of an AI-enabled product or service, there can be an<br>unexpected or unforeseen bias that comes into play. ADP’s goal is to continually<br>strive to identify new and unexpected sources of bias and then refresh and<br>enhance the design of our client offerings to address them.</i>"
          ],
          [
           "Fairness",
           " <i>IEEE Policies - Code of Ethics</i>",
           " 2022",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Fairness",
           " <i>We, the members of the IEEE, o hereby commit ourselves to the highest ethical<br>and professional conduct and agree to treat all persons fairly and with respect,<br>to avoid harassment or discrimination, and to avoid injuring others. To treat<br>all persons fairly and with respect, and to not engage in discrimination based<br>on characteristics such as race, religion, gender, disability, age, national<br>origin, sexual orientation, gender identity, or gender expression</i>"
          ],
          [
           "Fairness",
           " <i>Adobe’s Commitment to AI Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Fairness",
           " <i>We understand that special care must be taken to address bias if a product or<br>service will have a significant impact on an individual’s life, such as with<br>employment, housing, credit, and health.</i>"
          ],
          [
           "Fairness",
           " <i>Safe Face Pledge</i>",
           " 2021",
           " Recommendation",
           " Academic, Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Fairness",
           " <i>Implement internal bias evaluation processes and support independent evaluation.<br>By adopting internal systems to evaluate the performance of your facial analysis<br>products and services and also facilitating independent research in order to<br>identify and mitigate harmful bias in the design, development, deployment, and<br>use of these systems.</i>"
          ],
          [
           "Fairness",
           " <i>Draft - AI Utilization Principles</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Fairness",
           " <i>AI service providers, business users, and data providers should take into<br>consideration that individuals will not be discriminated unfairly by the<br>judgments of AI systems or AI services.</i>"
          ],
          [
           "Fairness",
           " <i>The Code of Ethics in the Field of Artificial Intelligence</i>",
           " 2022",
           " Recommendation",
           " Unspecified",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Fairness",
           " <i>To ensure fairness and non-discrimination, AI Actors should take measures to<br>verify that the algorithms, datasets, and processing methods for machine<br>learning are used to group and/or classify data that concern individuals or<br>groups do not entail intentional discrimination. AI Actors are encouraged to<br>create and apply methods and software solutions that identify and prevent<br>discrimination manifestations based on race, nationality, gender, political<br>views, religious beliefs, age, social and economic status, or information about<br>private life (at the same time, the rules of functioning or application of AI<br>systems for different groups of users wherein such factors are taken into<br>account for user segmentation, which is explicitly declared by an AI Actor,<br>cannot be defined as discrimination).</i>"
          ],
          [
           "Fairness",
           " <i>Shanghai Initiative for Safe and Secure AI Development</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Asia",
           " China",
           " Fairness",
           " <i>The harm of algorithm design to the public must be avoided in AI development.<br>There must be clear motives and interpretability of algorithms to address the<br>unfair biases produced and magnified by algorithms and datasets.</i>"
          ],
          [
           "Fairness",
           " <i>Chinese Young Scientists' Declaration on the Governance and Innovation of<br>Artificial Intelligence (Shanghai Declaration)</i>",
           " 2019",
           " Recommendation",
           " Academic, Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Asia",
           " China",
           " Fairness",
           " <i>Artificial intelligence should provide non-discriminatory services to various<br>groups of people under the principles of fairness, equity, and inclusion.</i>"
          ],
          [
           "Fairness",
           " <i>Trustworthy AI in Aotearoa: AI Principles</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " Oceania",
           " New Zealand",
           " Fairness",
           " <i>Designers, developers, and users of AI systems (AI stakeholders) must respect<br>principles of equality and fairness so that AI systems do not unjustly harm,<br>exclude, disempower or discriminate against individuals or particular groups.</i>"
          ],
          [
           "Fairness",
           " <i>Harmonious Artificial Intelligence Principles</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Fairness",
           " <i>AI cannot introduce bias to understand and interact with humanity, and should<br>actively interact with a human to remove generated potential bias. Without clear<br>technical judgment, a human cannot have a bias toward AI when human and AI shows<br>similar risks.</i>"
          ],
          [
           "Fairness",
           " <i>\"ARCC\": An Ethical Framework for Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " Eastern Asia",
           " China",
           " Fairness",
           " <i>Recommendation - Ensure that algorithms are reasonable, data is accurate, up-to-<br>date, complete, relevant, unbiased, and representative, and take technical<br>measures to identify, solve and eliminate bias.</i>"
          ],
          [
           "Fairness",
           " <i>Fu Ying: Six Principles of Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Fairness",
           " <i>It is necessary to ensure the security, applicability, and controllability of<br>artificial intelligence systems, protect personal privacy, and prevent data<br>leakage and abuse. Ensure the traceability and transparency of AI algorithms and<br>prevent algorithmic discrimination.</i>"
          ],
          [
           "Fairness",
           " <i>A Framework for the Ethical use of advanced Data Science Methodes in the<br>Humanitarian Sector</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe, Intergovernmental Organization",
           " Netherlands, United Nations",
           " Fairness",
           " <i>The humanitarian sector is under an obligation to adhere to the humanitarian<br>principles of humanity, neutrality, independence, and impartiality. The use of<br>data science may create perceptions of partiality/bias. The humanitarian sector<br>should be cautious of ever using (or allowing others to use) vulnerable people<br>as test cases when experimenting with new technologies. Training data should be<br>rigorously checked and tested for bias, the use of data proxies should be<br>justified, and relevant statistical methods should be applied.</i>"
          ],
          [
           "Fairness",
           " <i>Unified Ethical Frame for Big Data Analysis</i>",
           " 2014",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Fairness",
           " <i>Big data analytics, while meeting the needs of the organization that is<br>conducting or sponsoring the processing, must be fair to the individuals to whom<br>the data pertains. The analysis of fairness needs to look not only at protecting<br>against unseemly or risky actions but also at enhancing beneficial<br>opportunities. Human rights speak to the shared benefits of technology and<br>broader opportunities related to employment, health, and safety. Interfering<br>with such opportunities is also a fairness issue.</i>"
          ],
          [
           "Fairness",
           " <i>Civil Rights Principles for the Era of Big Data</i>",
           " 2014",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Fairness",
           " <i>Recommendation - Ensure Fairness in Automated Decisions. Computerized decision-<br>making in areas such as employment, health, education, and lending must be<br>judged by its impact on real people, must operate fairly for all communities,<br>and in particular, must protect the interests of those that are disadvantaged or<br>that have historically been the subject of discrimination. Systems that are<br>blind to the preexisting disparities faced by such communities can easily reach<br>decisions that reinforce existing inequities. Independent review and other<br>remedies may be necessary to assure that a system works fairly.</i>"
          ],
          [
           "Fairness",
           " <i>Human rights in the robot age: Challenges arising from the use of robotics,<br>artificial intelligence, and virtual and augmented reality</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Western Europe",
           " Netherlands",
           " Fairness",
           " <i>Recommendation - The Council of Europe could shed light on how algorithmic<br>accountability or fairness can be facilitated and how the developers of<br>algorithms can be enabled to devise automated decisions that respect human<br>rights will not (unintentionally) discriminate against individuals.</i>"
          ],
          [
           "Fairness",
           " <i>Technological convergence, artificial intelligence and human rights</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Fairness",
           " <i>The Assembly reiterates its call made in Resolution 2051 (2015) “Drones and<br>targeted killings: the need to uphold human rights and international law” to all<br>member States and observer States, as well as States whose parliaments have<br>observer status with the Assembly, to refrain from any automated (robotic)<br>procedures for selecting individuals for targeted killings or any sort of injury<br>based on communication patterns or other data collected through mass<br>surveillance techniques. This should be true not only for drones but also for<br>other combat equipment with artificial intelligence systems, as well as other<br>equipment and/or software that might potentially inflict damage on people,<br>property, personal data, or information databases, or interfere with privacy,<br>freedom of expression, or the right to equality and non-discrimination.</i>"
          ]
         ],
         "hovertemplate": "<b>Document ID </b>=%{customdata[1]}<br><b>Year of Publication </b>=%{customdata[2]}<br><b>Reguation Type </b>=%{customdata[3]}<br><b>Institution Type </b>=%{customdata[4]}<br><b>World Region </b>=%{customdata[5]}<br><b>Country </b>=%{customdata[6]}<br><b>Principle </b>=%{customdata[7]}<br><b>Description </b>=%{customdata[8]}<extra></extra>",
         "legendgroup": "Fairness",
         "marker": {
          "color": "#B6E880",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Fairness",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          5.089746,
          5.060234,
          8.656127,
          12.969567,
          -1.7318276,
          10.347745,
          6.270672,
          -11.873609,
          -3.5480766,
          3.6977224,
          14.885364,
          -17.386084,
          12.837419,
          12.100662,
          14.225861,
          18.664398,
          21.91653,
          8.549943,
          5.78144,
          -21.516647,
          7.64422,
          13.303763,
          -4.5980744,
          10.9101095,
          12.686601,
          14.747487,
          10.472358,
          12.855392,
          -12.307577,
          16.003052,
          23.237787,
          6.6796117,
          14.114447,
          3.731402,
          5.724271,
          0.7611744,
          7.175558,
          11.564167,
          7.702929,
          17.798075,
          8.409654,
          4.6149044,
          22.241457,
          17.332962,
          7.986663,
          6.1712613,
          4.6808844,
          11.337527,
          6.8378444,
          6.6247587,
          9.283672,
          8.017557,
          12.885446,
          4.801504,
          -0.44915617,
          11.359536,
          6.841795,
          14.400971,
          15.41221,
          8.578004,
          9.874165,
          11.1945305,
          5.510702,
          10.196941,
          10.241505,
          7.023927,
          -0.44216123,
          0.8379914,
          4.6808076,
          5.0474043,
          8.963208,
          10.100152,
          -18.819801,
          11.686553,
          7.6040072,
          11.170907,
          18.00033,
          9.249938,
          5.2841907,
          11.045221,
          1.0024896,
          1.6518126,
          9.17537,
          -1.3252449,
          2.8560371,
          11.471188,
          -12.503894,
          5.467796,
          -21.222586,
          0.20753495,
          11.7761545,
          -6.825983,
          11.49212,
          16.373716,
          9.880803,
          12.561995,
          -0.27654833,
          2.5550222,
          10.362975,
          2.411968,
          1.2157449,
          11.49272,
          15.74615,
          13.377418,
          14.727334,
          20.883034,
          -2.1001124,
          8.91411,
          2.4616444,
          4.1274214,
          -9.172742,
          9.380116,
          9.715895,
          12.283721,
          13.689423,
          0.48598638,
          -1.4748445,
          7.5890245,
          -16.596647,
          8.057245,
          4.606801,
          6.746549,
          1.9992912,
          12.997581,
          -0.6140791,
          14.469566,
          14.42893,
          5.367766,
          11.0772085,
          -2.4784114,
          9.615369,
          5.0207124,
          7.3849955,
          5.063759,
          15.797037,
          14.496663,
          6.5137973,
          8.495227,
          9.76504,
          10.261087,
          10.714174,
          7.6993732,
          6.52148,
          8.634122,
          -13.332343,
          8.677188,
          -1.4246494,
          4.033108,
          6.569491,
          -6.1511354
         ],
         "y": [
          9.367088,
          1.9639587,
          -11.231249,
          4.311108,
          -2.2113528,
          2.8290992,
          14.578164,
          -24.24507,
          14.75652,
          4.5847306,
          13.219995,
          8.082081,
          14.362358,
          1.0917557,
          13.867238,
          -1.7134272,
          1.9798474,
          12.16553,
          1.6809422,
          9.410946,
          18.031898,
          7.091334,
          11.917343,
          10.376984,
          9.44172,
          6.5784783,
          10.135791,
          0.2872252,
          16.951517,
          2.9422512,
          -0.7867766,
          5.3363056,
          8.066966,
          23.140432,
          6.3503613,
          20.70482,
          -12.699514,
          12.767366,
          1.820987,
          0.6391455,
          10.561764,
          7.536318,
          12.026187,
          7.360669,
          4.7748146,
          12.39128,
          23.962175,
          17.263968,
          0.6925665,
          -5.7102685,
          9.269151,
          9.500786,
          16.580748,
          4.425612,
          -7.449546,
          12.51239,
          5.346734,
          2.4470203,
          0.8257321,
          7.9415574,
          7.069715,
          5.267997,
          15.977582,
          9.404566,
          9.919659,
          5.7268524,
          -26.5794,
          11.764032,
          9.782844,
          17.45077,
          8.629204,
          4.008466,
          8.961999,
          1.8728975,
          1.9236174,
          14.304889,
          7.2998805,
          -0.44328317,
          5.523283,
          16.836796,
          13.28757,
          3.1875076,
          2.9200218,
          -6.8425903,
          -1.5421135,
          11.342587,
          -22.573324,
          -24.3699,
          -2.0071297,
          -6.745685,
          3.8782356,
          -12.993849,
          7.713058,
          12.303124,
          0.93000275,
          8.801651,
          4.984423,
          7.57387,
          8.002661,
          10.827407,
          17.331934,
          8.299916,
          1.8689992,
          4.0507226,
          1.8523916,
          3.1704478,
          -30.168152,
          -2.5107536,
          -2.351853,
          9.818525,
          -12.664989,
          5.889866,
          8.342436,
          3.9456952,
          10.327352,
          2.0481572,
          21.758806,
          2.252848,
          -15.446376,
          7.9206576,
          8.577801,
          5.6124077,
          8.635552,
          16.717823,
          -22.186535,
          -0.3542121,
          -0.03317678,
          8.415698,
          6.5416303,
          0.6125727,
          0.48530653,
          -19.049852,
          7.0909743,
          5.3476825,
          13.510071,
          14.6983595,
          16.118067,
          8.811718,
          4.937889,
          6.8276405,
          7.0807767,
          5.8271604,
          12.278672,
          10.95358,
          1.32609,
          22.994638,
          19.503565,
          1.6599479,
          0.44669765,
          -0.91154426
         ],
         "z": [
          -1.0527732,
          -10.206317,
          2.8781898,
          -1.7570441,
          -4.5091553,
          -11.005217,
          17.521976,
          6.7810245,
          -5.5954876,
          15.62279,
          -9.10807,
          -21.763256,
          -0.06396045,
          -4.709038,
          -8.092098,
          13.48062,
          -6.0064464,
          -14.123112,
          -0.21695195,
          9.579401,
          -1.2469215,
          -5.064218,
          -7.8081236,
          1.0623101,
          -8.540194,
          -14.507601,
          2.2649584,
          17.031397,
          -17.80196,
          -19.84681,
          12.06888,
          -2.1768556,
          -9.858825,
          -12.581684,
          -10.49251,
          -9.713863,
          0.8824208,
          -12.824753,
          -2.3087175,
          3.268388,
          -3.8706656,
          -8.580805,
          9.747699,
          -13.426866,
          -8.264097,
          -15.843453,
          -12.190531,
          -12.273001,
          -10.162968,
          -20.545069,
          -11.401659,
          -13.21273,
          -8.887321,
          -2.8926494,
          -17.919811,
          -3.1225739,
          -12.045255,
          17.097227,
          -7.588711,
          -15.474973,
          -18.494137,
          -5.470036,
          -12.5838,
          -1.768989,
          -3.5677836,
          12.874308,
          8.933471,
          -19.29578,
          -12.2931795,
          -18.220114,
          -6.434526,
          -5.812323,
          15.325085,
          -8.033819,
          -5.5103645,
          -6.5848618,
          -5.6635346,
          -2.726208,
          0.27352268,
          -13.282978,
          3.7299385,
          -5.396587,
          -1.436075,
          25.568338,
          -15.096309,
          -8.626726,
          -7.05133,
          -7.643532,
          11.839181,
          -7.733528,
          -0.66263,
          23.10802,
          -5.1854887,
          -3.7861938,
          -0.57592,
          -2.6659975,
          5.761421,
          19.816946,
          5.557151,
          -2.5800383,
          -10.467656,
          5.6239066,
          -11.902589,
          -7.9409947,
          16.049068,
          -3.3333087,
          -1.6158985,
          -16.07082,
          0.6356292,
          -8.324653,
          20.490427,
          -16.250116,
          -13.571688,
          -15.997876,
          -14.278037,
          3.9486065,
          -15.046451,
          1.3679554,
          3.8930674,
          -8.141117,
          18.732754,
          -6.275925,
          -14.073815,
          -4.1500454,
          -13.007984,
          -11.954933,
          -13.057605,
          -13.329799,
          -12.901861,
          0.7966472,
          -7.117602,
          8.695419,
          -3.865628,
          -8.581028,
          5.7269177,
          -10.970265,
          -6.5978317,
          -1.092532,
          -3.7935913,
          -9.2996645,
          0.09323408,
          -0.7165498,
          -3.6219025,
          -11.033489,
          -3.6446486,
          -7.929446,
          -9.879666,
          -15.573069,
          -15.603525,
          26.062304
         ]
        },
        {
         "customdata": [
          [
           "Human Centeredness",
           " <i>Artificial Intelligence and Machine Learning: Policy Paper</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Human Centeredness",
           " <i>AI system designers and builders need to apply a user-centric approach to the<br>technology. They need to consider their collective responsibility in building AI<br>systems that will not pose security risks to the Internet and Internet users.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Everyday Ethics for Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Human Centeredness",
           " <i>AI should be designed to align with the norms and values of your user group in<br>mind.</i>"
          ],
          [
           "Human Centeredness",
           " <i>10 ethical guidelines for the digitalisation of companies (10 ethische<br>Leitlinien für die Digitalisierung von Unternehmen)</i>",
           " 2017",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Human Centeredness",
           " <i>In the development and deployment of artificial intelligence (AI), ethical<br>principles must be taken into (value-based design).</i>"
          ],
          [
           "Human Centeredness",
           " <i>Ethics Guidelines for Trustworthy AI</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Human Centeredness",
           " <i>To do this, AI systems need to be human-centric, resting on a commitment to<br>their use in the service of humanity and the common good, intending to improve<br>human welfare and freedom.</i>"
          ],
          [
           "Human Centeredness",
           " <i>China’s Artificial Intelligence Industry Alliance Self-discipline Convention</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Human Centeredness",
           " <i>The development of artificial intelligence should uphold basic rights, such as<br>human freedom and dignity, follow the principle of human centeredness, and<br>prevent artificial intelligence from weakening and replacing humanity's<br>position.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Mid- to Long-Term Master Plan in Preparation for the Intelligent Information<br>Society Managing the Fourth Industrial Revolution</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " South Korea",
           " Human Centeredness",
           " <i>Establish human-centered ethics to govern data-collection processes and AI<br>algorithms.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Charlevoix Common Vision for the Future of Artificial Intelligence</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " International Organization",
           " Intergovernmental Organization",
           " G7",
           " Human Centeredness",
           " <i>We, the leaders of the G7, commit to promoting human-centric AI and commercial<br>adoption of AI, and continue to advance appropriate technical, ethical, and<br>technologically neutral approaches.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Responsible bots: 10 guidelines for developers of conversational AI</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Human Centeredness",
           " <i>Develop metrics to assess user satisfaction.</i>"
          ],
          [
           "Human Centeredness",
           " <i>The Future Computed – Artificial intelligence and its role in society</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Human Centeredness",
           " <i>We believe that AI offers incredible opportunities to drive widespread economic<br>and social progress. The key to attaining these benefits is to develop AI in<br>such a way that it is human-centered. AI should augment and amplify human<br>capabilities. AI systems should be designed to understand the context, needs,<br>and expectations of the people who use them. Goals for educational attainment<br>should include outcomes related to employment, skills, and advancement.</i>"
          ],
          [
           "Human Centeredness",
           " <i>For a meaningful Artificial Intelligence - Towards a French and European<br>strategy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Human Centeredness",
           " <i>We need to formulate ways in which humans and intelligent systems can work<br>together.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Principles to Promote Fairness, Ethics, Accountability and Transparency (FEAT)<br>in the Use of Artificial Intelligence and Data Analytics in Singapore’s<br>Financial Sector</i>",
           " 2018",
           " Recommendation",
           " Governmental Institution",
           " Southeast Asia",
           " Singapore",
           " Human Centeredness",
           " <i>The use of AIDA should be aligned with the firm’s ethical standards, values, and<br>codes of conduct. AIDA-driven decisions should be held to at least the same<br>ethical standards as human-driven decisions.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Model AI Governance Framework</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " Southeast Asia",
           " Singapore",
           " Human Centeredness",
           " <i>AI solutions should be human-centric.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Data, Responsibly (Vol. 1) Mirror, Mirror</i>",
           " 2020",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Human Centeredness",
           " <i>Maybe what we need instead is to ground the design of AI systems in people.<br>Using the data of the people, collected and deployed with an equitable<br>methodology as determined by the people, to create technology that is beneficial<br>for the people.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Asilomar AI Principles</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Human Centeredness",
           " <i>Highly autonomous AI systems should be designed so that their goals and<br>behaviors can be assured to align with human values throughout their operation.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Rome Call for AI Ethics</i>",
           " 2020",
           " Recommendation",
           " Religious Institution",
           " Southern Europe",
           " Vatican City State",
           " Human Centeredness",
           " <i>We must guarantee an outlook in which AI is developed with a focus not on<br>technology, but rather for the good of humanity and of the environment, of our<br>common and shared home, and of its human inhabitants, who are inextricably<br>connected.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Ethically Aligned Design: A Vision for Prioritizing Human Well-being with<br>Autonomous and Intelligent Systems, Version 2</i>",
           " 2017",
           " Recommendation",
           " Professional Association",
           " North America",
           " United States of America",
           " Human Centeredness",
           " <i>We need to establish societal and policy guidelines for such systems to remain<br>human-centric, serving humanity’s values and ethical principles.</i>"
          ],
          [
           "Human Centeredness",
           " <i>The Ethics of Code: Developing AI for Business with Five Core Principles</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Human Centeredness",
           " <i>Any AI system learning from bad examples could end up becoming socially<br>inappropriate—we have to remember that most AI today has no cognition of what it<br>is saying/doing. Reinforcement learning measures should be built not just based<br>on what AI or robots do to achieve an outcome, but also on how AI and robots<br>align with human values to accomplish that particular result.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Digital Ethics Guidelines on AI</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Human Centeredness",
           " <i>We recognize the widespread fear, that AI enabled machines will outsmart the<br>human intelligence. We as Deutsche Telekom think differently. We know and<br>believe in the human strengths like inspiration, intuition, sense making and<br>empathy. But we also recognize the strengths of AI like data recall, processing<br>speed and analysis. By combining both, AI systems will help humans to make<br>better decisions and accomplish objectives more effective and efficient.</i>"
          ],
          [
           "Human Centeredness",
           " <i>AI Ethics Principles & Guidelines</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Middle East",
           " United Arab Emirates",
           " Human Centeredness",
           " <i>AI should be developed to align with human values and contribute to human<br>flourishing.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Beijing AI Principles</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Eastern Asia",
           " China",
           " Human Centeredness",
           " <i>The R&D of AI should serve humanity and conform to human values as well as the<br>overall interests of humankind.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Responsible Artificial Intelligence in the Government of Canada (whitepaper)</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Human Centeredness",
           " <i>AI systems deployed on behalf of the government should be trained to reflect the<br>Values and Ethics of the Public Sector as well as Canadian and international<br>human rights obligations; they should be used to reinforce these values where<br>possible.</i>"
          ],
          [
           "Human Centeredness",
           " <i>SAP’s guiding principles for Artificial Intelligence</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Human Centeredness",
           " <i>By providing human­centered user experiences through augmented and intuitive<br>technologies, we leverage AI to support people in maximizing their potential. To<br>achieve this, we design our systems closely with users in a collaborative,<br>multidisciplinary, and demographically diverse environment.</i>"
          ],
          [
           "Human Centeredness",
           " <i>People + AI Guidebook</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Human Centeredness",
           " <i>Aligning your product with user needs is step one in any successful AI product.<br>Once you’ve found a need, you should evaluate whether using AI will uniquely<br>address the need. From there, consider whether some parts of the experience<br>should be automated or augmented. Lastly, design your reward function to create<br>a great user experience for all your users over the long run.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Responsible AI practices</i>",
           " Unspecified",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Human Centeredness",
           " <i>Reliable, effective user-centered AI systems should be designed following<br>general best practices for software systems, together with practices that<br>address considerations unique to machine learning. The way actual users<br>experience your system is essential to assessing the true impact of its<br>predictions, recommendations, and decisions. Engage with a diverse set of users<br>and use-case scenarios, and incorporate feedback before and throughout project<br>development. This will build a rich variety of user perspectives into the<br>project and increase the number of people who benefit from the technology.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Telefónica´s Approach to the Responsible Use of AI (Enfoque de Telefónica para<br>un uso responsable de la IA)</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Spain",
           " Human Centeredness",
           " <i>Human-centric AI means that AI should be at the service of society and generate<br>tangible benefits for people. AI systems should always stay under human control<br>and be driven by value-based considerations.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Telia Company Guiding Principles on trusted AI ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Sweden",
           " Human Centeredness",
           " <i>AI is used to simplify and enhance our customers’ lives. Employees’ issues are<br>recognized and respected. We acknowledge the advantages of a cooperative and<br>complementary model of human-machine interactions and seek to use this<br>sustainably. Our preference and intention are for AI to extend and complement<br>human abilities rather than lessen or restrict them.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Report on Artificial Intelligence and Human Society</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Human Centeredness",
           " <i>We also consider addressing the fundamental question, “What values are shared by<br>humans all over the world,” to be unavoidable.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Tokyo Statement - Useful Artificial Intelligence- Beneficial AI -Cooperation for<br>Realization</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Asia",
           " Japan",
           " Human Centeredness",
           " <i>Artificial intelligence must be proven to be safe, reliable, robust, and<br>developed in line with the values ​​of the society in which it is utilized.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Understanding artificial intelligence ethics and safety: A guide for the<br>responsible design and implementation of AI systems in the public sector</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Western Europe",
           " United Kingdom",
           " Human Centeredness",
           " <i>The demand for sensitivity to human factors should inform your approach to<br>devising delivery and implementation processes from start to finish. To provide<br>clear and effective explanations about the content and rationale of algorithmic<br>outputs, you will have to begin by building from the human ground up. By taking<br>a deliberate and human-centered approach to the delivery process, you should be<br>able to find the most effective way to convey your model’s statistical results<br>to users and decision subjects in a non-technical and socially meaningful<br>language that enables them to understand and evaluate the rational<br>justifiability of those results.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Opinion of the Data Ethics Commission</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Human Centeredness",
           " <i>At the center is the requirement to strive for algorithmic systems with a human-<br>centered and value-oriented design that takes fundamental rights and freedoms<br>into consideration. The Data Ethics Commission believes that the human-centered<br>approach must permeate the entire design process.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Artificial Intelligence and Data Protection</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Human Centeredness",
           " <i>AI developers, manufacturers, and service providers should adopt a values-<br>oriented approach in the design of their products and services, consistent with<br>Convention 108+, in particular with Article 10.2, and other relevant instruments<br>of the Council of Europe.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Vienna Manifesto on Digital Humanism</i>",
           " 2019",
           " Recommendation",
           " Academic",
           " Central Europe",
           " Austria",
           " Human Centeredness",
           " <i>We must shape technologies under human values and needs instead of allowing<br>technologies to shape humans. Our task is not only to rein in the downsides of<br>information and communication technologies but to encourage human-centered<br>innovation.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Artificial Intelligence: Economic importance, social challenges, human<br>responsibility</i>",
           " 2017",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Human Centeredness",
           " <i>Intelligent machines must serve people. People and machines should be able to<br>communicate with each other in the same way as people do with each other ‒ in<br>some respects even better.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Report of COMEST on robotics ethics</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Human Centeredness",
           " <i>When designing robotic technologies, ethical considerations should be taken into<br>account. Robots use algorithms to make decisions, which embody ethical values<br>and frameworks. In addition, robots have ethical implications for the practices<br>in which they are used, like health care, education, and social interactions. To<br>address these ethical dimensions of robots, ethics needs to be part of the<br>design process, building on approaches like the Value Sensitive Design approach.<br>This approach should also be adapted to consider animal welfare.</i>"
          ],
          [
           "Human Centeredness",
           " <i>ACM Code of Ethics and Professional Conduct</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Human Centeredness",
           " <i>A computing professional should ensure that the public good is the central<br>concern during all professional computing work. People—including users,<br>customers, colleagues, and others affected directly or indirectly—should always<br>be the central concern in computing.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Montréal declaration for a responsible development of artificial intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " Canada",
           " Human Centeredness",
           " <i>AI must be developed with the goal of collaborating with humans on complex tasks<br>and should foster collaborative work between humans.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Social Principles of Human-Centric AI</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia, Western Europe",
           " Japan, United Kingdom",
           " Human Centeredness",
           " <i>The utilization of AI must not infringe upon the fundamental human rights<br>guaranteed by the Constitution and international standards. AI should be<br>developed, utilized, and implemented in society to expand the abilities of<br>people and allow diverse people to pursue their well-being.</i>"
          ],
          [
           "Human Centeredness",
           " <i>DataEthics: Principles and Guidelines for Companies, Authorities & Organisations</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " Northern Europe",
           " Denmark",
           " Human Centeredness",
           " <i>Human interests always prevail over institutional and commercial interests.<br>People are not computer processes or pieces of software, but unique with<br>empathy, self-determination, unpredictability, intuition, and creativity and<br>therefore have a higher status than machines. The human being is at the center<br>and has the primary benefit of data processing.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Principles of Artificial Intelligence Ethics for the Intelligence Community</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Human Centeredness",
           " <i>We will develop and use AI to augment our national security and enhance our<br>trusted partnerships by tempering technological guidance with the application of<br>human judgment, especially when an action has the potential to deprive<br>individuals of constitutional rights or interfere with their free exercise of<br>civil liberties.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Vodafone Artificial Intelligence Framework</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Human Centeredness",
           " <i>Vodafone will proactively engage with industry peers and other relevant experts<br>(e.g. academics and civil society) in consultation exercises to ensure that AI-<br>based systems are human-centric and foster diversity and inclusivity. We will<br>establish and maintain a regular dialogue with our customers as to how we should<br>use data and AI tools to serve them.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Artificial Intelligence at the service of the citizen (L’intelligenzia<br>artificiale al servizio del cittadino)</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Southern Europe",
           " Italy",
           " Human Centeredness",
           " <i>Artificial intelligence should focus on promoting and helping human beings,<br>thinking about our future and how we can have a better quality of life, and also<br>thinking about solving our problems, but always having the human being as a<br>priority.</i>"
          ],
          [
           "Human Centeredness",
           " <i>oston Dynamics Ethical Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Human Centeredness",
           " <i>We prioritize the human element in human-robot partnerships. We build robots<br>designed from the ground up to leverage human intelligence, keep people safe and<br>relieve the most burdensome work.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Augmented Intelligence in Health Care H-480.940</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Professional Association",
           " North America",
           " United States of America",
           " Human Centeredness",
           " <i>AMA will seek to promote the development of thoughtfully designed, high-quality,<br>clinically validated healthcare AI that is designed and evaluated in keeping<br>with best practices in user-centered design, particularly for physicians and<br>other members of the healthcare team.</i>"
          ],
          [
           "Human Centeredness",
           " <i>The Ethical Norms for the New Generation Artificial Intelligence, China</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Human Centeredness",
           " <i>Various activities of AI shall abide by the following fundamental ethical norms,<br>like adherence to the people-oriented vision, abiding by the common values ​​of<br>humankind.</i>"
          ],
          [
           "Human Centeredness",
           " <i>The National Artificial Intelligence Research and Development Strategic Plan:<br>2019 Update</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Human Centeredness",
           " <i>Develop effective methods for human-AI collaboration. Increase understanding of<br>how to create AI systems that effectively complement and augment human<br>capabilities.</i>"
          ],
          [
           "Human Centeredness",
           " <i>The Holberton-Turing Oath</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Unspecified",
           " Unspecified",
           " Human Centeredness",
           " <i>I make these promises to create Artificial Intelligence, first, to collaborate<br>with people for the greater good, rather than usurp the human role and supplant<br>them.</i>"
          ],
          [
           "Human Centeredness",
           " <i>OpenAI Charter</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization, Private Corporation",
           " North America",
           " United States of America",
           " Human Centeredness",
           " <i>OpenAI’s mission is to ensure that artificial intelligence benefits all of<br>humanity. An important part of this effort is training AI systems to do what<br>humans want.</i>"
          ],
          [
           "Human Centeredness",
           " <i>AI UX: 7 Principles of Designing Good AI Products</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Europe",
           " Hungary",
           " Human Centeredness",
           " <i>When we work on AI UX, we help developers decide what to optimize for. Providing<br>meaningful insights about human reactions and human priorities can prove the<br>most important job of a designer in an AI project. UX people help collect<br>training data and define the expected outcome people want to see from the AI<br>product.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Policy guidance on AI for children</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution, International Organization",
           " Northern Europe, Intergovernmental Organization",
           " Finland, United Nations",
           " Human Centeredness",
           " <i>Create an enabling environment. Make it possible for all to contribute to child-<br>centred AI.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Thomson Reuters AI principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " Canada",
           " Human Centeredness",
           " <i>Thomson Reuters will strive to maintain a human-centric approach and will strive<br>to design, develop and deploy AI products and services that treat people fairly.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Alpha Principles for the Ethical Use of AI and Data Driven Technologies in<br>Ontario</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Human Centeredness",
           " <i>The processes and outcomes behind an algorithm should always be developed with<br>human users as the main consideration. Human-centered AI should reflect the<br>information, goals, and constraints that a human decision-maker weighs when<br>arriving at a decision. Keeping human users at the center entails evaluating any<br>outcomes (both direct and indirect) that might affect them due to the use of the<br>algorithm. Contingencies for unintended outcomes need to be in place as well,<br>including removing the algorithms entirely or ending their application.</i>"
          ],
          [
           "Human Centeredness",
           " <i>IBM AI Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Human Centeredness",
           " <i>The purpose of AI is to augment human intelligence.</i>"
          ],
          [
           "Human Centeredness",
           " <i>The Code of Ethics in the Field of Artificial Intelligence</i>",
           " 2022",
           " Recommendation",
           " Unspecified",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Human Centeredness",
           " <i>AI technologies developed by Actors should promote or not hinder the full<br>realization of all human capabilities to achieve harmony in social, economic,<br>and spiritual spheres, as well as the highest self-fulfillment of 2 human<br>beings.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Chinese Young Scientists' Declaration on the Governance and Innovation of<br>Artificial Intelligence (Shanghai Declaration)</i>",
           " 2019",
           " Recommendation",
           " Academic, Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Asia",
           " China",
           " Human Centeredness",
           " <i>Artificial Intelligence should comply with human values and interests.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Harmonious Artificial Intelligence Principles</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Human Centeredness",
           " <i>To create the Harmonious Human-AI Society, Artificial Intelligence models, and<br>engines should be designed with the philosophy of Humanization to continuously<br>strengthen their interactions with current and future Humanity. AI with various<br>emotions needs to be realized for better communication between humans and AI.</i>"
          ],
          [
           "Human Centeredness",
           " <i>\"ARCC\": An Ethical Framework for Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " Eastern Asia",
           " China",
           " Human Centeredness",
           " <i>Recommendation - Relation between AI and humans is not an either-or<br>relationship, on the contrary, AI can and should enhance human wisdom and<br>creativity.</i>"
          ],
          [
           "Human Centeredness",
           " <i>A Framework for the Ethical use of advanced Data Science Methodes in the<br>Humanitarian Sector</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe, Intergovernmental Organization",
           " Netherlands, United Nations",
           " Human Centeredness",
           " <i>Humanitarian solutions should be needs-based rather than technology-based, as<br>supported by the Signal Code’s Obligations in which the first obligation states<br>that “Humanitarians should ensure that Humanitarian Information Activities are<br>based on the needs of affected populations.” For this, it is essential to start<br>with a problem from the ground rather than apply a top-down approach.</i>"
          ],
          [
           "Human Centeredness",
           " <i>Stanford's Human-Centered AI Initiative Values</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Academic",
           " North America",
           " United States of America",
           " Human Centeredness",
           " <i>If AI is to serve the collective needs of humanity, it must incorporate an<br>understanding of what moves us — physically, intellectually, and emotionally. We<br>must design machine intelligence that can understand human language, feelings,<br>intentions, and behaviors, and interact with nuance and in multiple dimensions.</i>"
          ]
         ],
         "hovertemplate": "<b>Document ID </b>=%{customdata[1]}<br><b>Year of Publication </b>=%{customdata[2]}<br><b>Reguation Type </b>=%{customdata[3]}<br><b>Institution Type </b>=%{customdata[4]}<br><b>World Region </b>=%{customdata[5]}<br><b>Country </b>=%{customdata[6]}<br><b>Principle </b>=%{customdata[7]}<br><b>Description </b>=%{customdata[8]}<extra></extra>",
         "legendgroup": "Human Centeredness",
         "marker": {
          "color": "#FF97FF",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Human Centeredness",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          -10.540674,
          -0.6198992,
          -3.467096,
          1.1595702,
          1.8410488,
          5.7474084,
          22.560862,
          8.257679,
          7.865059,
          -0.87397254,
          -13.838525,
          0.4645023,
          6.6151524,
          -2.1344454,
          7.0020313,
          7.1488824,
          -4.283637,
          3.6554928,
          1.9271388,
          2.3662393,
          5.938951,
          3.050793,
          -5.7389135,
          -7.1459885,
          1.7121733,
          5.1242566,
          9.277562,
          -9.1417,
          -7.64913,
          4.1396203,
          1.6913592,
          18.281057,
          -2.1003728,
          -16.696743,
          19.558105,
          1.767229,
          2.2090154,
          -4.5557218,
          -2.0055888,
          10.849758,
          4.2544327,
          -5.5005646,
          -0.20613788,
          2.136457,
          1.4271575,
          -4.7687383,
          0.06730331,
          -11.522729,
          8.565043,
          -0.6140791,
          -7.291438,
          4.4021807,
          -1.4255694,
          0.55557656,
          1.159014,
          3.1947467,
          10.627935,
          3.137836
         ],
         "y": [
          -1.4251282,
          -6.042605,
          -10.279383,
          -5.808704,
          1.0104607,
          11.192788,
          0.47299653,
          13.522027,
          -11.499441,
          -12.029803,
          16.670088,
          -7.047772,
          -3.1699586,
          -5.682386,
          -4.4744816,
          12.282765,
          -7.046417,
          -11.583495,
          -5.6050982,
          -3.8382008,
          8.307824,
          -14.903872,
          -12.798223,
          -11.08603,
          -6.521459,
          -13.756036,
          12.674571,
          -8.971156,
          -7.2248116,
          10.946373,
          1.2383418,
          5.3589454,
          -11.39462,
          -6.9847107,
          12.350687,
          -8.022373,
          0.6566653,
          13.200335,
          -15.274355,
          -21.58618,
          -7.319987,
          -10.281807,
          -29.603712,
          -5.5550294,
          -13.367459,
          -15.066172,
          -7.9266243,
          -11.360773,
          2.6681583,
          -22.186535,
          -8.961848,
          -16.767443,
          4.354767,
          -3.6758804,
          -10.565768,
          -10.618751,
          24.674755,
          -9.929148
         ],
         "z": [
          1.4282111,
          16.9534,
          4.5256953,
          10.460884,
          12.9458475,
          4.8447247,
          -7.899805,
          -20.608498,
          10.048708,
          15.7385025,
          -18.030462,
          14.318449,
          8.177208,
          12.283378,
          12.952412,
          6.379722,
          12.453885,
          8.780881,
          16.581272,
          13.312204,
          9.014045,
          10.244494,
          -20.081264,
          -21.485638,
          11.799019,
          10.200363,
          7.7152066,
          11.012818,
          -23.52876,
          3.8600924,
          -1.2721523,
          10.983116,
          15.227437,
          17.882143,
          0.7119102,
          16.12775,
          10.380626,
          14.221551,
          7.370078,
          -4.5886683,
          13.210198,
          17.462202,
          -1.3002013,
          3.6380923,
          14.89402,
          12.78733,
          9.32901,
          -21.036293,
          23.466902,
          -13.007984,
          -22.755014,
          12.703334,
          12.999511,
          13.118127,
          12.219094,
          15.259496,
          -6.577289,
          10.61416
         ]
        },
        {
         "customdata": [
          [
           "Human Formation",
           " <i>AI Policies and Principles</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Industrial Association",
           " North America",
           " United States of America",
           " Human Formation",
           " <i>Current and future workers need to be prepared with the necessary education and<br>training to help them succeed. We recognize that delivering training is critical<br>and will require significant investment, not only in STEM education but also in<br>understanding human behavior via the humanities and social sciences. To ensure<br>the employability of the workforce of the future, the public and private sectors<br>should work together to design and deliver work-based learning and training<br>systems and advance approaches that provide students with real work experiences<br>and concrete skills.</i>"
          ],
          [
           "Human Formation",
           " <i>Responsible AI: A Global Policy Framework</i>",
           " 2021",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization, Professional Association",
           " North America",
           " United States of America",
           " Human Formation",
           " <i>Governments should promote educational policies that equip all children with the<br>skills, knowledge, and qualities required by the new economy and that promote<br>life-long learning. Governments should encourage the creation of opportunities<br>for adults to learn new useful skills, especially for those displaced by<br>automation.</i>"
          ],
          [
           "Human Formation",
           " <i>AI at Google: our principles</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Human Formation",
           " <i>we will responsibly share AI knowledge by publishing educational materials, best<br>practices, and research that enable more people to develop useful AI<br>applications.</i>"
          ],
          [
           "Human Formation",
           " <i>Responsible use of artificial intelligence (AI)</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Human Formation",
           " <i>To ensure the effective and ethical use of AI the government will: provide<br>sufficient training so that government employees developing and using AI<br>solutions have the responsible design, function, and implementation skills<br>needed to make AI-based public services better.</i>"
          ],
          [
           "Human Formation",
           " <i>10 ethical guidelines for the digitalisation of companies (10 ethische<br>Leitlinien für die Digitalisierung von Unternehmen)</i>",
           " 2017",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Human Formation",
           " <i>The training and further education, as well as the digital competencies of<br>employees, are to be promoted. Preparing employees for digitization and<br>providing them with training accordingly, is regarded as a duty.</i>"
          ],
          [
           "Human Formation",
           " <i>Ethics Guidelines for Trustworthy AI</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Human Formation",
           " <i>Communication, education, and training play an important role, both to ensure<br>that knowledge of the potential impact of AI systems is widespread, and to make<br>people aware that they can participate in shaping societal development.</i>"
          ],
          [
           "Human Formation",
           " <i>Declaration of Ethical Principles for AI in Latin America (Declaración de<br>Principios Éticos para la IA de Latinoamérica)</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Latin America",
           " Unspecified",
           " Human Formation",
           " <i>Labor transformation is a reality, the development of AI must also, as a<br>principle, collaborate in the retraining and placement of the workforce that it<br>replaces, through education and the complement of the new necessary skills and<br>competencies.</i>"
          ],
          [
           "Human Formation",
           " <i>IBM’s Principles for Trust and Transparency</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Human Formation",
           " <i>The purpose of AI and cognitive systems developed and applied by IBM is to<br>augment – not replace – human intelligence. Our technology is and will be<br>designed to enhance and extend human capability and potential. At IBM, we<br>believe AI should make ALL of us better at our jobs, and that the benefits of<br>the AI era should touch the many, not just the elite few. To that end, we are<br>investing in initiatives to help the global workforce gain the skills needed to<br>work in partnership with these technologies.</i>"
          ],
          [
           "Human Formation",
           " <i>China’s Artificial Intelligence Industry Alliance Self-discipline Convention</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Human Formation",
           " <i>Actively participate in universal education on artificial intelligence for the<br>public, morals and ethics education for relevant practitioners, and digital<br>labor skills retraining for personnel whose jobs have been replaced; alleviate<br>public concerns about artificial intelligence technology; raise public awareness<br>about safety and prevention, and actively respond to questions about current and<br>future workforce challenges.</i>"
          ],
          [
           "Human Formation",
           " <i>Mid- to Long-Term Master Plan in Preparation for the Intelligent Information<br>Society Managing the Fourth Industrial Revolution</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " South Korea",
           " Human Formation",
           " <i>It is important to tailor education, employment, and welfare services in<br>response to changes to ensure that all citizens can enjoy the benefits of the<br>intelligent information society. Provide education for the underprivileged to<br>minimize the information gap and foster and spread a human-centered<br>technological culture that accords due respect to technology and the humanities<br>alike.</i>"
          ],
          [
           "Human Formation",
           " <i>Charlevoix Common Vision for the Future of Artificial Intelligence</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " International Organization",
           " Intergovernmental Organization",
           " G7",
           " Human Formation",
           " <i>Support lifelong learning, education, training and reskilling, and exchange<br>information on workforce development for AI skills, including apprenticeships,<br>computer science, and STEM (science, technology, engineering, and mathematics)<br>education, especially for women, girls and those at risk of being left behind.</i>"
          ],
          [
           "Human Formation",
           " <i>MIT Schwarzman College of Computing Task Force Working Group on Social<br>Implications and Responsibilities of Computing Final Report</i>",
           " 2019",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Human Formation",
           " <i>As a leading engineering institution with world-class social science and<br>humanities and a tradition of multidisciplinary collaboration, MIT has a pivotal<br>opportunity to make leadership contributions to the social, ethical, and policy<br>challenges facing the world by integrating consideration of these issues with<br>the development of new computing technologies. Establishing and prioritizing<br>interdisciplinary structures, which include rigorous methodologies derived from<br>the liberal arts, humanities, social sciences, and other disciplines, will prove<br>critical in activating and sustaining habits of mind and action. The SCoC must<br>catalyze and facilitate complex interdisciplinary actions.</i>"
          ],
          [
           "Human Formation",
           " <i>Toward a G20 Framework for Artificial Intelligence in the Workplace</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " Canada",
           " Human Formation",
           " <i>Ongoing training in the workplace should be reinforced to help workers adapt.</i>"
          ],
          [
           "Human Formation",
           " <i>Digital ethics: a guide for professionals of the digital age</i>",
           " 2018",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " France",
           " Human Formation",
           " <i>Set up training workshops and/or skills refresher courses within the IT<br>Department.</i>"
          ],
          [
           "Human Formation",
           " <i>The Future Computed – Artificial intelligence and its role in society</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Human Formation",
           " <i>Equitable access to rigorous and engaging computer science courses must be a top<br>priority. If equitable access is left unaddressed, we will exclude entire<br>populations from fully participating in this new world of work. The goal of<br>equitable access should be computer science classrooms that are diverse across<br>race, gender, disability, and socioeconomic status.</i>"
          ],
          [
           "Human Formation",
           " <i>How Can Humans Keep The Upper Hand? The Ethical Matters Raised By Algorithms And<br>Artificial Intelligence</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Human Formation",
           " <i>Fostering education of all players involved in the “algorithmic chain”<br>(designers, professionals, citizens) in the subject of ethics. There could be<br>merits to including the social and human sciences approach (sociology,<br>anthropology, management, history of science and technology, information and<br>communication sciences, philosophy, and ethics) to these issues in engineer and<br>data scientist training. It would be advisable to educate public stakeholders in<br>the need for a balanced and symmetrical deployment of algorithms.</i>"
          ],
          [
           "Human Formation",
           " <i>For a meaningful Artificial Intelligence - Towards a French and European<br>strategy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Human Formation",
           " <i>Formal education and lifelong learning should be overhauled in order to promote<br>experimental teaching methods that can help graduates and staff develop the<br>creative skills that are becoming increasingly vital.</i>"
          ],
          [
           "Human Formation",
           " <i>Digital Technology and Healthcare which ethical issues for which regulations?</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " France",
           " Human Formation",
           " <i>Public and private actors should be further encouraged to adapt the training —<br>both initial training and continuing professional development — of the<br>healthcare workforce to the challenges of digital technology and to support the<br>emergence of new professions associated with the spread of digital technology in<br>the health and medico-social sectors.</i>"
          ],
          [
           "Human Formation",
           " <i>Business Ethics and Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " Western Europe",
           " United Kingdom",
           " Human Formation",
           " <i>To maximize the potential of AI, people need to learn how it works and what are<br>the most efficient and effective ways to use it. Employees and other<br>stakeholders need to be empowered to take personal responsibility for the<br>consequences of their use of AI and they need to be provided with the skills to<br>do so.</i>"
          ],
          [
           "Human Formation",
           " <i>Big Data, Artificial Intelligence, Machine Learning, and Data Protection</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Human Formation",
           " <i>Data protection should be part of the higher education curriculum for people<br>going into these roles.</i>"
          ],
          [
           "Human Formation",
           " <i>Model AI Governance Framework</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " Southeast Asia",
           " Singapore",
           " Human Formation",
           " <i>It is important to create and raise awareness of the latest AI technologies and<br>start educating employees on the opportunities and benefits, should their job<br>roles be enhanced.</i>"
          ],
          [
           "Human Formation",
           " <i>Code of Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Professional Association",
           " North America",
           " United States of America",
           " Human Formation",
           " <i>Software engineers shall participate in lifelong learning regarding the practice<br>of their profession and shall promote an ethical approach to the practice of the<br>profession.</i>"
          ],
          [
           "Human Formation",
           " <i>AI 4People 's Ethical Framework for a Good AI Society: Opportunities, Risks,<br>Principles, and Recommendations</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Human Formation",
           " <i>Stakeholders should support the creation of educational curricula and public<br>awareness activities around the societal, legal, and ethical impact of<br>Artificial Intelligence.</i>"
          ],
          [
           "Human Formation",
           " <i>Rome Call for AI Ethics</i>",
           " 2020",
           " Recommendation",
           " Religious Institution",
           " Southern Europe",
           " Vatican City State",
           " Human Formation",
           " <i>Transforming the world through the innovation of AI means undertaking to build a<br>future for and with younger generations.</i>"
          ],
          [
           "Human Formation",
           " <i>Ethical Guidelines of the German Informatics Society</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization, Professional Association",
           " Western Europe",
           " Germany",
           " Human Formation",
           " <i>GI members stay abreast of the current state of science and technology in their<br>respective areas of specialization; they take new developments into account and<br>provide constructive criticism. GI members are constantly working to improve<br>their professional competencies. GI members who are computer science instructors<br>foster in their students the capacity for critical thinking; they prepare<br>learners to accept their own individual and collective responsibility, and they<br>act as role models in this regard.</i>"
          ],
          [
           "Human Formation",
           " <i>Ethically Aligned Design: A Vision for Prioritizing Human Well-being with<br>Autonomous and Intelligent Systems, Version 2</i>",
           " 2017",
           " Recommendation",
           " Professional Association",
           " North America",
           " United States of America",
           " Human Formation",
           " <i>Ethics and ethical reflection need to be a core subject for aspiring engineers<br>and technologists beginning at the earliest appropriate level and for all<br>advanced degrees. Empowering the education sector with advanced courses on A/IS<br>is the first step toward creating a nation that can handle the new economic and<br>power shifts.</i>"
          ],
          [
           "Human Formation",
           " <i>Digital Ethics Guidelines on AI</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Human Formation",
           " <i>We acknowledge the transformative power of AI for our society. We will support<br>people and society in preparing for this future world. We live our digital<br>responsibility by sharing our knowledge, pointing out the opportunities of the<br>new technology without neglecting its risks. We will engage with our customers,<br>other companies, policy makers, education institutions and all other<br>stakeholders to ensure we understand their concerns and needs and can setup the<br>right safeguards. We will engage in AI and ethics education. Hereby preparing<br>ourselves, our colleagues and our fellow human beings for the new tasks ahead.</i>"
          ],
          [
           "Human Formation",
           " <i>AI Ethics Principles & Guidelines</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Middle East",
           " United Arab Emirates",
           " Human Formation",
           " <i>Access to training, opportunity and tools should be made available. Education<br>should evolve and reflect the latest developments in AI, enabling people to<br>adapt to societal change</i>"
          ],
          [
           "Human Formation",
           " <i>Data for the Benefit of the People: Recommendations from the Danish Expert Group<br>on Data Ethics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Denmark",
           " Human Formation",
           " <i>It is recommended that science education be increased, with a focus on ethics<br>and philosophy, across all educations and levels of education, right from<br>primary school where pupils need to learn to navigate responsibly when using new<br>technology, to students who, via an interdisciplinary approach to learning, need<br>to understand that they are contributing to a digital society with many data<br>ethics pitfalls.</i>"
          ],
          [
           "Human Formation",
           " <i>Algo.Rules: Rules for the Design of Algorithmic Systems</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Private Corporation",
           " Western Europe",
           " Germany",
           " Human Formation",
           " <i>Sharing individual and institutional knowledge as well as promoting<br>interdisciplinary exchange across task areas are just as crucial as ensuring<br>appropriate skills development. These approaches should be integrated into the<br>education, training, and onboarding of new employees. In addition, an<br>interdisciplinary exchange should be an ongoing endeavor that remains open to<br>those who are interested and/or affected.</i>"
          ],
          [
           "Human Formation",
           " <i>Beijing AI Principles</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Eastern Asia",
           " China",
           " Human Formation",
           " <i>Stakeholders of AI systems should be able to receive education and training to<br>help them adapt to the impact of AI development in psychological, emotional, and<br>technical aspects.</i>"
          ],
          [
           "Human Formation",
           " <i>Artificial Intelligence: opportunities, risks and recommendations for the<br>financial sector</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Luxembourg",
           " Human Formation",
           " <i>Institutions should ensure a sufficient level of internal AI skills to<br>understand, develop or supervise the solution, including via specific training<br>and knowledge transfer from external consultants when required. Institutions<br>willing to implement off-the-shelf packages integrating AI/ML technology should<br>carefully evaluate the skills required internally to maintain the solution once<br>in production.</i>"
          ],
          [
           "Human Formation",
           " <i>Data protection and Big Data (Datenschutz und Big Data)</i>",
           " 2017",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Human Formation",
           " <i>The essential differences of Big Data compared to previously known data<br>processing require new competencies in the company. They require new knowledge<br>and skills among all employees involved from all affected departments, i.e.,<br>especially in the areas of corporate development and IT. There are various ways<br>of building up these competencies. First and foremost, of course, training of<br>the employees concerned should be considered. Such training is particularly<br>recommended for the professional groups of application developers, data<br>architects, business intelligence analysts, database administrators, and system<br>administrators.</i>"
          ],
          [
           "Human Formation",
           " <i>Artificial Intelligence in Healthcare</i>",
           " 2019",
           " Recommendation",
           " Academic",
           " Western Europe",
           " United Kingdom",
           " Human Formation",
           " <i>Clinicians can and must be part of the change that will accompany the<br>development and use of AI. This will require changes in behavior and attitude<br>including rethinking many aspects of doctors’ education and careers. More<br>doctors will be needed who are as well versed in data science as they are in<br>medicine.</i>"
          ],
          [
           "Human Formation",
           " <i>Artificial Intelligence at Google: Our Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Human Formation",
           " <i>We believe that AI should uphold high standards of scientific excellence. We<br>will responsibly share AI knowledge by publishing educational materials, best<br>practices, and research that enable more people to develop useful AI<br>applications.</i>"
          ],
          [
           "Human Formation",
           " <i>Artificial Intelligence: Australia’s Ethics Framework - A Discussion Paper</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Oceania",
           " Australia",
           " Human Formation",
           " <i>An ethical approach to AI development requires helping people who are negatively<br>impacted by automation transition their careers. This could involve training,<br>reskilling and new career pathways. Improved information on risks and<br>opportunities can help workers take proactive action. Incentives can be used to<br>encourage the right type of training at the right times. Overall, acting early<br>improves the chances of avoiding job loss or ongoing unemployment.</i>"
          ],
          [
           "Human Formation",
           " <i>Sony Group AI Ethics Guidelines</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " Japan",
           " Human Formation",
           " <i>People’s lives have continuously changed with the advance in technology across<br>history. Sony will be cognizant of the effects and impact of products and<br>services that utilize AI on society and will proactively work to contribute to<br>developing AI to create a better society and foster human talent capable of<br>shaping our collective bright future through R&D and/or utilization of AI.</i>"
          ],
          [
           "Human Formation",
           " <i>Telefónica´s Approach to the Responsible Use of AI (Enfoque de Telefónica para<br>un uso responsable de la IA)</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Spain",
           " Human Formation",
           " <i>It is of utmost importance to explain to employees what AI is, how it works and<br>how it might lead to undesired consequences. Telefónica has therefore developed<br>courses related to AI & Ethics that are accessible to all employees through the<br>standard corporate portals in three languages (Spanish, English, and<br>Portuguese).</i>"
          ],
          [
           "Human Formation",
           " <i>AI Now Report 2018</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Human Formation",
           " <i>University AI programs should expand beyond computer science and engineering<br>disciplines. AI began as an interdisciplinary field, but over the decades has<br>narrowed to become a technical discipline. With the increasing application of AI<br>systems to social domains, it needs to expand its disciplinary orientation. That<br>means centering forms of expertise from the social and humanistic disciplines.</i>"
          ],
          [
           "Human Formation",
           " <i>Report on Artificial Intelligence and Human Society</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Human Formation",
           " <i>The significant issues are understanding the advantages and limitations of the<br>present AI technologies, properly utilizing AI technologies, and performing<br>creative activities in collaboration with AI technologies. Educational policy<br>functions according to discussions of how to efficiently reform curriculums<br>based on evidence that shows the technologies’ limitations, the critical human<br>abilities differentiated from present AI technologies, and the essential human<br>abilities to be acquired. It is important to consider what abilities should be<br>still learned by humans for proper brain development even though the activities<br>enabled by said abilities can be performed instead by AI technologies.</i>"
          ],
          [
           "Human Formation",
           " <i>Opinion of the Data Ethics Commission</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Human Formation",
           " <i>Education and training must also play a prominent role in safeguarding the free<br>democratic basic order, since they influence, in a wide variety of ways, the<br>participation of citizens in the shaping of society – a process that is of<br>critical and fundamental importance for democracy, these citizens’ understanding<br>and appraisal of socially relevant interrelationships and developments, and –<br>ultimately – their level of confidence in a future that can be shaped and that<br>is founded on values. Education and training must impart not only technical and<br>mathematical skills but also skills in the fields of ethics, law, economics, and<br>the social sciences.</i>"
          ],
          [
           "Human Formation",
           " <i>Artificial Intelligence and Data Protection</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Human Formation",
           " <i>Policymakers should invest resources in digital literacy and education to<br>increase data subjects’ awareness and understanding of AI applications and their<br>effects. They should also encourage professional training for AI developers to<br>raise awareness and understanding of the potential effects of AI on individuals<br>and society. They should support research in human rights-oriented AI.</i>"
          ],
          [
           "Human Formation",
           " <i>Report with recommendations to the Commission on Civil Law Rules on Robotics</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " European Union",
           " European Union",
           " Human Formation",
           " <i>The European Parliament draws attention to the Commission's forecast that by<br>2020 Europe might be facing a shortage of up to 825 000 ICT professionals and<br>that 90 % of jobs will require at least basic digital skills; welcomes the<br>Commission’s initiative of proposing a roadmap for the possible use and revision<br>of a Digital Competence framework and descriptors of Digital Competencies for<br>all levels of learners, and calls upon the Commission to provide significant<br>support for the development of digital abilities in all age groups and<br>irrespective of employment status, as the first step towards better-aligning<br>labor market shortages and demand; stresses that the growth in the robotics<br>requires the Member States to develop more flexible training and education<br>systems so as to ensure that skill strategy matches the needs of the robot<br>economy.</i>"
          ],
          [
           "Human Formation",
           " <i>Preparing for the future of Artificial Intelligence</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Human Formation",
           " <i>The NSTC Subcommittees on MLAI and NITRD, in conjunction with the NSTC Committee<br>on Science, Technology, Engineering, and Education (CoSTEM), should initiate a<br>study on the AI workforce pipeline in order to develop actions that ensure an<br>appropriate increase in the size, quality, and diversity of the workforce,<br>including AI researchers, specialists, and users.</i>"
          ],
          [
           "Human Formation",
           " <i>Vienna Manifesto on Digital Humanism</i>",
           " 2019",
           " Recommendation",
           " Academic",
           " Central Europe",
           " Austria",
           " Human Formation",
           " <i>Education on computer science/informatics and its societal impact must start as<br>early as possible. Students should learn to combine information-technology<br>skills with an awareness of the ethical and societal issues at stake. A vision<br>is needed for new educational curricula, combining knowledge from the<br>humanities, the social sciences, and engineering studies. In the age of<br>automated decision-making and AI, creativity and attention to human aspects are<br>crucial to the education of future engineers and technologists.</i>"
          ],
          [
           "Human Formation",
           " <i>Artificial Intelligence: Economic importance, social challenges, human<br>responsibility</i>",
           " 2017",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Human Formation",
           " <i>Germany needs an investment spurt in all areas of research, development, and<br>education, especially in AI. The mobilization of AI potential requires focused<br>efforts in many areas. This applies to the entire research landscape, school<br>education, the system of continuing education, and retraining. From now on,<br>massive investments at all levels must be made in digital education, information<br>literacy, and the courage to make one’s judgments and decisions.</i>"
          ],
          [
           "Human Formation",
           " <i>Machine learning: the power and promise of computers that learn by example</i>",
           " 2017",
           " Recommendation",
           " Academic",
           " Western Europe",
           " United Kingdom",
           " Human Formation",
           " <i>Schools need to ensure that key concepts in machine learning are taught to those<br>who will be users, developers, and citizens. Government, mathematics and<br>computing communities, businesses, and education professionals should help<br>ensure that relevant insights into machine learning are built into the current<br>education curriculum and associated enrichment activity in schools over the next<br>five years and that teachers are supported in delivering these activities.<br>Government should consider introducing a newly funded program of master's<br>courses in machine learning, potentially in parallel with encouragement for<br>approaches to training in machine learning via Massive Open Online Courses<br>(MOOCs), to increase the pool of informed users of machine learning.</i>"
          ],
          [
           "Human Formation",
           " <i>AI in the UK: ready, willing and able?</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Human Formation",
           " <i>All citizens have the right to be educated to enable them to flourish mentally,<br>emotionally, and economically alongside artificial intelligence.</i>"
          ],
          [
           "Human Formation",
           " <i>Preliminary Study on the Ethics of Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Human Formation",
           " <i>Algorithm awareness and a basic understanding of the workings of AI are needed<br>to empower citizens. AI requires that education fosters AI literacy, critical<br>thinking, resilience in the labor market, and education ethics for engineers.</i>"
          ],
          [
           "Human Formation",
           " <i>Report of COMEST on robotics ethics</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Human Formation",
           " <i>The appropriate educational system and additional training of existing workers<br>need to be established and adjusted so that this latest technological revolution<br>does not result in producing a mass of unemployable workers due to their lack of<br>skills with the latest technologies.</i>"
          ],
          [
           "Human Formation",
           " <i>Top 10 Principles for Ethical Artificial Intelligence</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " Switzerland",
           " Human Formation",
           " <i>As AI systems develop and augmented realities are formed, workers and work tasks<br>will be displaced. To ensure a just transition, as well as sustainable future<br>developments, it is vital that corporate policies are put in place that ensure<br>corporate accountability in relation to this displacement, such as retraining<br>programs and job change possibilities. Governmental measures to help displaced<br>workers retrain and find new employment are additionally required. AI systems<br>coupled with the wider transition to the digital economy will require that<br>workers on all levels and in all occupations have access to social security and<br>to continuous lifelong learning to remain employable. It is the responsibility<br>of states and companies to find solutions that provide all workers, in all forms<br>of work, the right to and access to both.</i>"
          ],
          [
           "Human Formation",
           " <i>Montréal declaration for a responsible development of artificial intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " Canada",
           " Human Formation",
           " <i>It is crucial to empower citizens regarding digital technologies by ensuring<br>access to the relevant forms of knowledge, promoting the learning of fundamental<br>skills (digital and media literacy), and fostering the development of critical<br>thinking.</i>"
          ],
          [
           "Human Formation",
           " <i>Ethical Framework for Artificial Intelligence in Colombia (Marco Ético para la<br>Inteligencia Artificial en Colombia)</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Latin America",
           " Colombia",
           " Human Formation",
           " <i>Training and education programs should be generated to enable children and<br>adolescents to know and understand the characteristics of this technology and<br>its implications, highlighting ethical training.</i>"
          ],
          [
           "Human Formation",
           " <i>Artificial Intelligence for Children: Beijing Principles</i>",
           " 2020",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Human Formation",
           " <i>The development of AI should protect and promote the free development and<br>diversified growth of children. AI should promote the development of children's<br>multiple intelligences and personalities, actively provide feedback to<br>children's curiosity, help stimulate children's potential, and help guide<br>children to form sound and scientific values. The development of AI should help<br>provide a more inclusive, fairer, and quality education for children.</i>"
          ],
          [
           "Human Formation",
           " <i>Social Principles of Human-Centric AI</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia, Western Europe",
           " Japan, United Kingdom",
           " Human Formation",
           " <i>To prevent generating disparities between people or to create socially<br>vulnerable individuals, opportunities for education in a wide range of literacy<br>skills are to be provided in early childhood education and primary and secondary<br>education. Opportunities are also to be provided for the reeducation of working<br>adults and the elderly. Concerning literacy education and skills required to use<br>AI, our society needs an educational system that allows anyone to acquire the<br>basics of AI, mathematics, and data science. These characteristics include bias<br>in data, the possibility of causing bias depending on how AI is used, and issues<br>of fairness, impartiality, and privacy protection that are inherently needed in<br>the use of AI.</i>"
          ],
          [
           "Human Formation",
           " <i>The Toronto Declaration</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " North America, Western Europe",
           " Canada, United Kingdom",
           " Human Formation",
           " <i>States should ensure that public bodies carry out training in human rights and<br>data analysis for officials involved in the procurement, development, use, and<br>review of machine learning tools.</i>"
          ],
          [
           "Human Formation",
           " <i>Position on Robotics and Artificial Intelligence</i>",
           " 2016",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Human Formation",
           " <i>We call for employers to help workers acquire new skills and make education and<br>training a core issue to absorb potential shocks in the job market.</i>"
          ],
          [
           "Human Formation",
           " <i>AI Governance in Japan Ver. 1.1, Report from the expert group on how AI<br>principles should be implemented</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Human Formation",
           " <i>To prevent generating disparities between people or to create socially<br>vulnerable individuals, opportunities for education in a wide range of literacy<br>skills are to be provided in early childhood education and primary and secondary<br>education. Opportunities are also to be provided for the reeducation of working<br>adults and the elderly. Concerning literacy education and skills required to use<br>AI, our society needs an educational system that allows anyone to acquire the<br>basics of AI, mathematics, and data science. These characteristics include bias<br>in data, the possibility of causing bias depending on how AI is used, and issues<br>of fairness, impartiality, and privacy protection that are inherently needed in<br>the use of AI.</i>"
          ],
          [
           "Human Formation",
           " <i>Vodafone Artificial Intelligence Framework</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Human Formation",
           " <i>We will support our existing employees to gain new skills so that they can apply<br>for appropriate roles that are created by our improved digital capability. We<br>will deploy AI-based systems to provide more effective work environments,<br>simplifying the work of our employees and improving their experience. We will<br>provide training and education to help our employees use AI-based systems to<br>support their work.</i>"
          ],
          [
           "Human Formation",
           " <i>Artificial Intelligence at the service of the citizen (L’intelligenzia<br>artificiale al servizio del cittadino)</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Southern Europe",
           " Italy",
           " Human Formation",
           " <i>Recommendation - Facilitate the dissemination of skills through the promotion of<br>certification of professionals working in the area of AI (through the creation<br>and adoption of a shared framework ) and provide for the establishment of<br>training paths for the inclusion of workers with the ability to understand and<br>implement AI solutions in the public administration (for example through<br>specific courses at the National School of Administration). The numerous<br>professional skills lacking are an opportunity to think about training courses<br>focus on lasting and sustainable gender equality, both from a numerical point of<br>view (ex. STEM graduates) and from a financial point of view (ex. remuneration<br>equality).</i>"
          ],
          [
           "Human Formation",
           " <i>Augmented Intelligence in Health Care H-480.940</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Professional Association",
           " North America",
           " United States of America",
           " Human Formation",
           " <i>AMA will seek to encourage education for patients, physicians, medical students,<br>other healthcare professionals, and health administrators to promote a greater<br>understanding of the promise and limitations of healthcare AI.</i>"
          ],
          [
           "Human Formation",
           " <i>WLiAI Report 2019: 10 Principles of Responsible AI</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " United Kingdom",
           " Human Formation",
           " <i>Recommendation - To carry out a skills audit to identify the wide range of<br>skills required to embrace the AI revolution. To compel companies and other<br>organizations to bring their workforce with them – by publishing the impact of<br>AI on their workforce and offering retraining programs for employees whose jobs<br>are being automated. To establish an education and training program to meet the<br>needs identified by the skills audit, including content on data ethics and<br>social responsibility.</i>"
          ],
          [
           "Human Formation",
           " <i>The Ethical Norms for the New Generation Artificial Intelligence, China</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Human Formation",
           " <i>Various activities of AI shall abide by the following fundamental ethical norms,<br>like Actively learning and popularizing knowledge related to AI ethics,<br>objectively understanding ethical issues, and do not underestimate or exaggerate<br>ethical risks. Actively carry out or participate in the discussions on the<br>ethical issues of AI, deeply promote the practice of AI ethics and governance,<br>and improve the ability to respond to related issues.</i>"
          ],
          [
           "Human Formation",
           " <i>Work in the age of artificial intelligence: Four perspectives on the economy,<br>employment, skills and ethics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Finland",
           " Human Formation",
           " <i>Artificial intelligence will change the content of occupations and jobs. A risk<br>of exclusion of those with a lower level of education and an increase in<br>structural unemployment is always inherent in structural changes. In order to<br>prepare for the changes, it should be ensured that young people completing their<br>basic education have general knowledge and skills which give them eligibility<br>for further studies and promote lifelong learning. In order to combat high<br>structural unemployment in the future, a competence program will be drawn up,<br>which will ensure in practice that everyone will have at least a secondary level<br>qualification. In addition to providing more places for education and training,<br>compulsory education will be extended to the secondary level. The use of<br>technology in education should be promoted at all levels with the aim of<br>offering more individualized education content of higher quality in a cost-<br>effective manner.</i>"
          ],
          [
           "Human Formation",
           " <i>Discussion Paper: National Strategy for Artificial Intelligence</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " South Asia",
           " India",
           " Human Formation",
           " <i>For addressing issues relating to skilling, a two-pronged approach is warranted,<br>one set of interventions aimed at the workforce and the second for the students.<br>The education sector needs to be re-aligned to effectively harness the potential<br>of AI sustainably. In primary and secondary schools, there is a need to<br>transition to skill-based education in subjects relevant to AI.</i>"
          ],
          [
           "Human Formation",
           " <i>The National Artificial Intelligence Research and Development Strategic Plan:<br>2019 Update</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Human Formation",
           " <i>Federal agencies are giving priority to training and fellowship programs at all<br>levels to prepare the workforce with requisite AI R&D skills through<br>apprenticeships, skills programs, fellowships, and coursework in relevant<br>disciplines.</i>"
          ],
          [
           "Human Formation",
           " <i>OECD, Recommendation of the Council on Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " France",
           " Human Formation",
           " <i>Governments should work closely with stakeholders to prepare for the<br>transformation of the world of work and of society. They should empower people<br>to effectively use and interact with AI systems across the breadth of<br>applications, including by equipping them with the necessary skills.</i>"
          ],
          [
           "Human Formation",
           " <i>Oxford Munich Code of Conduct</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Human Formation",
           " <i>The Data Scientist will always strive to improve his/her competence and<br>technical excellence. For example, Data Scientists should be encouraged to<br>attend topical presentations, seminars, and courses covering new advances.</i>"
          ],
          [
           "Human Formation",
           " <i>Partnership on AI Tenets</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization",
           " Unspecified",
           " Unspecified",
           " Human Formation",
           " <i>We will educate and listen to the public and actively engage stakeholders to<br>seek their feedback on our focus, inform them of our work, and address their<br>questions.</i>"
          ],
          [
           "Human Formation",
           " <i>UNESCO Recommendation on the Ethics of Artificial Intelligence</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Human Formation",
           " <i>Public awareness and understanding of AI technologies and the value of data<br>should be promoted through open and accessible education, civic engagement,<br>digital skills and AI ethics training, media and information literacy and<br>training led jointly by governments, intergovernmental organizations, civil<br>society, academia, the media, community leaders and the private sector, and<br>considering the existing linguistic, social and cultural diversity, to ensure<br>effective public participation so that all members of society can make informed<br>decisions about their use of AI systems and be protected from undue influence.</i>"
          ],
          [
           "Human Formation",
           " <i>AI Principles: Recommendations on the Ethical Use of Artificial Intelligence by<br>the Department of Defense - Defense Innovation Board</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Human Formation",
           " <i>Recommendation - Each Service, Combatant Command, Office of the Secretary of<br>Defense Component, defense agency, and defense field activity should establish<br>programs for training and education that are relevant to their respective DoD<br>personnel in AI-related skills and knowledge.</i>"
          ],
          [
           "Human Formation",
           " <i>The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and<br>Mitigation</i>",
           " 2018",
           " Recommendation",
           " Academic, Non-profit Organization, Private Corporation",
           " Western Europe, North America ",
           " United Kingdom, United States of America",
           " Human Formation",
           " <i>Recommendation - AI researchers and the organizations that employ them are in a<br>unique position to shape the security landscape of the AI-enabled world. We<br>highlight the importance of education, ethical statements and standards,<br>framings, norms, and expectations.</i>"
          ],
          [
           "Human Formation",
           " <i>Policy guidance on AI for children</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution, International Organization",
           " Northern Europe, Intergovernmental Organization",
           " Finland, United Nations",
           " Human Formation",
           " <i>Support children’s development and well-being. Let AI help me develop to my full<br>potential. Prepare children for present and future developments in AI. If I am<br>well prepared now, I can contribute to responsible AI for the future.</i>"
          ],
          [
           "Human Formation",
           " <i>Ethics & Governance of Artificial Intelligence for Health</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Human Formation",
           " <i>Sustainability also requires governments and companies to address anticipated<br>disruptions in the workplace, including training for healthcare workers to adapt<br>to the use of AI systems, and potential job losses due to the use of automated<br>systems.</i>"
          ],
          [
           "Human Formation",
           " <i>ADP: Ethics in Artificial Intelligence</i>",
           " 2022",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Human Formation",
           " <i>We support skills development to accelerate the growth of a diverse workforce<br>that can develop and deploy the ML solutions of the future.</i>"
          ],
          [
           "Human Formation",
           " <i>IEEE Position Statement - Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Human Formation",
           " <i>To ensure that artificial intelligence serves the interests of society, IEEE<br>urges governments to adopt policies that support and fund AI education and<br>training to meet future workforce needs.</i>"
          ],
          [
           "Human Formation",
           " <i>Artificial intelligence - Common good as a benchmark, good work as a principle</i>",
           " 2019",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Human Formation",
           " <i>Whether as a private user or as an employee at work, the handling and mastering<br>of artificial intelligence processes require comprehensive qualification. This<br>competence has to be learned. Recommendation - Facilitate education and<br>training. All citizens are entitled to it.</i>"
          ],
          [
           "Human Formation",
           " <i>The Code of Ethics in the Field of Artificial Intelligence</i>",
           " 2022",
           " Recommendation",
           " Unspecified",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Human Formation",
           " <i>AI Actors are encouraged to follow practices adopted in the professional<br>community, maintain a proper level of professional competence required for safe<br>and effective work with AI systems and promote the improvement of the<br>professional competence of experts in the field of AI, i.e., within programs and<br>educational disciplines on AI ethics.</i>"
          ],
          [
           "Human Formation",
           " <i>Transparency and Trust in the Cognitive Era</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Human Formation",
           " <i>The economic and societal benefits of this new era will not be realized if the<br>human side of the equation is not supported. This is uniquely important with<br>cognitive technology, which augments human intelligence and expertise and works<br>collaboratively with humans. Therefore, IBM will work to help students, workers,<br>and citizens acquire the skills and knowledge to engage safely, securely, and<br>effectively in a relationship with cognitive systems, and to perform the new<br>kinds of work and jobs that will emerge in a cognitive economy.</i>"
          ],
          [
           "Human Formation",
           " <i>Decree of the President of the Russian Federation on the Development of<br>Artificial Intelligence in the Russian Federation</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Human Formation",
           " <i>The basic principles of the development and use of artificial intelligence<br>technologies, the observance of which is obligatory during the implementation of<br>this Strategy, include: the right to work, and affording individuals the<br>opportunity to obtain the knowledge and acquire the skills needed to<br>successfully adapt to the conditions of a digital economy.</i>"
          ]
         ],
         "hovertemplate": "<b>Document ID </b>=%{customdata[1]}<br><b>Year of Publication </b>=%{customdata[2]}<br><b>Reguation Type </b>=%{customdata[3]}<br><b>Institution Type </b>=%{customdata[4]}<br><b>World Region </b>=%{customdata[5]}<br><b>Country </b>=%{customdata[6]}<br><b>Principle </b>=%{customdata[7]}<br><b>Description </b>=%{customdata[8]}<extra></extra>",
         "legendgroup": "Human Formation",
         "marker": {
          "color": "#FECB52",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Human Formation",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          23.155176,
          20.923168,
          2.0204873,
          2.7924142,
          24.225641,
          13.452069,
          17.745398,
          5.31926,
          15.935252,
          20.447388,
          19.06062,
          22.396778,
          23.119719,
          23.005238,
          22.245045,
          22.311789,
          22.814909,
          24.678198,
          13.271175,
          -5.27358,
          14.147269,
          19.02111,
          10.345204,
          6.829651,
          24.414324,
          25.576859,
          4.4620757,
          15.392986,
          24.220974,
          23.326286,
          12.0478,
          -1.2972293,
          -0.11710828,
          2.1922357,
          2.5180247,
          14.115332,
          1.3682076,
          13.07379,
          19.424658,
          8.079349,
          21.366104,
          15.151853,
          4.5753407,
          21.427507,
          23.331741,
          18.294422,
          17.948086,
          7.653021,
          15.15983,
          21.329115,
          15.867403,
          21.999823,
          25.492208,
          2.893503,
          18.266401,
          -1.9432753,
          21.74227,
          17.761902,
          8.700045,
          18.048498,
          -0.6984969,
          17.406687,
          3.3425405,
          18.92554,
          19.561407,
          18.970228,
          15.909479,
          -5.4701533,
          5.347025,
          13.631525,
          20.205124,
          9.090049,
          5.090333,
          15.744549,
          9.776056,
          13.426039,
          15.340157,
          -4.6948147,
          7.1479464,
          3.5884233
         ],
         "y": [
          -11.146058,
          -8.492457,
          -21.32271,
          -11.271248,
          -5.116535,
          -11.889446,
          -13.786834,
          -19.189444,
          -12.374556,
          -6.778487,
          -13.972876,
          -3.004511,
          -14.720578,
          -16.318756,
          -0.2690913,
          -5.8837204,
          -8.418632,
          -4.121928,
          -15.471414,
          7.935355,
          -13.946172,
          17.148087,
          -12.219001,
          -18.921848,
          13.805601,
          -5.3071475,
          -18.628788,
          -12.222243,
          -5.4376464,
          -10.293821,
          -12.023649,
          -0.37741098,
          17.13366,
          -29.678028,
          -20.9043,
          -15.338266,
          -24.174992,
          -18.410837,
          -6.5183606,
          -12.131012,
          -4.991728,
          -9.550963,
          -9.481711,
          -14.990345,
          -3.0472474,
          -9.845952,
          -12.543254,
          3.5045369,
          -8.765633,
          -11.029171,
          -12.878195,
          -3.5438013,
          -4.794053,
          4.878964,
          -6.372302,
          9.509908,
          -14.939646,
          -6.8226733,
          -18.06038,
          -15.359351,
          -28.944233,
          -16.458996,
          -5.389768,
          -9.937703,
          -11.367256,
          -17.12992,
          -12.396839,
          23.214146,
          -17.493101,
          -9.77441,
          -19.117792,
          -10.756185,
          4.6016493,
          -12.826197,
          -20.943363,
          -10.728256,
          -16.391024,
          -5.6657166,
          -20.461332,
          -16.20803
         ],
         "z": [
          5.7976093,
          7.310081,
          -0.2173294,
          -6.9018645,
          8.950894,
          0.7121335,
          8.528705,
          11.631333,
          -0.9186513,
          10.03701,
          1.9925913,
          -0.72865033,
          7.590467,
          5.523742,
          3.139822,
          0.96887994,
          5.406824,
          10.972057,
          3.6219952,
          -2.1410267,
          2.5201662,
          3.3981981,
          1.3833463,
          3.8601117,
          4.858889,
          0.55426896,
          2.9569259,
          2.9907148,
          2.692368,
          2.8977833,
          2.0696616,
          -12.902363,
          -14.393015,
          1.7557846,
          -1.2232649,
          7.417116,
          9.671746,
          4.7060504,
          -1.6069114,
          7.914595,
          6.4018335,
          -0.23864847,
          26.80559,
          -2.7658124,
          1.7233611,
          0.6724661,
          -6.0889826,
          17.9241,
          3.4051378,
          8.023996,
          9.138969,
          8.567944,
          4.3350825,
          21.684252,
          4.1838193,
          -5.9318223,
          9.508399,
          5.1070004,
          7.4074645,
          3.2175775,
          0.78668064,
          5.47955,
          0.9374279,
          7.4506316,
          4.1401525,
          0.6342317,
          6.059861,
          -16.805613,
          -3.989512,
          -1.2124629,
          1.7788286,
          -12.763541,
          22.698902,
          12.622686,
          6.6229005,
          5.9717636,
          3.2765,
          5.5589366,
          11.808505,
          19.758074
         ]
        },
        {
         "customdata": [
          [
           "Intellectual Property",
           " <i>Responsible AI: A Global Policy Framework</i>",
           " 2021",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization, Professional Association",
           " North America",
           " United States of America",
           " Intellectual Property",
           " <i>Organisations that develop, make available, or use AI systems should seek to<br>strike a fair balance between benefiting from adequate protection for the<br>intellectual property rights for both the AI system and the AI output and<br>allowing availability for the wider societal benefit.</i>"
          ],
          [
           "Intellectual Property",
           " <i>Declaration of Ethical Principles for AI in Latin America (Declaración de<br>Principios Éticos para la IA de Latinoamérica)</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Latin America",
           " Unspecified",
           " Intellectual Property",
           " <i>Respect and protect intellectual property at all levels and to the highest<br>standard. All the actors involved in the creation will receive the corresponding<br>compensation for their work.</i>"
          ],
          [
           "Intellectual Property",
           " <i>Mid- to Long-Term Master Plan in Preparation for the Intelligent Information<br>Society Managing the Fourth Industrial Revolution</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " South Korea",
           " Intellectual Property",
           " <i>Secure the rights ad access to intellectual properties available worldwide<br>through R&D, M&A, and strategic alliances.</i>"
          ],
          [
           "Intellectual Property",
           " <i>Charlevoix Common Vision for the Future of Artificial Intelligence</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " International Organization",
           " Intergovernmental Organization",
           " G7",
           " Intellectual Property",
           " <i>We, the leaders of the G7, recognize the need for effective protection and<br>enforcement of intellectual property rights.</i>"
          ],
          [
           "Intellectual Property",
           " <i>Ethically Aligned Design: A Vision for Prioritizing Human Well-being with<br>Autonomous and Intelligent Systems, Version 2</i>",
           " 2017",
           " Recommendation",
           " Professional Association",
           " North America",
           " United States of America",
           " Intellectual Property",
           " <i>It is understood that specifics relating to algorithms or systems contain<br>intellectual property that cannot be released to the general public.<br>Nonetheless, standards providing oversight of the manufacturing process of<br>intelligent and autonomous technologies need to be created to avoid harm and<br>negative consequences of the use of these technologies.  It is understood that<br>specifics relating to algorithms or systems contain intellectual property that<br>cannot be released to the general public. Nonetheless, standards providing<br>oversight of the manufacturing process of intelligent and autonomous<br>technologies need to be created to avoid harm and negative consequences of the<br>use of these technologies.</i>"
          ],
          [
           "Intellectual Property",
           " <i>Report with recommendations to the Commission on Civil Law Rules on Robotics</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " European Union",
           " European Union",
           " Intellectual Property",
           " <i>The European Parliament calls on the Commission to support a horizontal and<br>technologically neutral approach to intellectual property applicable to the<br>various sectors in which robotics could be employed.</i>"
          ],
          [
           "Intellectual Property",
           " <i>Artificial Intelligence: Economic importance, social challenges, human<br>responsibility</i>",
           " 2017",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Intellectual Property",
           " <i>The protection of intellectual property is fundamental for technological<br>innovations and must be designed to promote innovations. It must not become a<br>stumbling block for investment and research. This requires a balanced approach<br>and careful consideration.</i>"
          ],
          [
           "Intellectual Property",
           " <i>ACM Code of Ethics and Professional Conduct</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Intellectual Property",
           " <i>A computing professional should respect the work required to produce new ideas,<br>inventions, creative works, and computing artifacts. Computing professionals<br>should therefore credit the creators of ideas, inventions, work, and artifacts,<br>and respect copyrights, patents, trade secrets, license agreements, and other<br>methods of protecting authors’ works.</i>"
          ],
          [
           "Intellectual Property",
           " <i>Augmented Intelligence in Health Care H-480.940</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Professional Association",
           " North America",
           " United States of America",
           " Intellectual Property",
           " <i>AMA will seek to explore the legal implications of health care AI, such as<br>issues of liability or intellectual property, and advocate for appropriate<br>professional and governmental oversight for safe, effective, and equitable use<br>of and access to health care AI.</i>"
          ],
          [
           "Intellectual Property",
           " <i>The Ethical Norms for the New Generation Artificial Intelligence, China</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Intellectual Property",
           " <i>Various activities of AI shall abide by the following fundamental ethical norms,<br>like any means that infringe on the intellectual property rights of other<br>subjects are forbidden.</i>"
          ],
          [
           "Intellectual Property",
           " <i>Discussion Paper: National Strategy for Artificial Intelligence</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " South Asia",
           " India",
           " Intellectual Property",
           " <i>Recommendation - Set up a task force, comprising jointly the Ministry of<br>Corporate Affairs and DIPP, to examine and issue appropriate modifications to<br>the IP (Intellectual Property) regulatory regime pertaining to AI.</i>"
          ],
          [
           "Intellectual Property",
           " <i>National Association of Insurance Commissioners (NAIC) Principles on Artificial<br>Intelligence (AI)</i>",
           " 2020",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Intellectual Property",
           " <i>AI actors must have the ability to protect the confidentiality of proprietary<br>algorithms, provided adherence to individual state laws and regulations in all<br>states where AI is deployed can be demonstrated.</i>"
          ],
          [
           "Intellectual Property",
           " <i>IEEE Position Statement - Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Intellectual Property",
           " <i>To ensure that artificial intelligence serves the interests of society, IEEE<br>urges governments to adopt policies that ensure that intellectual property<br>rights laws account for the unique characteristics of AI. AI potentially has the<br>capability to both infringe on intellectual property (IP) and to generate<br>outputs that are worthy of additional intellectual property protection.</i>"
          ],
          [
           "Intellectual Property",
           " <i>Transparency and Trust in the Cognitive Era</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Intellectual Property",
           " <i>The principle that clients own their own business models and intellectual<br>property and that they can use AI and cognitive systems to enhance the<br>advantages they have built, often through years of experience. We will work with<br>our clients to protect their data and insights and will encourage our clients,<br>partners, and industry colleagues to adopt similar practices.</i>"
          ]
         ],
         "hovertemplate": "<b>Document ID </b>=%{customdata[1]}<br><b>Year of Publication </b>=%{customdata[2]}<br><b>Reguation Type </b>=%{customdata[3]}<br><b>Institution Type </b>=%{customdata[4]}<br><b>World Region </b>=%{customdata[5]}<br><b>Country </b>=%{customdata[6]}<br><b>Principle </b>=%{customdata[7]}<br><b>Description </b>=%{customdata[8]}<extra></extra>",
         "legendgroup": "Intellectual Property",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Intellectual Property",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          -1.7211891,
          22.277945,
          24.505018,
          24.589666,
          -3.1242352,
          1.619205,
          23.825268,
          21.145247,
          -3.5407834,
          2.1944988,
          8.180664,
          -9.3308,
          7.6936836,
          -15.719014
         ],
         "y": [
          -0.963139,
          9.985023,
          8.092995,
          5.7266836,
          0.7730207,
          -6.9751873,
          9.683446,
          11.943032,
          -29.06681,
          -1.9215995,
          -4.3214574,
          1.1726129,
          -4.3501062,
          6.382356
         ],
         "z": [
          -6.9717255,
          -4.051471,
          -4.4739046,
          -7.270715,
          -8.363291,
          28.350103,
          -5.717433,
          -1.9372991,
          1.0771723,
          4.1698365,
          -10.130572,
          3.8417506,
          -7.0490546,
          -6.2641106
         ]
        },
        {
         "customdata": [
          [
           "Labor Rights",
           " <i>AI Policies and Principles</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Industrial Association",
           " North America",
           " United States of America",
           " Labor Rights",
           " <i>We should leverage traditional human-centered resources as well as new career<br>educational models and newly developed AI technologies to assist both the<br>existing workforce and future workforce in successfully navigating career<br>development and job transitions. Additionally, we must have PPPs that<br>significantly improve the delivery and effectiveness of lifelong career<br>education and learning, inclusive of workforce adjustment programs.</i>"
          ],
          [
           "Labor Rights",
           " <i>Responsible AI: A Global Policy Framework</i>",
           " 2021",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization, Professional Association",
           " North America",
           " United States of America",
           " Labor Rights",
           " <i>Organisations that implement AI systems in the workplace should provide<br>opportunities for affected employees to participate in the decision-making<br>process related to such implementation. Organizations that develop, deploy or<br>use AI systems that have an impact on employment should conduct a Responsible AI<br>Impact Assessment to determine the net effects of such implementation.</i>"
          ],
          [
           "Labor Rights",
           " <i>10 ethical guidelines for the digitalisation of companies (10 ethische<br>Leitlinien für die Digitalisierung von Unternehmen)</i>",
           " 2017",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Labor Rights",
           " <i>A good work-life balance is strived for; employees are not expected to be<br>available outside working hours. Their performance should not be evaluated<br>solely based on quantitative data. Machines should not make autonomous decisions<br>about employees. When using crowd working, fair and equitable working conditions<br>are offered. Employees are to be involved in decision-making and processes and<br>there is room for innovative suggestions.</i>"
          ],
          [
           "Labor Rights",
           " <i>Mid- to Long-Term Master Plan in Preparation for the Intelligent Information<br>Society Managing the Fourth Industrial Revolution</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " South Korea",
           " Labor Rights",
           " <i>It is important to tailor education, employment, and welfare services in<br>response to changes to ensure that all citizens can enjoy the benefits of the<br>intelligent information society. Provide workers hoping to make career<br>transitions with education and training on founding new technology businesses.</i>"
          ],
          [
           "Labor Rights",
           " <i>Charlevoix Common Vision for the Future of Artificial Intelligence</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " International Organization",
           " Intergovernmental Organization",
           " G7",
           " Labor Rights",
           " <i>We, the leaders of the G7, will seek to promote active labor market policies,<br>workforce development, and reskilling programs to develop the skills needed for<br>new jobs and for those at risk of being left out, including policies<br>specifically targeting the needs of women and underrepresented populations to<br>increase labor participation rates for those groups.</i>"
          ],
          [
           "Labor Rights",
           " <i>Toward a G20 Framework for Artificial Intelligence in the Workplace</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " Canada",
           " Labor Rights",
           " <i>Governments should plan for transition support as jobs disappear or are<br>significantly changed.</i>"
          ],
          [
           "Labor Rights",
           " <i>Digital ethics: a guide for professionals of the digital age</i>",
           " 2018",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " France",
           " Labor Rights",
           " <i>Forecast, with the help of teams specialising in forwardplanning and strategy,<br>the impacts of technological change on the company’s jobs and activities.<br>Include the impacts of automation and more broadly of digital technology in<br>strategic workforce planning.</i>"
          ],
          [
           "Labor Rights",
           " <i>The Future Computed – Artificial intelligence and its role in society</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Labor Rights",
           " <i>The public and private sectors should seek to meet the needs of people at all<br>stages of the workforce continuum — from students entering the workforce to<br>unemployed and underemployed workers, to people currently in the workforce who<br>need help gaining new skills to ensure their long-term employability. Businesses<br>should engage in discussions about the importance of next-generation versions of<br>unemployment insurance and employment services that take into account newer<br>models of work; anticipate that individuals may move in and out of the workforce<br>with greater frequency; promote greater labor mobility, and help workers gain<br>new skills and connect with new opportunities.</i>"
          ],
          [
           "Labor Rights",
           " <i>For a meaningful Artificial Intelligence - Towards a French and European<br>strategy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Labor Rights",
           " <i>The labor market is undergoing vast changes, but it is not yet fully equipped to<br>address them. Legislation could be implemented to deal with working conditions<br>at a time of increasing automation in order to factor in new risks.</i>"
          ],
          [
           "Labor Rights",
           " <i>It’s Time to Do Something: Mitigating the Negative Impacts of Computing Through<br>a Change to the Peer Review Process</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " Eastern Asia, Central Europe",
           " Turkey, Turkey",
           " Labor Rights",
           " <i>Under our recommendations, researchers engaged in developing crowd work<br>frameworks should find ways to engineer its framework such that negative<br>externalities (incentivizing very low pay) are structurally mitigated.<br>Alternatively or additionally, they should advocate for minimum wage laws to be<br>adapted to a contingent labor context.</i>"
          ],
          [
           "Labor Rights",
           " <i>Business Ethics and Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " Western Europe",
           " United Kingdom",
           " Labor Rights",
           " <i>Companies must look at the best approaches to minimize the potential disruption<br>of jobs while innovation and competition are still encouraged. AI companies must<br>be conscious of how AI systems will affect both employees and customers since<br>there is an existing fear that AI will automate many jobs.</i>"
          ],
          [
           "Labor Rights",
           " <i>Model AI Governance Framework</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " Southeast Asia",
           " Singapore",
           " Labor Rights",
           " <i>This Guide suggests that organizations can consider adopting a practical and<br>humancentric approach in redesigning jobs when implementing AI so as to augment<br>their employees’ cognitive capacity. Although there are certain tasks that could<br>be fully automated by AI, it is important to avoid deskilling humans and<br>recognize the value of retaining human experience.</i>"
          ],
          [
           "Labor Rights",
           " <i>G20 Ministerial Statement on Trade and Digital Economy</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " G20",
           " Labor Rights",
           " <i>AI actors should respect internationally recognized labor rights.</i>"
          ],
          [
           "Labor Rights",
           " <i>AI 4People 's Ethical Framework for a Good AI Society: Opportunities, Risks,<br>Principles, and Recommendations</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Labor Rights",
           " <i>Stakeholders should develop legal instruments and contractual templates to lay<br>the foundation for a smooth and rewarding human-machine collaboration in the<br>work environment.</i>"
          ],
          [
           "Labor Rights",
           " <i>Ethical Guidelines of the German Informatics Society</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization, Professional Association",
           " Western Europe",
           " Germany",
           " Labor Rights",
           " <i>GI members are active proponents of socially equitable contractual agreements<br>concerning terms of employment, inclusive of opportunities for professional<br>development and shared governance.</i>"
          ],
          [
           "Labor Rights",
           " <i>Ethically Aligned Design: A Vision for Prioritizing Human Well-being with<br>Autonomous and Intelligent Systems, Version 2</i>",
           " 2017",
           " Recommendation",
           " Professional Association",
           " North America",
           " United States of America",
           " Labor Rights",
           " <i>Make sure workers can improve their adaptability to fast technological changes<br>by providing them with adequate training programs. Those training programs could<br>be available to any worker with special attention to low-skilled workforce<br>members. Those programs can be private (sponsored by the employer) or public<br>(offered freely through specific public channels and policies), and they should<br>be open while the worker is in-between jobs or still employed.</i>"
          ],
          [
           "Labor Rights",
           " <i>Artificial intelligence and the work of tomorrow (Künstliche Intelligenz und die<br>Arbeit von Morgen)</i>",
           " 2019",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Labor Rights",
           " <i>The aim should be to formulate the requirements for the design of AI for good<br>work and to identify ways of implementing it. After all, machine learning is not<br>just about the automatic elimination of jobs, but about a broad spectrum of<br>possibilities for organizing work more intelligently. The goal should be to<br>promote AI-based assistance systems to increase the quality of work and create<br>new, high-value employment opportunities in conjunction with the appropriate<br>education and training.</i>"
          ],
          [
           "Labor Rights",
           " <i>Beijing AI Principles</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Eastern Asia",
           " China",
           " Labor Rights",
           " <i>An inclusive attitude should be taken towards the potential impact of AI on<br>human employment. A cautious attitude should be taken towards the promotion of<br>AI applications that may have huge impacts on human employment. Explorations on<br>Human-AI coordination and new forms of work that would give full play to human<br>advantages and characteristics should be encouraged.</i>"
          ],
          [
           "Labor Rights",
           " <i>Responsible Artificial Intelligence in the Government of Canada (whitepaper)</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Labor Rights",
           " <i>AI systems should be deployed in a manner that minimizes negative impact to<br>employees where possible, and should, where feasible, be created alongside the<br>employees that will work with them. Federal institutions should also be reminded<br>that some collective bargaining agreements contain specific sections on<br>workforce adjustment due to technological change. To ensure that these<br>requirements are honored, TBS recommends that unions and non-represented staff<br>alike are engaged early in the planning phases. Staff and unions will be useful<br>partners to help automate processes in a way that is both most useful to the<br>user as well as least affecting of positions.</i>"
          ],
          [
           "Labor Rights",
           " <i>Artificial Intelligence: Australia’s Ethics Framework - A Discussion Paper</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Oceania",
           " Australia",
           " Labor Rights",
           " <i>An ethical approach to widespread AI-based automation of tasks performed by<br>human workers requires helping the workers transition smoothly and proactively<br>into new jobs and new careers.</i>"
          ],
          [
           "Labor Rights",
           " <i>AI Now Report 2018</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Labor Rights",
           " <i>Technology companies need to protect workers’ ability to organize, whistleblow,<br>and make ethical choices about what projects they work on. This should include<br>clear policies accommodating and protecting conscientious objectors, ensuring<br>workers the right to know what they are working on, and the ability to abstain<br>from such work without retaliation or retribution. Workers raising ethical<br>concerns must also be protected, as should whistleblowing in the public<br>interest. More funding and support are needed for litigation, labor organizing,<br>and community participation on AI accountability issues. The people most at risk<br>of harm from AI systems are often those least able to contest the outcomes. We<br>need increased support for robust mechanisms of legal redress and civic<br>participation.</i>"
          ],
          [
           "Labor Rights",
           " <i>Report on Artificial Intelligence and Human Society</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Labor Rights",
           " <i>Individuals changing their work style and updating their abilities propose to<br>harmonize each person’s abilities with a creative job/task. These changes also<br>require that companies reconsider their decision-making techniques and staff<br>(re)assignment to take advantage of work flexibility. At the government level,<br>combining educational and employment policies is one of the effective procedures<br>for mobilizing labor, revitalizing the economy, and preventing economic<br>disparities.</i>"
          ],
          [
           "Labor Rights",
           " <i>Report with recommendations to the Commission on Civil Law Rules on Robotics</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " European Union",
           " European Union",
           " Labor Rights",
           " <i>The European Parliament calls on the Commission to start analyzing and<br>monitoring medium- and long-term job trends more closely, with a special focus<br>on the creation, displacement, and loss of jobs in the different fields/areas of<br>qualification in order to know in which fields jobs are being created and those<br>in which jobs are being lost as a result of the increased use of robots.</i>"
          ],
          [
           "Labor Rights",
           " <i>Fairwork Principles</i>",
           " Unspecified",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany, United Kingdom",
           " Labor Rights",
           " <i>Workers, irrespective of their employment classification, should earn a decent<br>income in their home jurisdiction after taking account of work-related costs and<br>active hours worked. They should be paid on time, and for all work completed.<br>Platforms should have policies in place to protect workers from foundational<br>risks arising from the processes of work and should take proactive measures to<br>protect and promote the health and safety of workers. Terms and conditions<br>should be transparent, concise, and always accessible to workers. The party<br>contracting with the worker must be subject to local law and must be identified<br>in the contract. Workers are notified of proposed changes in a reasonable<br>timeframe before changes come into effect. The contract is free of clauses that<br>unreasonably exclude liability on the part of the platform, and which prevent<br>workers from seeking redress for grievances. Contracts should be consistent with<br>the terms of workers’ engagement on the platform. There should be a documented<br>due process for decisions affecting workers. Workers must have the ability to<br>appeal decisions affecting them, such as disciplinary actions and deactivation,<br>and be informed of the reasons behind those decisions. The use of algorithms is<br>transparent and results in equitable outcomes for workers. There should be an<br>identifiable and documented policy that ensures equity in the way workers are<br>managed on a platform (for example, in the hiring, disciplining, or firing of<br>workers). Platforms should provide a documented process through which worker<br>voice can be expressed. Irrespective of their employment classification, workers<br>have the right to organize in collective bodies, and platforms should be<br>prepared to cooperate and negotiate with them.</i>"
          ],
          [
           "Labor Rights",
           " <i>Report of COMEST on robotics ethics</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Labor Rights",
           " <i>Robots will increasingly displace humans in a wide range of areas and so lead to<br>a significant reduction in job opportunities in certain sectors. It will also<br>give rise to new job opportunities. States, professional organizations, and<br>educational institutions should therefore consider the implications of this,<br>paying particular attention to those sections of society likely to be most<br>vulnerable to the changes, and make appropriate provisions for retraining and<br>retooling of the workforce to enable the potential advantages to be realized.</i>"
          ],
          [
           "Labor Rights",
           " <i>Top 10 Principles for Ethical Artificial Intelligence</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " Switzerland",
           " Labor Rights",
           " <i>In a world where the casualization or individualization of work is rising, all<br>workers in all forms of work must have the same, strong social and fundamental<br>rights. All AI systems must include a check and balance on whether their<br>deployment and augmentation go hand in hand with workers’ rights as laid out in<br>human rights laws, ILO conventions, and collective agreements. An algorithm<br>“8798” reflecting the core ILO conventions 87 and 98 that are built into the<br>system could serve that very purpose. Upon failure, the system must be shut<br>down.</i>"
          ],
          [
           "Labor Rights",
           " <i>Montréal declaration for a responsible development of artificial intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " Canada",
           " Labor Rights",
           " <i>Industrial AI development must be compatible with acceptable working conditions<br>at every step of their life cycle, from natural resources extraction to<br>recycling, including data processing.</i>"
          ],
          [
           "Labor Rights",
           " <i>fAIr LAC: Responsible and Widespread Adoption of Artificial Intelligence in<br>Latin America and the Caribbean</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Latin America",
           " Unspecified",
           " Labor Rights",
           " <i>AI actors should respect the rule of law, human rights, and democratic values,<br>throughout the AI system lifecycle. These include labor rights.</i>"
          ],
          [
           "Labor Rights",
           " <i>WLiAI Report 2019: 10 Principles of Responsible AI</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " United Kingdom",
           " Labor Rights",
           " <i>Recommendation - Where no redeployment is possible, compel companies to make a<br>contribution towards a digital skills fund for those employees.</i>"
          ],
          [
           "Labor Rights",
           " <i>Work in the age of artificial intelligence: Four perspectives on the economy,<br>employment, skills and ethics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Finland",
           " Labor Rights",
           " <i>When new technologies are introduced, an effective labor market will be more<br>important than ever. Measures are needed to promote the transition of those who<br>are employed to tasks and jobs that are a better match with their skills and<br>more productive, in a manner experienced as secure. Change should appear more<br>attractive than preserving the status quo. This way, the nation’s skills can be<br>used better, and vacancies will also become available for new entrants in the<br>labor market. In order to promote labor mobility, employment services should<br>also be offered to the employed. Concrete measures could include a notification<br>service of suitable vacancies implemented using artificial intelligence and<br>directing employment services to not only the unemployed but also those already<br>in employment. Complimentary income transfers or pay subsidies could also be<br>used more, as is done in Sweden.</i>"
          ],
          [
           "Labor Rights",
           " <i>Discussion Paper: National Strategy for Artificial Intelligence</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " South Asia",
           " India",
           " Labor Rights",
           " <i>For addressing issues relating to skilling, a two-pronged approach is warranted,<br>one set of interventions aimed at the workforce and the second for the students.<br>Re-skilling of the current workforce will require integration with relevant<br>existing skilling initiatives, the building of new platforms that can enable<br>improved learning, and novel methods of allowing large-scale employment<br>generation through the promotion of AI.</i>"
          ],
          [
           "Labor Rights",
           " <i>The National Artificial Intelligence Research and Development Strategic Plan:<br>2019 Update</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Labor Rights",
           " <i>Better understand the national AI R&D workforce needs. Improve opportunities for<br>R&D workforce development to strategically foster an AI-ready workforce.</i>"
          ],
          [
           "Labor Rights",
           " <i>OECD, Recommendation of the Council on Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " France",
           " Labor Rights",
           " <i>AI actors should respect the rule of law, human rights, and democratic values,<br>throughout the AI system lifecycle. These include freedom, dignity and autonomy,<br>privacy and data protection, nondiscrimination and equality, diversity,<br>fairness, social justice, and internationally recognized labor rights.<br>Governments should take steps, including through social dialogue, to ensure a<br>fair transition for workers as AI is deployed, such as through training programs<br>along with the working life, support for those affected by displacement, and<br>access to new opportunities in the labor market. Governments should also work<br>closely with stakeholders to promote the responsible use of AI at work, enhance<br>the safety of workers and the quality of jobs, foster entrepreneurship and<br>productivity, and aim to ensure that the benefits from AI are broadly and fairly<br>shared.</i>"
          ],
          [
           "Labor Rights",
           " <i>UNESCO Recommendation on the Ethics of Artificial Intelligence</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Labor Rights",
           " <i>the Member States should support collaboration agreements among governments,<br>academic institutions, vocational education and training institutions, industry,<br>workers’ organizations, and civil society to bridge the gap in skillset<br>requirements to align training programs and strategies with the implications of<br>the future of work and the needs of industry, including small and medium<br>enterprises. Member States should work with private sector companies, civil<br>society organizations, and other stakeholders, including workers and unions to<br>ensure a fair transition for at-risk employees.</i>"
          ],
          [
           "Labor Rights",
           " <i>Ethics & Governance of Artificial Intelligence for Health</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Labor Rights",
           " <i>Sustainability also requires governments and companies to address anticipated<br>disruptions in the workplace, including training for healthcare workers to adapt<br>to the use of AI systems, and potential job losses due to the use of automated<br>systems.</i>"
          ],
          [
           "Labor Rights",
           " <i>Ethical ML Institute Responsible Machine Learning Principles</i>",
           " Unspecified",
           " Recommendation",
           " Academic",
           " Western Europe",
           " United Kingdom",
           " Labor Rights",
           " <i>We should look beyond the technology itself, and have the initiative to support<br>the necessary stakeholders so they can develop a change-management strategy when<br>rolling out the technology. Technologists should focus on building processes &<br>methods to identify & document the inherent bias in the data, features, and<br>inference results, and subsequently the implications of this bias. I commit to<br>identifying and documenting relevant information so that business change<br>processes can be developed to mitigate the impact of workers being automated.</i>"
          ],
          [
           "Labor Rights",
           " <i>IEEE Position Statement - Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Labor Rights",
           " <i>To ensure that artificial intelligence serves the interests of society, IEEE<br>urges governments to adopt policies that support and fund retraining<br>opportunities for people whose jobs are affected by AI. AI is disrupting<br>existing industries, often resulting in a reduction in jobs or economic strength<br>in these industries. There is a need to design educational, training, and<br>development strategies for jobs that are changed as a result of AI, including<br>jobs that can take advantage of the division of labor between humans and<br>machines.</i>"
          ],
          [
           "Labor Rights",
           " <i>Artificial intelligence - Common good as a benchmark, good work as a principle</i>",
           " 2019",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Labor Rights",
           " <i>It is, therefore, necessary to clarify politically, economically and in terms of<br>tax law how future profits will be in the field of artificial intelligence are<br>recorded and disclosed to promote employment redistribution into areas of need<br>such as the socially necessary service areas. Realizing health, care, education,<br>and mobility. This also requires control mechanisms to develop the economic<br>gains through productivity gains in the field. Let artificial intelligence flow<br>into the strengthening of social security systems.</i>"
          ],
          [
           "Labor Rights",
           " <i>Decree of the President of the Russian Federation on the Development of<br>Artificial Intelligence in the Russian Federation</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Labor Rights",
           " <i>The basic principles of the development and use of artificial intelligence<br>technologies, the observance of which is obligatory during the implementation of<br>this Strategy, include: the right to work, and affording individuals the<br>opportunity to obtain the knowledge and acquire the skills needed to<br>successfully adapt to the conditions of a digital economy.</i>"
          ]
         ],
         "hovertemplate": "<b>Document ID </b>=%{customdata[1]}<br><b>Year of Publication </b>=%{customdata[2]}<br><b>Reguation Type </b>=%{customdata[3]}<br><b>Institution Type </b>=%{customdata[4]}<br><b>World Region </b>=%{customdata[5]}<br><b>Country </b>=%{customdata[6]}<br><b>Principle </b>=%{customdata[7]}<br><b>Description </b>=%{customdata[8]}<extra></extra>",
         "legendgroup": "Labor Rights",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Labor Rights",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          19.610159,
          4.6185284,
          27.034666,
          20.919083,
          21.830822,
          20.33059,
          16.638527,
          23.072712,
          19.022522,
          25.962566,
          13.138002,
          10.78028,
          -3.947512,
          9.774092,
          22.649376,
          22.870337,
          10.595719,
          10.791358,
          14.376246,
          13.444411,
          21.68209,
          23.198284,
          3.3015714,
          25.093708,
          16.295527,
          24.50597,
          9.321189,
          -1.3803694,
          19.72263,
          20.892117,
          20.718262,
          17.179607,
          0.56413436,
          25.19909,
          15.300765,
          1.0906174,
          13.861023,
          13.162578,
          3.4755352
         ],
         "y": [
          -13.399543,
          -7.326692,
          -8.920493,
          -8.028088,
          -14.5593605,
          -10.252569,
          -16.440819,
          -12.410682,
          -12.822313,
          -10.90194,
          -13.40927,
          -14.930196,
          5.1155586,
          -14.491461,
          12.647703,
          -12.777463,
          -15.927164,
          -12.475669,
          -17.476448,
          -14.828692,
          -10.733352,
          -9.931751,
          -10.47314,
          -8.621774,
          -10.4902,
          -6.668546,
          -9.524664,
          5.284751,
          -17.56844,
          -11.165002,
          -11.803005,
          -17.08179,
          3.085231,
          -10.7703,
          -11.793732,
          9.572603,
          -10.879069,
          -8.934659,
          -16.75097
         ],
         "z": [
          6.701099,
          -16.469343,
          -5.9825077,
          9.802396,
          13.271117,
          13.056822,
          12.485805,
          11.015399,
          10.958808,
          -5.8527856,
          11.130926,
          9.2482195,
          2.6735623,
          4.5276494,
          8.819916,
          8.4992,
          13.522916,
          10.177482,
          11.525789,
          8.305616,
          -9.413068,
          10.40734,
          26.51863,
          -8.204666,
          9.705718,
          -8.180179,
          16.034788,
          3.8641222,
          7.492855,
          10.719699,
          4.1345882,
          -0.6182435,
          2.032373,
          8.094048,
          12.800326,
          -14.153923,
          7.601619,
          9.620344,
          18.601503
         ]
        },
        {
         "customdata": [
          [
           "Privacy",
           " <i>Declaration on Ethics and Data Protection in Artifical Intelligence</i>",
           " 2018",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " Belgium",
           " Privacy",
           " <i>privacy and data protection are increasingly challenged by the development of<br>artificial intelligence and this development should be complemented by ethical<br>and human rights considerations.</i>"
          ],
          [
           "Privacy",
           " <i>Intel’s AI Privacy Policy White Paper: Protecting individuals’ privacy and data<br>in the artificial intelligence world</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Privacy",
           " <i>Privacy requires that data is both reliable and that it will not be used to harm<br>individuals. Organizations should embrace risk-based accountability approaches,<br>putting in place technical (privacy-by-design) or organizational measures<br>(product development lifecycles and ethics review boards) to minimize privacy<br>risks in AI.</i>"
          ],
          [
           "Privacy",
           " <i>AI Policies and Principles</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Industrial Association",
           " North America",
           " United States of America",
           " Privacy",
           " <i>Since AI flourishing depends on how robust users trust the systems, AI systems<br>should be designed in ways that protect the privacy of individuals by<br>anonymizing data, re-identification, or aggregation to ensure the protection of<br>personal information.</i>"
          ],
          [
           "Privacy",
           " <i>Artificial Intelligence and Machine Learning: Policy Paper</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Privacy",
           " <i>AI systems must be data responsible. They should use only what they need and<br>delete it when it is no longer needed (“data minimization”). They should encrypt<br>data in transit and at rest, and restrict access to authorized persons (“access<br>control”). AI systems should only collect, use, share and store data following<br>privacy and personal data laws and best practices.</i>"
          ],
          [
           "Privacy",
           " <i>Everyday Ethics for Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Privacy",
           " <i>AI companies must be guided by national and international policies and laws on<br>privacy and rights. Therefore, AI must be designed to protect users’ data and<br>preserve the user’s power over access and uses in these places.</i>"
          ],
          [
           "Privacy",
           " <i>Icelander Institute for Intelligent Machine Ethics Policy</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization",
           " Northern Europe",
           " Iceland",
           " Privacy",
           " <i>One of the ethical policies of IIIM is to ensure that its project does not cause<br>bodily or emotional distress to any person by invading their privacy or<br>violating their human rights as stipulated in the United Nations Declaration of<br>Human Rights.</i>"
          ],
          [
           "Privacy",
           " <i>Responsible AI: A Global Policy Framework</i>",
           " 2021",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization, Professional Association",
           " North America",
           " United States of America",
           " Privacy",
           " <i>Organisations that develop, make available, or use AI systems and any national<br>laws that regulate such use shall endeavor to ensure that AI systems are<br>compliant with privacy norms and regulations, taking into account the unique<br>characteristics of AI systems, and the evolution of standards on privacy.</i>"
          ],
          [
           "Privacy",
           " <i>Trusted AI</i>",
           " Unspecified",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Privacy",
           " <i>In IBM, AI systems are designed to protect themselves against attacks and also<br>created to adhere to privacy requirements. The IBM AI systems are designed using<br>mathematical noise to preserve individuals’ privacy and confidentiality.</i>"
          ],
          [
           "Privacy",
           " <i>The Japanese Society for Artificial Intelligence Ethical Guidelines</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Academic",
           " Eastern Asia",
           " Japan",
           " Privacy",
           " <i>Members of the JSAI will respect the privacy of others concerning their research<br>and the development of AI.</i>"
          ],
          [
           "Privacy",
           " <i>Hambach Declaration on Artificial Intelligence(Hambacher Erklärung zur<br>Künstlichen Intelligenz)</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Germany",
           " Privacy",
           " <i>For the development and use of AI systems in which personal data are processed,<br>the GDPR contains important legal requirements.</i>"
          ],
          [
           "Privacy",
           " <i>AI at Google: our principles</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Privacy",
           " <i>We will incorporate our privacy principles in the development and use of our AI<br>technologies. We will give opportunity for notice and consent, encourage<br>architectures with privacy safeguards, and provide appropriate transparency and<br>control over the use of data.</i>"
          ],
          [
           "Privacy",
           " <i>10 ethical guidelines for the digitalisation of companies (10 ethische<br>Leitlinien für die Digitalisierung von Unternehmen)</i>",
           " 2017",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Privacy",
           " <i>Privacy shall be protected. All data of customers, employees, as well as third<br>parties, shall be handled with care and to protect their privacy.</i>"
          ],
          [
           "Privacy",
           " <i>Ethics Guidelines for Trustworthy AI</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Privacy",
           " <i>AI systems must guarantee privacy and data protection throughout a system’s<br>entire lifecycle. This includes the information initially provided by the user,<br>as well as the information generated about the user throughout their interaction<br>with the system (e.g. outputs that the AI system generated for specific users or<br>how users responded to particular recommendations).</i>"
          ],
          [
           "Privacy",
           " <i>Declaration of Ethical Principles for AI in Latin America (Declaración de<br>Principios Éticos para la IA de Latinoamérica)</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Latin America",
           " Unspecified",
           " Privacy",
           " <i>Protect the right of each person regarding the privacy of their data (sensitive<br>personal information) and in the same way give an ethical use to the information<br>of each individual, always with the prior consent of its owner. Consent will be<br>required from each person about the use of the generation of new data created<br>from the AI.</i>"
          ],
          [
           "Privacy",
           " <i>IBM’s Principles for Trust and Transparency</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Privacy",
           " <i>IBM is fully committed to protecting the privacy of our client's data, which is<br>fundamental in a data-driven society. IBM has not provided client data to any<br>government agency under any surveillance program involving bulk collection of<br>content or metadata.</i>"
          ],
          [
           "Privacy",
           " <i>China’s Artificial Intelligence Industry Alliance Self-discipline Convention</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Privacy",
           " <i>Adhere to the principles of legality, legitimacy, and necessity when collecting<br>and using personal information. Strengthen privacy protections for special data<br>subjects such as minors. Strengthen technical methods, ensure data security, and<br>be on guard against risks such as data leaks.</i>"
          ],
          [
           "Privacy",
           " <i>Mid- to Long-Term Master Plan in Preparation for the Intelligent Information<br>Society Managing the Fourth Industrial Revolution</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " South Korea",
           " Privacy",
           " <i>Find and differentiate measures to support the distribution and utilization of<br>data under data type.</i>"
          ],
          [
           "Privacy",
           " <i>Charlevoix Common Vision for the Future of Artificial Intelligence</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " International Organization",
           " Intergovernmental Organization",
           " G7",
           " Privacy",
           " <i>We, the leaders of the G7, commit to safeguarding privacy, ensuring AI design<br>and implementation respect, and promoting applicable frameworks for privacy and<br>personal data protection.</i>"
          ],
          [
           "Privacy",
           " <i>Governance Recommendations - Use of Artificial Intelligence by Public<br>Authorities</i>",
           " 2021",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Latin America",
           " Brazil",
           " Privacy",
           " <i>People, as data subjects, need to be clearly informed of the purpose of personal<br>data collection. It is important to understand how these government bodies store<br>and use their data on their AI tools. Otherwise, this type of service is not<br>compliant with principles established by the General Law of Personal Data<br>Protection.</i>"
          ],
          [
           "Privacy",
           " <i>Next-Generation AI Governance Principles - Develop responsible artificial<br>intelligence</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Privacy",
           " <i>AI development should respect and protect personal privacy and fully protect the<br>individual's right to know and right to choose. In personal information<br>collection, storage, processing, use, and other aspects, boundaries should be<br>set and standards should be established. Improve personal data authorization and<br>revocation mechanisms to combat any theft, tampering, disclosure, or other<br>illegal collection or use of personal information.</i>"
          ],
          [
           "Privacy",
           " <i>Draft AI R&D Guidelines for International Discussions</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Privacy",
           " <i>Developers of AI systems must ensure that AI systems will not and do not<br>infringe the privacy of AI users. The privacy referred to in this document is<br>spatial: peace of personal life, personal data, and secrecy of communications.<br>To ensure this, developers must always ensure that they follow international<br>guidelines on privacy, such as the \"OECD Guidelines on the Protection of Privacy<br>and Transborder Flows of Personal Data”.</i>"
          ],
          [
           "Privacy",
           " <i>Responsible bots: 10 guidelines for developers of conversational AI</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Privacy",
           " <i>Ensure your bot respects user privacy; Inform users upfront about the data that<br>is collected and how it is used and obtain their consent beforehand; Collect no<br>more personal data than you need, limit access to it, and store it for no longer<br>than needed; Provide privacy-protecting user controls; Obtain legal and privacy<br>review.</i>"
          ],
          [
           "Privacy",
           " <i>Facial recognition: It’s time for action</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Privacy",
           " <i>The law should require that entities that use facial recognition to identify<br>consumers place conspicuous notice that clearly conveys that these services are<br>being used. The law should specify that consumers consent to the use of facial<br>recognition services when they enter premises or proceed to use online services<br>that have this type of clear notice. Legislation should limit the use of facial<br>recognition technology for monitor and surveillance of specified individuals.</i>"
          ],
          [
           "Privacy",
           " <i>Toward a G20 Framework for Artificial Intelligence in the Workplace</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " Canada",
           " Privacy",
           " <i>Data should be anonymized where possible. Big data collection and AI must comply<br>with laws that regulate privacy and data collection, use, and storage. AI data<br>and algorithms must be protected against theft, and employers or AI providers<br>need to inform employees, customers, and partners of any breach of information,<br>in particular PII (personally identifiable information), as soon as possible.</i>"
          ],
          [
           "Privacy",
           " <i>Digital ethics: a guide for professionals of the digital age</i>",
           " 2018",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " France",
           " Privacy",
           " <i>Adopt a privacy by design approach, following the requirements of the GDPR: this<br>means building the protection of personal data into products and services by<br>design, but also by default (notably by abiding by the data minimization<br>principle introduced by the GDPR); this is also a cultural challenge because<br>this concept needs to be factored into a project early on.</i>"
          ],
          [
           "Privacy",
           " <i>The Future Computed – Artificial intelligence and its role in society</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Privacy",
           " <i>AI systems should be secure and respect privacy.AI systems should be designed so<br>that private information is used following privacy standards and protected from<br>bad actors who might seek to steal private information or inflict harm.</i>"
          ],
          [
           "Privacy",
           " <i>How Can Humans Keep The Upper Hand? The Ethical Matters Raised By Algorithms And<br>Artificial Intelligence</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Privacy",
           " <i>Data processing shall be at the service of every citizen. It shall develop in<br>the context of international cooperation. It shall infringe neither human<br>identity, nor the rights of man, nor privacy, nor individual or public<br>liberties.</i>"
          ],
          [
           "Privacy",
           " <i>Responsible AI - Microsoft AI principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Privacy",
           " <i>AI systems should be secure and respect privacy.</i>"
          ],
          [
           "Privacy",
           " <i>For a meaningful Artificial Intelligence - Towards a French and European<br>strategy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Privacy",
           " <i>It is recommended that aspects relating to data ethics, privacy, and data<br>protection form an integral part of artificial intelligence courses.</i>"
          ],
          [
           "Privacy",
           " <i>Digital Technology and Healthcare which ethical issues for which regulations?</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " France",
           " Privacy",
           " <i>It would therefore be good practice, as far as possible, to have a consent<br>procedure that enables people to authorize the sharing of their data in the<br>knowledge of how they will be shared (sharing plan), rather than why (by whom<br>and for what research). It is also important to acquire the scientific,<br>technical, and regulatory resources to control the risks of people being re-<br>identified from databases in which direct identifying information has been<br>removed and to support the development of ethical tools for the regulation of<br>access to sensitive data.</i>"
          ],
          [
           "Privacy",
           " <i>Business Ethics and Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " Western Europe",
           " United Kingdom",
           " Privacy",
           " <i>AI designers and companies must ensure that they adhere to ethical guidelines<br>relating to the protection and respect of privacy. They must consult documents<br>that stipulate personal data protection, such as the General Data Protection<br>Regulation (GDPR).</i>"
          ],
          [
           "Privacy",
           " <i>Big Data, Artificial Intelligence, Machine Learning, and Data Protection</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Privacy",
           " <i>It should also be noted that under the GDPR if a data controller is relying on<br>legitimate interests, it will have to explain what these are in its privacy<br>notice. Data protection legislation embodies the concept of data minimisation –<br>that is, organisations should minimise the amount of data they collect and<br>process, and the length of time they keep the data.</i>"
          ],
          [
           "Privacy",
           " <i>Model AI Governance Framework</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " Southeast Asia",
           " Singapore",
           " Privacy",
           " <i>Adopting this voluntary Model Framework will not absolve organizations from<br>compliance with current laws and regulations. However, as this is an<br>accountability-based framework, adopting it will assist organizations in<br>demonstrating that they had implemented accountability-based practices in data<br>management and protection, e.g., the PDPA and OECD Privacy Principles.</i>"
          ],
          [
           "Privacy",
           " <i>Asilomar AI Principles</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Privacy",
           " <i>People should have the right to access, manage and control the data they<br>generate, given AI systems’ power to analyze and utilize that data.</i>"
          ],
          [
           "Privacy",
           " <i>G20 Ministerial Statement on Trade and Digital Economy</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " G20",
           " Privacy",
           " <i>AI actors should respect privacy and data protection.</i>"
          ],
          [
           "Privacy",
           " <i>  Philips Data Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Netherlands",
           " Privacy",
           " <i>We handle all personal data with integrity in compliance with all applicable<br>privacy regulations of the countries in which we operate. We adhere to the<br>Philips Code of Conduct – our binding corporate rules – that govern data<br>transfers and processing within our company. When our business partners process<br>personal data on our behalf, we ensure that they comply with our security and<br>privacy requirements.</i>"
          ],
          [
           "Privacy",
           " <i>AI 4People 's Ethical Framework for a Good AI Society: Opportunities, Risks,<br>Principles, and Recommendations</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Privacy",
           " <i>AI technology must be in line with ensuring the prevention of infringements on<br>personal privacy</i>"
          ],
          [
           "Privacy",
           " <i>AI & Data Topical Guide Series</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Southern Africa",
           " South Africa",
           " Privacy",
           " <i>Rapidly seek to bring into effect the Protection of Personal Information Act and<br>equip the Information Regulator with all necessary resources to provide<br>effective oversight over the processing of personal data in South Africa.</i>"
          ],
          [
           "Privacy",
           " <i>Rome Call for AI Ethics</i>",
           " 2020",
           " Recommendation",
           " Religious Institution",
           " Southern Europe",
           " Vatican City State",
           " Privacy",
           " <i>AI systems must work securely and respect the privacy of users.</i>"
          ],
          [
           "Privacy",
           " <i>Ethically Aligned Design: A Vision for Prioritizing Human Well-being with<br>Autonomous and Intelligent Systems, Version 2</i>",
           " 2017",
           " Recommendation",
           " Professional Association",
           " North America",
           " United States of America",
           " Privacy",
           " <i>The ethics of creating secret and proprietary A/IS from people’s personally<br>identifiable information (PII) need to be considered based on the potential<br>impact on the human condition. To preserve human dignity, policies, protections,<br>and practices must provide all individuals the same agency and control over<br>their digital personas and identity they exercise in their real-world iterations<br>no matter what A/IS may be in place to monitor, assist, or interact with their<br>data.</i>"
          ],
          [
           "Privacy",
           " <i>Privacy and Freedom of Expression In the Age of Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " Western Europe",
           " United Kingdom",
           " Privacy",
           " <i>The right to freedom of expression and the right to privacy are mutually<br>reinforcing – all the more so in the digital age. Privacy is a prerequisite to<br>the exercise of freedom of expression: without it, individuals lack the space to<br>think, speak and develop their voice. Without freedom of expression, individuals<br>would be unable to develop their sense of self.</i>"
          ],
          [
           "Privacy",
           " <i>Hippocratic Oath for Data Scientists</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization",
           " Western Europe",
           " France",
           " Privacy",
           " <i>Do not collect or use unnecessary personal and/or sensitive data.</i>"
          ],
          [
           "Privacy",
           " <i>Artificial intelligence and Privacy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Norway",
           " Privacy",
           " <i>The Data Protection Authority believes that the principle of data minimization<br>should play a major role in the development of artificial intelligence so that<br>the rights of data subjects are protected and general confidence in the models<br>is retained.</i>"
          ],
          [
           "Privacy",
           " <i>Code of conduct for data-driven health and care technology</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Privacy",
           " <i>Demonstrate that the product collects, stores, and processes users’ information<br>in a safe, fair and lawful way.  Innovators must comply with the law. They are<br>responsible for not only ensuring their innovation complies with relevant<br>legislation such as GDPR/Data Protection Act 2018 but also demonstrating this.<br>They should also ensure the legal basis for processing confidential patient<br>information.</i>"
          ],
          [
           "Privacy",
           " <i>Digital Ethics Guidelines on AI</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Privacy",
           " <i>We never process privacy-relevant data without legal permission. This policy<br>applies to our AI systems just as much as it does to all of our activities.<br>Additionally, we limit the usage to appropriate use cases and thoroughly secure<br>our systems to obstruct external access and ensure data privacy.</i>"
          ],
          [
           "Privacy",
           " <i>Artificial intelligence and the work of tomorrow (Künstliche Intelligenz und die<br>Arbeit von Morgen)</i>",
           " 2019",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Privacy",
           " <i>When introducing AI systems in a company context, the personal rights of<br>employees (privacy) must be protected. To this end, the requirements of the<br>European General Data Protection Regulation (GDPR) and the Federal Data<br>Protection Act [New] must first be observed.</i>"
          ],
          [
           "Privacy",
           " <i>Ethics Framework - Responsible AI</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Privacy",
           " <i>Compliance with legislation (such as the GDPR) is a good starting point for an<br>ethical assessment of data and privacy.</i>"
          ],
          [
           "Privacy",
           " <i>AI Ethics Principles & Guidelines</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Middle East",
           " United Arab Emirates",
           " Privacy",
           " <i>AI systems should respect privacy and use the minimum intrusion necessary. AI<br>systems should uphold high standards of data governance and security, protecting<br>personal information.</i>"
          ],
          [
           "Privacy",
           " <i>From Principles to Practice: An interdisciplinary framework to operationalise AI<br>ethics</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Professional Association",
           " Western Europe",
           " Germany",
           " Privacy",
           " <i>Safeguarding an individual’s private sphere is not only a necessary precondition<br>for the protection of individual autonomy and agency but also serves vital<br>interests in self-development, self-realization, engaging in intimate social<br>relations as well as participating in democratic public deliberation.</i>"
          ],
          [
           "Privacy",
           " <i>Beijing AI Principles</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Eastern Asia",
           " China",
           " Privacy",
           " <i>Human privacy, dignity, freedom, autonomy, and rights should be sufficiently<br>respected.</i>"
          ],
          [
           "Privacy",
           " <i>Artificial Intelligence: opportunities, risks and recommendations for the<br>financial sector</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Luxembourg",
           " Privacy",
           " <i>Institutions should limit the use of personal data in their AI/ML projects and<br>apply protection measures.</i>"
          ],
          [
           "Privacy",
           " <i>Data protection and Big Data (Datenschutz und Big Data)</i>",
           " 2017",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Privacy",
           " <i>In principle, personal data may only be collected, processed, or used if this is<br>permitted or ordered by the Federal Data Protection Act (BDSG) or an overriding<br>legal provision, or if the data subject has consented following Section 4a BDSG.<br>Thus, the prohibition with reservation of permission applies. If the above-<br>mentioned permissions do not allow the collection, processing, or use of<br>personal data, a company always requires the consent of the data subject<br>(Section 4 BDSG), which must always be given in writing. This consent must be<br>following § Section 4a of the BDSG must explicitly refer to the data collected<br>and the purpose of the collection.</i>"
          ],
          [
           "Privacy",
           " <i>Responsible Artificial Intelligence in the Government of Canada (whitepaper)</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Privacy",
           " <i>Understanding the need to protect the privacy and national security, AI systems<br>should be deployed in the most transparent manner possible.</i>"
          ],
          [
           "Privacy",
           " <i>SAP’s guiding principles for Artificial Intelligence</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Privacy",
           " <i>Data protection and privacy are a corporate requirement and at the core of every<br>product and service. We communicate clearly how, why, where, and when customer<br>and anonymized user data is used in our AI software.</i>"
          ],
          [
           "Privacy",
           " <i>People + AI Guidebook</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Privacy",
           " <i>As with any product, protecting user privacy and security is essential. Set up<br>the infrastructure, training, and guidance programs for privacy protection and<br>plan for situations where an adversary might get a hold of the data.</i>"
          ],
          [
           "Privacy",
           " <i>Responsible AI practices</i>",
           " Unspecified",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Privacy",
           " <i>Collect and handle data responsibly. Identify whether your ML model can be<br>trained without the use of sensitive data. If it is essential to process<br>sensitive training data, strive to minimize the use of such data. Anonymize and<br>aggregate incoming data using best practice data-scrubbing pipelines.</i>"
          ],
          [
           "Privacy",
           " <i>Artificial Intelligence at Google: Our Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Privacy",
           " <i>We believe that AI should Incorporate privacy design principles. We will<br>incorporate our privacy principles in the development and use of our AI<br>technologies. We will give opportunity for notice and consent, encourage<br>architectures with privacy safeguards, and provide appropriate transparency and<br>control over the use of data. We will not pursue technologies that gather or use<br>information for surveillance violating internationally accepted norms.</i>"
          ],
          [
           "Privacy",
           " <i>Universal principles of data ethics: 12 guidelines for developing ethics codes</i>",
           " 2016",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Privacy",
           " <i>Strive to match privacy and security safeguards with privacy and security<br>expectations. Data subjects hold a range of expectations about the privacy and<br>security of their data and those expectations are often context-dependent.<br>Designers and data professionals should give due consideration to those<br>expectations and align safeguards and expectations as much as possible.</i>"
          ],
          [
           "Privacy",
           " <i>Artificial Intelligence: Australia’s Ethics Framework - A Discussion Paper</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Oceania",
           " Australia",
           " Privacy",
           " <i>Any system, including AI systems, must ensure people’s private data is protected<br>and kept confidential plus prevent data breaches that could cause reputational,<br>psychological, financial, professional, or other types of harm. The Australian<br>Privacy Act 1988 (Privacy Act) regulates how personal information is handled.</i>"
          ],
          [
           "Privacy",
           " <i>Universal Guidelines for Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Belgium",
           " Privacy",
           " <i>No institution shall establish or maintain a secret profiling system. No<br>national government shall establish or maintain a general-purpose score on its<br>citizens or residents.</i>"
          ],
          [
           "Privacy",
           " <i>Sony Group AI Ethics Guidelines</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " Japan",
           " Privacy",
           " <i>Sony, in compliance with laws and regulations as well as applicable internal<br>rules and policies, seeks to enhance the security and protection of customers'<br>data acquired via products and services utilizing AI, and build an environment<br>where said personal data is processed in ways that respect the intention and<br>trust of customers.</i>"
          ],
          [
           "Privacy",
           " <i>Principles for the safe and effective use of data and analytics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Oceania",
           " New Zealand",
           " Privacy",
           " <i>Keep in mind the people behind the data and how to protect them against misuse<br>of information. It‘s essential to consider the privacy and ethical implications<br>of any analytical process that draws on data collected about people, as using<br>data and analytics for decision-making can have real-life impacts. Personal<br>information should only be kept for as long as necessary.</i>"
          ],
          [
           "Privacy",
           " <i>Code of Ethics for Data-Based Value Creation</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Switzerland",
           " Privacy",
           " <i>You should enable individuals and communities to act in a self-determined<br>manner. This basic orientation includes, among other things, the value of<br>privacy (e.g., by not collecting certain data). Personal data must be processed<br>lawfully.</i>"
          ],
          [
           "Privacy",
           " <i>Guidelines for the responsible use of artificial intelligence and other digital<br>technologies in human resources work</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Privacy",
           " <i>Anyone who uses personal data for AI solutions must define in advance the<br>purposes for which these are used and ensure that these data are only collected,<br>stored, and used for the intended purpose.</i>"
          ],
          [
           "Privacy",
           " <i>Telefónica´s Approach to the Responsible Use of AI (Enfoque de Telefónica para<br>un uso responsable de la IA)</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Spain",
           " Privacy",
           " <i>Privacy and Security by Design mean that when creating AI systems, which are<br>fueled by data, privacy, and security aspects are an inherent part of the<br>system’s lifecycle.</i>"
          ],
          [
           "Privacy",
           " <i>Automated and connected automated driving (Automatisiertes und Vernetztes<br>Fahren)</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Germany",
           " Privacy",
           " <i>Permitted business models that make use of the data generated by automated and<br>connected driving, which may or may not be relevant for vehicle control, are<br>limited by the autonomy and data sovereignty of road users. Vehicle owners or<br>users decide in principle on the transfer and use of data.</i>"
          ],
          [
           "Privacy",
           " <i>Telia Company Guiding Principles on trusted AI ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Sweden",
           " Privacy",
           " <i>We aim to know and show how we respect human rights. We seek to identify,<br>prevent, mitigate and account for how we address our impacts on human rights and<br>how we manage human rights risks and opportunities, such as privacy, children’s<br>rights, and anti-discrimination.</i>"
          ],
          [
           "Privacy",
           " <i>Responsible AI and robotics: An ethical framework</i>",
           " Unspecified",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Privacy",
           " <i>the importance of data protection, IP ownership, and cyber security must be<br>recognized and balanced against the need to use data to promote innovation.</i>"
          ],
          [
           "Privacy",
           " <i>Report on Artificial Intelligence and Human Society</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Privacy",
           " <i>Technologies for cyber security and privacy protection must be advanced. It is<br>especially essential to develop technology that enables us to choose how much<br>personal data to share, the level of individual privacy to be protected, and<br>what kind of information can be used publicly.</i>"
          ],
          [
           "Privacy",
           " <i>Safety First for Automated Driving – Proposed technical standards for the<br>development of Automated Driving</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Privacy",
           " <i>Automated vehicles shall record the relevant data about the status of the<br>automated driving system when an event or incident is recognized in manner that<br>complies with the applicable data privacy laws.</i>"
          ],
          [
           "Privacy",
           " <i>Opinion of the Data Ethics Commission</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Privacy",
           " <i>The individual’s right to determine who may access which personal information<br>relating to him or her, and when and for what purpose they may do so, is<br>justified by the supreme ethical importance of the ability to prevent intrusions<br>into one’s private sphere and also to appear in public in the certainty that<br>one’s privacy is protected. Efforts to protect human dignity must include<br>legislative measures to regulate the responsible use of personal data.</i>"
          ],
          [
           "Privacy",
           " <i>Artificial Intelligence and Data Protection</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Privacy",
           " <i>The Parties to Convention 108 will ensure and enable that AI development and use<br>respect the rights to privacy and data protection (Article 8 of the European<br>Convention on Human Rights), thereby enhancing human rights and fundamental<br>freedoms.</i>"
          ],
          [
           "Privacy",
           " <i>Statement on Artificial Intelligence, Robotics and 'Autonomous‘ Systems</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Privacy",
           " <i>‘Autonomous’ systems must not interfere with the right to private life which<br>comprises the right to be free from technologies that influence personal<br>development and opinions, the right to establish and develop relationships with<br>other human beings, and the right to be free from surveillance.</i>"
          ],
          [
           "Privacy",
           " <i>Report with recommendations to the Commission on Civil Law Rules on Robotics</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " European Union",
           " European Union",
           " Privacy",
           " <i>The European Parliament notes that the potential for empowerment through the use<br>of robotics is nuanced by a set of tensions or risks and should be seriously<br>assessed from the point of view of privacy and data protection. The European<br>Parliament calls on the Commission and the Member States to ensure that civil<br>law regulations in the robotics sector are consistent with the General Data<br>Protection Regulation. The European Parliament emphasizes that the right to the<br>protection of private life and of personal data as enshrined in Article 7 and 8<br>of the Charter and Article 16 of the Treaty on the Functioning of the European<br>Union (TFEU) apply to all areas of robotics and that the Union legal framework<br>for data protection must be fully complied with.</i>"
          ],
          [
           "Privacy",
           " <i>Preparing for the future of Artificial Intelligence</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Privacy",
           " <i>In light of the future importance of AI in surface and air, Federal actors<br>should focus in the near term on developing increasingly rich sets of data,<br>consistent with consumer privacy, that can better inform policy-making as these<br>technologies mature.</i>"
          ],
          [
           "Privacy",
           " <i>Vienna Manifesto on Digital Humanism</i>",
           " 2019",
           " Recommendation",
           " Academic",
           " Central Europe",
           " Austria",
           " Privacy",
           " <i>Privacy and freedom of speech are essential values for democracy and should be<br>at the center of our activities. Therefore, artifacts such as social media or<br>online platforms need to be altered to better safeguard the free expression of<br>opinion, the dissemination of information, and the protection of privacy.</i>"
          ],
          [
           "Privacy",
           " <i>Artificial Intelligence: Economic importance, social challenges, human<br>responsibility</i>",
           " 2017",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Privacy",
           " <i>Where restrictions and impediments to the further development of AI applications<br>based on data protection regulations are identified, which are not necessary for<br>the protection of personal data, amendments must be made, or special legal<br>regulations are created.</i>"
          ],
          [
           "Privacy",
           " <i>A guide to using artificial intelligence in the public sector</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Privacy",
           " <i>With an AI project you should consider several factors, including AI ethics and<br>safety. hese factors span safety, ethical, legal and administrative concerns and<br>include: privacy - complying with appropriate data policies, for example the<br>General Data Protection Regulations (GDPR) and the Data Protection Act 2018.</i>"
          ],
          [
           "Privacy",
           " <i>AI in the UK: ready, willing and able?</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Privacy",
           " <i>Artificial intelligence should not be used to diminish the data rights or<br>privacy of individuals, families, or communities.</i>"
          ],
          [
           "Privacy",
           " <i>Report of COMEST on robotics ethics</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Privacy",
           " <i>The value of privacy is related to Article 12 of the Universal Declaration of<br>Human Rights (UN, 1948) which states that: No one shall be subjected to<br>arbitrary interference with his privacy, family, home, or correspondence, nor to<br>attacks upon his honor and reputation. Everyone has the right to the protection<br>of the law against such interference or attacks.</i>"
          ],
          [
           "Privacy",
           " <i>ACM Code of Ethics and Professional Conduct</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Privacy",
           " <i>A computing professional should respect privacy. Computing professionals should<br>only use personal information for legitimate ends and without violating the<br>rights of individuals and groups. This requires taking precautions to prevent<br>re-identification of anonymized data or unauthorized data collection, ensuring<br>the accuracy of data, understanding the provenance of the data, and protecting<br>it from unauthorized access and accidental disclosure.</i>"
          ],
          [
           "Privacy",
           " <i>Montréal declaration for a responsible development of artificial intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " Canada",
           " Privacy",
           " <i>Personal spaces in which people are not subjected to surveillance or digital<br>evaluation must be protected from the intrusion of AI and data acquisition and<br>archiving systems (DAAS). The intimacy of thoughts and emotions must be strictly<br>protected from AI and DAAS uses capable of causing harm, especially uses that<br>impose moral judgments on people or their lifestyle choices. DAAS must guarantee<br>data confidentiality and personal profile anonymity.</i>"
          ],
          [
           "Privacy",
           " <i>Ethical Framework for Artificial Intelligence in Colombia (Marco Ético para la<br>Inteligencia Artificial en Colombia)</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Latin America",
           " Colombia",
           " Privacy",
           " <i>Artificial intelligence must be preceded by respect for the privacy of<br>individuals and their private sphere that prevents the use of information that<br>they have not authorized.</i>"
          ],
          [
           "Privacy",
           " <i>fAIr LAC: Responsible and Widespread Adoption of Artificial Intelligence in<br>Latin America and the Caribbean</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Latin America",
           " Unspecified",
           " Privacy",
           " <i>AI actors should respect the rule of law, human rights, and democratic values,<br>throughout the AI system lifecycle. These include privacy and data protection.</i>"
          ],
          [
           "Privacy",
           " <i>Artificial Intelligence for Children: Beijing Principles</i>",
           " 2020",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Privacy",
           " <i>The development of AI should protect children's privacy in a much stricter<br>manner. The collection of information on children should follow the principle of<br>\"legal, proper, and necessary,\" ensure their guardians' informed consent and<br>avoid illegal collection and abuse of children's information. AI systems should<br>ensure that children, parents, legal guardians, or other caregivers have the<br>right to consent, refuse, erase data, revoke authorizations, etc.</i>"
          ],
          [
           "Privacy",
           " <i>Social Principles of Human-Centric AI</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia, Western Europe",
           " Japan, United Kingdom",
           " Privacy",
           " <i>AI using personal data should have mechanisms to ensure accuracy and legitimacy,<br>and to allow individuals to be substantially involved in managing the privacy of<br>their data. This would make it possible for people to provide personal data with<br>peace of mind when using AI, and effectively benefit from the data they provide.<br>Personal data must be protected appropriately according to its degree of<br>importance and sensitivity.</i>"
          ],
          [
           "Privacy",
           " <i>Position on Robotics and Artificial Intelligence</i>",
           " 2016",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Privacy",
           " <i>Lawmakers should make sure that the development and commercial use of emerging<br>technologies comply with existing laws and fundamental rights, including privacy<br>by design. The development process should follow the principles of data<br>minimization. Whenever personal data is used, it shall be adequate, relevant,<br>and limited to what is necessary concerning the purposes for which they are<br>processed.</i>"
          ],
          [
           "Privacy",
           " <i>AI Governance in Japan Ver. 1.1, Report from the expert group on how AI<br>principles should be implemented</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Privacy",
           " <i>AI using personal data should have mechanisms to ensure accuracy and legitimacy,<br>and to allow individuals to be substantially involved in managing the privacy of<br>their data. This would make it possible for people to provide personal data with<br>peace of mind when using AI, and effectively benefit from the data they provide.<br>Personal data must be protected appropriately according to its degree of<br>importance and sensitivity.</i>"
          ],
          [
           "Privacy",
           " <i>Principles of Artificial Intelligence Ethics for the Intelligence Community</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Privacy",
           " <i>Our use of AI will fully comply with applicable legal authorities and with<br>policies and procedures that protect privacy, civil rights, and civil liberties.</i>"
          ],
          [
           "Privacy",
           " <i>Vodafone Artificial Intelligence Framework</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Privacy",
           " <i>We will ensure that customer data is carefully managed, in line with our strong<br>privacy commitments and prevailing legislation, and only used with AI systems<br>when we have established a clear legal basis to do so.</i>"
          ],
          [
           "Privacy",
           " <i>oston Dynamics Ethical Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Privacy",
           " <i>We believe robotic use must comply with privacy and civil rights laws. We will<br>not authorize nor partner with those who wish to use our robots in a way that<br>violates privacy and civil rights laws. We understand that emerging artificial<br>intelligence technologies including computer vision and personal identification<br>algorithms raise questions about the ethics, legality, and potential for bias<br>around their use in the public sphere.</i>"
          ],
          [
           "Privacy",
           " <i>Augmented Intelligence in Health Care H-480.940</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Professional Association",
           " North America",
           " United States of America",
           " Privacy",
           " <i>AMA will seek to promote the development of thoughtfully designed, high-quality,<br>clinically validated healthcare AI that safeguards patients’ and other<br>individuals’ privacy interests and preserves the security and integrity of<br>personal information.</i>"
          ],
          [
           "Privacy",
           " <i>WLiAI Report 2019: 10 Principles of Responsible AI</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " United Kingdom",
           " Privacy",
           " <i>Recommendation - Introduce a ‘certificate of fairness’ for AI systems that are<br>audited for risks concerning discrimination, unfairness, and privacy.</i>"
          ],
          [
           "Privacy",
           " <i>The Ethical Norms for the New Generation Artificial Intelligence, China</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Privacy",
           " <i>Various activities of AI shall abide by the following fundamental ethical norms,<br>like fully respecting the rights of personal information, to know, and to<br>consent, etc., handling personal information, protecting personal privacy and<br>data security following the principles of lawfulness, justifiability, necessity,<br>and integrity, do no harm to the legitimate rights of personal data, must not<br>illegally collect and use personal information by stealing, tampering, or<br>leaking, etc., and must not infringe on the rights of personal privacy.</i>"
          ],
          [
           "Privacy",
           " <i>Work in the age of artificial intelligence: Four perspectives on the economy,<br>employment, skills and ethics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Finland",
           " Privacy",
           " <i>Responsibility means that decision-making based on artificial intelligence does<br>not pose a threat to anyone’s health or safety. This requirement applies to an<br>individual’s physical and psychological health as well as data protection and<br>protection of privacy.</i>"
          ],
          [
           "Privacy",
           " <i>A Framework for Responsible Limits on Facial RecognitionUse Case: Flow<br>Management</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization",
           " Western Europe",
           " Switzerland",
           " Privacy",
           " <i>Organizations using facial recognition systems should design systems to support<br>privacy, including privacy considerations in system requirements and carrying<br>through privacy support in the design, development, and testing of technology as<br>well as in supporting business practices and ongoing system maintenance.</i>"
          ],
          [
           "Privacy",
           " <i>A Code of Ethics for the Human-Robot Interaction Profession</i>",
           " 2014",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Privacy",
           " <i>The human’s right to privacy shall always be respected to the greatest extent<br>consistent with reasonable design objectives.</i>"
          ],
          [
           "Privacy",
           " <i>Discussion Paper: National Strategy for Artificial Intelligence</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " South Asia",
           " India",
           " Privacy",
           " <i>The work being done by Justice Srikrishna Committee on data protection law is<br>very opportune and timely. The 7-core principles of data protection and privacy<br>– informed consent, technology agnosticism, data controller accountability, data<br>minimization, holistic application, deterrent penalties, and structured<br>enforcement – are quite comprehensive and should provide a strong privacy<br>protection regime in the country once enacted. Recommendation - Address and<br>implement a data protection framework, which protects human rights and privacy<br>without stifling innovation in India.</i>"
          ],
          [
           "Privacy",
           " <i>Advisory statement on human ethics in artificial intelligence and big data<br>research (2017)</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Privacy",
           " <i>Protect Privacy and Personal Information. Take special measures in the design<br>and planning of research to protect the privacy of individuals and personal<br>information about themselves as required by the NRC Policy and its model, The<br>Tri-Council Policy Statement: Ethical Conduct for Research Involving Humans<br>(TCPS or the Policy). Recognize the right of individuals to access their<br>personal information held by NRC.</i>"
          ],
          [
           "Privacy",
           " <i>The National Artificial Intelligence Research and Development Strategic Plan:<br>2019 Update</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Privacy",
           " <i>The United States must foster public trust and confidence in AI technologies and<br>protect civil liberties, privacy, and American values in their application in<br>order to fully realize the potential of AI technologies for the American people.</i>"
          ],
          [
           "Privacy",
           " <i>The Holberton-Turing Oath</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Unspecified",
           " Unspecified",
           " Privacy",
           " <i>I will respect the privacy of humans for their personal data are not disclosed<br>to Artificial Intelligence systems so that the world may know. I will respect<br>the secrets that are confided in me.</i>"
          ],
          [
           "Privacy",
           " <i>OECD, Recommendation of the Council on Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " France",
           " Privacy",
           " <i>AI actors should respect the rule of law, human rights, and democratic values,<br>throughout the AI system lifecycle. These include freedom, dignity and autonomy,<br>privacy and data protection, nondiscrimination and equality, diversity,<br>fairness, social justice, and internationally recognized labor rights.</i>"
          ],
          [
           "Privacy",
           " <i>OP Financial Group’s Ethical Guidelines for Artificial Intelligence</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Finland",
           " Privacy",
           " <i>We safeguard the privacy and personal information of individuals represented in<br>the data we hold in accordance with our privacy policies.</i>"
          ],
          [
           "Privacy",
           " <i>Oxford Munich Code of Conduct</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Privacy",
           " <i>The Data Scientist must act to protect the privacy and confidentiality of data,<br>respect the ownership of proprietary data, and not expose data (within private<br>or public fora) that might cause any harm to individuals or legal entities. The<br>Data Scientist shall not apply any technique (combination, enriching, etc.) to<br>turn information that has been designed to be “de-identifiable” into<br>“identifiable” again. The Data Scientist shall be aware of the implications of<br>new decentralized data storage technologies where critical privacy-protecting<br>operations (such as physical record deletion), are not directly supported.</i>"
          ],
          [
           "Privacy",
           " <i>Partnership on AI Tenets</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization",
           " Unspecified",
           " Unspecified",
           " Privacy",
           " <i>We will work to maximize the benefits and address the potential challenges of AI<br>technologies, by working to protect the privacy and security of individuals.</i>"
          ],
          [
           "Privacy",
           " <i>UNESCO Recommendation on the Ethics of Artificial Intelligence</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Privacy",
           " <i>Privacy, a right essential to the protection of human dignity, human autonomy,<br>and human agency, must be respected, protected, and promoted throughout the life<br>cycle of AI systems. Data for AI systems must be collected, used, shared,<br>archived, and deleted in ways that are consistent with international law and in<br>line with the values and principles outlined in this Recommendation while<br>respecting relevant national, regional and international legal frameworks.</i>"
          ],
          [
           "Privacy",
           " <i>Megvii's Artificial Intelligence Application Guidelines</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " China",
           " Privacy",
           " <i>During the development and use of artificial intelligence solutions, it is<br>necessary to strictly protect the personal privacy of users and ensure data<br>security.</i>"
          ],
          [
           "Privacy",
           " <i>Policy guidance on AI for children</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution, International Organization",
           " Northern Europe, Intergovernmental Organization",
           " Finland, United Nations",
           " Privacy",
           " <i>Protect children’s data and privacy. Ensure my privacy in an AI world.</i>"
          ],
          [
           "Privacy",
           " <i>Ethics & Governance of Artificial Intelligence for Health</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Privacy",
           " <i>Respect for human autonomy also requires protection of privacy and<br>confidentiality and obtaining valid informed consent through appropriate legal<br>frameworks for data protection.</i>"
          ],
          [
           "Privacy",
           " <i>Ethical ML Institute Responsible Machine Learning Principles</i>",
           " Unspecified",
           " Recommendation",
           " Academic",
           " Western Europe",
           " United Kingdom",
           " Privacy",
           " <i>Technologists should enforce privacy by design across systems, as well as<br>continuous processes to build trust not only with users, but also with relevant<br>stakeholders such as procurement frameworks, operational users, and beyond. I<br>commit to building and communicating processes that protect and handle data with<br>stakeholders that may interact with the system directly and/or indirectly.</i>"
          ],
          [
           "Privacy",
           " <i>HPE AI Ethics and Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Privacy",
           " <i>Respect individuals' privacy, be secure, and minimize the risk of errors and<br>unintended malicious use.</i>"
          ],
          [
           "Privacy",
           " <i>Thomson Reuters AI principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " Canada",
           " Privacy",
           " <i>Thomson Reuters will prioritize safety, security, and privacy throughout the<br>design, development, and deployment of our AI products and services.</i>"
          ],
          [
           "Privacy",
           " <i>Integrate’s AI principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " Canada",
           " Privacy",
           " <i>Keeping customers and end-users safe should be a function of every AI system. If<br>they aren’t, everything else is irrelevant. Data security and customer privacy<br>are foundational to what we do. That’s why we’ve implemented Privacy by Design<br>standards. We’re also transparent about how we handle data. We never accept,<br>use, or store any personally identifiable information (PII). We do not<br>compromise on our principle of safety, even in instances where a risky approach<br>might yield better results.</i>"
          ],
          [
           "Privacy",
           " <i>National Association of Insurance Commissioners (NAIC) Principles on Artificial<br>Intelligence (AI)</i>",
           " 2020",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Privacy",
           " <i>AI actors should respect the rule of law throughout the AI life cycle. This<br>includes, but is not limited to, insurance laws and regulations, such as those<br>relating to trade practices, unfair discrimination, access to insurance,<br>underwriting, privacy, consumer protection and eligibility practices, ratemaking<br>standards, advertising decisions, claims practices, and solvency.</i>"
          ],
          [
           "Privacy",
           " <i>IBM AI Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Privacy",
           " <i>Data and insights belong to their creator. IBM clients’ data is their data, and<br>their insights are their insights. AI systems must prioritize and safeguard<br>consumers’ privacy and data rights.</i>"
          ],
          [
           "Privacy",
           " <i>Linux Foundation AI Principles</i>",
           " 2020",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Privacy",
           " <i>Privacy requires AI systems to guarantee privacy and data protection throughout<br>a system’s entire lifecycle. The lifecycle activities include the information<br>initially collected from users, as well as information generated about users<br>throughout their interaction with the system e.g., outputs that are AI-generated<br>for specific users or how users responded to recommendations. Any AI must ensure<br>that data collected or inferred about individuals will not be used to unlawfully<br>or unfairly discriminate against them. Privacy and transparency are especially<br>needed when dealing with digital records that allow inferences such as identity,<br>preferences, and future behavior.</i>"
          ],
          [
           "Privacy",
           " <i>ADP: Ethics in Artificial Intelligence</i>",
           " 2022",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Privacy",
           " <i>We have implemented an enterprise-wide Privacy-By-Design approach that<br>incorporates privacy and data security into our ML model development and data<br>processing systems more generally. ADP provides information about how we handle<br>personal data in privacy statements made available to our client's employees,<br>consumers, and job applicants. Our ML models seek to minimize access to<br>identifiable information to ensure we use only the personal data we need to<br>generate insights. We also maintain a robust security program for our ML models,<br>including designing them in line with our security standards and protecting them<br>against misuse or compromise.</i>"
          ],
          [
           "Privacy",
           " <i>Ethical Aspects of Autonomous and Intelligent Systems</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Privacy",
           " <i>A/IS developers should respect each individual’s ability to maintain appropriate<br>control over their data and identifying information.</i>"
          ],
          [
           "Privacy",
           " <i>IEEE Position Statement - Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Privacy",
           " <i>To ensure that artificial intelligence serves the interests of society, IEEE<br>urges governments to adopt policies that ensure that AI regulations always<br>comply with human rights laws and prioritize the protection of personal data<br>relating to the individuals coming into contact with AI systems or algorithms.</i>"
          ],
          [
           "Privacy",
           " <i>IEEE Policies - Code of Ethics</i>",
           " 2022",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Privacy",
           " <i>We, the members of the IEEE, o hereby commit ourselves to the highest ethical<br>and professional conduct and agree to hold paramount the safety, health, and<br>welfare of the public, to strive to comply with ethical design and sustainable<br>development practices, to protect the privacy of others, and to disclose<br>promptly factors that might endanger the public or the environment.</i>"
          ],
          [
           "Privacy",
           " <i>Safe Face Pledge</i>",
           " 2021",
           " Recommendation",
           " Academic, Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Privacy",
           " <i>Do not facilitate secret and discriminatory government surveillance. By<br>acknowledging the right of the public to understand whether and how facial<br>analysis technologies are used by the government. By refraining from knowingly<br>selling to the government any products and services that are not subject to<br>public scrutiny, inspection, and oversight.</i>"
          ],
          [
           "Privacy",
           " <i>Artificial intelligence - Common good as a benchmark, good work as a principle</i>",
           " 2019",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Privacy",
           " <i>If data is to be legally protected, public space must also be protected from<br>surveillance. This includes a framework for the provision of private services<br>and personalized collections of data and metadata.</i>"
          ],
          [
           "Privacy",
           " <i>Algorithmic Decision-making for the Benefit of Consumers</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization",
           " Western Europe",
           " Germany",
           " Privacy",
           " <i>The scope of application for automated individual decision-making (Article 22 of<br>the General Data Protection Regulation, GDPR) needs to be extended to cover not<br>only decisions that are based solely on automated data processing but to cover<br>also those based on predominantly automated data processing. To establish<br>safeguards and reduce errors and risks in ADM systems, these systems must be<br>required by law to only use data if it is pertinent to the decision being made.</i>"
          ],
          [
           "Privacy",
           " <i>Draft - AI Utilization Principles</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Privacy",
           " <i>Users and data providers should take into consideration that the utilization of<br>AI systems or AI services will not infringe on the privacy of users or others.</i>"
          ],
          [
           "Privacy",
           " <i>The Code of Ethics in the Field of Artificial Intelligence</i>",
           " 2022",
           " Recommendation",
           " Unspecified",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Privacy",
           " <i>AI Actors should responsibly treat issues related to the influence of AI systems<br>on society and citizens at every stage of the AI systems’ life cycle, i.a. on<br>privacy, ethical, safe, and responsible use of personal data.</i>"
          ],
          [
           "Privacy",
           " <i>Shanghai Initiative for Safe and Secure AI Development</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Asia",
           " China",
           " Privacy",
           " <i>Ai development must not undermine user privacy and data security or come at the<br>expense of user privacy. Laws and technology roadmaps should be improved to<br>strengthen the protection of user privacy in Ai Technologies.</i>"
          ],
          [
           "Privacy",
           " <i>Chinese Young Scientists' Declaration on the Governance and Innovation of<br>Artificial Intelligence (Shanghai Declaration)</i>",
           " 2019",
           " Recommendation",
           " Academic, Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Asia",
           " China",
           " Privacy",
           " <i>Recommendation - Verify user ownership, strengthen the awareness of privacy<br>protection, and collect and use data in an open, transparent, and lawful manner.</i>"
          ],
          [
           "Privacy",
           " <i>Trustworthy AI in Aotearoa: AI Principles</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " Oceania",
           " New Zealand",
           " Privacy",
           " <i>AI stakeholders must ensure AI systems and related data are reliable, accurate,<br>and secure and the privacy of individuals is protected throughout the AI<br>system’s life cycle, with potential risks identified and managed on an ongoing<br>basis.</i>"
          ],
          [
           "Privacy",
           " <i>Harmonious Artificial Intelligence Principles</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Privacy",
           " <i>AI needs to respect human privacy. And has no right to utilize and share private<br>information of humans without explicit confirmation. Humans need to respect the<br>privacy of AI, on the basis that AI does not bring any actual challenge to human<br>safety. AI is obliged to uncover necessary private details to keep safe<br>interactions with humanity. When conflicts emerged from interactions between<br>humans and AI, benefits for humanity and benefits for AI should be actively<br>coordinated based on Empathy and Altruism.</i>"
          ],
          [
           "Privacy",
           " <i>\"ARCC\": An Ethical Framework for Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " Eastern Asia",
           " China",
           " Privacy",
           " <i>Privacy protection. Recommendation - Comply with privacy requirements, and<br>safeguard against data abuse.</i>"
          ],
          [
           "Privacy",
           " <i>Fu Ying: Six Principles of Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Privacy",
           " <i>It is necessary to ensure the security, applicability, and controllability of<br>artificial intelligence systems, protect personal privacy, and prevent data<br>leakage and abuse.</i>"
          ],
          [
           "Privacy",
           " <i>A Framework for the Ethical use of advanced Data Science Methodes in the<br>Humanitarian Sector</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe, Intergovernmental Organization",
           " Netherlands, United Nations",
           " Privacy",
           " <i>All sectors must ensure their systems are robust and secure to protect the<br>privacy and maintain the integrity and confidentiality of personal data. Privacy<br>and data governance should not only ensure full respect for privacy and data<br>protection, but also ensure adequate data governance mechanisms, considering the<br>quality and integrity of the data, and ensuring legitimized access to data.</i>"
          ],
          [
           "Privacy",
           " <i>Civil Rights Principles for the Era of Big Data</i>",
           " 2014",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Privacy",
           " <i>Recommendation - Stop High-Tech Profiling. New surveillance tools and data<br>gathering techniques that can assemble detailed information about any person or<br>group create a heightened risk of profiling and discrimination. Clear<br>limitations and robust audit mechanisms are necessary to make sure that if these<br>tools are used it is responsibly and equitably.</i>"
          ],
          [
           "Privacy",
           " <i>Human rights in the robot age: Challenges arising from the use of robotics,<br>artificial intelligence, and virtual and augmented reality</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Western Europe",
           " Netherlands",
           " Privacy",
           " <i>Recommendation - We recommend that the Council of Europe takes a stance<br>concerning the ubiquitous and massive personal data processing of the modern<br>era, reinforcing the human rights principles as enshrined in the Conventions.<br>The Council of Europe could clarify to what extent in the context of the robot<br>age the right to respect for privacy implies the right to not be measured,<br>analyzed, or coached.</i>"
          ],
          [
           "Privacy",
           " <i>Technological convergence, artificial intelligence and human rights</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Privacy",
           " <i>Moreover, the Assembly proposes that guidelines be drawn upon the following<br>issues: the recognition of new rights in terms of respect for private and family<br>life, the ability to refuse to be subjected to profiling, to have one’s location<br>tracked, to be manipulated or influenced by a “coach”.</i>"
          ],
          [
           "Privacy",
           " <i>Stanford's Human-Centered AI Initiative Values</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Academic",
           " North America",
           " United States of America",
           " Privacy",
           " <i>We respect every individual’s fundamental right to privacy.</i>"
          ],
          [
           "Privacy",
           " <i>Principles and Practices for the Responsible Application of Artificial<br>Intelligence at Motorola Solutions - White Paper</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Privacy",
           " <i>Where possible, Motorola Solutions will work with anonymized data (no assignable<br>PII content) at the source, synthesized data (by machine methods or through<br>controlled customer interactions such as training exercises), or accumulate our<br>training data from publicly available sources. We utilize tools and frameworks<br>that facilitate privacy-sensitive training by encoding general patterns rather<br>than facts about specific training examples wherever possible.</i>"
          ]
         ],
         "hovertemplate": "<b>Document ID </b>=%{customdata[1]}<br><b>Year of Publication </b>=%{customdata[2]}<br><b>Reguation Type </b>=%{customdata[3]}<br><b>Institution Type </b>=%{customdata[4]}<br><b>World Region </b>=%{customdata[5]}<br><b>Country </b>=%{customdata[6]}<br><b>Principle </b>=%{customdata[7]}<br><b>Description </b>=%{customdata[8]}<extra></extra>",
         "legendgroup": "Privacy",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Privacy",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          -6.382159,
          -15.054096,
          -13.441711,
          -10.927782,
          -10.71567,
          13.892234,
          -4.1607947,
          -15.0315485,
          3.8498106,
          -5.976478,
          -7.842056,
          -18.013294,
          -13.82271,
          -9.840062,
          -14.28477,
          -11.802666,
          4.892702,
          24.493013,
          -9.066952,
          -10.536691,
          -13.149531,
          -11.180172,
          1.7672908,
          -9.799557,
          -14.128068,
          -12.177169,
          -0.14224382,
          -11.38521,
          -5.7769704,
          -5.808013,
          -8.963419,
          -11.927956,
          -16.661396,
          -11.707315,
          -7.056021,
          -17.351494,
          -10.816947,
          -16.006773,
          -10.169392,
          -9.115538,
          -9.51545,
          -12.547213,
          -6.302687,
          -11.104463,
          -17.25704,
          -7.387455,
          -14.290311,
          -10.785917,
          -7.8853264,
          -2.272694,
          -8.367417,
          -9.579704,
          -9.621027,
          -18.858974,
          -14.677507,
          -7.098759,
          -7.898087,
          -16.099842,
          -13.870092,
          3.1658704,
          -2.7057257,
          -4.1935053,
          -3.9070408,
          -10.664362,
          -18.008574,
          -25.854113,
          7.478955,
          24.317776,
          -13.215608,
          -27.230352,
          -7.3887157,
          -3.1321273,
          -9.81087,
          0.71054196,
          -19.858345,
          -10.962633,
          -3.2647274,
          -21.201296,
          -6.9753094,
          -7.6920514,
          -9.991306,
          -13.495994,
          -8.405409,
          -1.670296,
          0.9253151,
          -11.287612,
          -11.159399,
          -11.813789,
          -4.718131,
          -19.269398,
          -9.630797,
          -1.451997,
          8.326426,
          -0.20598027,
          -16.956633,
          2.4275892,
          -5.563815,
          -12.776458,
          -6.545924,
          -1.8956513,
          -1.6316152,
          0.8084663,
          -18.894852,
          -3.4357815,
          0.027000403,
          -5.946878,
          -8.212461,
          -14.762082,
          -5.6744194,
          -14.746572,
          -12.515138,
          -3.8333256,
          -17.945679,
          -2.4784114,
          -14.055845,
          -14.487309,
          -17.424644,
          -11.629962,
          5.452868,
          14.885699,
          4.1760035,
          -11.591542,
          -4.330899,
          -7.7301774,
          -5.787118,
          -9.98012,
          -13.044869,
          -11.251587,
          -9.018209,
          -14.467049,
          -14.165867,
          -15.0558815,
          1.8011651,
          -0.0041210167,
          -13.391665,
          -6.424627,
          -23.301342
         ],
         "y": [
          9.577357,
          13.793508,
          6.153091,
          8.144459,
          9.466085,
          16.527544,
          -0.7479981,
          5.5911336,
          15.755781,
          11.76415,
          7.8220844,
          16.292227,
          8.654089,
          14.983867,
          9.474966,
          20.779112,
          12.116921,
          2.1608255,
          15.169213,
          12.848574,
          9.541961,
          24.163641,
          16.380335,
          10.981918,
          18.148333,
          5.8774567,
          14.842754,
          5.1301227,
          8.380676,
          21.815294,
          11.1973915,
          17.459763,
          17.415646,
          6.9810653,
          4.6524973,
          15.067785,
          7.330313,
          25.63679,
          5.728321,
          14.30103,
          19.471254,
          24.764313,
          12.294358,
          20.368406,
          10.44409,
          11.855312,
          19.757576,
          6.885919,
          16.744198,
          19.40599,
          6.3867416,
          18.492523,
          3.162923,
          12.306592,
          20.53306,
          13.262052,
          7.8483396,
          20.480457,
          12.230431,
          15.296974,
          -26.220942,
          17.087915,
          20.351662,
          13.919554,
          6.507126,
          6.0148106,
          23.906952,
          10.123861,
          16.939205,
          5.30533,
          18.098413,
          9.361767,
          11.058687,
          -5.542665,
          5.3043084,
          19.372925,
          11.213233,
          -1.0578235,
          7.977916,
          20.244366,
          21.624237,
          10.207424,
          6.9564934,
          3.1080399,
          9.138012,
          12.898612,
          18.236794,
          11.934523,
          4.0055914,
          11.216958,
          -5.999532,
          -27.908737,
          -1.7444241,
          -2.3244345,
          4.1038146,
          13.616142,
          21.158121,
          24.648775,
          26.41462,
          -13.686392,
          15.887434,
          4.012371,
          15.548974,
          22.231436,
          -17.711287,
          11.602934,
          7.2731104,
          6.2024684,
          23.455572,
          18.777777,
          22.410427,
          -20.874212,
          10.250431,
          0.6125727,
          7.507192,
          9.458707,
          10.757698,
          13.677191,
          -4.3976903,
          15.369266,
          17.574316,
          18.807745,
          14.655273,
          3.8699024,
          -4.7740626,
          9.357883,
          22.889637,
          2.528261,
          4.4909554,
          22.36772,
          1.3877591,
          15.770434,
          20.425442,
          -2.4398468,
          14.375143,
          21.8386,
          -3.5787685
         ],
         "z": [
          1.6426333,
          -4.7340455,
          -1.4457701,
          -1.7642821,
          0.90191907,
          14.430421,
          -3.5445893,
          1.5429318,
          17.185787,
          -2.6080396,
          -7.0482197,
          1.6364326,
          -0.03787725,
          -1.6958323,
          -8.271257,
          -2.211923,
          -18.80419,
          -8.962663,
          -5.3056617,
          1.3473256,
          2.319619,
          -2.59544,
          -4.777618,
          -4.3735113,
          -3.3410978,
          1.0349841,
          -1.1560614,
          2.7542872,
          -0.25175697,
          -4.838415,
          -0.4944591,
          -4.4714055,
          -6.2536235,
          -4.8879013,
          3.9738197,
          4.475386,
          4.4569635,
          -6.7050385,
          2.782778,
          3.2946436,
          7.04419,
          0.5809879,
          1.1373672,
          -4.8742256,
          2.3541555,
          -1.916148,
          -6.0666695,
          0.1940634,
          6.5795355,
          9.237382,
          -2.1925523,
          -9.800075,
          -5.2202063,
          -0.1119842,
          -0.98679346,
          -11.642875,
          -8.216263,
          3.1076417,
          0.34942666,
          -1.2908739,
          10.422396,
          -9.807167,
          2.6782813,
          -6.1437035,
          -0.9948658,
          1.7689985,
          7.7004952,
          -6.911165,
          1.8346512,
          1.5041553,
          4.596281,
          3.3743482,
          8.682166,
          25.5,
          -5.482525,
          7.6239715,
          -1.804231,
          13.757272,
          6.0149407,
          6.2497797,
          0.657257,
          5.011189,
          6.062699,
          3.780904,
          24.140785,
          -2.1771715,
          -0.7665745,
          -2.5528653,
          -1.9906107,
          2.3693404,
          22.769472,
          -1.4390956,
          -15.234714,
          2.81014,
          11.309083,
          -6.8501916,
          8.515484,
          -7.1676936,
          -4.0543456,
          7.768339,
          17.64815,
          4.0121813,
          3.3560574,
          -13.937228,
          5.8684316,
          3.6174755,
          1.540598,
          5.8009224,
          0.09683003,
          -0.41284737,
          0.44768065,
          -13.920917,
          -1.4657742,
          0.7966472,
          -5.647749,
          -0.87990034,
          -3.9928477,
          3.9799178,
          -6.0336156,
          7.106279,
          -3.3039281,
          3.3218877,
          -1.5613996,
          0.6740072,
          3.0353622,
          2.8960588,
          -2.9993443,
          -0.4745997,
          7.3477306,
          -2.9278862,
          -1.5995528,
          -1.0696018,
          -6.154745,
          25.631021,
          10.967302,
          9.743393,
          -16.618414
         ]
        },
        {
         "customdata": [
          [
           "Reliability",
           " <i>AI Policies and Principles</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Industrial Association",
           " North America",
           " United States of America",
           " Reliability",
           " <i>AI researchers, experts, stakeholders, and technicians should ensure that AI<br>systems that are designed and deployed are responsible. This sort of<br>responsibility includes addressing safety and controllable mechanisms in AI<br>systems, using robust and representative data, and stating the risks and<br>solutions in AI systems in the specific context in which the system operates.</i>"
          ],
          [
           "Reliability",
           " <i>Artificial Intelligence and Machine Learning: Policy Paper</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Reliability",
           " <i>The capacity of an AI agent to act autonomously, and to adapt its behavior over<br>time without human direction, calls for significant safety checks before<br>deployment, and ongoing monitoring.</i>"
          ],
          [
           "Reliability",
           " <i>Responsible AI: A Global Policy Framework</i>",
           " 2021",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization, Professional Association",
           " North America",
           " United States of America",
           " Reliability",
           " <i>Organisations that develop make available, or use AI systems and any national<br>laws that regulate such use shall adopt design regimes and standards ensuring<br>high safety and reliability of AI systems on one hand while limiting the<br>exposure of developers and deployers on the other hand.</i>"
          ],
          [
           "Reliability",
           " <i>Trusted AI</i>",
           " Unspecified",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Reliability",
           " <i>At IBM Research, we’re working on a range of approaches to ensure that AI<br>systems built in the future are fair, robust, explainable, accountable, and<br>align with the values of the society they’re designed for. We need assurances<br>that AI cannot be tampered with and that the system itself is secure.</i>"
          ],
          [
           "Reliability",
           " <i>The Japanese Society for Artificial Intelligence Ethical Guidelines</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Academic",
           " Eastern Asia",
           " Japan",
           " Reliability",
           " <i>As specialists, members of the JSAI shall recognize the need for AI to be safe<br>and acknowledge their responsibility in keeping AI under control. If potential<br>danger is identified, a warning must be effectively communicated to all of<br>society.</i>"
          ],
          [
           "Reliability",
           " <i>Kakao Algorithm Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " South Korea",
           " Reliability",
           " <i>Kakao blocks the possibility that our algorithms may be damaged or distorted<br>under the influence of a specific intention (i.e., robustness to adversarial<br>attacks).</i>"
          ],
          [
           "Reliability",
           " <i>KI Seal of Approval</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Reliability",
           " <i>An AI system requires confidentiality and integrity of data processing. These<br>include secure and privacy-compliant collection, storage, and processing of<br>large amounts of training data; robustness to adversarial input data; preventing<br>degeneration and manipulation of self-learning systems; Safeguarding against<br>new, non-human failure modes; unauthorized access to personal data through<br>neural network mining.</i>"
          ],
          [
           "Reliability",
           " <i>AI at Google: our principles</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Reliability",
           " <i>We will continue to develop and apply strong safety and security practices to<br>avoid unintended results that create risks of harm. We will design our AI<br>systems to be appropriately cautious, and seek to develop them following best<br>practices in AI safety research. Many technologies have multiple uses. We will<br>work to limit potentially harmful or abusive applications.</i>"
          ],
          [
           "Reliability",
           " <i>Directive on Automated Decision-Making</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Reliability",
           " <i>The expected results of this Directive are as follows: Impacts of algorithms on<br>administrative decisions are assessed and negative outcomes are reduced, when<br>encountered.</i>"
          ],
          [
           "Reliability",
           " <i>Responsible use of artificial intelligence (AI)</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Reliability",
           " <i>To ensure the effective and ethical use of AI the government will: understand<br>and measure the impact of using AI by developing and sharing tools and<br>approaches.</i>"
          ],
          [
           "Reliability",
           " <i>10 ethical guidelines for the digitalisation of companies (10 ethische<br>Leitlinien für die Digitalisierung von Unternehmen)</i>",
           " 2017",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Reliability",
           " <i>The security and quality of the data shall be guaranteed. The quality of<br>personal data must be checked and faulty collection, processing, and linking of<br>data must be avoided. Adequate security technologies shall protect the company<br>from hacking. In the event of security breaches or a hacking attack, the<br>affected parties and the public must be informed immediately.</i>"
          ],
          [
           "Reliability",
           " <i>Ethics Guidelines for Trustworthy AI</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Reliability",
           " <i>A crucial component of achieving Trustworthy AI is technical robustness, which<br>is closely linked to the principle of prevention of harm. Technical robustness<br>requires that AI systems be developed with a preventative approach to risks and<br>in a manner such that they reliably behave as intended while minimizing<br>unintentional and unexpected harm, and preventing unacceptable harm.</i>"
          ],
          [
           "Reliability",
           " <i>Declaration of Ethical Principles for AI in Latin America (Declaración de<br>Principios Éticos para la IA de Latinoamérica)</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Latin America",
           " Unspecified",
           " Reliability",
           " <i>Given the non-deterministic nature of intelligent systems, constant testing, and<br>validation system must be established, which includes the inputs made to the<br>system and its global behavior. The architecture of AI systems must set<br>behavioral limits. Allocate resources and focus on the security of systems and<br>data. Cyber ​​security must be a priority for everyone, not only to maintain and<br>improve services but also as a fundamental part of creating the necessary trust.</i>"
          ],
          [
           "Reliability",
           " <i>IBM’s Principles for Trust and Transparency</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Reliability",
           " <i>IBM is devoting our powerful engines of innovation to creating tools to protect<br>our clients, their data, and global trade from cyber threats. We are also<br>convening a broader discussion on balancing security, privacy, and freedom.</i>"
          ],
          [
           "Reliability",
           " <i>China’s Artificial Intelligence Industry Alliance Self-discipline Convention</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Reliability",
           " <i>Ensure that AI systems operate securely/safely, reliably, and controllably<br>throughout their lifecycle. Evaluate system security/safety and potential risks,<br>and continuously improve system maturity, robustness, and anti-tampering<br>capabilities. Ensure that the system can be supervised and promptly taken over<br>by humans to avoid the negative effects of loss of system control.</i>"
          ],
          [
           "Reliability",
           " <i>Mid- to Long-Term Master Plan in Preparation for the Intelligent Information<br>Society Managing the Fourth Industrial Revolution</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " South Korea",
           " Reliability",
           " <i>Establish a public-private partnership council tasked with monitoring,<br>researching, and preventing technological trends and risks that may perpetuate<br>the negative impacts of new technologies. Develop AI-based cyber immunity and<br>automated defense systems.</i>"
          ],
          [
           "Reliability",
           " <i>Charlevoix Common Vision for the Future of Artificial Intelligence</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " International Organization",
           " Intergovernmental Organization",
           " G7",
           " Reliability",
           " <i>We, the leaders of the G7, commit to investing in cybersecurity, promoting<br>research and development by industry in safety, assurance, data quality, and<br>data security.</i>"
          ],
          [
           "Reliability",
           " <i>The Ethics of Artificial Intelligence</i>",
           " Unspecified",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Reliability",
           " <i>It will also become increasingly important that AI algorithms be robust against<br>manipulation. Robustness against manipulation is an ordinary criterion in<br>information security; nearly the criterion.</i>"
          ],
          [
           "Reliability",
           " <i>Next-Generation AI Governance Principles - Develop responsible artificial<br>intelligence</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Reliability",
           " <i>It's necessary to pay close attention to the safety/security of AI systems,<br>improve the robustness and tamper-resistance of AI, and form AI security<br>assessment and management capabilities.</i>"
          ],
          [
           "Reliability",
           " <i>Draft AI R&D Guidelines for International Discussions</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Reliability",
           " <i>AI developers must ensure that they verify and validate their systems in advance<br>to control relatable risk. They must ensure that there is the quality of<br>experiment done before applying the systems in society. Furthermore, developers<br>must ensure that trustworthy humans or other AI systems new supervise these<br>systems. AI designers must ensure that they pay attention to the security of AI<br>systems. In this sense, they ought to follow the security guidelines and<br>international security standards to mitigate risks.</i>"
          ],
          [
           "Reliability",
           " <i>Responsible bots: 10 guidelines for developers of conversational AI</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Reliability",
           " <i>Assess whether the bot’s intended purpose can be performed responsibly;<br>Establish how the bot can help and the limitations associated with its use;<br>Apply machine learning techniques and keyword filtering mechanisms to enable<br>your bot to detect and — critically — respond appropriately to sensitive or<br>offensive input from users; Your bot should be resilient; Obtain security<br>review.</i>"
          ],
          [
           "Reliability",
           " <i>Toward a G20 Framework for Artificial Intelligence in the Workplace</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " Canada",
           " Reliability",
           " <i>AI should be designed within explicit operational requirements and undergo<br>exhaustive testing to ensure that it responds safely to unanticipated situations<br>and does not evolve in unexpected ways.</i>"
          ],
          [
           "Reliability",
           " <i>Digital ethics: a guide for professionals of the digital age</i>",
           " 2018",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " France",
           " Reliability",
           " <i>Ensure that digital applications and solutions have not been designed in such a<br>way as to deliberately manipulate users by exploiting cognitive biases.</i>"
          ],
          [
           "Reliability",
           " <i>The Future Computed – Artificial intelligence and its role in society</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Reliability",
           " <i>AI systems should perform reliably and safely. Design and testing should also<br>anticipate and protect against the potential for unintended system interactions<br>or bad actors to influence operations, such as through cyberattacks.</i>"
          ],
          [
           "Reliability",
           " <i>Statement on Algorithmic Transparency and Accountability</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Reliability",
           " <i>Institutions should use rigorous methods to validate their models and document<br>those methods and results. In particular, they should routinely perform tests to<br>assess and determine whether the model generates discriminatory harm.<br>Institutions are encouraged to make the results of such tests public.</i>"
          ],
          [
           "Reliability",
           " <i>Responsible AI - Microsoft AI principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Reliability",
           " <i>AI systems should perform reliably and safely.</i>"
          ],
          [
           "Reliability",
           " <i>For a meaningful Artificial Intelligence - Towards a French and European<br>strategy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Reliability",
           " <i>Public authorities must act to develop and implement standards, tests, and<br>measurement methods in a bid to make AI technology more secure, more reliable,<br>useable, and interoperable.</i>"
          ],
          [
           "Reliability",
           " <i>It’s Time to Do Something: Mitigating the Negative Impacts of Computing Through<br>a Change to the Peer Review Process</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " Eastern Asia, Central Europe",
           " Turkey, Turkey",
           " Reliability",
           " <i>Peer reviewers should require that papers and proposals rigorously consider all<br>reasonable broader impacts, both positive and negative. Reviewers should not<br>only require that potential positive and negative impacts simply be mentioned,<br>but also that they are strongly motivated.</i>"
          ],
          [
           "Reliability",
           " <i>Digital Technology and Healthcare which ethical issues for which regulations?</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " France",
           " Reliability",
           " <i>The ethical issues of digital technology in healthcare are dealt differently at<br>the European or international level, but there is a consensus on the need to<br>take practical measures, which will be as responsive to change as possible, to<br>ensure the reliability of digital applications and control of their use.</i>"
          ],
          [
           "Reliability",
           " <i>Business Ethics and Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " Western Europe",
           " United Kingdom",
           " Reliability",
           " <i>AI designers and companies must ensure that we can rely on AI to perform the<br>task it is created to perform. Designers of AI systems must ensure that their<br>systems produce correct, precise, and reliable results. Designers must ensure<br>that we can rely on AI to perform its designed task.</i>"
          ],
          [
           "Reliability",
           " <i>Digital Decisions</i>",
           " Unspecified",
           " Recommendation",
           " Non-profit Organization",
           " Western Europe, North America",
           " Belgium, United States of America",
           " Reliability",
           " <i>A system must be able to be trusted to behave as is expected and anticipated by<br>its designers. Rather than requiring designers to understand the specific reason<br>for an outcome, reliable systems can be trusted to deliver consistent results.</i>"
          ],
          [
           "Reliability",
           " <i>Big Data, Artificial Intelligence, Machine Learning, and Data Protection</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Reliability",
           " <i>It may not be possible to establish with absolute certainty that an individual<br>cannot be identified from a particular dataset, taken together with other data<br>that may exist elsewhere. Organisations should focus on mitigating the risks to<br>the point where the chance of reidentification is extremely remote.<br>Organisations using anonymised data need to be able to show they have robustly<br>assessed the risk of re-identification, and have adopted solutions proportionate<br>to the risk.</i>"
          ],
          [
           "Reliability",
           " <i>Model AI Governance Framework</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " Southeast Asia",
           " Singapore",
           " Reliability",
           " <i>Organisations can consider implementing a sound system of risk management and<br>internal controls that specifically addresses the risks involved in the<br>deployment of the selected AI model.</i>"
          ],
          [
           "Reliability",
           " <i>Artificial Intelligence Ethics and Safety: practical tools for creating \"good\"<br>models</i>",
           " 2021",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Latin America",
           " Brazil",
           " Reliability",
           " <i>This is one of the roles of the AI safety engineer. Not only to evaluate the<br>possible biases and problems that may arise during the training of a model and<br>after its implementation in a given context but to seek to mitigate new problems<br>that may arise. For this, we need quantitative methods to evaluate, stress, and<br>attack our models.</i>"
          ],
          [
           "Reliability",
           " <i>Asilomar AI Principles</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Reliability",
           " <i>AI systems should be safe and secure throughout their operational lifetime, and<br>verifiably so where applicable and feasible. Risks posed by AI systems,<br>especially catastrophic or existential risks, must be subject to planning and<br>mitigation efforts commensurate with their expected impact.</i>"
          ],
          [
           "Reliability",
           " <i>Code of Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Professional Association",
           " North America",
           " United States of America",
           " Reliability",
           " <i>Software engineers shall ensure that their products and related modifications<br>meet the highest professional standards possible.</i>"
          ],
          [
           "Reliability",
           " <i>G20 Ministerial Statement on Trade and Digital Economy</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " G20",
           " Reliability",
           " <i>AI systems should be robust, secure, and safe throughout their entire lifecycle.</i>"
          ],
          [
           "Reliability",
           " <i>Philips AI Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Netherlands",
           " Reliability",
           " <i>We develop AI-enabled solutions that are intended to do no harm, with the<br>appropriate protection against deliberate or inadvertent misuse.</i>"
          ],
          [
           "Reliability",
           " <i>  Philips Data Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Netherlands",
           " Reliability",
           " <i>We ensure the security of all data entrusted to us. We operate under global<br>security policies that guide our activities to protect against vulnerabilities<br>and manage any incidents.</i>"
          ],
          [
           "Reliability",
           " <i>AI 4People 's Ethical Framework for a Good AI Society: Opportunities, Risks,<br>Principles, and Recommendations</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Reliability",
           " <i>Those developing AI should assume their responsibility by working against the<br>risks arising from their technological innovations.</i>"
          ],
          [
           "Reliability",
           " <i>Rome Call for AI Ethics</i>",
           " 2020",
           " Recommendation",
           " Religious Institution",
           " Southern Europe",
           " Vatican City State",
           " Reliability",
           " <i>AI systems must be able to work reliably.</i>"
          ],
          [
           "Reliability",
           " <i>A practical guide to Responsible Artificial Intelligence (AI)</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Reliability",
           " <i>To be effective and reliable, AI systems need to be resilient, secure, and safe.<br>Above all, though, AI systems must be safe for the people whose lives they<br>affect, whether they are users of AI or the subjects of AI-enabled decisions.</i>"
          ],
          [
           "Reliability",
           " <i>Ethically Aligned Design: A Vision for Prioritizing Human Well-being with<br>Autonomous and Intelligent Systems, Version 2</i>",
           " 2017",
           " Recommendation",
           " Professional Association",
           " North America",
           " United States of America",
           " Reliability",
           " <i>A/IS must be verifiably safe and secure throughout their operational lifetime.<br>Because designers cannot anticipate all possible operating conditions and<br>potential failures of A/IS, multiple additional strategies to mitigate the<br>chance and magnitude of harm must be in place. Teams working on developing AGI<br>systems should be aware that much technical robustness and safety issues are<br>even present in today’s systems and that, given more research, some corrective<br>techniques for those can likely scale with more complex problem manifestations.</i>"
          ],
          [
           "Reliability",
           " <i>Užupis Principles for Trustworthy AI Design</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Europe",
           " Lithuania",
           " Reliability",
           " <i>I promise to do my best to identify anybody and anything affected by my AI and<br>that I will research and anticipate its impact, its uses, and its possible<br>misuses. I promise to continuously monitor the impact of my AI and regularly<br>seek feedback from the various groups affected by it. I promise to revise or<br>even discard my AI if I discover that it did or could cause harm to anybody or<br>anything.</i>"
          ],
          [
           "Reliability",
           " <i>Hippocratic Oath for Data Scientists</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization",
           " Western Europe",
           " France",
           " Reliability",
           " <i>Configure and test several models by not stopping at the first model and<br>configuration that seems good to me. Ensure that the data for which I am<br>responsible is managed and stored securely.</i>"
          ],
          [
           "Reliability",
           " <i>Artificial intelligence and Privacy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Norway",
           " Reliability",
           " <i>Anyone processing personal data must assess the risks involved. If an enterprise<br>believes that a planned process is likely to pose a high risk to natural<br>persons’ rights and freedoms, it must conduct a data protection impact<br>assessment (DPIA). This is described in Article 35 of the GDPR.</i>"
          ],
          [
           "Reliability",
           " <i>Safety & Ethics</i>",
           " 2021",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Reliability",
           " <i>AI systems can only benefit the world if we make them reliable and safe.<br>Technical safety is a core element of our research. Our goal is to ensure that<br>AI systems of the future are proven to be safe - because we’ve built them that<br>way. Just as software engineering has a set of best practices for security and<br>reliability, our AI safety teams develop approaches to specification,<br>robustness, and assurance for AI systems both now and in the future. Our team of<br>ethicists and policy researchers works closely with our AI research team to<br>understand how technological advances will impact society, and find ways to<br>reduce risk.</i>"
          ],
          [
           "Reliability",
           " <i>Code of conduct for data-driven health and care technology</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Reliability",
           " <i>Ensure that the product is appropriately tested and is fit for its purpose. All<br>health technology should be sufficiently tested across a range of domains as<br>appropriate and listed below, to evidence that it is suitable for its stated<br>purpose and will provide a robust and stable service. All digital health<br>technologies must be clinically safe to use. To sell into the NHS, manufacturers<br>must demonstrate compliance with the Clinical Safety Standards referred to as<br>DCB0129 and DCB0160. This is mandated under the Health and Social Care Act 2012.</i>"
          ],
          [
           "Reliability",
           " <i>Digital Ethics Guidelines on AI</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Reliability",
           " <i>Data security is a prime quality of Deutsche Telekom. To maintain this asset, we<br>ensure that our security measures are up to date while having a full overview of<br>how customer related data is used and who has access to which kind of data.</i>"
          ],
          [
           "Reliability",
           " <i>Ethics Framework - Responsible AI</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Reliability",
           " <i>Safety and potential harm should be considered, both in consequence of the<br>product’s intended use and other reasonably foreseeable uses. There should be<br>processes in place to monitor and evaluate the integrity of the system over<br>time, with clarity over what the quality measures are, and how chosen.</i>"
          ],
          [
           "Reliability",
           " <i>AI Ethics Principles & Guidelines</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Middle East",
           " United Arab Emirates",
           " Reliability",
           " <i>Developers should make efforts to mitigate the risks inherent in the systems<br>they design. AI systems should be verifiably secure and controllable throughout<br>their operational lifetime, to the extent permitted by technology. Recursively<br>self-improving AI development should be disclosed and tightly monitored and<br>controlled for risk. Long-term risks of AI should be identified and planned for.</i>"
          ],
          [
           "Reliability",
           " <i>Principles of Robotics</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Reliability",
           " <i>Robots are products. They should be designed using processes that assure their<br>safety and security.</i>"
          ],
          [
           "Reliability",
           " <i>Algo.Rules: Rules for the Design of Algorithmic Systems</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Private Corporation",
           " Western Europe",
           " Germany",
           " Reliability",
           " <i>The security of an algorithmic system must be tested before and during its<br>implementation. The reliability and robustness of an algorithmic system, as well<br>as its underlying data concerning attacks, access, and manipulation, must be<br>guaranteed. Security must be built into the architecture of the algorithmic<br>system (security by design). The system must be tested in a protected<br>environment before implementation. Security precautions must be documented.</i>"
          ],
          [
           "Reliability",
           " <i>From Principles to Practice: An interdisciplinary framework to operationalise AI<br>ethics</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Professional Association",
           " Western Europe",
           " Germany",
           " Reliability",
           " <i>The consequences of erroneous outcomes, accidents, or misuse of AI systems can<br>affect individuals, parts of a system, or an entire society. Because of the<br>different dimensions of harm, adequate strategies to build a reliable and<br>trustworthy infrastructure have to be developed. As reliability is not only the<br>precondition for trust in and/or predictability of the AI system but also a<br>significant factor in the prevention of individual and societal harm, it is not<br>only a technical but also an ethical principle.</i>"
          ],
          [
           "Reliability",
           " <i>Beijing AI Principles</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Eastern Asia",
           " China",
           " Reliability",
           " <i>Continuous efforts should be made to improve the maturity, robustness,<br>reliability, and controllability of AI systems, to ensure the security for the<br>data, the safety and security for the AI system itself, and the safety for the<br>external environment where the AI system deploys. Continuous research on the<br>potential risks of Augmented Intelligence, Artificial General Intelligence<br>(AGI), and Superintelligence should be encouraged. Strategic designs should be<br>considered to ensure that AI will always be beneficial to society.</i>"
          ],
          [
           "Reliability",
           " <i>Artificial Intelligence: opportunities, risks and recommendations for the<br>financial sector</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Luxembourg",
           " Reliability",
           " <i>Institutions should perform impact assessments to determine the possible<br>(physical or psychological) impacts that the solution may have on humans and<br>consider the level of autonomy of the AI/ML solution. Whenever appropriate,<br>institutions should embed adequate safety protections into the design of the<br>AI/ML product.</i>"
          ],
          [
           "Reliability",
           " <i>Data protection and Big Data (Datenschutz und Big Data)</i>",
           " 2017",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Reliability",
           " <i>If certain personal data is unlawfully disclosed to third parties and this<br>seriously affects the data subjects, companies must report the data breach to<br>the responsible supervisory authority and the data subjects themselves (Section<br>42a BDSG). No computer used for business should be connected to the Internet<br>without protection by a suitable firewall. IT systems should be regularly<br>maintained. An action plan for security updates and regular and comprehensive<br>security backups are also recommended.</i>"
          ],
          [
           "Reliability",
           " <i>Responsible Artificial Intelligence in the Government of Canada (whitepaper)</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Reliability",
           " <i>Organizations should ensure that reliable contingencies are in place for when AI<br>systems fail, or to provide services to those unable to access these systems.<br>If AI is going to make decisions, recommendations, or help design policy, there<br>needs to be a sufficient level of social trust that these systems work, and work<br>to the population’s benefit. If trust and support do not exist, then these tools<br>will fail.</i>"
          ],
          [
           "Reliability",
           " <i>Artificial Intelligence in Healthcare</i>",
           " 2019",
           " Recommendation",
           " Academic",
           " Western Europe",
           " United Kingdom",
           " Reliability",
           " <i>As with traditional clinical activity, patient safety must remain paramount and<br>AI must be developed in a regulated way in partnership between clinicians and<br>computer scientists.</i>"
          ],
          [
           "Reliability",
           " <i>SAP’s guiding principles for Artificial Intelligence</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Reliability",
           " <i>As with any of our products, our AI software is subject to our quality assurance<br>process, which we continuously adapt when necessary. Our AI software undergoes<br>thorough testing under real-world scenarios to firmly validate that they are fit<br>for purpose and that the product specifications are met.</i>"
          ],
          [
           "Reliability",
           " <i>People + AI Guidebook</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Reliability",
           " <i>When dealing with a probabilistic, dynamic system, a user could perceive a<br>failure in situations where the system is working as intended. Acknowledging<br>that a product is a work-in-progress can help encourage the adoption and<br>feedback that designers and engineers need to continue improving the AI. The<br>inherent complexity of AI-powered systems can make identifying the source of an<br>error challenges. It’s important to discuss as a team how you’ll discover errors<br>and discern their sources.</i>"
          ],
          [
           "Reliability",
           " <i>Responsible AI practices</i>",
           " Unspecified",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Reliability",
           " <i>Identify potential threats to the system. Consider whether anyone would have an<br>incentive to make the system misbehave. Identify what unintended consequences<br>would result from the system making a mistake, and assess the likelihood and<br>severity of these consequences. Test the performance of your systems in the<br>adversarial setting.</i>"
          ],
          [
           "Reliability",
           " <i>Artificial Intelligence at Google: Our Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Reliability",
           " <i>We believe that AI should be built and tested for safety. We will continue to<br>develop and apply strong safety and security practices to avoid unintended<br>results that create risks of harm. We will design our AI systems to be<br>appropriately cautious, and seek to develop them in accordance with best<br>practices in AI safety research. In appropriate cases, we will test AI<br>technologies in constrained environments and monitor their operation after<br>deployment.</i>"
          ],
          [
           "Reliability",
           " <i>Universal principles of data ethics: 12 guidelines for developing ethics codes</i>",
           " 2016",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Reliability",
           " <i>Strive to match privacy and security safeguards with privacy and security<br>expectations. Data subjects hold a range of expectations about the privacy and<br>security of their data and those expectations are often context-dependent.<br>Designers and data professionals should give due consideration to those<br>expectations and align safeguards and expectations as much as possible.</i>"
          ],
          [
           "Reliability",
           " <i>Universal Guidelines for Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Belgium",
           " Reliability",
           " <i>Institutions must ensure the accuracy, reliability, and validity of decisions.<br>Institutions must establish data provenance, and assure quality and relevance<br>for the data input into algorithms. Institutions must assess the public safety<br>risks that arise from the deployment of AI systems that direct or control<br>physical devices, and implement safety controls. Institutions must secure AI<br>systems against cybersecurity threats.</i>"
          ],
          [
           "Reliability",
           " <i>The Future Society, Law & Society Initiative, Principles for the Governance of<br>AI</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Reliability",
           " <i>AI’s effectiveness shall be measurable in the real-world applications for which<br>it is intended. Measurability means the ability for both expert users and<br>ordinary citizens to gauge concretely whether AI or hybrid intelligence systems<br>are meeting their objectives. Operators of AI systems shall have appropriate<br>competencies. When our health, our rights, our lives, or our liberty depend on<br>hybrid intelligence, such systems should be designed, executed, and measured by<br>professionals with the requisite expertise.</i>"
          ],
          [
           "Reliability",
           " <i>Sony Group AI Ethics Guidelines</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " Japan",
           " Reliability",
           " <i>Sony understands the need for safety when dealing with products and services<br>utilizing AI and will continue to respond to security risks such as unauthorized<br>access. AI systems may utilize statistical or probabilistic methods to achieve<br>results. In the interest of Sony’s customers and to maintain their trust, Sony<br>will design whole systems with an awareness of the responsibility associated<br>with the characteristics of such methods.</i>"
          ],
          [
           "Reliability",
           " <i>Principles for the safe and effective use of data and analytics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Oceania",
           " New Zealand",
           " Reliability",
           " <i>Decision-makers need to be aware of how data is collected and analyzed,<br>including the accuracy, precision, consistency, and completeness of data<br>quality, and take special care when re-using data that was originally collected<br>for another purpose. Regular assessments to check for bias and other harmful<br>elements, and address any over-reliance on correlations, are essential in the<br>development and operation of analytical processes. Feeding assessment outcomes<br>back into the design of systems and processes can help ensure unfair or<br>discriminatory outcomes aren’t generated.</i>"
          ],
          [
           "Reliability",
           " <i>Recommendations for the responsible use of AI and automated decision-making -<br>Corporate Digital Responsibility and Decision Making (Empfehlungen für den<br>verantwortlichen Einsatz von KI und automatisierten Entscheidungen - Corporate<br>Digital Responsibility and Decision Making)</i>",
           " 2018",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Reliability",
           " <i>As part of the ethical guidelines, it must be ensured that the algorithms can<br>make the prediction precisely and accurately. Companies should carefully review<br>the data to be used, data categories, and the use of data before deploying an AI<br>system, and the criteria according to which data is introduced, especially in<br>self-learning systems, should be reviewed with a view to sources of error and<br>documented as comprehensibly as possible.</i>"
          ],
          [
           "Reliability",
           " <i>Code of Ethics for Data-Based Value Creation</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Switzerland",
           " Reliability",
           " <i>You should not harm individuals or communities. This basic orientation includes<br>the values of protection (e.g., against data loss) and security (e.g., of data<br>against hackers).</i>"
          ],
          [
           "Reliability",
           " <i>Guidelines for the responsible use of artificial intelligence and other digital<br>technologies in human resources work</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Reliability",
           " <i>Anyone offering or using AI solutions must make sure that they are empirically<br>evaluated are and have a theoretical basis. Those who introduce AI solutions<br>following these guidelines should transparently ensure that the guidelines are<br>also observed during operational implementation and further development.</i>"
          ],
          [
           "Reliability",
           " <i>Telefónica´s Approach to the Responsible Use of AI (Enfoque de Telefónica para<br>un uso responsable de la IA)</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Spain",
           " Reliability",
           " <i>Privacy and Security by Design mean that when creating AI systems, which are<br>fueled by data, privacy, and security aspects are an inherent part of the<br>system’s lifecycle.</i>"
          ],
          [
           "Reliability",
           " <i>Automated and connected automated driving (Automatisiertes und Vernetztes<br>Fahren)</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Germany",
           " Reliability",
           " <i>Partially and fully automated traffic systems serve first and foremost to<br>improve the safety of all road users. In addition, the aim is to increase<br>mobility opportunities and enable other benefits. Manufacturers or operators are<br>obliged to continuously optimize their systems and also to monitor and improve<br>systems that have already been delivered, where this is technically possible and<br>permissible. Automated driving is only justifiable to the extent that<br>conceivable attacks, in particular manipulation of the IT system or inherent<br>system weaknesses, do not lead to such damage as to cause a lasting loss of<br>confidence in road traffic.</i>"
          ],
          [
           "Reliability",
           " <i>Telia Company Guiding Principles on trusted AI ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Sweden",
           " Reliability",
           " <i>We monitor AI solutions so that we are continuously ready to intervene into AI,<br>datasets, and algorithms, to identify needs for improvements and to prevent<br>and/or reduce damage. Our solutions are built and tested to prevent possible<br>misuse and reduce the risk of being compromised or causing harm.</i>"
          ],
          [
           "Reliability",
           " <i>Responsible AI and robotics: An ethical framework</i>",
           " Unspecified",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Reliability",
           " <i>As more reliance is placed on AI, the importance of cybersecurity will increase.<br>Security must be a top priority for all actors if trust is to be maintained. the<br>need for strong protection against hacking will increase as AI systems take a<br>heightened role in society.</i>"
          ],
          [
           "Reliability",
           " <i>European ethical Charter on the use of Artificial Intelligence in judicial<br>systems and their environment</i>",
           " 2018",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Reliability",
           " <i>concerning the processing of judicial decisions and data, use certified sources<br>and intangible data with models elaborated in a multi-disciplinary manner, in a<br>secure technological environment.</i>"
          ],
          [
           "Reliability",
           " <i>Report on Artificial Intelligence and Human Society</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Reliability",
           " <i>Technologies for cyber security and privacy protection must be advanced. R&D<br>should be conducted to develop technologies that enable people to control the<br>safety features of AI technologies, to explain the processes and logics of<br>calculations inside AI technologies, to provide interfaces that smoothly perform<br>transitions of control from AI to human, especially in emergencies.</i>"
          ],
          [
           "Reliability",
           " <i>Tokyo Statement - Useful Artificial Intelligence- Beneficial AI -Cooperation for<br>Realization</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Asia",
           " Japan",
           " Reliability",
           " <i>Artificial intelligence must be proven to be safe, reliable, robust, and<br>developed in line with the values ​​of the society in which it is utilized.</i>"
          ],
          [
           "Reliability",
           " <i>Understanding artificial intelligence ethics and safety: A guide for the<br>responsible design and implementation of AI systems in the public sector</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Western Europe",
           " United Kingdom",
           " Reliability",
           " <i>Beyond safeguarding the sustainability of your AI project as it relates to its<br>social impacts on individual wellbeing and public welfare, your project team<br>must also confront the related challenge of technical sustainability or safety.<br>A technically sustainable AI system is safe, accurate, reliable, secure, and<br>robust.</i>"
          ],
          [
           "Reliability",
           " <i>Safety First for Automated Driving – Proposed technical standards for the<br>development of Automated Driving</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Reliability",
           " <i>If safety-related functions or system components become hazardous (e.g.<br>unavailable), the automated driving system shall: be capable of compensating and<br>transferring the system to a safe condition/state (with acceptable risk),<br>ensuring a sufficient time frame for the safe transition of control to the<br>vehicle operator. The loss of safety-related functions or system components<br>shall not lead to a safety-related situation.</i>"
          ],
          [
           "Reliability",
           " <i>Opinion of the Data Ethics Commission</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Reliability",
           " <i>Guaranteeing security entails compliance with stringent requirements, e.g. in<br>relation to human/machine interaction or system resilience to attacks and<br>misuse. Algorithmic systems must be robust and secure, otherwise, the legitimate<br>goals they are used to pursuing will not be achieved or will be achieved only at<br>the expense of potential harm to ethically and legally protected rights and<br>interests.</i>"
          ],
          [
           "Reliability",
           " <i>Artificial Intelligence and Data Protection</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Reliability",
           " <i>An approach focused on avoiding and mitigating the potential risks of processing<br>personal data is a necessary element of responsible innovation in the field of<br>AI. AI developers, manufacturers, and service providers should assess the<br>possible adverse consequences of AI applications on human rights and fundamental<br>freedoms, and, considering these consequences, adopt a precautionary approach<br>based on appropriate risk prevention and mitigation measures.</i>"
          ],
          [
           "Reliability",
           " <i>Statement on Artificial Intelligence, Robotics and 'Autonomous‘ Systems</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Reliability",
           " <i>Safety and security of ‘autonomous’ systems materialize in three forms: (1)<br>external safety for their environment and users, (2) reliability and internal<br>robustness, e.g., against hacking, and (3) emotional safety concerning human-<br>machine interaction. All dimensions of safety must be taken into account by AI<br>developers and strictly tested before release to ensure that ‘autonomous’<br>systems do not infringe on the human right to bodily and mental integrity and a<br>safe and secure environment.</i>"
          ],
          [
           "Reliability",
           " <i>Report with recommendations to the Commission on Civil Law Rules on Robotics</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " European Union",
           " European Union",
           " Reliability",
           " <i>The European Parliament notes that the potential for empowerment through the use<br>of robotics is nuanced by a set of tensions or risks and should be seriously<br>assessed from the point of view of human safety, health and security. The<br>European Parliament stresses that a high level of security in robotics systems,<br>including their internal data systems and data flows, is crucial to the<br>appropriate use of robots and AI. The European Parliament emphasizes that the<br>protection of networks of interconnected robots and artificial intelligence has<br>to be ensured to prevent potential security breaches.</i>"
          ],
          [
           "Reliability",
           " <i>Preparing for the future of Artificial Intelligence</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Reliability",
           " <i>The Department of Transportation should work with industry and researchers on<br>ways to increase sharing of data for safety, research, and other purposes.<br>Schools and universities should include ethics, and related topics in security,<br>privacy, and safety, as an integral part of curricula on AI, machine learning,<br>computer science, and data science. AI professionals, safety professionals, and<br>their professional societies should work together to continue progress toward a<br>mature field of AI safety engineering.</i>"
          ],
          [
           "Reliability",
           " <i>Principles for Accountable Algorithms and a Social Impact Statement for<br>Algorithms</i>",
           " Unspecified",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Unspecified",
           " Unspecified",
           " Reliability",
           " <i>Identity, log, and articulate sources of error and uncertainty throughout the<br>algorithm and its data sources so that expected and worst-case implications can<br>be understood and inform mitigation procedures. Enable interested third parties<br>to probe, understand, and review the behavior of the algorithm through<br>disclosure of information that enables monitoring, checking, or criticism,<br>including through the provision of detailed documentation, technically suitable<br>APIs, and permissive terms of use.</i>"
          ],
          [
           "Reliability",
           " <i>Artificial Intelligence: Economic importance, social challenges, human<br>responsibility</i>",
           " 2017",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Reliability",
           " <i>When introducing AI-based decision-making processes, it is important to ensure<br>and respect the appropriate level of accuracy concerning documentation and<br>quality assurance.</i>"
          ],
          [
           "Reliability",
           " <i>Machine learning: the power and promise of computers that learn by example</i>",
           " 2017",
           " Recommendation",
           " Academic",
           " Western Europe",
           " United Kingdom",
           " Reliability",
           " <i>Progress in some areas of machine learning research will impact directly on the<br>social acceptability of machine learning in applications and hence on public<br>confidence and trust. Funding bodies should encourage and support research<br>applications in these areas, though not to the exclusion of other areas of<br>machine learning research. These areas include algorithm interpretability,<br>robustness, privacy, fairness, inference of causality, human-machine<br>interactions, and security.</i>"
          ],
          [
           "Reliability",
           " <i>Guidance for Regulation of Artificial Intelligence Applications</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Reliability",
           " <i>Consistent with law, agencies should take into consideration the following<br>principles when formulating regulatory and non-regulatory approaches to the<br>design, development, deployment, and operation of AI applications, both general<br>and sector-specific. These principles, many of which are interrelated, reflect<br>the goals and principles in Executive Order 13859. Agencies should promote the<br>development of AI systems that are safe, secure, and operate as intended, and<br>encourage the consideration of safety and security issues throughout the AI<br>design, development, deployment, and operation process.</i>"
          ],
          [
           "Reliability",
           " <i>Tieto’s AI ethics guidelines</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Finland",
           " Reliability",
           " <i>At Tieto, we are committed to building AI systems that prevent misuse and reduce<br>the risk of being compromised.</i>"
          ],
          [
           "Reliability",
           " <i>A guide to using artificial intelligence in the public sector</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Reliability",
           " <i>With an AI project you should consider several factors, including AI ethics and<br>safety. hese factors span safety, ethical, legal and administrative concerns and<br>include: data quality - the success of your AI project depends on the quality of<br>your data.</i>"
          ],
          [
           "Reliability",
           " <i>AI in the UK: ready, willing and able?</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Reliability",
           " <i>We recommend that universities and research councils providing grants and<br>funding to AI researchers must insist that applications for such money<br>demonstrate an awareness of the implications of the research and how it might be<br>misused, and include details of the steps that will be taken to prevent such<br>misuse before any funding is provided. We recommend that the Cabinet Office’s<br>final Cyber Security Science & Technology Strategy take into account the risks<br>as well as the opportunities of using AI in cybersecurity applications, and<br>applications more broadly.</i>"
          ],
          [
           "Reliability",
           " <i>Report of COMEST on robotics ethics</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Reliability",
           " <i>The private use of drones should be under license, and their areas of operation<br>are subject to strict control for safety, privacy, and legal reasons. It should<br>be unlawful to equip domestic drones with either lethal or non-lethal weapons.</i>"
          ],
          [
           "Reliability",
           " <i>Introducing Unity’s Guiding Principles for Ethical AI</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Reliability",
           " <i>Consider the potential negative consequences of the AI tools we build.<br>Anticipate what might cause potential direct or indirect harm and engineer to<br>avoid and minimize these problems. Guard the AI-derived data as if it were<br>handed to you by your customer directly in trust to only be used as directed<br>under the other principles found in this guide.</i>"
          ],
          [
           "Reliability",
           " <i>ACM Code of Ethics and Professional Conduct</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Reliability",
           " <i>Computing professionals should perform due diligence to ensure the system<br>functions as intended, and take appropriate action to secure resources against<br>accidental and intentional misuse, modification, and denial of service.</i>"
          ],
          [
           "Reliability",
           " <i>Montréal declaration for a responsible development of artificial intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " Canada",
           " Reliability",
           " <i>Every person involved in AI development must exercise caution by anticipating,<br>as far as possible, the adverse consequences of AIS use and by taking the<br>appropriate measures to avoid them. Before being placed on the market and<br>whether they are offered for a charge or for free, AI must meet strict<br>reliability, security, and integrity requirements and be subjected to tests that<br>do not put people’s lives in danger, harm their quality of life, or negatively<br>impact their reputation or psychological integrity. These tests must be open to<br>the relevant public authorities and stakeholders.</i>"
          ],
          [
           "Reliability",
           " <i>fAIr LAC: Responsible and Widespread Adoption of Artificial Intelligence in<br>Latin America and the Caribbean</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Latin America",
           " Unspecified",
           " Reliability",
           " <i>AI systems should be robust, secure, and safe throughout their entire lifecycle<br>so that, in conditions of normal use, foreseeable use or misuse, or other<br>adverse conditions, they function appropriately and do not pose an unreasonable<br>safety risk.</i>"
          ],
          [
           "Reliability",
           " <i>Artificial Intelligence for Children: Beijing Principles</i>",
           " 2020",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Reliability",
           " <i>The application of AI should adhere to strict and prudent principles, strive to<br>control and minimize the potential risks to children. Considering that the<br>influence of AI on children's psychology, physiology, and behaviors is still to<br>be studied, and children's thinking and behaviors are highly uncertain, AI<br>technology and products for children should conform to higher standards and<br>requirements in terms of maturity, robustness, reliability, controllability,<br>safety, and security, etc.</i>"
          ],
          [
           "Reliability",
           " <i>Social Principles of Human-Centric AI</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia, Western Europe",
           " Japan, United Kingdom",
           " Reliability",
           " <i>Society must promote broad, deep research and development related to AI (from<br>immediate measures to deep essential understanding), such as the proper<br>assessment of risks in the utilization of AI and research to reduce risks.<br>Society must make firm efforts to conduct risk management including safeguarding<br>cybersecurity.</i>"
          ],
          [
           "Reliability",
           " <i>The Toronto Declaration</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " North America, Western Europe",
           " Canada, United Kingdom",
           " Reliability",
           " <i>Any state deploying machine learning technologies must thoroughly investigate<br>systems for discrimination and other rights risks before development or<br>acquisition, where possible, before use, and on an ongoing basis throughout the<br>lifecycle of the technologies, in the contexts in which they are deployed. This<br>may include: conducting regular impact assessments before public procurement,<br>taking appropriate measures to mitigate risks identified through impact<br>assessments, subjecting systems to live, regular tests and audits, disclosing<br>known limitations of the system in question.  Where the risk of discrimination<br>or other rights violations has been assessed to be too high or impossible to<br>mitigate, private sector actors should not deploy a machine learning system in<br>that context.</i>"
          ],
          [
           "Reliability",
           " <i>Position on Robotics and Artificial Intelligence</i>",
           " 2016",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Reliability",
           " <i>Robots as products should be designed to be safe, secure, and fit for purpose,<br>as other products. We propose that robots and artificial intelligence should be<br>developed and produced based on an impact assessment, to the best available<br>technical standards regarding security, and with the possibility to intervene.</i>"
          ],
          [
           "Reliability",
           " <i>Governing Artificial Intelligence: Upholding human rights & dignity</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Reliability",
           " <i>Technology companies and researchers should conduct Human Rights Impact<br>Assessments (HRIAs) through the life cycle of their AI systems. Researchers<br>should reevaluate HRIA methodology for AI, particularly in light of new<br>developments in algorithmic impact assessments. Toolkits should be developed to<br>assess specific industry needs.</i>"
          ],
          [
           "Reliability",
           " <i>AI Governance in Japan Ver. 1.1, Report from the expert group on how AI<br>principles should be implemented</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Reliability",
           " <i>Society must promote broad, deep research and development related to AI (from<br>immediate measures to deep essential understanding), such as the proper<br>assessment of risks in the utilization of AI and research to reduce risks.<br>Society must make firm efforts to conduct risk management including safeguarding<br>cybersecurity.</i>"
          ],
          [
           "Reliability",
           " <i>Principles of Artificial Intelligence Ethics for the Intelligence Community</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Reliability",
           " <i>We will develop and employ best practices for maximizing the reliability,<br>security, and accuracy of AI design, development, and use. We will employ<br>security best practices to build resilience and minimize the potential for<br>adversarial influence.</i>"
          ],
          [
           "Reliability",
           " <i>Vodafone Artificial Intelligence Framework</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Reliability",
           " <i>Our customer data will always be securely stored under strict access control and<br>in compliance with our Group data security policies and applicable local laws.<br>We will make sure that our security systems for AI are continually updated as<br>the threat landscape evolves.</i>"
          ],
          [
           "Reliability",
           " <i>Artificial Intelligence at the service of the citizen (L’intelligenzia<br>artificiale al servizio del cittadino)</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Southern Europe",
           " Italy",
           " Reliability",
           " <i>Recommendation - Define guidelines and processes based on the principle of<br>security-by-design in the use of AI, increasing the levels of control and<br>facilitating the sharing of data on cyberattacks to and from AI by all European<br>countries.</i>"
          ],
          [
           "Reliability",
           " <i>oston Dynamics Ethical Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Reliability",
           " <i>We build trustworthy robots. It is imperative that robots be trustworthy if<br>people are to work productively with them. Therefore, we will build robots whose<br>missions and capabilities are predictable, understandable, transparent and in<br>service of human needs.</i>"
          ],
          [
           "Reliability",
           " <i>WLiAI Report 2019: 10 Principles of Responsible AI</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " United Kingdom",
           " Reliability",
           " <i>Recommendation - Introduce mandatory AIAs (Algorithm Impact Assessments) for<br>organizations employing AI systems that have a significant effect on<br>individuals.</i>"
          ],
          [
           "Reliability",
           " <i>The Ethical Norms for the New Generation Artificial Intelligence, China</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Reliability",
           " <i>Various activities of AI shall abide by the following fundamental ethical norms,<br>like enhancing bottom-line thinking and risk awareness, strengthening the<br>research and judgment on the potential risks during the development of AI,<br>carrying out systematic risk monitoring and evaluations promptly, establishing<br>an effective early warning mechanism for risks, and enhance the ability of<br>manage, control, and disposal of ethical risks of AI. Emergency mechanisms and<br>loss compensation plans and measures should be investigated and formulated.</i>"
          ],
          [
           "Reliability",
           " <i>Work in the age of artificial intelligence: Four perspectives on the economy,<br>employment, skills and ethics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Finland",
           " Reliability",
           " <i>The requirement of traceability is highlighted as the functions become more<br>security-critical. Particularly accurate traceability should be required in<br>functions directly concerned with human health and safety. These applications of<br>artificial intelligence are found especially in healthcare, transport, energy<br>production, and national defense.</i>"
          ],
          [
           "Reliability",
           " <i>A Framework for Responsible Limits on Facial RecognitionUse Case: Flow<br>Management</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization",
           " Western Europe",
           " Switzerland",
           " Reliability",
           " <i>Organizations creating facial recognition platforms or using facial recognition<br>as part of an experience or systems should conduct a comprehensive risk<br>assessment of their systems, including the impact on privacy, the potential for<br>errors, susceptibility to unfair bias, vulnerability to hacking and<br>cyberattacks, lack of transparency in the decision-making process and potential<br>for civil rights infringements.</i>"
          ],
          [
           "Reliability",
           " <i>A Code of Ethics for the Human-Robot Interaction Profession</i>",
           " 2014",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Reliability",
           " <i>Predictability in robotic behavior is desirable. Trustworthy system design<br>principles are required across all aspects of a robot’s operation, for both<br>hardware and software design, and for any data processing on or off the<br>platform. Obvious opt-out mechanisms (kill switches) are required to the<br>greatest extent consistent with reasonable design objectives.</i>"
          ],
          [
           "Reliability",
           " <i>Discussion Paper: National Strategy for Artificial Intelligence</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " South Asia",
           " India",
           " Reliability",
           " <i>The accountability debate on AI, which in most cases today is aimed at<br>ascertaining the liability, needs to be shifted to objectively identifying the<br>component that failed and how to prevent that in the future. An analogy can be<br>drawn to how the airlines have become a relatively safe industry today. Every<br>accident has been elaborately investigated, and a future course of action has<br>been determined. Something similar is needed to ensure safe AI. One possible<br>framework that can be mooted involves a negligence test for damages caused by AI<br>software, as opposed to strict liability. This involves self-regulation by the<br>stakeholders by conducting damage impact assessment at every stage of the<br>development of an AI model.</i>"
          ],
          [
           "Reliability",
           " <i>The National Artificial Intelligence Research and Development Strategic Plan:<br>2019 Update</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Reliability",
           " <i>Ensure the safety and security of AI systems. Advance knowledge of how to design<br>AI systems that are reliable, dependable, safe, and trustworthy. Measure and<br>evaluate AI technologies through standards and benchmarks. Develop a broad<br>spectrum of evaluative techniques for AI, including technical standards and<br>benchmarks.</i>"
          ],
          [
           "Reliability",
           " <i>OECD, Recommendation of the Council on Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " France",
           " Reliability",
           " <i>AI systems should be robust, secure, and safe throughout their entire lifecycle<br>so that, in conditions of normal use, foreseeable use or misuse, or other<br>adverse conditions, they function appropriately and do not pose an unreasonable<br>safety risk. AI actors should based on their roles, the context, and their<br>ability to act, apply a systematic risk management approach to each phase of the<br>AI system lifecycle on a continuous basis to address risks related to AI<br>systems, including privacy, digital security, safety, and bias.</i>"
          ],
          [
           "Reliability",
           " <i>OP Financial Group’s Ethical Guidelines for Artificial Intelligence</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Finland",
           " Reliability",
           " <i>We carefully study the impact of choices related to our work on our customers<br>and the community around us, and we always make responsible choices when<br>utilizing artificial intelligence.</i>"
          ],
          [
           "Reliability",
           " <i>OpenAI Charter</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization, Private Corporation",
           " North America",
           " United States of America",
           " Reliability",
           " <i>We are committed to doing the research required to make AGI safe, and to driving<br>the broad adoption of such research across the AI community. We are committed to<br>providing public goods that help society navigate the path to AGI. Today this<br>includes publishing most of our AI research, but we expect that safety and<br>security concerns will reduce our traditional publishing in the future while<br>increasing the importance of sharing safety, policy, and standards research.</i>"
          ],
          [
           "Reliability",
           " <i>Oxford Munich Code of Conduct</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Reliability",
           " <i>The Data Scientist is accountable for selecting the best accuracy measure<br>possible depending on the nature of the problem, as well as proactively<br>assessing the validity of the model. Options, accuracy measures, and choices<br>should be documented. The Data Scientist is responsible for assessing the<br>adequacy of data to solve the particular problem and sharing the results of the<br>analysis, indicating risks or potential implications due to lack of data quality<br>or availability. The Data Scientist shall be responsible to ensure<br>reproducibility in situations where understanding the overall behavior of the<br>system is critical.</i>"
          ],
          [
           "Reliability",
           " <i>Partnership on AI Tenets</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization",
           " Unspecified",
           " Unspecified",
           " Reliability",
           " <i>We will work to maximize the benefits and address the potential challenges of AI<br>technologies, by ensuring that AI research and technology is robust, reliable,<br>trustworthy, and operates within secure constraints.</i>"
          ],
          [
           "Reliability",
           " <i>UNESCO Recommendation on the Ethics of Artificial Intelligence</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Reliability",
           " <i>Unwanted harms (safety risks), as well as vulnerabilities to attack (security<br>risks), should be avoided and should be addressed, prevented, and eliminated<br>throughout the life cycle of AI systems to ensure human, environmental, and<br>ecosystem safety and security. Safe and secure AI will be enabled by the<br>development of sustainable, privacy-protective data access frameworks that<br>foster better training and validation of AI models utilizing quality data.</i>"
          ],
          [
           "Reliability",
           " <i>AI Principles: Recommendations on the Ethical Use of Artificial Intelligence by<br>the Department of Defense - Defense Innovation Board</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Reliability",
           " <i>DoD AI systems should have an explicit, well-defined domain of use, and the<br>safety, security, and robustness of such systems should be tested and assured<br>across their entire life cycle within that domain of use.</i>"
          ],
          [
           "Reliability",
           " <i>Megvii's Artificial Intelligence Application Guidelines</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " China",
           " Reliability",
           " <i>AI solutions should be able to make accurate and effective decisions while being<br>sufficiently secure and defensive against external attacks. AI solutions should<br>be extensively tested, used sparingly, and closely monitored.</i>"
          ],
          [
           "Reliability",
           " <i>The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and<br>Mitigation</i>",
           " 2018",
           " Recommendation",
           " Academic, Non-profit Organization, Private Corporation",
           " Western Europe, North America ",
           " United Kingdom, United States of America",
           " Reliability",
           " <i>Recommendation - Researchers and engineers in artificial intelligence should<br>take the dual-use nature of their work seriously, allowing misuse-related<br>considerations to influence research priorities and norms, and proactively<br>reaching out to relevant actors when harmful applications are foreseeable. Best<br>practices should be identified in research areas with more mature methods for<br>addressing dual-use concerns, such as computer security, and imported where<br>applicable to the case of AI.</i>"
          ],
          [
           "Reliability",
           " <i>AI UX: 7 Principles of Designing Good AI Products</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Europe",
           " Hungary",
           " Reliability",
           " <i>Recommendation - Find and handle edge cases so no weird or unpleasant things<br>happen to your users. Test the AI UX with methods like the Wizard of Oz testing.<br>Use the test participant’s own data when emulating AI content requires.</i>"
          ],
          [
           "Reliability",
           " <i>Policy guidance on AI for children</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution, International Organization",
           " Northern Europe, Intergovernmental Organization",
           " Finland, United Nations",
           " Reliability",
           " <i>Ensure safety for children. I need to be safe in the AI world.</i>"
          ],
          [
           "Reliability",
           " <i>Ethics & Governance of Artificial Intelligence for Health</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Reliability",
           " <i>Measures of quality control in practice and quality improvement in the use of AI<br>overtime should be available. Preventing harm requires that AI not result in<br>mental or physical harm that could be avoided by the use of an alternative<br>practice or approach.</i>"
          ],
          [
           "Reliability",
           " <i>Ethical ML Institute Responsible Machine Learning Principles</i>",
           " Unspecified",
           " Recommendation",
           " Academic",
           " Western Europe",
           " United Kingdom",
           " Reliability",
           " <i>Technologists should commit to preparing for both types of security risks<br>through explicit efforts, such as educating relevant personnel, establishing<br>processes around data, and assessing the implications of ML backdoors (such as<br>adversarial attacks). I commit to developing and improving reasonable processes<br>and infrastructure to ensure data and model security are being taken into<br>consideration during the development of machine learning systems.</i>"
          ],
          [
           "Reliability",
           " <i>HPE AI Ethics and Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Reliability",
           " <i>Be engineered to build in quality testing, include safeguards to maintain<br>functionality, and minimize misuse and impact of failure.</i>"
          ],
          [
           "Reliability",
           " <i>Thomson Reuters AI principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " Canada",
           " Reliability",
           " <i>Thomson Reuters will prioritize safety, security, and privacy throughout the<br>design, development, and deployment of our AI products and services.</i>"
          ],
          [
           "Reliability",
           " <i>Defense Innovation Unit Responsible AI Guidelines in Practice: Lessons Learned<br>from the DIU Portfolio</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Reliability",
           " <i>The Department’s AI capabilities will have explicit, well-defined uses and the<br>safety, security, and effectiveness of such capabilities will be subject to<br>testing and assurance within those defined uses across their entire life cycles.<br>The Department will design and engineer AI capabilities to fulfill their<br>intended functions while possessing the ability to detect and avoid unintended<br>consequences, and the ability to disengage or deactivate deployed systems that<br>demonstrate unintended behavior.</i>"
          ],
          [
           "Reliability",
           " <i>DoD Ethical Principles for Artificial Intelligence</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Reliability",
           " <i>The Department’s AI capabilities will have explicit, well-defined uses and the<br>safety, security, and effectiveness of such capabilities will be subject to<br>testing and assurance within those defined uses across their entire life cycles.<br>The Department will design and engineer AI capabilities to fulfill their<br>intended functions while possessing the ability to detect and avoid unintended<br>consequences, and the ability to disengage or deactivate deployed systems that<br>demonstrate unintended behavior.</i>"
          ],
          [
           "Reliability",
           " <i>Alpha Principles for the Ethical Use of AI and Data Driven Technologies in<br>Ontario</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Reliability",
           " <i>Data-driven technologies like AI and ML systems must function in a robust,<br>secure, and safe way throughout their life cycles and potential risks should be<br>continually assessed and managed. Designers and developers should implement<br>mechanisms and safeguards, such as the capacity for human determination and<br>complete halt of the system operations, that are appropriate to the context and<br>predetermined at initial deployment.</i>"
          ],
          [
           "Reliability",
           " <i>Transparency Guidelines for Data-Driven Technology in Government</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Reliability",
           " <i>Many jurisdictions are beta testing impact assessments to support safe and<br>responsible AI and data use. These tools can help express intentions,<br>expectations, and outcomes. Adding a deeper dimension to measurement and risk<br>mitigations beyond technical specifications.</i>"
          ],
          [
           "Reliability",
           " <i>Integrate’s AI principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " Canada",
           " Reliability",
           " <i>Keeping customers and end-users safe should be a function of every AI system. If<br>they aren’t, everything else is irrelevant. Data security and customer privacy<br>are foundational to what we do. That’s why we’ve implemented Privacy by Design<br>standards. We’re also transparent about how we handle data. We never accept,<br>use, or store any personally identifiable information (PII). We do not<br>compromise on our principle of safety, even in instances where a risky approach<br>might yield better results.</i>"
          ],
          [
           "Reliability",
           " <i>National Association of Insurance Commissioners (NAIC) Principles on Artificial<br>Intelligence (AI)</i>",
           " 2020",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Reliability",
           " <i>AI systems should be robust, secure, and safe throughout the entire life cycle<br>so that in conditions of normal or reasonably foreseeable use, or adverse<br>conditions, they can function in compliance with applicable laws and<br>regulations. To this end, AI actors should ensure a reasonable level of<br>traceability concerning datasets, processes, and decisions made during the AI<br>system life cycle. AI actors should enable an analysis of the AI system’s<br>outcomes, responses, and other insurance-related inquiries, as</i>"
          ],
          [
           "Reliability",
           " <i>Samsung Principles for AI Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " South Korea",
           " Reliability",
           " <i>AI system will be adequately protected and have security measures to prevent<br>data breach and cyber attacks.</i>"
          ],
          [
           "Reliability",
           " <i>IBM AI Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Reliability",
           " <i>AI must be secure and robust.</i>"
          ],
          [
           "Reliability",
           " <i>Linux Foundation AI Principles</i>",
           " 2020",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Reliability",
           " <i>Reproducibility is the ability of an independent team to replicate in an<br>equivalent AI environment, domain or area, the same experiences or results using<br>the same AI methods, data, software, codes, algorithms, models, and<br>documentation, to reach the same conclusions as the original research or<br>activity. Adhering to this principle will ensure the reliability of the results<br>or experiences produced by any AI. Robustness refers to the stability,<br>resilience, and performance of the systems and machines dealing with changing<br>ecosystems. AI must function robustly throughout its life cycle and potential<br>risks should be continually assessed and managed. Security and safety of AI<br>should be tested and assured across the entire life cycle within an explicit and<br>well-defined domain of use. In addition, any AI should be designed to also<br>safeguard the people who are impacted.</i>"
          ],
          [
           "Reliability",
           " <i>ADP: Ethics in Artificial Intelligence</i>",
           " 2022",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Reliability",
           " <i>While AI holds the potential to mitigate human bias, without proper oversight it<br>can incorporate bias as well. We have implemented audit and risk assessments to<br>test our ML models as the baseline of our oversight methodologies. We continue<br>to actively monitor and improve our models and systems to ensure that changes in<br>the underlying data or model conditions do not inappropriately affect the<br>desired results. And we apply our existing compliance, business ethics, and risk<br>management governance structures to our ML development activities.</i>"
          ],
          [
           "Reliability",
           " <i>Ethical Aspects of Autonomous and Intelligent Systems</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Reliability",
           " <i>Developers and operators should consider the effectiveness and fitness of A/IS<br>technologies for the purpose of their systems.  Designers of A/IS creators<br>should consider and guard against potential misuses and operational risks.<br>Designers of A/IS should specify operators should possess the knowledge and<br>skill required for safe and effective operation.</i>"
          ],
          [
           "Reliability",
           " <i>IEEE Position Statement - Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Reliability",
           " <i>To ensure that artificial intelligence serves the interests of society, IEEE<br>urges governments to adopt policies that develop protocols for field testing<br>systems employing artificial intelligence. Engineers need field trials to test<br>AI systems in a public setting to determine their safety and effectiveness, to<br>gather data, and to let the machine learn to operate in public. But field<br>testing of AI systems can pose a risk to the public, one that the public may not<br>recognize that it is accepting. Necessary protocols would be similar to clinical<br>trial protocols and would have a similar purpose.</i>"
          ],
          [
           "Reliability",
           " <i>IEEE Policies - Code of Ethics</i>",
           " 2022",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Reliability",
           " <i>We, the members of the IEEE, o hereby commit ourselves to the highest ethical<br>and professional conduct and agree to uphold the highest standards of integrity,<br>responsible behavior, and ethical conduct in professional activities</i>"
          ],
          [
           "Reliability",
           " <i>Adobe’s Commitment to AI Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Reliability",
           " <i>We will approach designing and maintaining our AI technology with thoughtful<br>evaluation and careful consideration of the impact and consequences of its<br>deployment.</i>"
          ],
          [
           "Reliability",
           " <i>Algorithmic Decision-making for the Benefit of Consumers</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization",
           " Western Europe",
           " Germany",
           " Reliability",
           " <i>Drawing on a list of criteria and a system of verification, legislators need to<br>define which ADM systems have a high potential to cause harm or damage to<br>individuals and/or society. The various areas/types of application need to be<br>assigned to open positive and negative lists that are not definitive but do<br>provide greater clarity for market participants. ADM systems for use in<br>particularly sensitive areas (such as healthcare or self-driving vehicles) need<br>to undergo an ex-ante control process, i.e. obtain approval before they are<br>placed on the market. Automated data processing must be based on accepted<br>mathematical-statistical methods. The method’s suitability as a forecasting<br>instrument and its validity and reliability must be scientifically proven.</i>"
          ],
          [
           "Reliability",
           " <i>Draft - AI Utilization Principles</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Reliability",
           " <i>Users and data providers should pay attention to the quality of data used for<br>learning or other methods of AI systems. Users should take into consideration<br>that AI systems or AI services in use will not harm the life, body, or property<br>of users, indirect users, or third parties through the actuators or other<br>devices. Users and data providers should pay attention to the security of AI<br>systems or AI services.</i>"
          ],
          [
           "Reliability",
           " <i>The Code of Ethics in the Field of Artificial Intelligence</i>",
           " 2022",
           " Recommendation",
           " Unspecified",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Reliability",
           " <i>AI Actors should forecast possible negative consequences for the development of<br>human cognitive abilities at the earliest stages of AI systems creation and<br>refrain from the development of AI systems that purposefully cause such<br>consequences. AI Actors are encouraged to cooperate in identifying and verifying<br>information about ways and forms of design of so-called universal (\"strong\") AI<br>systems and prevention of possible threats they carry. The issues concerning the<br>use of \"strong\" AI technologies should be under the control of the state.</i>"
          ],
          [
           "Reliability",
           " <i>Shanghai Initiative for Safe and Secure AI Development</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Asia",
           " China",
           " Reliability",
           " <i>AI development must be achieved with a proper balance between innovation and<br>security. Security provides a guarantee for innovation, and innovation enhances<br>security. While AI security is ensured, AI technologies should be applied to<br>address security challenges confronting mankind. Countries need to plan, in a<br>scientific way, the paths for AI development to ensure AI will progress as<br>expected by mankind and deliver benefits to mankind. There must be risk<br>assessment and security oversight on critical processes such as seld-improvement<br>and self-replication of machines. A strict risk assessment must be conducted for<br>automatic R&D and the use of weapons. Efforts must be made to prevent the threat<br>to global peace and stability caused by the abuse of AI technologies in military<br>fields.</i>"
          ],
          [
           "Reliability",
           " <i>Chinese Young Scientists' Declaration on the Governance and Innovation of<br>Artificial Intelligence (Shanghai Declaration)</i>",
           " 2019",
           " Recommendation",
           " Academic, Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Asia",
           " China",
           " Reliability",
           " <i>Artificial intelligence should be safe and reliable. We are dedicated to<br>accentuating technical robustness and security throughout the research process,<br>providing a secure and reliable system to improve the ability to prevent attacks<br>and conduct self-repair.</i>"
          ],
          [
           "Reliability",
           " <i>Trustworthy AI in Aotearoa: AI Principles</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " Oceania",
           " New Zealand",
           " Reliability",
           " <i>AI stakeholders must ensure AI systems and related data are reliable, accurate,<br>and secure and the privacy of individuals is protected throughout the AI<br>system’s life cycle, with potential risks identified and managed on an ongoing<br>basis.</i>"
          ],
          [
           "Reliability",
           " <i>Harmonious Artificial Intelligence Principles</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Reliability",
           " <i>Artificial Intelligence should be with concrete design to avoid known and<br>potential safety issues (for themselves, other AI, and humans) with different<br>levels of risks.</i>"
          ],
          [
           "Reliability",
           " <i>\"ARCC\": An Ethical Framework for Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " Eastern Asia",
           " China",
           " Reliability",
           " <i>Recommendation - AI should be safe and reliable, and capable of safeguarding<br>against cyberattacks and other unintended consequences. Ensure AGI/ASI that may<br>appear in the future serves the interests of humanity.</i>"
          ],
          [
           "Reliability",
           " <i>Fu Ying: Six Principles of Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Reliability",
           " <i>It is necessary to ensure the security, applicability, and controllability of<br>artificial intelligence systems.</i>"
          ],
          [
           "Reliability",
           " <i>A Framework for the Ethical use of advanced Data Science Methodes in the<br>Humanitarian Sector</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe, Intergovernmental Organization",
           " Netherlands, United Nations",
           " Reliability",
           " <i>The humanitarian sector should improve its Skills and technology. Seeking<br>effective and responsible AI involves collaboration between stakeholders from<br>different sectors (tech, policy, legal, etc.), also depending on a culture of<br>risk aversion, especially in comparison with the private sector which can likely<br>afford to take on high-risk projects and commit to longer-term strategies.</i>"
          ],
          [
           "Reliability",
           " <i>Unified Ethical Frame for Big Data Analysis</i>",
           " 2014",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Reliability",
           " <i>Risks should also be clearly defined so that they may be evaluated as well. If<br>the benefits that will be created are limited, uncertain, or if the parties that<br>benefit are not the ones at risk from the processing, those circumstances should<br>be taken into consideration, and appropriate mitigation for the risk should be<br>developed before the analysis begins. Organizations should not create the risks<br>associated with big data analytics if other processes will accomplish the same<br>objectives with fewer risks.</i>"
          ],
          [
           "Reliability",
           " <i>Civil Rights Principles for the Era of Big Data</i>",
           " 2014",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Reliability",
           " <i>Protect People from Inaccurate Data. Government and corporate databases must<br>allow everyone — including the urban and rural poor, people with disabilities,<br>seniors, and people who lack access to the Internet — to appropriately ensure<br>the accuracy of personal information that is used to make important decisions<br>about them. This requires disclosure of the underlying data, and the right to<br>correct it when inaccurate.</i>"
          ],
          [
           "Reliability",
           " <i>Decree of the President of the Russian Federation on the Development of<br>Artificial Intelligence in the Russian Federation</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Reliability",
           " <i>The basic principles of the development and use of artificial intelligence<br>technologies, the observance of which is obligatory during the implementation of<br>this Strategy, include: the prevention and minimization of the risks of negative<br>consequences of the use of artificial intelligence technologies.</i>"
          ],
          [
           "Reliability",
           " <i>Principles and Practices for the Responsible Application of Artificial<br>Intelligence at Motorola Solutions - White Paper</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Reliability",
           " <i>We thoroughly validate the operation of the trained algorithms with a<br>representative and diverse set of test cases that are applied across a range of<br>operational conditions. We also test and retest our products in actual customer<br>environments. In fielded operation, our systems generate telemetry that we can<br>continuously monitor to identify performance issues, as well as any inconsistent<br>or undesirable behaviors.</i>"
          ]
         ],
         "hovertemplate": "<b>Document ID </b>=%{customdata[1]}<br><b>Year of Publication </b>=%{customdata[2]}<br><b>Reguation Type </b>=%{customdata[3]}<br><b>Institution Type </b>=%{customdata[4]}<br><b>World Region </b>=%{customdata[5]}<br><b>Country </b>=%{customdata[6]}<br><b>Principle </b>=%{customdata[7]}<br><b>Description </b>=%{customdata[8]}<extra></extra>",
         "legendgroup": "Reliability",
         "marker": {
          "color": "#ab63fa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Reliability",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          -7.2738695,
          -13.590309,
          -5.172675,
          -8.431832,
          6.307123,
          -11.684153,
          -14.708227,
          -5.7426314,
          -17.349878,
          1.5319577,
          -18.13962,
          -13.239765,
          -19.635962,
          -13.323501,
          -17.02208,
          8.419565,
          25.422224,
          -17.31684,
          -16.164473,
          -13.2304325,
          -21.729296,
          -20.06707,
          7.566579,
          -18.076616,
          13.191365,
          -17.069265,
          -0.56580555,
          13.7367115,
          24.526861,
          -13.0944395,
          -15.090661,
          -5.6853294,
          -6.730705,
          -15.251782,
          -16.742867,
          19.709587,
          -18.183203,
          -6.383907,
          -20.934002,
          -3.4831707,
          -16.075548,
          -14.277924,
          -22.327528,
          -6.8312883,
          -7.8933597,
          -5.768289,
          -16.967222,
          7.4191318,
          -22.032993,
          -21.908052,
          -15.362246,
          -9.853081,
          -21.240156,
          -12.327489,
          -19.660675,
          0.12024793,
          -18.878138,
          -12.106888,
          -10.533975,
          -7.696341,
          -19.988262,
          -20.045614,
          -5.55275,
          -16.788841,
          -11.7197695,
          -16.031614,
          -3.3938754,
          5.156724,
          2.1979485,
          2.3417196,
          -1.1419424,
          -18.674192,
          -25.618956,
          -6.261682,
          -18.029274,
          -6.0317316,
          -17.732199,
          -9.357626,
          -18.453989,
          -27.44148,
          -20.877516,
          0.98022634,
          -15.832202,
          0.6489726,
          21.23215,
          -10.123986,
          -4.3792853,
          16.2574,
          -12.553744,
          3.873675,
          -22.486511,
          9.256895,
          -6.7648864,
          -7.4672046,
          -19.218693,
          -11.756542,
          -17.55182,
          0.21218471,
          8.339066,
          0.51398504,
          -8.69226,
          3.4685578,
          8.068252,
          -3.5229714,
          -20.55569,
          5.7928724,
          -7.185418,
          5.619454,
          1.8055408,
          -15.283362,
          2.7402601,
          -13.885832,
          -9.10303,
          -14.453427,
          -16.191677,
          -2.9143271,
          4.0296454,
          -3.0304043,
          -1.1646315,
          -17.226631,
          -18.433994,
          -16.308655,
          10.719769,
          -8.173034,
          -15.832914,
          -12.512511,
          -3.6540916,
          -22.536629,
          -3.6046393,
          -19.523115,
          -20.291214,
          -17.204245,
          2.808357,
          -19.052229,
          -15.210666,
          -12.879135,
          -18.99378,
          -15.756323,
          1.7505667,
          -23.857182,
          6.21401,
          16.107094,
          -2.9551551,
          -23.519032,
          -7.9477344,
          -8.160183,
          -5.688926,
          -19.119528,
          -11.080004,
          -11.0691,
          -20.646067,
          -14.662162,
          10.037263,
          -3.193428,
          -7.304268,
          1.263125,
          -9.694048
         ],
         "y": [
          -7.8271985,
          -0.47503644,
          -1.6254358,
          -14.295904,
          16.307314,
          -21.602108,
          3.8727236,
          -17.186892,
          6.3216968,
          -12.256872,
          16.949146,
          -7.496809,
          -1.6917129,
          8.8104925,
          -1.8872825,
          -11.227492,
          3.227373,
          -0.8477787,
          -0.40208265,
          -4.557191,
          7.361982,
          -9.007817,
          10.739786,
          -7.2978473,
          18.019567,
          -8.905997,
          -12.347737,
          4.1735134,
          -0.9655951,
          -6.917781,
          -9.922258,
          23.161371,
          -3.505224,
          -2.4232383,
          -4.833223,
          17.869535,
          -7.7433405,
          -19.812202,
          14.502179,
          -11.426575,
          -9.93404,
          -2.8447614,
          -5.5227904,
          -16.902836,
          12.038042,
          12.910105,
          -4.28075,
          2.8275108,
          14.683749,
          -0.69657433,
          -4.101136,
          -7.1270633,
          0.17950928,
          -7.75355,
          -3.50601,
          0.863365,
          17.995874,
          -8.989157,
          -11.573061,
          -19.64057,
          -9.370456,
          -5.5761547,
          -16.629196,
          21.049194,
          -0.6776462,
          -14.284657,
          -24.804493,
          9.536124,
          -6.6644034,
          24.62396,
          -8.715562,
          6.510913,
          3.1443264,
          -22.119654,
          1.358841,
          8.905904,
          1.7953109,
          -8.511925,
          -2.1350195,
          2.1110737,
          0.9738513,
          2.659599,
          -0.077811055,
          -7.436779,
          -9.230954,
          2.7410314,
          2.0203838,
          -11.588463,
          -24.744144,
          -26.285007,
          -2.3894694,
          -14.427886,
          -1.2512127,
          -13.801992,
          -4.4242816,
          -4.2915244,
          -6.2491293,
          6.3447275,
          -12.782205,
          9.33552,
          -6.1424346,
          0.4148542,
          -13.689072,
          -18.688206,
          11.931831,
          -11.782759,
          -10.149688,
          -5.229417,
          -4.4389467,
          2.4475906,
          12.286558,
          -10.030641,
          -9.998688,
          -2.6245263,
          -4.5234227,
          -18.889524,
          -23.471785,
          21.247494,
          -18.575645,
          -2.1105673,
          -12.409808,
          -7.7711124,
          -13.540399,
          -12.62471,
          5.313248,
          -12.69705,
          9.186239,
          -1.9421487,
          -22.034927,
          -14.183793,
          -14.854282,
          -3.720119,
          0.5345214,
          10.200007,
          -5.688694,
          3.1847353,
          -10.025384,
          -7.6839714,
          4.8192344,
          -6.753804,
          -8.925663,
          13.092638,
          -18.07628,
          -5.2082944,
          1.6196622,
          -4.5868115,
          -11.0079565,
          -5.9856334,
          3.1701326,
          -5.279593,
          -4.810479,
          -0.43512106,
          -5.1286736,
          13.645956,
          18.713991,
          -19.02435,
          -20.378742
         ],
         "z": [
          -1.3124776,
          3.047685,
          -4.7086043,
          -12.931192,
          19.63804,
          5.8369303,
          -0.6284429,
          5.0574594,
          -22.595434,
          -8.406098,
          -1.1316328,
          7.39483,
          0.6679058,
          -9.16695,
          2.7462583,
          -8.628923,
          -6.471937,
          -6.4794974,
          1.308508,
          1.851818,
          9.440046,
          2.6123352,
          -7.654844,
          2.0818136,
          -14.202603,
          3.3591478,
          -9.799595,
          -21.089058,
          12.963572,
          1.8633221,
          12.5466385,
          -9.070819,
          -6.3387194,
          10.973298,
          2.603748,
          1.9505526,
          4.900333,
          2.6532469,
          3.4139903,
          -1.9398086,
          3.903818,
          5.251077,
          2.951513,
          8.375024,
          -13.288361,
          -6.286201,
          8.787036,
          -25.068546,
          -1.0860662,
          -5.4688706,
          1.3644221,
          16.620804,
          2.5992956,
          6.2486324,
          3.6064057,
          -11.392085,
          -2.302651,
          4.405071,
          9.489901,
          -2.026324,
          -1.912801,
          -0.3662022,
          3.9773984,
          2.3879526,
          -2.574613,
          -10.707045,
          10.793482,
          -16.138058,
          -12.320184,
          1.8802787,
          -12.637395,
          -0.014921636,
          3.0293062,
          1.0311275,
          0.5075426,
          -16.803267,
          -2.4550648,
          10.002604,
          8.330928,
          4.5053005,
          3.7131112,
          -6.6537247,
          6.3140483,
          24.809652,
          -3.026131,
          -20.947546,
          -14.493564,
          -7.3257008,
          -7.64654,
          -6.537663,
          13.704722,
          -10.257649,
          23.53063,
          5.3798575,
          -2.7732673,
          3.8103368,
          4.3146453,
          24.630125,
          -6.1263156,
          -6.339539,
          16.810493,
          -5.9744024,
          -6.7279205,
          4.9133787,
          2.6900222,
          -13.534192,
          17.115858,
          -15.151389,
          -0.67846423,
          -5.017479,
          -7.859813,
          14.167709,
          -0.087561026,
          8.679589,
          4.684825,
          -1.6275198,
          2.3658822,
          -17.215967,
          4.7140245,
          5.8266535,
          2.2679029,
          0.061615583,
          -10.483718,
          -22.620184,
          6.596762,
          8.356719,
          -12.172057,
          -2.336037,
          -13.301297,
          -1.3581346,
          -0.752959,
          -0.16345827,
          -10.429934,
          -1.8718427,
          5.2395415,
          3.774798,
          5.811423,
          7.9957566,
          -10.701097,
          2.6666505,
          -5.2361803,
          7.9662414,
          1.2858753,
          -8.681718,
          0.58534193,
          6.219375,
          9.192623,
          7.440292,
          -1.4443258,
          10.597828,
          5.248317,
          -0.9129991,
          -2.8156018,
          -15.675945,
          -0.08864716,
          18.835651,
          -1.9414735
         ]
        },
        {
         "customdata": [
          [
           "Sustainability",
           " <i>Responsible AI: A Global Policy Framework</i>",
           " 2021",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization, Professional Association",
           " North America",
           " United States of America",
           " Sustainability",
           " <i>Organisations that develop, make available, or use AI systems should assess the<br>overall environmental impact of such AI systems, throughout their<br>implementation, including consumption of resources, energy costs of data storage<br>and processing, and the net energy efficiencies or environmental benefits that<br>they may produce. Organizations should seek to promote and implement the uses of<br>AI systems to achieve overall carbon neutrality or carbon reduction.</i>"
          ],
          [
           "Sustainability",
           " <i>10 ethical guidelines for the digitalisation of companies (10 ethische<br>Leitlinien für die Digitalisierung von Unternehmen)</i>",
           " 2017",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Sustainability",
           " <i>Digitization should be used to conserve natural resources. The aim is to exploit<br>the potential of intelligent systems and digital technologies to conserve<br>natural resources and minimize environmental impact.</i>"
          ],
          [
           "Sustainability",
           " <i>Ethics Guidelines for Trustworthy AI</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Sustainability",
           " <i>In line with the principles of fairness and prevention of harm, the broader<br>society, other sentient beings, and the environment should be also considered as<br>stakeholders throughout the AI system’s life cycle. Sustainability and<br>ecological responsibility of AI systems should be encouraged, and research<br>should be fostered into AI solutions addressing areas of global concern, such as<br>instance the Sustainable Development Goals. Ideally, AI systems should be used<br>to benefit all human beings, including future generations.</i>"
          ],
          [
           "Sustainability",
           " <i>Declaration of Ethical Principles for AI in Latin America (Declaración de<br>Principios Éticos para la IA de Latinoamérica)</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Latin America",
           " Unspecified",
           " Sustainability",
           " <i>The development of AI technology must take care of the effects on the<br>environment. The impact that each creation may have cannot represent a threat to<br>our environment.</i>"
          ],
          [
           "Sustainability",
           " <i>Next-Generation AI Governance Principles - Develop responsible artificial<br>intelligence</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Sustainability",
           " <i>AI should promote green development and meet the requirements of environmental<br>friendliness and resource conservation.</i>"
          ],
          [
           "Sustainability",
           " <i>Digital ethics: a guide for professionals of the digital age</i>",
           " 2018",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " France",
           " Sustainability",
           " <i>Factor in environmental impact when entering into any contract that has<br>consequences for the environmental footprint of the IT system. Conduct a regular<br>assessment of the environmental footprint of the IT system (at least every two<br>years), based on recognised and auditable indicators (Green IT or WWF France).</i>"
          ],
          [
           "Sustainability",
           " <i>For a meaningful Artificial Intelligence - Towards a French and European<br>strategy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Sustainability",
           " <i>We need to ensure that the artificial intelligence being developed makes the<br>most economical use of energy and resources possible.</i>"
          ],
          [
           "Sustainability",
           " <i>Model AI Governance Framework</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " Southeast Asia",
           " Singapore",
           " Sustainability",
           " <i>Favour implementations that effectively predict future behavior and generate<br>beneficial insights over a reasonable period.</i>"
          ],
          [
           "Sustainability",
           " <i>G20 Ministerial Statement on Trade and Digital Economy</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " G20",
           " Sustainability",
           " <i>Stakeholders should proactively engage in responsible stewardship of trustworthy<br>AI in pursuit of beneficial outcomes for people and the planet, such as<br>protecting natural environments.</i>"
          ],
          [
           "Sustainability",
           " <i>AI 4People 's Ethical Framework for a Good AI Society: Opportunities, Risks,<br>Principles, and Recommendations</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Sustainability",
           " <i>AI technology must be in line with ensuring the basic preconditions for life on<br>our planet, continued prospering for mankind, and the preservation of a good<br>environment for future generations. Stakeholders should incentivize financially,<br>at the EU level, the development and use of AI technologies within the EU that<br>are socially preferable (not merely acceptable) and environmentally friendly<br>(not merely sustainable but favorable to the environment).</i>"
          ],
          [
           "Sustainability",
           " <i>Rome Call for AI Ethics</i>",
           " 2020",
           " Recommendation",
           " Religious Institution",
           " Southern Europe",
           " Vatican City State",
           " Sustainability",
           " <i>For technological advancement to align with true progress for the human race and<br>respect for the planet it must be mindful of the complex reality of our<br>ecosystem and be characterized by how it cares for and protects the planet (our<br>“common and shared home”) with a highly sustainable approach.</i>"
          ],
          [
           "Sustainability",
           " <i>Ethical Guidelines of the German Informatics Society</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization, Professional Association",
           " Western Europe",
           " Germany",
           " Sustainability",
           " <i>In the design, manufacture, operation and use of IT systems, GI members should<br>contribute to the betterment of local and global living conditions. GI members<br>are responsible for the social and societal consequences of their work. Their<br>influence on positioning, marketing and further development of IT systems should<br>contribute to the socially acceptable and sustainable application of these<br>technologies.</i>"
          ],
          [
           "Sustainability",
           " <i>Ethically Aligned Design: A Vision for Prioritizing Human Well-being with<br>Autonomous and Intelligent Systems, Version 2</i>",
           " 2017",
           " Recommendation",
           " Professional Association",
           " North America",
           " United States of America",
           " Sustainability",
           " <i>We are motivated by a desire to create ethical principles for A/IS that<br>prioritize benefits to humanity and the natural environment from the use of<br>A/IS. Note that these should not be at odds — one depends on the other.<br>Prioritizing human well-being does not mean degrading the environment.</i>"
          ],
          [
           "Sustainability",
           " <i>Hippocratic Oath for Data Scientists</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization",
           " Western Europe",
           " France",
           " Sustainability",
           " <i>Question the purpose of the project, its legality, and its possible social and<br>environmental impact.</i>"
          ],
          [
           "Sustainability",
           " <i>From Principles to Practice: An interdisciplinary framework to operationalise AI<br>ethics</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Professional Association",
           " Western Europe",
           " Germany",
           " Sustainability",
           " <i>Environmental sustainability is a form of intergenerational justice and<br>describes the obligation towards future generations to ensure and preserve their<br>living conditions. This obligation is typically geared towards a careful use of<br>natural resources, e.g., to combat pollution and to preserve biodiversity as<br>well as mitigate the worst effects of climate change. Within the field of AI,<br>this includes setting up resource-saving infrastructures for information<br>technology, primarily through building power-efficient data centers as well as<br>developing less power-consuming machine learning models.</i>"
          ],
          [
           "Sustainability",
           " <i>Beijing AI Principles</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Eastern Asia",
           " China",
           " Sustainability",
           " <i>AI should be designed and developed to promote the progress of society and human<br>civilization, to promote the sustainable development of nature and society, to<br>benefit all humankind and the environment, and to enhance the well-being of<br>society and ecology.</i>"
          ],
          [
           "Sustainability",
           " <i>Sony Group AI Ethics Guidelines</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " Japan",
           " Sustainability",
           " <i>Sony will engage in sustainable social development and endeavor to utilize the<br>power of AI for contributing to global problem-solving and for the development<br>of a peaceful and sustainable society.</i>"
          ],
          [
           "Sustainability",
           " <i>Code of Ethics for Data-Based Value Creation</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Switzerland",
           " Sustainability",
           " <i>You should not harm individuals or communities. This basic orientation includes<br>sustainability (i.e., minimizing negative effects on the environment, e.g.,<br>through energy-efficient data processing).</i>"
          ],
          [
           "Sustainability",
           " <i>Telefónica´s Approach to the Responsible Use of AI (Enfoque de Telefónica para<br>un uso responsable de la IA)</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Spain",
           " Sustainability",
           " <i>AI used in products and services should in no way lead to a negative impact on<br>human rights or the achievement of the UN’s Sustainable Development Goals.</i>"
          ],
          [
           "Sustainability",
           " <i>Understanding artificial intelligence ethics and safety: A guide for the<br>responsible design and implementation of AI systems in the public sector</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Western Europe",
           " United Kingdom",
           " Sustainability",
           " <i>Think big-picture about the wider impacts of the AI technologies you are<br>conceiving and developing. Think about the ramifications of their effects and<br>externalities for others around the globe, for future generations, and the<br>biosphere as a whole. Designers and users of AI systems must remain aware that<br>these technologies have transformative effects on individuals and society.</i>"
          ],
          [
           "Sustainability",
           " <i>Opinion of the Data Ethics Commission</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Sustainability",
           " <i>The principle of security relates not only to the physical and emotional safety<br>of humans but also to environmental protection, and as such involves the<br>preservation of vitally important assets.  Malfunctions of algorithmically<br>controlled public infrastructures, e.g. traffic or energy and water supply<br>infrastructures, may cause enormous amounts of damage. The pursuit of<br>sustainability goals set by the United Nations should be a particular focus of<br>public investments into the data economy and algorithmic systems. When<br>allocating government funding, priority should be given not to economic gains<br>which are only short-term in nature, but to the development of data and<br>algorithmic systems for purposes such as recording and monitoring environmental<br>impacts and developments, or systems for optimizing and reducing energy and<br>resource consumption.</i>"
          ],
          [
           "Sustainability",
           " <i>Statement on Artificial Intelligence, Robotics and 'Autonomous‘ Systems</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Sustainability",
           " <i>AI technology must be in line with the human responsibility to ensure the basic<br>preconditions for life on our planet, continued prospering for mankind, and<br>preservation of a good environment for future generations. Strategies to prevent<br>future technologies from detrimentally affecting human life and nature are to be<br>based on policies that ensure the priority of environmental protection and<br>sustainability.</i>"
          ],
          [
           "Sustainability",
           " <i>Report with recommendations to the Commission on Civil Law Rules on Robotics</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " European Union",
           " European Union",
           " Sustainability",
           " <i>The European Parliament notes that the development of robotics and artificial<br>intelligence should be done in such a manner that the environmental impact is<br>limited through effective energy consumption, energy efficiency by promoting the<br>use of renewable energy and scarce materials, and minimal waste, such as<br>electric and electronic waste, and reparability.</i>"
          ],
          [
           "Sustainability",
           " <i>Artificial Intelligence: Economic importance, social challenges, human<br>responsibility</i>",
           " 2017",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Sustainability",
           " <i>All stakeholders in business, politics, and society must accept the ethical and<br>data-ecological responsibility concerning sustainable data economies.</i>"
          ],
          [
           "Sustainability",
           " <i>Preliminary Study on the Ethics of Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Sustainability",
           " <i>For all AI applications, the potential benefits need to be balanced against the<br>environmental impact of the entire AI and IT production cycle. AI should be<br>developed in a sustainable manner taking into account the entire AI and IT<br>production cycle. AI can be used for environmental monitoring and risk<br>management, and to prevent and mitigate environmental crises.</i>"
          ],
          [
           "Sustainability",
           " <i>Report of COMEST on robotics ethics</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Sustainability",
           " <i>Interdependency implies that robots are part of our technical creations (part of<br>the technocosm that we construct) and they also have environmental impacts<br>(e-waste, energy consumption and CO2 emissions, ecological footprint) that must<br>be considered and evaluated in the balance of benefit and risk. While<br>constructing robots (nano, micro, or macro), efforts should be made to use<br>degradable materials and environmentally friendly technology and to improve the<br>recycling of materials.</i>"
          ],
          [
           "Sustainability",
           " <i>Top 10 Principles for Ethical Artificial Intelligence</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " Switzerland",
           " Sustainability",
           " <i>AI systems must protect and even improve our planet’s ecosystems and<br>biodiversity.</i>"
          ],
          [
           "Sustainability",
           " <i>ACM Code of Ethics and Professional Conduct</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Sustainability",
           " <i>Computing professionals should promote environmental sustainability both locally<br>and globally.</i>"
          ],
          [
           "Sustainability",
           " <i>Montréal declaration for a responsible development of artificial intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " Canada",
           " Sustainability",
           " <i>The development and use of AIS must be carried out so as to ensure a strong<br>environmental sustainability of the planet. AIS hardware, its digital<br>infrastructure, and the relevant objects on which it relies such as data<br>centers, must aim for the greatest energy efficiency and to mitigate greenhouse<br>gas emissions over its entire life cycle</i>"
          ],
          [
           "Sustainability",
           " <i>fAIr LAC: Responsible and Widespread Adoption of Artificial Intelligence in<br>Latin America and the Caribbean</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Latin America",
           " Unspecified",
           " Sustainability",
           " <i>Stakeholders should proactively engage in protecting natural environments, thus<br>invigorating inclusive growth, sustainable development, and well-being.</i>"
          ],
          [
           "Sustainability",
           " <i>Artificial Intelligence for Children: Beijing Principles</i>",
           " 2020",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Sustainability",
           " <i>The development of AI should uphold a responsible attitude towards the next<br>generations, fully consider and try to reduce and avoid the potential ethical,<br>legal, and social impacts and risks that AI might bring to children. The<br>continued benefits for children's growth and development should be regarded as<br>the development goal of AI for children. Attention should be paid to the<br>uncertainty in the long-term application of AI on children, and short-<br>sightedness that might bring in negative impacts on children in pursuit of<br>short-term benefits should be avoided.</i>"
          ],
          [
           "Sustainability",
           " <i>Social Principles of Human-Centric AI</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia, Western Europe",
           " Japan, United Kingdom",
           " Sustainability",
           " <i>We need to use AI to create a succession of new businesses and solutions,<br>resolve social disparities, and develop a sustainable society that can deal with<br>issues such as global environmental problems and climate change. Japan, as a<br>leading science and technology-oriented country, should strengthen its<br>accumulated scientific and technological resources by utilizing AI and thereby<br>contributing to the creation of such a sustainable society.</i>"
          ],
          [
           "Sustainability",
           " <i>Position on Robotics and Artificial Intelligence</i>",
           " 2016",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Sustainability",
           " <i>We call for an increase in energy efficiency by promoting the use of renewable<br>technologies for robotics, the use, and reuse of secondary raw materials, and<br>the reduction of waste. We underline that the possible positive gains that<br>robotics and AI could have on the environment should not be dismissed, but<br>rather taken seriously in the fight against climate change.</i>"
          ],
          [
           "Sustainability",
           " <i>AI Governance in Japan Ver. 1.1, Report from the expert group on how AI<br>principles should be implemented</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Sustainability",
           " <i>We need to use AI to create a succession of new businesses and solutions,<br>resolve social disparities, and develop a sustainable society that can deal with<br>issues such as global environmental problems and climate change. Japan, as a<br>leading science and technology-oriented country, should strengthen its<br>accumulated scientific and technological resources by utilizing AI and thereby<br>contributing to the creation of such a sustainable society.</i>"
          ],
          [
           "Sustainability",
           " <i>The Ethical Norms for the New Generation Artificial Intelligence, China</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Sustainability",
           " <i>Various activities of AI shall abide by the following fundamental ethical norms,<br>like promoting the sustainable development of economy, society, and ecology, and<br>jointly building a human community with a shared future.</i>"
          ],
          [
           "Sustainability",
           " <i>Discussion Paper: National Strategy for Artificial Intelligence</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " South Asia",
           " India",
           " Sustainability",
           " <i>Recommendation - Set up CSTS to address issues relating to ethics, privacy,<br>legal aspects, social sustainability, and global competitiveness of the<br>technologies developed.</i>"
          ],
          [
           "Sustainability",
           " <i>OECD, Recommendation of the Council on Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " France",
           " Sustainability",
           " <i>Stakeholders should proactively engage in responsible stewardship of trustworthy<br>AI in pursuit of beneficial outcomes for people and the planet, such as<br>augmenting human capabilities and enhancing creativity, advancing the inclusion<br>of underrepresented populations, reducing economic, social, gender, and other<br>inequalities, and protecting natural environments, thus invigorating inclusive<br>growth, sustainable development, and well-being.</i>"
          ],
          [
           "Sustainability",
           " <i>UNESCO Recommendation on the Ethics of Artificial Intelligence</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Sustainability",
           " <i>The development of sustainable societies relies on the achievement of a complex<br>set of objectives on a continuum of human, social, cultural, economic, and<br>environmental dimensions. The advent of AI technologies can either benefit<br>sustainability objectives or hinder their realization, depending on how they are<br>applied across countries with varying levels of development. The continuous<br>assessment of the human, social, cultural, economic, and environmental impact of<br>AI technologies should therefore be carried out with full cognizance of the<br>implications of AI technologies for sustainability as a set of constantly<br>evolving goals across a range of dimensions, such as currently identified in the<br>Sustainable Development Goals (SDGs) of the United Nations.</i>"
          ],
          [
           "Sustainability",
           " <i>Ethics & Governance of Artificial Intelligence for Health</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Sustainability",
           " <i>AI systems should be designed to minimize their environmental consequences and<br>increase energy efficiency. That is, the use of AI should be consistent with<br>global efforts to reduce the impact of human beings on the Earth’s environment,<br>ecosystems, and climate.</i>"
          ],
          [
           "Sustainability",
           " <i>Alpha Principles for the Ethical Use of AI and Data Driven Technologies in<br>Ontario</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Sustainability",
           " <i>Other byproducts of deploying data-driven technologies such as environmental,<br>sustainability, and societal impacts should be considered as they apply to<br>specific sectors and use cases and applicable frameworks, best practices, or<br>laws. Experts in both technology and ethics should be consulted in the<br>development of data-driven technologies such as AI to guard against any adverse<br>effects (including societal, environmental, and other long-term effects).</i>"
          ],
          [
           "Sustainability",
           " <i>IEEE Policies - Code of Ethics</i>",
           " 2022",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Sustainability",
           " <i>We, the members of the IEEE, o hereby commit ourselves to the highest ethical<br>and professional conduct and agree to hold paramount the safety, health, and<br>welfare of the public, to strive to comply with ethical design and sustainable<br>development practices, to protect the privacy of others, and to disclose<br>promptly factors that might endanger the public or the environment.</i>"
          ],
          [
           "Sustainability",
           " <i>Chinese Young Scientists' Declaration on the Governance and Innovation of<br>Artificial Intelligence (Shanghai Declaration)</i>",
           " 2019",
           " Recommendation",
           " Academic, Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Asia",
           " China",
           " Sustainability",
           " <i>Artificial intelligence should entail the sustainable development of human<br>beings. We are committed to conducting eco-friendly research and services such<br>as model cutting and optimization, high-performance hardware architecture, and<br>green data centers.</i>"
          ],
          [
           "Sustainability",
           " <i>Trustworthy AI in Aotearoa: AI Principles</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " Oceania",
           " New Zealand",
           " Sustainability",
           " <i>Where appropriate, AI stakeholders should design, develop and use AI systems to<br>promote, as much as possible, the wellbeing of New Zealand’s people and<br>environment in areas such as health, education, employment, sustainability,<br>diversity, inclusion, and recognition of the unique values of Te Ao Māori.</i>"
          ],
          [
           "Sustainability",
           " <i>Unified Ethical Frame for Big Data Analysis</i>",
           " 2014",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Sustainability",
           " <i>Big data analysts should understand this concept and articulate their best<br>understanding of how long an insight might endure once it is reflected in the<br>application. Big data insights, when placed into production, should provide<br>value that is sustainable over a reasonable time frame. Considerations that<br>affect the longevity of big data analytics include whether the source data will<br>be available for some time in the future, whether the data can be kept current,<br>whether one has the legal permissions to process the data for the particular<br>application, and whether the discovery may need to be changed or refined to keep<br>up with evolving trends and individual expectations.</i>"
          ]
         ],
         "hovertemplate": "<b>Document ID </b>=%{customdata[1]}<br><b>Year of Publication </b>=%{customdata[2]}<br><b>Reguation Type </b>=%{customdata[3]}<br><b>Institution Type </b>=%{customdata[4]}<br><b>World Region </b>=%{customdata[5]}<br><b>Country </b>=%{customdata[6]}<br><b>Principle </b>=%{customdata[7]}<br><b>Description </b>=%{customdata[8]}<extra></extra>",
         "legendgroup": "Sustainability",
         "marker": {
          "color": "#FFA15A",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Sustainability",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          10.354521,
          7.8398104,
          4.351205,
          8.150735,
          5.053529,
          25.089811,
          6.467772,
          -3.323244,
          7.287672,
          11.002263,
          9.6202135,
          24.762527,
          12.151432,
          12.317955,
          13.834575,
          4.009714,
          1.2138093,
          3.1070185,
          6.582686,
          0.25365454,
          -20.061743,
          10.613896,
          1.9558332,
          9.398145,
          11.747763,
          0.4330357,
          8.65749,
          21.208776,
          12.8551445,
          7.88734,
          1.9786822,
          14.1461315,
          3.354059,
          14.1461315,
          3.845898,
          25.931576,
          5.838737,
          13.292655,
          8.9033375,
          8.195484,
          16.918352,
          7.0914326,
          12.717386,
          -3.323662
         ],
         "y": [
          -6.711644,
          -8.305445,
          -9.824521,
          -4.017176,
          -4.330468,
          8.083342,
          -8.111131,
          -11.113512,
          -14.041742,
          -6.890751,
          -4.313265,
          11.001203,
          8.717891,
          14.845158,
          -4.690915,
          -3.3397226,
          -26.737387,
          24.034128,
          0.13341612,
          -11.637051,
          1.5698491,
          -5.6770616,
          -8.414545,
          -15.4756,
          -7.564172,
          -10.262146,
          -3.5443254,
          9.709578,
          -5.033185,
          -13.313426,
          5.8089485,
          -11.714678,
          -8.863033,
          -11.714678,
          -4.2755046,
          -1.5659094,
          -11.062964,
          -7.023435,
          -5.85129,
          -4.9045677,
          15.345267,
          -7.9599767,
          -1.6996807,
          16.156408
         ],
         "z": [
          19.206184,
          20.362532,
          3.8551857,
          15.9129,
          19.003895,
          2.7501042,
          17.771194,
          -23.868948,
          2.6017969,
          14.4462805,
          12.679376,
          5.280733,
          15.942578,
          -18.41077,
          15.578341,
          17.27251,
          8.37461,
          2.6848466,
          15.195878,
          2.7546506,
          5.544602,
          15.007125,
          22.951105,
          -0.14300849,
          17.609444,
          20.73226,
          19.85014,
          2.1847343,
          19.120224,
          -1.9932897,
          23.995552,
          18.033249,
          21.3219,
          18.033249,
          4.394866,
          0.023321956,
          1.5078281,
          16.322569,
          18.798006,
          -21.105341,
          7.300126,
          15.469376,
          10.952811,
          -12.620136
         ]
        },
        {
         "customdata": [
          [
           "Transparency",
           " <i>Declaration on Ethics and Data Protection in Artifical Intelligence</i>",
           " 2018",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " Belgium",
           " Transparency",
           " <i>artificial intelligence systems transparency and intelligibility should be<br>improved, with the objective of effective implementation, investing in public<br>and private scientific research on explainable artificial intelligence, making<br>organizations’ practices more transparent, notably by promoting algorithmic<br>transparency and the auditability of systems, while ensuring meaningfulness of<br>the information provided.</i>"
          ],
          [
           "Transparency",
           " <i>Intel’s AI Privacy Policy White Paper: Protecting individuals’ privacy and data<br>in the artificial intelligence world</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Transparency",
           " <i>Organisations implementing AI solutions should be able to demonstrate that they<br>have the right processes, policies, and resources in place to minimize privacy<br>risks and adverse impacts to the individual. Industry and governments should<br>work together on algorithm explainability and risk-based degrees of human<br>oversight.</i>"
          ],
          [
           "Transparency",
           " <i>Artificial Intelligence and Machine Learning: Policy Paper</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Transparency",
           " <i>Decisions made by an AI agent should be possible to understand, especially if<br>those decisions have implications for public safety, or result in discriminatory<br>practices.</i>"
          ],
          [
           "Transparency",
           " <i>Everyday Ethics for Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Transparency",
           " <i>The principle of explainability in AI development to that users interact and<br>understand the recommendations and conclusions made by AI. AI should be designed<br>to enable users to perceive, detect, and understand its decision process. If<br>this principle is not met, AI should not be deployed to the market.</i>"
          ],
          [
           "Transparency",
           " <i>Responsible AI: A Global Policy Framework</i>",
           " 2021",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization, Professional Association",
           " North America",
           " United States of America",
           " Transparency",
           " <i>Organisations that develop, make available or use AI systems, and any national<br>laws or industry standards that govern such use, shall ensure that such use is<br>transparent and that the decision outcomes of the AI system are explainable.</i>"
          ],
          [
           "Transparency",
           " <i>Trusted AI</i>",
           " Unspecified",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Transparency",
           " <i>Systems created in IBM are made so that they can explain the decisions they make<br>and why AI decisions were made. This is done through a wide range of actions<br>such as training highly optimized, directly interpretable models and explanation<br>of black-box models and visualizations of neural network information flow.</i>"
          ],
          [
           "Transparency",
           " <i>Kakao Algorithm Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " South Korea",
           " Transparency",
           " <i>Algorithms must be faithfully explained within a scope that does not impair the<br>competitiveness of Kakao.</i>"
          ],
          [
           "Transparency",
           " <i>Hambach Declaration on Artificial Intelligence(Hambacher Erklärung zur<br>Künstlichen Intelligenz)</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Germany",
           " Transparency",
           " <i>Personal data must be processed in a way that is comprehensible to the data<br>subject. This requires, in particular, transparent processing in which the<br>information about the process of processing and, where applicable, also about<br>the training data used is easily accessible and comprehensible.</i>"
          ],
          [
           "Transparency",
           " <i>KI Seal of Approval</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Transparency",
           " <i>Each step concerning the data should be documented as part of a transparent<br>procedure. The results of bias detection shall be documented at regular<br>intervals, regardless of how a company decides to deal with bias. AI procedures<br>shall be accompanied by known and appropriate analysis procedures.</i>"
          ],
          [
           "Transparency",
           " <i>Directive on Automated Decision-Making</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Transparency",
           " <i>The expected results of this Directive are as follows: Data and information on<br>the use of Automated Decision Systems in federal institutions are made available<br>to the public, where appropriate.</i>"
          ],
          [
           "Transparency",
           " <i>Responsible use of artificial intelligence (AI)</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Transparency",
           " <i>To ensure the effective and ethical use of AI the government will: be<br>transparent about how and when we are using AI, starting with a clear user need<br>and public benefit. Provide meaningful explanations about AI decision-making,<br>while also offering opportunities to review results and challenge these<br>decisions.</i>"
          ],
          [
           "Transparency",
           " <i>10 ethical guidelines for the digitalisation of companies (10 ethische<br>Leitlinien für die Digitalisierung von Unternehmen)</i>",
           " 2017",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Transparency",
           " <i>Ethical principles that aim on creating trust should be mandatory. These include<br>the creation of Information symmetry between customers and companies (such as<br>transparency), information fairness (such as data economy), and information<br>autonomy (such as the right to data deletion).</i>"
          ],
          [
           "Transparency",
           " <i>Ethics Guidelines for Trustworthy AI</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Transparency",
           " <i>Explicability is crucial for building and maintaining users’ trust in AI<br>systems. This means that processes need to be transparent, the capabilities and<br>purpose of AI systems openly communicated, and decisions – to the extent<br>possible –explainable to those directly and indirectly affected.</i>"
          ],
          [
           "Transparency",
           " <i>IBM’s Principles for Trust and Transparency</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Transparency",
           " <i>For the public to trust AI, it must be transparent. Technology companies must be<br>clear about who trains their AI systems, what data was used in that training<br>and, most importantly, what went into their algorithm’s recommendations. If we<br>are to use AI to help make important decisions, it must be explainable.</i>"
          ],
          [
           "Transparency",
           " <i>China’s Artificial Intelligence Industry Alliance Self-discipline Convention</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Transparency",
           " <i>Continuously improve the transparency of artificial intelligence systems.<br>Regarding system decision-making processes, data structures, and the intent of<br>system developers and technological implementers: be capable of accurate<br>description, monitoring, and reproduction; and realize explainability,<br>predictability, traceability, and verifiability or algorithmic logic, system<br>decisions, and action outcomes.</i>"
          ],
          [
           "Transparency",
           " <i>Charlevoix Common Vision for the Future of Artificial Intelligence</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " International Organization",
           " Intergovernmental Organization",
           " G7",
           " Transparency",
           " <i>We, the leaders of the G7, commit to exploring the use of other transformative<br>technologies to protect personal privacy and transparency.</i>"
          ],
          [
           "Transparency",
           " <i>Governance Recommendations - Use of Artificial Intelligence by Public<br>Authorities</i>",
           " 2021",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Latin America",
           " Brazil",
           " Transparency",
           " <i>The government must ensure that algorithms are explained well enough: allowing<br>citizens to understand how they work, how decisions have been made with their<br>support, their purpose and reason, besides the data used in processing.</i>"
          ],
          [
           "Transparency",
           " <i>The Ethics of Artificial Intelligence</i>",
           " Unspecified",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Transparency",
           " <i>It will become increasingly important to develop AI algorithms that are not just<br>powerful and scalable, but also transparent to inspection—to name one of many<br>socially important properties. It is also important that AI algorithms taking<br>over social functions be predictable to those they govern.</i>"
          ],
          [
           "Transparency",
           " <i>Next-Generation AI Governance Principles - Develop responsible artificial<br>intelligence</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Transparency",
           " <i>AI systems should continuously improve transparency, explainability,<br>reliability, and controllability, and gradually achieve audibility,<br>traceability, and trustworthiness.</i>"
          ],
          [
           "Transparency",
           " <i>Draft AI R&D Guidelines for International Discussions</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Transparency",
           " <i>AI developers must ensure verifiability of inputs/outputs of their systems and<br>the explainability of their judgment. The attention paid to verifiability and<br>explainability ought to be in line with the reasonable scope in light of the<br>characteristics of the technology and trust from users in society.</i>"
          ],
          [
           "Transparency",
           " <i>Responsible bots: 10 guidelines for developers of conversational AI</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Transparency",
           " <i>Be transparent about the fact that you use bots as part of your product or<br>service; It should be apparent to the user that they are not having an<br>interaction with another person; Be transparent about bot reliability.</i>"
          ],
          [
           "Transparency",
           " <i>Facial recognition: It’s time for action</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Transparency",
           " <i>We will document and clearly communicate the capabilities and limitations of<br>facial recognition technology.</i>"
          ],
          [
           "Transparency",
           " <i>Toward a G20 Framework for Artificial Intelligence in the Workplace</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " Canada",
           " Transparency",
           " <i>There should be a clear and testable explanation of the type and purpose of the<br>data being sourced. Workers and contractors with experience in the work<br>processes and data environment of the firm should be incorporated into the<br>review of data sources.  Workers, customers, and vendors need to have<br>information about how AI systems operate so that they can understand how<br>decisions are made.</i>"
          ],
          [
           "Transparency",
           " <i>Digital ethics: a guide for professionals of the digital age</i>",
           " 2018",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " France",
           " Transparency",
           " <i>Have a systems explainability policy encompassing the whole chain (data<br>provenance, explanation of the reasoning followed). Develop algorithms that are<br>transparent by design, to make it easier to explain them and to analyse how they<br>reason. Ensure that the information given to users is clear and transparent.</i>"
          ],
          [
           "Transparency",
           " <i>The Future Computed – Artificial intelligence and its role in society</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Transparency",
           " <i>AI systems should be understandable. Industry groups and others should build off<br>these principles to create detailed best practices for key aspects of the<br>development of AI systems, such as the nature of the data used to train AI<br>systems, the analytical techniques deployed, and how the results of AI systems<br>are explained to people using those systems.</i>"
          ],
          [
           "Transparency",
           " <i>How Can Humans Keep The Upper Hand? The Ethical Matters Raised By Algorithms And<br>Artificial Intelligence</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Transparency",
           " <i>Given the opacity of algorithmic systems, transparency is an oft-cited<br>requirement, with the idea that it could be a condition for fairness. It should<br>be possible for everyone to understand this logic, which must therefore be<br>explained in words rather than in lines of code. Public authorities must do<br>their utmost to open up the source code of deterministic algorithms.</i>"
          ],
          [
           "Transparency",
           " <i>Statement on Algorithmic Transparency and Accountability</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Transparency",
           " <i>Systems and institutions that use algorithmic decision-making are encouraged to<br>produce explanations regarding both the procedures followed by the algorithm and<br>the specific decisions that are made. This is particularly important in public<br>policy contexts. A description of how the training data was collected should be<br>maintained by the builders of the algorithms, accompanied by an exploration of<br>the potential biases induced by the human or algorithmic data-gathering process.<br>Models, algorithms, data, and decisions should be recorded so that they can be<br>audited in cases where harm is suspected.</i>"
          ],
          [
           "Transparency",
           " <i>Responsible AI - Microsoft AI principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Transparency",
           " <i>AI systems should be understandable.</i>"
          ],
          [
           "Transparency",
           " <i>For a meaningful Artificial Intelligence - Towards a French and European<br>strategy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " France",
           " Transparency",
           " <i>AI should be explainable. Our digital society could not be governed by black-box<br>algorithms. It should be possible to open these black boxes.</i>"
          ],
          [
           "Transparency",
           " <i>Principles to Promote Fairness, Ethics, Accountability and Transparency (FEAT)<br>in the Use of Artificial Intelligence and Data Analytics in Singapore’s<br>Financial Sector</i>",
           " 2018",
           " Recommendation",
           " Governmental Institution",
           " Southeast Asia",
           " Singapore",
           " Transparency",
           " <i>To increase public confidence, the use of AIDA should be proactively disclosed<br>to data subjects as part of general communication. Data subjects should be<br>provided, upon request, with clear explanations on what data is used to make<br>AIDA-driven decisions about the data subject and how the data affects the<br>decision. Data subjects should be provided, upon request, with clear<br>explanations on the consequences that AIDA-driven decisions may have on them.</i>"
          ],
          [
           "Transparency",
           " <i>Facebook and Google: This is What an Effective Ad Archive API Looks Like</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Transparency",
           " <i>A functional, open API should have information about how much an advertiser paid<br>to place the ad; information about microtargeting, including whether the ad was<br>tested and the different versions of the ad; if the ad used a lookalike<br>audience; the features (race, gender, geography, etc.) used to create that<br>audience; if the ad was directed at platform-defined user segments or interests,<br>and the segments or interests used, or if the ad was targeted based on a user<br>list the advertiser already possessed.</i>"
          ],
          [
           "Transparency",
           " <i>Code of Practice on Disinformation</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " International Organization",
           " European Union",
           " European Union",
           " Transparency",
           " <i>The Signatories of this Code recognize that transparency should be ensured with<br>a view to enabling users to understand why they have been targeted by a given<br>political or issue-based advertisement.</i>"
          ],
          [
           "Transparency",
           " <i>It’s Time to Do Something: Mitigating the Negative Impacts of Computing Through<br>a Change to the Peer Review Process</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " Eastern Asia, Central Europe",
           " Turkey, Turkey",
           " Transparency",
           " <i>One recommendation is that if the research community makes decision-making<br>processes clearer and more transparent, then this will make the expected<br>positive and negative impacts of the research more prominent.</i>"
          ],
          [
           "Transparency",
           " <i>Business Ethics and Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " Western Europe",
           " United Kingdom",
           " Transparency",
           " <i>Designers of AI systems must ensure that their systems are transparent by<br>providing an explanation to the public on how AI works and enable that people<br>have access to their codes. By so, the public can understand, trust, and<br>effectively manage intelligent machines. Furthermore, designers of AI must<br>ensure that their models are simple to explain and understand.</i>"
          ],
          [
           "Transparency",
           " <i>Digital Decisions</i>",
           " Unspecified",
           " Recommendation",
           " Non-profit Organization",
           " Western Europe, North America",
           " Belgium, United States of America",
           " Transparency",
           " <i>Institutions must ensure that algorithmic decisions, as well as any data driving<br>those decisions, can be explained to end-users and other stakeholders in non-<br>technical terms. Creating a system that can be audited creates accountability<br>and credibility, particularly if the result of an audit can be reviewed<br>externally</i>"
          ],
          [
           "Transparency",
           " <i>Big Data, Artificial Intelligence, Machine Learning, and Data Protection</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Transparency",
           " <i>Information addressed to the public or the data subject should be concise,<br>easily accessible and easy to understand, and that clear and plain language.<br>Even if it is difficult to explain in simple terms how the analytics works, it<br>should be possible to explain the purposes in a way that does not deceive or<br>mislead. Auditability should be ‘baked in’ to algorithms in the development<br>stage to enable third parties to check, monitor, review and critique their<br>behaviour.</i>"
          ],
          [
           "Transparency",
           " <i>Model AI Governance Framework</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " Southeast Asia",
           " Singapore",
           " Transparency",
           " <i>Organizations using AI in decision-making should ensure that the decision-making<br>process is explainable, transparent, and fair. Explainability is achieved by<br>explaining how deployed AI models’ algorithms function and/or how the decision-<br>making process incorporates model predictions.</i>"
          ],
          [
           "Transparency",
           " <i>Asilomar AI Principles</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Transparency",
           " <i>If an AI system causes harm, it should be possible to ascertain why. Any<br>involvement by an autonomous system in judicial decision-making should provide a<br>satisfactory explanation auditable by a competent human authority.</i>"
          ],
          [
           "Transparency",
           " <i>G20 Ministerial Statement on Trade and Digital Economy</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " G20",
           " Transparency",
           " <i>AI Actors should commit to transparency and responsible disclosure regarding AI<br>systems. To this end, they should provide meaningful information, appropriate to<br>the context, and consistent with the state of art.</i>"
          ],
          [
           "Transparency",
           " <i>Philips AI Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Netherlands",
           " Transparency",
           " <i>We disclose which functions and features of our offerings are AI-enabled, the<br>validation process, and the responsibility for ultimate decision-making.</i>"
          ],
          [
           "Transparency",
           " <i>AI 4People 's Ethical Framework for a Good AI Society: Opportunities, Risks,<br>Principles, and Recommendations</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Transparency",
           " <i>AI systems should be understandable and interpretable. Stakeholders should<br>develop a framework to enhance the explicability of AI systems that make<br>socially significant decisions</i>"
          ],
          [
           "Transparency",
           " <i>AI & Data Topical Guide Series</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Southern Africa",
           " South Africa",
           " Transparency",
           " <i>In developing South Africa’s national strategy on AI, specific attention should<br>be paid to developing strong transparency mechanisms for the use of AI in line<br>with the principles of governance set out in the Constitution and, for<br>businesses, under the King Codes.</i>"
          ],
          [
           "Transparency",
           " <i>Rome Call for AI Ethics</i>",
           " 2020",
           " Recommendation",
           " Religious Institution",
           " Southern Europe",
           " Vatican City State",
           " Transparency",
           " <i>AI systems must be understandable to all.</i>"
          ],
          [
           "Transparency",
           " <i>A practical guide to Responsible Artificial Intelligence (AI)</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Transparency",
           " <i>To instill trust in AI systems, people must be enabled to look “under the hood”<br>at their underlying models, explore the data used to train them, expose the<br>reasoning behind each decision, and provide coherent explanations to all<br>stakeholders promptly. These explanations should be tailored to the different<br>stakeholders, including regulators, data scientists, business sponsors, and end<br>consumers.</i>"
          ],
          [
           "Transparency",
           " <i>Ethical Guidelines of the German Informatics Society</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization, Professional Association",
           " Western Europe",
           " Germany",
           " Transparency",
           " <i>GI members who conduct research in the field of computer science adhere to the<br>rules of best practices in scientific research. Of particular importance in this<br>regard is openness and transparency in dealing with criticism and conflicts of<br>interest, the ability to express and to accept criticism as well as the<br>willingness to allow the impact of one’s own scientific work in the research<br>process to become the subject of discussion. Scientific research breaches<br>boundaries. These must be clearly articulated.</i>"
          ],
          [
           "Transparency",
           " <i>Ethically Aligned Design: A Vision for Prioritizing Human Well-being with<br>Autonomous and Intelligent Systems, Version 2</i>",
           " 2017",
           " Recommendation",
           " Professional Association",
           " North America",
           " United States of America",
           " Transparency",
           " <i>To maximize effective evaluation by third parties (e.g., regulators, accident<br>investigators), A/IS should be designed, specified, and documented to permit the<br>use of strong verification and validation techniques for assessing the system’s<br>safety and norm compliance, to possibly achieve accountability to the relevant<br>communities.</i>"
          ],
          [
           "Transparency",
           " <i>Privacy and Freedom of Expression In the Age of Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " Western Europe",
           " United Kingdom",
           " Transparency",
           " <i>Corporate, technical, and state actors must allow for meaningful multi-<br>stakeholder participation, including civil society actors, in setting technical<br>standards, regulation, and industry guidelines for AI systems, technology<br>policy, and industry standards to ensure transparent processes and legitimacy of<br>outcomes. In particular, non-binding frameworks must be accompanied by strong<br>accountability and oversight measures.</i>"
          ],
          [
           "Transparency",
           " <i>Hippocratic Oath for Data Scientists</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization",
           " Western Europe",
           " France",
           " Transparency",
           " <i>Communicate, or otherwise remind the competent teams, of the need to communicate<br>to the persons concerned, the use that will be made of their data, in the<br>clearest, explicit and transparent way possible. Ensure that the consent of the<br>people whose data I collect is obtained under fair and transparent conditions<br>for them. Ensure that the person in charge of the system can explain the results<br>of the algorithmic model to the people concerned as much as possible, and this<br>is all the more so if he is legally required to explain these decisions.</i>"
          ],
          [
           "Transparency",
           " <i>Artificial intelligence and Privacy</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Norway",
           " Transparency",
           " <i>Data subjects must be informed about how the information will be used, whether<br>this information is collected by the data subjects themselves or by others (GDPR<br>Articles 13 and 14).</i>"
          ],
          [
           "Transparency",
           " <i>Code of conduct for data-driven health and care technology</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Transparency",
           " <i>Be fair, transparent, and accountable about what data is being used. Individuals<br>have the right to be informed about the collection and use of their personal<br>data. This is a key transparency requirement under the Data Protection Act 2018.</i>"
          ],
          [
           "Transparency",
           " <i>Digital Ethics Guidelines on AI</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Transparency",
           " <i>In no case do we hide it when the customer’s counterpart is an AI. And, we are<br>transparent about how we use customer data. As Deutsche Telekom, we always have<br>the customer’s trust in mind – trust is what we stand for.</i>"
          ],
          [
           "Transparency",
           " <i>Artificial intelligence and the work of tomorrow (Künstliche Intelligenz und die<br>Arbeit von Morgen)</i>",
           " 2019",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Transparency",
           " <i>When purchasing external systems, the active participation of employees and<br>their representatives should also be ensured when formulating the requirements<br>for the AI system. These processes are the basis for a technical and social<br>impact assessment (impact assessment) of learning systems in the operational<br>context. This also includes transparency of comprehensible and verifiable<br>information as well as clarification of implementation responsibility and<br>intervention mechanics.</i>"
          ],
          [
           "Transparency",
           " <i>Ethics Framework - Responsible AI</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Transparency",
           " <i>Companies should be able to explain the purpose and limitations of their<br>solutions so that users are not misled or confused. Companies must be able to<br>communicate clearly the benefits and potential risks of their products and the<br>actions they have taken to deliver benefits and avoid, minimize, or mitigate the<br>risks. They must ensure that processes are in place to address the concerns and<br>complaints of users and other parties and that these are transparent.</i>"
          ],
          [
           "Transparency",
           " <i>AI Ethics Principles & Guidelines</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Middle East",
           " United Arab Emirates",
           " Transparency",
           " <i>Developers should build systems whose failures can be traced and diagnosed.<br>People should be told when significant decisions about them are being made by<br>AI. Within the limits of privacy and the preservation of intellectual property,<br>those who deploy AI systems should be transparent about the data and algorithms<br>they use.</i>"
          ],
          [
           "Transparency",
           " <i>Algo.Rules: Rules for the Design of Algorithmic Systems</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Private Corporation",
           " Western Europe",
           " Germany",
           " Transparency",
           " <i>The function and potential effects of an algorithmic system must be understood.<br>The objectives of an algorithmic system must be clearly defined and information<br>regarding its use must be documented. People interacting with algorithmic<br>systems must be able to identify that a decision or prediction is based on an<br>algorithm. The decision-making processes within an algorithmic system must<br>always be comprehensible.</i>"
          ],
          [
           "Transparency",
           " <i>From Principles to Practice: An interdisciplinary framework to operationalise AI<br>ethics</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Professional Association",
           " Western Europe",
           " Germany",
           " Transparency",
           " <i>For this rating, the value of transparency is understood as explainability and<br>interpretability of the algorithmic system, including the model and data used.<br>The question is here how or in how far transparency is being achieved.<br>Transparency, therefore, refers to disclosing the data’s origin and properties<br>of the AI model in use as well as access to and comprehensibility of the<br>information disclosed. In this sense, we aim for transparency in both the<br>general operating principle and each output of the AI system. Transparency<br>furthermore must be tailored to the requirements of the target groups such as<br>users and persons affected, i.e. the system must be comprehensible to them.</i>"
          ],
          [
           "Transparency",
           " <i>Beijing AI Principles</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Eastern Asia",
           " China",
           " Transparency",
           " <i>AI R&D should take ethical design approaches to make the system trustworthy.<br>This may include, but is not limited to: making the system as fair as possible,<br>reducing possible discrimination and biases, improving its transparency,<br>explainability, and predictability, and making the system more traceable,<br>auditable, and accountable.</i>"
          ],
          [
           "Transparency",
           " <i>Artificial Intelligence: opportunities, risks and recommendations for the<br>financial sector</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Luxembourg",
           " Transparency",
           " <i>Institutions should implement measures to ensure the explainability of their<br>AI/ML systems from the design phase. Even when full transparency cannot be<br>achieved due to the intrinsic nature of the algorithm employed (e.g. deep neural<br>networks), steps can be taken to identify and isolate in a human-understandable<br>format the main factors contributing to the final decision.</i>"
          ],
          [
           "Transparency",
           " <i>Data protection and Big Data (Datenschutz und Big Data)</i>",
           " 2017",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Transparency",
           " <i>Data subjects have the right to request information about the data that<br>companies have collected about them at any time, see § 34 BDSG. The company must<br>disclose what personal data is stored, where this data was collected, to whom<br>this data is disclosed, and for what purpose it was stored. The type, scope, and<br>content of the data collection must be recognizable to the data subject. You<br>should be transparent with your customers on this point and not try to \"trick\"<br>consent. This is neither legally permitted nor does it strengthen the basis of<br>trust between a company and its customers.</i>"
          ],
          [
           "Transparency",
           " <i>Responsible Artificial Intelligence in the Government of Canada (whitepaper)</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Transparency",
           " <i>Understanding the need to protect privacy and national security, AI systems<br>should be deployed in the most transparent manner possible.</i>"
          ],
          [
           "Transparency",
           " <i>Artificial Intelligence in Healthcare</i>",
           " 2019",
           " Recommendation",
           " Academic",
           " Western Europe",
           " United Kingdom",
           " Transparency",
           " <i>External critical appraisal and transparency of tech companies are necessary for<br>clinicians to be confident that the tools they are providing are safe to use.</i>"
          ],
          [
           "Transparency",
           " <i>SAP’s guiding principles for Artificial Intelligence</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Transparency",
           " <i>Our systems are held to specific standards following their level of technical<br>ability and intended usage. Their input, capabilities, intended purpose, and<br>limitations will be communicated clearly to our customers, and we provide means<br>for oversight and control by customers and users. They are, and will always<br>remain, in control of the deployment of our products. We actively support<br>industry collaboration and will research to further system transparency.</i>"
          ],
          [
           "Transparency",
           " <i>People + AI Guidebook</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Transparency",
           " <i>Telling the user what data are being used in the AI’s prediction can help your<br>product avoid contextual surprises and privacy suspicion and help the user know<br>when to apply their judgment.  In some cases, there may be no way to offer an<br>explicit, comprehensive explanation. The calculations behind an output may be<br>inscrutable, even to the developers of those systems. In other cases, it may be<br>possible to surface the reasoning behind a prediction, but it may not be easy to<br>explain to users in terms they will understand. In these cases, use partial<br>explanations.</i>"
          ],
          [
           "Transparency",
           " <i>Responsible AI practices</i>",
           " Unspecified",
           " Recommendation",
           " Private Corporation",
           " North America",
           " United States of America",
           " Transparency",
           " <i>Design the model to be interpretable. Use the smallest set of inputs necessary<br>for your performance goals to make it clearer what factors are affecting the<br>model. Constrain your model to produce input-output relationships that reflect<br>domain expert knowledge. Use the simplest model that meets your performance<br>goals. Provide explanations that are understandable and appropriate for the<br>user.</i>"
          ],
          [
           "Transparency",
           " <i>Universal principles of data ethics: 12 guidelines for developing ethics codes</i>",
           " 2016",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Transparency",
           " <i>Aspire to design practices that incorporate transparency, accountability, and<br>audibility. Products and research practices should be subject to internal, and<br>potentially external ethical review. Maximizing transparency at the point of<br>data collection can minimize more significant risks as data travels through the<br>data supply chain.</i>"
          ],
          [
           "Transparency",
           " <i>Artificial Intelligence: Australia’s Ethics Framework - A Discussion Paper</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Oceania",
           " Australia",
           " Transparency",
           " <i>People must be informed when an algorithm is being used that impacts them and<br>they should be provided with information about what information the algorithm<br>uses to make decisions.</i>"
          ],
          [
           "Transparency",
           " <i>Universal Guidelines for Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Belgium",
           " Transparency",
           " <i>All individuals have the right to know the basis of an AI decision that concerns<br>them. This includes access to the factors, logic, and techniques that produced<br>the outcome. The institution responsible for an AI system must be made known to<br>the public.</i>"
          ],
          [
           "Transparency",
           " <i>The Future Society, Law & Society Initiative, Principles for the Governance of<br>AI</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Transparency",
           " <i>AI shall be transparent. Transparency is the ability to trace cause and effect<br>in the decision-making pathways of algorithms and, in hybrid intelligence<br>systems, of their operators.</i>"
          ],
          [
           "Transparency",
           " <i>Sony Group AI Ethics Guidelines</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " Japan",
           " Transparency",
           " <i>During the planning and design stages for its products and services that utilize<br>AI, Sony will strive to introduce methods of capturing the reasoning behind the<br>decisions made by AI utilized in said products and services. Additionally, it<br>will endeavor to provide intelligible explanations and information to customers<br>about the possible impact of using these products and services.</i>"
          ],
          [
           "Transparency",
           " <i>Principles for the safe and effective use of data and analytics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Oceania",
           " New Zealand",
           " Transparency",
           " <i>Data use and analytical processes should be well documented and in line with all<br>relevant legislation, and state sector guidelines. Explanations of decisions –<br>and the analytical activities behind them – should be in clear, simple, easy-to-<br>understand language.</i>"
          ],
          [
           "Transparency",
           " <i>Recommendations for the responsible use of AI and automated decision-making -<br>Corporate Digital Responsibility and Decision Making (Empfehlungen für den<br>verantwortlichen Einsatz von KI und automatisierten Entscheidungen - Corporate<br>Digital Responsibility and Decision Making)</i>",
           " 2018",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Transparency",
           " <i>Companies take effective (self-imposed and thus trust-building) measures to make<br>the \"if\" and the \"how\" of the use of algorithms understandable for the user.<br>This may include the use of automated decisions, the use of specific groups of<br>data, and the reason or goal of the technology used. The user should be enabled<br>to have a basic understanding of the decisions supported by algorithms, machine<br>learning, or AI.</i>"
          ],
          [
           "Transparency",
           " <i>Code of Ethics for Data-Based Value Creation</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Switzerland",
           " Transparency",
           " <i>You should document and communicate what happens to data and how it is done. The<br>focus of transparency is both the customer and, for example, an auditor; the<br>concrete requirements for transparency differ according to these target groups.</i>"
          ],
          [
           "Transparency",
           " <i>Guidelines for the responsible use of artificial intelligence and other digital<br>technologies in human resources work</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Transparency",
           " <i>Before introducing an AI solution, the objective for its use must be clarified.<br>In this process, all relevant stakeholders should be identified and involved.<br>Anyone who uses AI solutions in their organization must be able to understand<br>and explain their logic.</i>"
          ],
          [
           "Transparency",
           " <i>Telefónica´s Approach to the Responsible Use of AI (Enfoque de Telefónica para<br>un uso responsable de la IA)</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " Spain",
           " Transparency",
           " <i>Transparent and Explainable AI mean to be explicit about the kind of personal<br>and/or non-personal data the AI systems uses as well as about the purpose the<br>data is used for. When people directly interact with an AI system, it should be<br>clear to the users that this is the case. When AI systems take, or support,<br>decisions, a certain level of understanding of how the conclusions are arrived<br>at needs to be ensured, by generation explanations about how they reached that<br>decision like is illustrated in for the particular case of supervised machine<br>learning. Those explanations should always consider the user profile to adjust<br>them to the transparency level required. This also applies in the case of using<br>third-party AI technology.</i>"
          ],
          [
           "Transparency",
           " <i>Automated and connected automated driving (Automatisiertes und Vernetztes<br>Fahren)</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " Germany",
           " Transparency",
           " <i>The public has a right to sufficiently differentiate information about new<br>technologies and their use. For the concrete implementation of the principles<br>developed here, guidelines for the use and programming of automated vehicles<br>should be derived in as transparent a form as possible and communicated to the<br>public.</i>"
          ],
          [
           "Transparency",
           " <i>Telia Company Guiding Principles on trusted AI ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Sweden",
           " Transparency",
           " <i>We strive towards transparency and proactively explain the use of AI in our<br>operations to customers, employees, and other stakeholders in a user-friendly<br>way, based on applicable industry best practices and relevant standards.</i>"
          ],
          [
           "Transparency",
           " <i>Responsible AI and robotics: An ethical framework</i>",
           " Unspecified",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Transparency",
           " <i>It must be clear when AI systems need to explain their actions to humans to show<br>why a decision was made, and when, if ever, such transparency is not necessary.</i>"
          ],
          [
           "Transparency",
           " <i>European ethical Charter on the use of Artificial Intelligence in judicial<br>systems and their environment</i>",
           " 2018",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Transparency",
           " <i>make data processing methods accessible and understandable, authorize external<br>audits.</i>"
          ],
          [
           "Transparency",
           " <i>AI Now Report 2018</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Transparency",
           " <i>Fairness, accountability, and transparency in AI require a detailed account of<br>the “full stack supply chain.” For meaningful accountability, we need to better<br>understand and track the parts of an AI system and the full supply chain on<br>which it relies: that means accounting for the origins and use of training data,<br>test data, models, application program interfaces (APIs), and other<br>infrastructural components over a product life cycle. We call this accounting<br>for the “full stack supply chain” of AI systems, and it is a necessary condition<br>for a more responsible form of auditing.</i>"
          ],
          [
           "Transparency",
           " <i>Report on Artificial Intelligence and Human Society</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Transparency",
           " <i>Basic research to ensure that AI technologies are controllable and transparent<br>by explaining the processes and logic of calculations made by AI technologies<br>contribute to their social implications.</i>"
          ],
          [
           "Transparency",
           " <i>Understanding artificial intelligence ethics and safety: A guide for the<br>responsible design and implementation of AI systems in the public sector</i>",
           " 2019",
           " Recommendation",
           " Academic, Non-profit Organization",
           " Western Europe",
           " United Kingdom",
           " Transparency",
           " <i>Designers and implementers of AI systems must be able (1) to explain to affected<br>stakeholders in everyday language how and why a model performed the way it did<br>in a specific context and (2) to justify the ethical permissibility, the<br>discriminatory non-harm, and the public trustworthiness both of its outcome and<br>the processes behind its design and use. Your project team must ensure that<br>every step of the process of designing and implementing your AI project is<br>accessible for audit, oversight, and review. A successful audit requires<br>builders and implementers of algorithmic systems to keep records and to make<br>accessible information that enables monitoring of the soundness and diligence of<br>the innovation processes that produced the AI system.</i>"
          ],
          [
           "Transparency",
           " <i>Safety First for Automated Driving – Proposed technical standards for the<br>development of Automated Driving</i>",
           " 2019",
           " Recommendation",
           " Private Corporation",
           " Western Europe",
           " Germany",
           " Transparency",
           " <i>The aspects of the driving task which remain under the user’s responsibility<br>must be clear to the user. The automated function must ensure that the currently<br>active driving mode can be recognized explicitly and unmistakably at any time.<br>In addition, a change in driving mode must be clearly apparent to the user as<br>well. The behavior of the automated function needs to not only be easy-to-<br>understand for surrounding (vulnerable) road users, but also predictable and<br>manageable.</i>"
          ],
          [
           "Transparency",
           " <i>Data Ethics Framework</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Transparency",
           " <i>Transparency means that your actions, processes, and data are made open to<br>inspection by publishing information about the project in a completely open,<br>understandable, easily accessible, and free format.</i>"
          ],
          [
           "Transparency",
           " <i>Opinion of the Data Ethics Commission</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Transparency",
           " <i>An adequate level of transparency and explainability is an essential<br>prerequisite for auditing algorithmic systems appropriately on the basis of<br>their real potential for harm. In order to be able to carry out a reliable<br>ethical and legal assessment of an algorithmic system, it is essential that<br>enough information be available about its scope, functionality, pool of data,<br>and data analysis. Only a truly transparent system can be examined to determine<br>whether it is pursuing a legitimate purpose.</i>"
          ],
          [
           "Transparency",
           " <i>Artificial Intelligence and Data Protection</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Transparency",
           " <i>Without prejudice to confidentiality safeguarded by law, public procurement<br>procedures should impose on AI developers, manufacturers, and service providers<br>specific duties of transparency, prior assessment of the impact of data<br>processing on human rights and fundamental freedoms, and vigilance on the<br>potential adverse effects and consequences of AI applications (hereinafter<br>referred to as algorithm vigilance).</i>"
          ],
          [
           "Transparency",
           " <i>Statement on Artificial Intelligence, Robotics and 'Autonomous‘ Systems</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " European Union",
           " European Union",
           " Transparency",
           " <i>All ‘autonomous’ technologies must, hence, honor the human ability to choose<br>whether, when, and how to delegate decisions and actions to them. This also<br>involves the transparency and predictability of ‘autonomous’ systems, without<br>which users would not be able to intervene or terminate them if they would<br>consider this morally required.</i>"
          ],
          [
           "Transparency",
           " <i>Report with recommendations to the Commission on Civil Law Rules on Robotics</i>",
           " 2017",
           " Government-Regulation",
           " Governmental Institution",
           " European Union",
           " European Union",
           " Transparency",
           " <i>The European Parliament highlights the principle of transparency, namely that it<br>should always be possible to supply the rationale behind any decision taken with<br>the aid of AI that can have a substantive impact on one or more persons’ lives.<br>The European Parliament considers that it must always be possible to reduce the<br>AI system´s computations to a form comprehensible by humans.</i>"
          ],
          [
           "Transparency",
           " <i>Preparing for the future of Artificial Intelligence</i>",
           " 2016",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Transparency",
           " <i>Federal agencies that make grants to state and local governments in support of<br>the use of AI-based systems to make consequential decisions about individuals<br>should review the terms of grants to ensure that AI-based products or services<br>purchased with Federal grant funds produce results in a sufficiently transparent<br>fashion and are supported by evidence of efficacy and fairness.</i>"
          ],
          [
           "Transparency",
           " <i>Principles for Accountable Algorithms and a Social Impact Statement for<br>Algorithms</i>",
           " Unspecified",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Unspecified",
           " Unspecified",
           " Transparency",
           " <i>Ensure that algorithmic decisions, as well as any data driving those decisions,<br>can be explained to end-users and other stakeholders in non-technical terms.</i>"
          ],
          [
           "Transparency",
           " <i>Artificial Intelligence: Economic importance, social challenges, human<br>responsibility</i>",
           " 2017",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Transparency",
           " <i>It is desirable that results of IT systems ‒ e. g. calculations, forecasts,<br>follow-up processes, and decisions ‒ are transparent and comprehensible. This<br>particularly applies to AI-based systems, which are often perceived as black-<br>boxes. Comprehensive documentation, including objectives, methods, data, tests,<br>and approval processes, must ensure the highest possible degree of transparency<br>and quality assurance.</i>"
          ],
          [
           "Transparency",
           " <i>Guidance for Regulation of Artificial Intelligence Applications</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Transparency",
           " <i>Consistent with law, agencies should take into consideration the following<br>principles when formulating regulatory and non-regulatory approaches to the<br>design, development, deployment, and operation of AI applications, both general<br>and sector-specific. These principles, many of which are interrelated, reflect<br>the goals and principles in Executive Order 13859. Agencies should carefully<br>consider the sufficiency of existing or evolving legal, policy, and regulatory<br>environments before contemplating additional measures for disclosure and<br>transparency. What constitutes appropriate disclosure and transparency is<br>context-specific, depending on assessments of potential harms, the magnitude of<br>those harms, the technical state of the art, and the potential benefits of the<br>AI application.</i>"
          ],
          [
           "Transparency",
           " <i>Tieto’s AI ethics guidelines</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Finland",
           " Transparency",
           " <i>At Tieto, we are committed to striving towards AI that can be explained and<br>explain itself.</i>"
          ],
          [
           "Transparency",
           " <i>A guide to using artificial intelligence in the public sector</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Transparency",
           " <i>With an AI project you should consider several factors, including AI ethics and<br>safety. hese factors span safety, ethical, legal and administrative concerns and<br>include: explainability and transparency - so the affected stakeholders can know<br>how the AI model reached its decision.</i>"
          ],
          [
           "Transparency",
           " <i>AI in the UK: ready, willing and able?</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Transparency",
           " <i>Artificial intelligence should operate on principles of intelligibility and<br>fairness. The Government must understand the need to build public trust and<br>confidence in how to use artificial intelligence, as well as explain the risks.<br>The industry should take the lead in establishing voluntary mechanisms for<br>informing the public when artificial intelligence is being used for significant<br>or sensitive decisions concerning consumers.</i>"
          ],
          [
           "Transparency",
           " <i>Preliminary Study on the Ethics of Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Transparency",
           " <i>AI should be explainable, able to provide insight into its functioning. The data<br>used to train AI systems should be transparent.</i>"
          ],
          [
           "Transparency",
           " <i>Report of COMEST on robotics ethics</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Transparency",
           " <i>Given the complexity of the design, construction, and programming of robots, a<br>central ethical issue is ‘traceability’: the possibility to track the causes of<br>all past actions (and omissions) of a robot.</i>"
          ],
          [
           "Transparency",
           " <i>Top 10 Principles for Ethical Artificial Intelligence</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " Switzerland",
           " Transparency",
           " <i>A transparent artificial intelligence system is one in which it is possible to<br>discover how, and why, the system made a decision, or in the case of a robot,<br>acted the way it did. Workers must be consulted on AI systems’ implementation,<br>development, and deployment. Workers must have the right to demand transparency<br>in the decisions and outcomes of AI systems as well as the underlying<br>algorithms. This includes the right to appeal decisions made by AI/algorithms<br>and have them reviewed by a human being.</i>"
          ],
          [
           "Transparency",
           " <i>Introducing Unity’s Guiding Principles for Ethical AI</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Transparency",
           " <i>Trust the users of the technology to understand the product’s purpose so they<br>can make informed decisions about whether to use the product. Be clear and be<br>transparent.</i>"
          ],
          [
           "Transparency",
           " <i>ACM Code of Ethics and Professional Conduct</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Transparency",
           " <i>A computing professional should accept and provide an appropriate professional<br>review. High-quality professional work in computing depends on professional<br>review at all stages. Whenever appropriate, computing professionals should seek<br>and utilize peer and stakeholder reviews. Computing professionals should also<br>provide constructive, critical reviews of others’ work.</i>"
          ],
          [
           "Transparency",
           " <i>Montréal declaration for a responsible development of artificial intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " Canada",
           " Transparency",
           " <i>AI must meet intelligibility, justifiability, and accessibility criteria, and<br>must be subjected to democratic scrutiny, debate, and control. AI processes that<br>make decisions affecting a person’s life, quality of life, or reputation must be<br>intelligible to their creators</i>"
          ],
          [
           "Transparency",
           " <i>Ethical Framework for Artificial Intelligence in Colombia (Marco Ético para la<br>Inteligencia Artificial en Colombia)</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Latin America",
           " Colombia",
           " Transparency",
           " <i>This principle should be understood as the openness to provide meaningful and<br>understandable information on the design, operation, and impact of artificial<br>intelligence systems both for the developers and users of the system and for<br>those individuals who may be affected by its decisions and results. The<br>information should be easily accessible and understandable, to promote the<br>active participation of citizens in the design, implementation, and evaluation<br>of AI systems.</i>"
          ],
          [
           "Transparency",
           " <i>fAIr LAC: Responsible and Widespread Adoption of Artificial Intelligence in<br>Latin America and the Caribbean</i>",
           " 2020",
           " Recommendation",
           " International Organization",
           " Latin America",
           " Unspecified",
           " Transparency",
           " <i>AI Actors should commit to transparency and responsible disclosure regarding AI<br>systems. To this end, they should provide meaningful information, appropriate to<br>the context, and consistent with the state of art: (i) to foster a general<br>understanding of AI systems, (ii) to make stakeholders aware of their<br>interactions with AI systems, including in the workplace, (iii) to enable those<br>affected by an AI system to understand the outcome, and, (iv) to enable those<br>adversely affected by an AI system to challenge its outcome based on plain and<br>easy-to-understand information on the factors, and the logic that served as the<br>basis for the prediction, recommendation or decision.</i>"
          ],
          [
           "Transparency",
           " <i>Artificial Intelligence for Children: Beijing Principles</i>",
           " 2020",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Transparency",
           " <i>AI models, products, applications, and services should, based on continuous<br>efforts to improve their transparency and interpretability, further consider the<br>cognitive levels, self-needs, and expression abilities of children at different<br>stages, provide the corresponding level of transparency and explanations, and<br>provide children with effective feedback mechanisms and interaction methods.</i>"
          ],
          [
           "Transparency",
           " <i>Social Principles of Human-Centric AI</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia, Western Europe",
           " Japan, United Kingdom",
           " Transparency",
           " <i>Appropriate explanations should be given on a case-by-case basis depending on<br>the application of AI and each particular situation, including such things as<br>when AI is being used, how the AI data is obtained and used, and what measures<br>have been taken to ensure the appropriateness of results obtained from AI<br>operations. For people to understand AI's proposals and make judgments on them,<br>there should be appropriate opportunities for an open dialogue, as required,<br>regarding the use, adoption, and operation of AI.</i>"
          ],
          [
           "Transparency",
           " <i>The Toronto Declaration</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " North America, Western Europe",
           " Canada, United Kingdom",
           " Transparency",
           " <i>Transparency is a key component of human rights due diligence, and involves<br>“communication, providing a measure of transparency and accountability to<br>individuals or groups who may be impacted and to other relevant stakeholders.”<br>States should publicly disclose where machine learning systems are used in the<br>public sphere, provide information that explains in clear and accessible terms<br>how automated and machine learning decision-making processes are reached, and<br>document actions are taken to identify, document, and mitigate against<br>discriminatory or other rights-harming impacts. States should enable independent<br>analysis and oversight by using auditable systems. States should avoid using<br>‘black box systems that cannot be subjected to meaningful standards of<br>accountability and transparency, and refrain from using these systems at all in<br>high-risk contexts.</i>"
          ],
          [
           "Transparency",
           " <i>Governing Artificial Intelligence: Upholding human rights & dignity</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Transparency",
           " <i>UN human rights investigators and special rapporteurs should continue<br>researching and publicizing the human rights impacts resulting from AI systems.<br>UN officials and participating governments should evaluate whether existing UN<br>mechanisms for international rights monitoring, accountability, and redress are<br>adequate to respond to AI and other rapidly emerging technologies. UN leadership<br>should also assume a central role in international technology debates by<br>promoting shared global values based on fundamental rights and human dignity.</i>"
          ],
          [
           "Transparency",
           " <i>DataEthics: Principles and Guidelines for Companies, Authorities & Organisations</i>",
           " 2017",
           " Recommendation",
           " Non-profit Organization",
           " Northern Europe",
           " Denmark",
           " Transparency",
           " <i>Data processing activities and automated decisions must make sense for the<br>individual. They must be truly transparent and explainable. The purpose and<br>interests of data processing must be clearly understood by the individual in<br>terms of understanding risks, as well as social, ethical, and societal<br>consequences.</i>"
          ],
          [
           "Transparency",
           " <i>AI Governance in Japan Ver. 1.1, Report from the expert group on how AI<br>principles should be implemented</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Transparency",
           " <i>Appropriate explanations should be given on a case-by-case basis depending on<br>the application of AI and each particular situation, including such things as<br>when AI is being used, how the AI data is obtained and used, and what measures<br>have been taken to ensure the appropriateness of results obtained from AI<br>operations. For people to understand AI's proposals and make judgments on them,<br>there should be appropriate opportunities for an open dialogue, as required,<br>regarding the use, adoption, and operation of AI.</i>"
          ],
          [
           "Transparency",
           " <i>Principles of Artificial Intelligence Ethics for the Intelligence Community</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Transparency",
           " <i>We will provide appropriate transparency to the public and our customers<br>regarding our AI methods, applications, and uses within the bounds of security,<br>technology, and releasability by law and policy, and consistent with the<br>Principles of Intelligence Transparency for the IC.</i>"
          ],
          [
           "Transparency",
           " <i>Vodafone Artificial Intelligence Framework</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Western Europe",
           " United Kingdom",
           " Transparency",
           " <i>We endeavor to clearly inform our customers and employees when they communicate<br>directly with AI-powered systems. We believe that people should be informed<br>about when they interact with an algorithm or some form of AI/non-human system.<br>We strive to clearly inform our customers and employees about what data we<br>collect on our users and how our systems utilize that data. Anyone who feels<br>they have been unfairly treated as a result of a decision made by an AI system<br>deployed by Vodafone will have the opportunity to escalate their concerns under<br>the published process for Vodafone complaints in their country of operation.</i>"
          ],
          [
           "Transparency",
           " <i>Artificial Intelligence at the service of the citizen (L’intelligenzia<br>artificiale al servizio del cittadino)</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Southern Europe",
           " Italy",
           " Transparency",
           " <i>The articles must be 100% sincere and transparent, and explain the terms used<br>properly so that no person who is going to read them can get confused.<br>Recommendation - Disclose to the public the intermediate results of the<br>elaboration of AI algorithms (ex. parameters of neural networks) operated on<br>data from public administrations, subject to conditions that may harm the<br>privacy and security of citizens. These results must allow the reproducibility<br>of the processes, their evaluation, and verifiability.</i>"
          ],
          [
           "Transparency",
           " <i>Artificial Intelligence: open questions about gender inclusion</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Latin America",
           " Argentina",
           " Transparency",
           " <i>We Recommend that G20 countries embrace regulation promoting transparency in<br>machine learning and AI-powered systems that can meaningfully affect people’s<br>lives. This should include reliance on open data and open AI whenever government<br>relies on these technologies for service provision. These requirements can be<br>included in government procurement guidelines for AI systems that support the<br>delivery of public services.</i>"
          ],
          [
           "Transparency",
           " <i>oston Dynamics Ethical Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Transparency",
           " <i>We are committed to being transparent with the public and our customers<br>regarding the state of our technology.</i>"
          ],
          [
           "Transparency",
           " <i>Augmented Intelligence in Health Care H-480.940</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Professional Association",
           " North America",
           " United States of America",
           " Transparency",
           " <i>AMA will seek to promote the development of thoughtfully designed, high-quality,<br>clinically validated healthcare AI that is transparent.</i>"
          ],
          [
           "Transparency",
           " <i>WLiAI Report 2019: 10 Principles of Responsible AI</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " United Kingdom",
           " Transparency",
           " <i>Recommendation - Establish an AI regulatory function working alongside the<br>Information Commissioner’s Office and Centre for Data Ethics – to audit<br>algorithms, investigate complaints by individuals, issue notices and fines for<br>breaches of GDPR and equality and human rights law, give wider guidance, spread<br>best practice and ensure algorithms must be fully explained to users and<br>open to public scrutiny. Introduce a mandatory requirement for public sector<br>organizations using AI for particular purposes to inform citizens that decisions<br>are made by machines, explain how the decision is reached and what would need to<br>change for individuals to get a different outcome.</i>"
          ],
          [
           "Transparency",
           " <i>The Ethical Norms for the New Generation Artificial Intelligence, China</i>",
           " 2021",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " China",
           " Transparency",
           " <i>Various activities of AI shall abide by the following fundamental ethical norms,<br>like enhancing safety, security, and transparency. In the phases of algorithm<br>design, implementation, and application, etc., improve transparency,<br>interpretability, understandability, reliability, and controllability, enhance<br>the resilience, adaptability, and the ability of anti-interference of AI<br>systems, and gradually realize verifiable, auditable, supervisable, traceable,<br>predictable and trustworthy AI.</i>"
          ],
          [
           "Transparency",
           " <i>Work in the age of artificial intelligence: Four perspectives on the economy,<br>employment, skills and ethics</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Northern Europe",
           " Finland",
           " Transparency",
           " <i>Transparency refers to openness regarding 1) what data are collected and for<br>what purpose (to underpin decision-making based on artificial intelligence), and<br>2) what the aim of the algorithms supporting and making decisions is. The<br>employees of work organizations using artificial intelligence in decision-making<br>should also be aware of this. In terms of the transparency of decisions made in<br>a work organization, it makes no difference in principle if the decisions are<br>made purely by humans, by an algorithm, or by some combination of these two. The<br>importance of transparency of algorithms is accentuated in a very special way in<br>the decision-making of public organizations, where the decisions in many cases<br>concern citizens’ statutory rights and obligations</i>"
          ],
          [
           "Transparency",
           " <i>A Framework for Responsible Limits on Facial RecognitionUse Case: Flow<br>Management</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization",
           " Western Europe",
           " Switzerland",
           " Transparency",
           " <i>Processes should be put in place to inform end-users who have questions and/or<br>need information on the use of facial recognition systems. End users should have<br>access to their personal biometric data upon request. Individuals should provide<br>informed, explicit and affirmative consent for the use of facial recognition<br>systems. Any time data subjects enroll for a new service powered by facial<br>recognition technology, they should express clear consent with regards to the<br>length of data retention. When used in public spaces, clear signage should be<br>deployed to ensure obvious communication with end-users on the use of facial<br>recognition. Areas, where facial recognition systems are used, should always be<br>delimited and indicated to individuals. A visual sign should also inform<br>individuals when the system is in operation.</i>"
          ],
          [
           "Transparency",
           " <i>A Code of Ethics for the Human-Robot Interaction Profession</i>",
           " 2014",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Transparency",
           " <i>Maximal, reasonable transparency in the programming of robotic systems is<br>required.</i>"
          ],
          [
           "Transparency",
           " <i>How to Prevent Discriminatory Outcomes in Machine Learning</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization",
           " Western Europe",
           " Switzerland",
           " Transparency",
           " <i>Involvement of ML systems in decision-making that affects individual rights must<br>be disclosed, and the systems must be able to provide an explanation of their<br>decision-making that is understandable to end-users and reviewable by a<br>competent human authority. Where this is impossible and rights are at stake,<br>leaders in the design, deployment, and regulation of ML technology must question<br>whether or not it should be used.</i>"
          ],
          [
           "Transparency",
           " <i>Discussion Paper: National Strategy for Artificial Intelligence</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " South Asia",
           " India",
           " Transparency",
           " <i>Opening the Black Box, assuming it is possible and useful at this stage (there<br>is considerable debate on that as well), should not aim towards the opening of<br>code or technical disclosure – few clients of AI solutions would be<br>sophisticated AI experts - but should rather aim at “explainability”. With<br>extended disclosure though, what needs to be balanced is whether the algorithm’s<br>parameter may induce the individuals and companies to change their behavior and<br>in turn game the system. More collaborative research is required in this area.</i>"
          ],
          [
           "Transparency",
           " <i>The National Artificial Intelligence Research and Development Strategic Plan:<br>2019 Update</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Transparency",
           " <i>Researchers must learn how to design these systems so that their actions and<br>decision-making are transparent and easily interpretable by humans, and thus can<br>be examined for any bias they may contain, rather than just learning and<br>repeating these biases.</i>"
          ],
          [
           "Transparency",
           " <i>OECD, Recommendation of the Council on Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Western Europe",
           " France",
           " Transparency",
           " <i>AI Actors should commit to transparency and responsible disclosure regarding AI<br>systems. To this end, they should provide meaningful information, appropriate to<br>the context, and consistent with the state of art.</i>"
          ],
          [
           "Transparency",
           " <i>OP Financial Group’s Ethical Guidelines for Artificial Intelligence</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Northern Europe",
           " Finland",
           " Transparency",
           " <i>We operate openly in relation to our customers, partners, and stakeholders,<br>ensuring the transparency required for the evaluation of artificial intelligence<br>we develop.</i>"
          ],
          [
           "Transparency",
           " <i>Oxford Munich Code of Conduct</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Western Europe",
           " Germany",
           " Transparency",
           " <i>The Data Scientist will strive for transparency within as wide a forum as<br>allowable by legal and proprietary constraints. The data scientist will not<br>withhold concerns or potential limitations from colleagues and managers.</i>"
          ],
          [
           "Transparency",
           " <i>Partnership on AI Tenets</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization",
           " Unspecified",
           " Unspecified",
           " Transparency",
           " <i>We believe that it is important for the operation of AI systems to be<br>understandable and interpretable by people, for purposes of explaining the<br>technology.</i>"
          ],
          [
           "Transparency",
           " <i>UNESCO Recommendation on the Ethics of Artificial Intelligence</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Transparency",
           " <i>The transparency and explainability of AI systems are often essential<br>preconditions to ensure the respect, protection, and promotion of human rights,<br>fundamental freedoms, and ethical principles. Transparency is necessary for<br>relevant national and international liability regimes to work effectively. A<br>lack of transparency could also undermine the possibility of effectively<br>challenging decisions based on outcomes produced by AI systems and may thereby<br>infringe the right to a fair trial and effective remedy, and limits the areas in<br>which these systems can be legally used.</i>"
          ],
          [
           "Transparency",
           " <i>AI Principles: Recommendations on the Ethical Use of Artificial Intelligence by<br>the Department of Defense - Defense Innovation Board</i>",
           " 2019",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Transparency",
           " <i>DoD’s AI engineering discipline should be sufficiently advanced such that<br>technical experts possess an appropriate understanding of the technology,<br>development processes, and operational methods of its AI systems, including<br>transparent and auditable methodologies, data sources, design procedure, and<br>documentation.</i>"
          ],
          [
           "Transparency",
           " <i>Megvii's Artificial Intelligence Application Guidelines</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " China",
           " Transparency",
           " <i>AI solutions should be auditable and accountable. Errors, flaws, biases, or<br>other negative effects of AI solutions should be recognized immediately and<br>addressed aggressively as soon as they are discovered.</i>"
          ],
          [
           "Transparency",
           " <i>AI UX: 7 Principles of Designing Good AI Products</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Europe",
           " Hungary",
           " Transparency",
           " <i>We see our job as a UX company as helping people understand how machines work so<br>they can use them better. We should give users hints about what the algorithm<br>does or what data it uses.</i>"
          ],
          [
           "Transparency",
           " <i>Policy guidance on AI for children</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution, International Organization",
           " Northern Europe, Intergovernmental Organization",
           " Finland, United Nations",
           " Transparency",
           " <i>Provide transparency, explainability, and accountability for children. I need to<br>know how AI impacts me. You need to be accountable for that.</i>"
          ],
          [
           "Transparency",
           " <i>Ethics & Governance of Artificial Intelligence for Health</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Transparency",
           " <i>AI technologies should be intelligible or understandable to developers, medical<br>professionals, patients, users, and regulators. Two broad approaches to<br>intelligibility are to improve the transparency of AI technology and to make AI<br>technology explainable. Transparency requires that sufficient information be<br>published or documented before the design or deployment of an AI technology and<br>that such information facilitates meaningful public consultation and debate on<br>how the technology is designed and how it should or should not be used. AI<br>technologies should be explainable according to the capacity of those to whom<br>they are explained.</i>"
          ],
          [
           "Transparency",
           " <i>Ethical ML Institute Responsible Machine Learning Principles</i>",
           " Unspecified",
           " Recommendation",
           " Academic",
           " Western Europe",
           " United Kingdom",
           " Transparency",
           " <i>technologists should invest reasonable efforts where necessary to continuously<br>improve tools and processes that allow them to explain results based on features<br>and models chosen. I commit to developing tools and processes to continuously<br>improve the transparency and explainability of machine learning systems where<br>reasonable. I commit to developing the infrastructure required to enable a<br>reasonable level of reproducibility across the operations of ML systems.</i>"
          ],
          [
           "Transparency",
           " <i>Thomson Reuters AI principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " Canada",
           " Transparency",
           " <i>Thomson Reuters will implement practices intended to make the use of AI in our<br>products and services explainable.</i>"
          ],
          [
           "Transparency",
           " <i>Defense Innovation Unit Responsible AI Guidelines in Practice: Lessons Learned<br>from the DIU Portfolio</i>",
           " 2021",
           " Recommendation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Transparency",
           " <i>The Department’s AI capabilities will be developed and deployed such that<br>relevant personnel possesses an appropriate understanding of the technology,<br>development processes, and operational methods applicable to AI capabilities,<br>including transparent and auditable methodologies, data sources, and design<br>procedure and documentation.</i>"
          ],
          [
           "Transparency",
           " <i>DoD Ethical Principles for Artificial Intelligence</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " United States of America",
           " Transparency",
           " <i>The Department’s AI capabilities will be developed and deployed such that<br>relevant personnel possesses an appropriate understanding of the technology,<br>development processes, and operational methods applicable to AI capabilities,<br>including transparent and auditable methodologies, data sources, and design<br>procedure and documentation.</i>"
          ],
          [
           "Transparency",
           " <i>Alpha Principles for the Ethical Use of AI and Data Driven Technologies in<br>Ontario</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Transparency",
           " <i>There must be transparent and responsible disclosure around data-driven<br>technology like AI, automated decisions, and ML systems to ensure that people<br>understand outcomes and can discuss, challenge, and improve them. Where<br>automated decision making has been used to make individualized and automated<br>decisions about humans, meaningful information about the logic involved, as well<br>as the significance and the envisaged consequences of such processing for the<br>data subject should be available.</i>"
          ],
          [
           "Transparency",
           " <i>Transparency Guidelines for Data-Driven Technology in Government</i>",
           " 2020",
           " Government-Regulation",
           " Governmental Institution",
           " North America",
           " Canada",
           " Transparency",
           " <i>Respect the public’s right to know when and how data enhancements to a decision<br>or process may impact their lives. When acquiring or using technology such as AI<br>that significantly affects individuals and communities notice should be provided<br>that is public, timely, and clear. Notice should be accessible to a broad<br>audience and outline the purpose and potential impacts of a technological<br>intervention like AI as well as clear channels for further communication. Clear<br>lines of communication to learn more, provide input or submit challenges should<br>be accessible and promoted during multiple stages of development and use of<br>data-driven technologies.</i>"
          ],
          [
           "Transparency",
           " <i>Integrate’s AI principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " Canada",
           " Transparency",
           " <i>We are responsible for the products we design and their outputs. For a user of<br>our products to make responsible decisions within their organizations, we need<br>to understand how and why a prediction was made. This is one reason why our<br>models must be explainable. In other words, we can understand how and why a<br>prediction was made. So, transparency is essential. We build products that<br>complement and enhance your decision-making abilities. Not products that replace<br>them. At the end of the day, because we take responsibility for the things we<br>build, we’ll never create tools that can be misused or abused in any way.</i>"
          ],
          [
           "Transparency",
           " <i>National Association of Insurance Commissioners (NAIC) Principles on Artificial<br>Intelligence (AI)</i>",
           " 2020",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Transparency",
           " <i>To improve the public’s confidence in AI, AI actors should commit to<br>transparency and responsible disclosures regarding AI systems to relevant<br>stakeholders. AI actors must have the ability to protect the confidentiality of<br>proprietary algorithms, provided adherence to individual state laws and<br>regulations in all states where AI is deployed can be demonstrated. These<br>proactive disclosures include revealing the kind of data being used, the purpose<br>of the data in the AI system, and consequences for all stakeholders. Consistent<br>with applicable laws and regulations, stakeholders (which includes regulators<br>and consumers) should have a way to inquire about, review, and seek recourse for<br>AI-driven insurance decisions. This information should be easy-to-understand and<br>describe the factors that lead to the prediction, recommendation, or decision.<br>This information may be presented differently and should be appropriate for<br>applicable stakeholders.</i>"
          ],
          [
           "Transparency",
           " <i>Samsung Principles for AI Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Asia",
           " South Korea",
           " Transparency",
           " <i>Users will be aware that they are interacting with AI. AI will be explainable<br>for users to understand its decision or recommendation to the extent<br>technologically feasible. The process of collecting or utilizing personal data<br>will be transparent.</i>"
          ],
          [
           "Transparency",
           " <i>IBM AI Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Transparency",
           " <i>Technology must be transparent and explainable. Companies must be clear about<br>who trains their AI systems, what data was used in training and, most<br>importantly, what went into their algorithms’ recommendations.</i>"
          ],
          [
           "Transparency",
           " <i>Linux Foundation AI Principles</i>",
           " 2020",
           " Recommendation",
           " Non-profit Organization",
           " North America",
           " United States of America",
           " Transparency",
           " <i>Transparency entails the disclosure around AI systems to ensure that people<br>understand AI-based outcomes, especially in high-risk AI domains. When relevant<br>and not immediately obvious, users should be clearly informed when and how they<br>are interacting with an AI and not a human being. For transparency, ensuring<br>that clear information is provided about the AI’s capabilities and limitations,<br>in particular the purpose for which the systems are intended, is necessary.<br>Information about training and testing data sets where feasible, the conditions<br>under which AI can be expected to function as intended and the expected level of<br>accuracy in achieving the specified purpose, should also be supplied.<br>Explainability is the ability to describe how AI works, i.e., makes decisions.<br>Explanations should be produced regarding both the procedures followed by the AI<br>(i.e., its inputs, methods, models, and outputs) and the specific decisions that<br>are made. These explanations should be accessible to people with varying degrees<br>of expertise and capabilities including the public. For the explainability<br>principle to take effect, the AI engineering discipline should be sufficiently<br>advanced such that technical experts possess an appropriate understanding of the<br>technology, development processes, and operational methods of its AI systems,<br>including the ability to explain the sources and triggers for decisions through<br>transparent, traceable processes and auditable methodologies, data sources, and<br>design procedure and documentation.</i>"
          ],
          [
           "Transparency",
           " <i>ADP: Ethics in Artificial Intelligence</i>",
           " 2022",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Transparency",
           " <i>We strive to develop ML models that are explainable and direct, with clear<br>purposes. Our ML models are designed with understanding as a key attribute,<br>measured against an expressed the desired outcome. We test and evaluate our ML<br>models accordingly, adjusting as needed to maintain accuracy in line with the<br>models’ purposes. We provide our clients with information about how our ML<br>models operate, their proper use, and their limitations so that clients can<br>implement those models following their design and purpose, operate them<br>effectively, and use their outputs as intended.</i>"
          ],
          [
           "Transparency",
           " <i>Ethical Aspects of Autonomous and Intelligent Systems</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Transparency",
           " <i>To the greatest extent feasible, the technical basis of the particular decisions<br>made by an A/IS should be discoverable.</i>"
          ],
          [
           "Transparency",
           " <i>IEEE Position Statement - Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Transparency",
           " <i>To ensure that artificial intelligence serves the interests of society, IEEE<br>urges governments to adopt policies that facilitate public understanding and<br>discourse about AI. Develop strategies for informing and engaging the public on<br>AI policies, as well as the benefits, risks, and challenges of AI applications.<br>This will be critical to creating an environment conducive to effective<br>decision-making, particularly as more government services come to rely on AI.<br>Public opinion related to trust, safety, privacy, employment, society, and the<br>economy will drive public policy.</i>"
          ],
          [
           "Transparency",
           " <i>IEEE Policies - Code of Ethics</i>",
           " 2022",
           " Self-Regulation/Voluntary Self-Commitment",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Transparency",
           " <i>We, the members of the IEEE, o hereby commit ourselves to the highest ethical<br>and professional conduct and agree to hold paramount the safety, health, and<br>welfare of the public, to strive to comply with ethical design and sustainable<br>development practices, to protect the privacy of others, and to disclose<br>promptly factors that might endanger the public or the environment.</i>"
          ],
          [
           "Transparency",
           " <i>Adobe’s Commitment to AI Ethics</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Transparency",
           " <i>We will be open about, and explain, our use of AI to our customers so they have<br>a clear understanding of our AI systems and their application. We want our<br>customers to understand how Adobe uses AI, the value AI-assisted tools bring to<br>them, and what controls and preferences they have available when they engage<br>with and utilize Adobe’s AI-enhanced tools and services.</i>"
          ],
          [
           "Transparency",
           " <i>Safe Face Pledge</i>",
           " 2021",
           " Recommendation",
           " Academic, Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " North America",
           " United States of America",
           " Transparency",
           " <i>Submit models on the market for benchmark evaluation where available. By<br>submitting to ongoing external evaluation to the available standards bodies that<br>benchmark facial analysis technology in the countries of operation. Increase<br>public awareness of facial analysis technology use. By publishing accessible<br>information on how facial analysis technologies are sold and used, including the<br>types of entities they are sold to and any safeguards taken to mitigate misuse<br>and risks. By proactively making a public explanation of how the systems work in<br>clear and simple terms so that the people can understand how they work.</i>"
          ],
          [
           "Transparency",
           " <i>Artificial intelligence - Common good as a benchmark, good work as a principle</i>",
           " 2019",
           " Recommendation",
           " Industrial Association",
           " Western Europe",
           " Germany",
           " Transparency",
           " <i>Recommendation - Defining data pools, transparent and open standards for<br>encrypted data transmission, and defining intervention and product liability<br>mechanisms that allow for targeted control enable.</i>"
          ],
          [
           "Transparency",
           " <i>Algorithmic Decision-making for the Benefit of Consumers</i>",
           " 2019",
           " Recommendation",
           " Non-profit Organization",
           " Western Europe",
           " Germany",
           " Transparency",
           " <i>Mandatory standards for the technical design, logging, documentation, and<br>description of ADM systems are required so that it is possible to scrutinize<br>them effectively (transparency by design). Operators of relevant ADM systems<br>must be obliged to provide technical interfaces that the competent supervisory<br>authorities can use to access the systems for the purpose of verifying their<br>legality and checking for technical and methodological errors.</i>"
          ],
          [
           "Transparency",
           " <i>Draft - AI Utilization Principles</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Asia",
           " Japan",
           " Transparency",
           " <i>AI service providers and business users should pay attention to the<br>verifiability of inputs/outputs of AI systems or AI services and the<br>explainability of their judgments.</i>"
          ],
          [
           "Transparency",
           " <i>The Code of Ethics in the Field of Artificial Intelligence</i>",
           " 2022",
           " Recommendation",
           " Unspecified",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Transparency",
           " <i>AI Actors should ensure comprehensive human supervision of any AI system in the<br>scope and order depending on the purpose of this AI system, i.a., for instance,<br>record significant human decisions at all stages of the AI systems’ life cycle<br>or make registration records of the operation of AI systems. AI Actors should<br>also ensure transparency of AI systems use, the opportunity of cancellation by a<br>person, and (or) prevention of socially and legally significant decisions and<br>actions of AI systems at any stage of their life cycle where it is reasonably<br>applicable. In special cases concerning critical applications of an AI system,<br>it is encouraged that risk assessment is conducted with the involvement of a<br>neutral third party or authorized official body given that it does not harm the<br>performance and information security of the AI system and ensures the protection<br>of the intellectual property and trade secrets of the developer.</i>"
          ],
          [
           "Transparency",
           " <i>Shanghai Initiative for Safe and Secure AI Development</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Asia",
           " China",
           " Transparency",
           " <i>Security risks caused by bçlack box technology must be avoided in AI<br>development. There must be a regulation mechanism that is accountable,<br>trackable, and deducible to ensure unity between intended functions and<br>technical realization.</i>"
          ],
          [
           "Transparency",
           " <i>Chinese Young Scientists' Declaration on the Governance and Innovation of<br>Artificial Intelligence (Shanghai Declaration)</i>",
           " 2019",
           " Recommendation",
           " Academic, Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Eastern Asia",
           " China",
           " Transparency",
           " <i>Artificial intelligence should be auditable and traceable. We are committed to<br>confirming test standards, deployment processes, and specifications, ensuring<br>algorithms are verifiable, and gradually improving the accountability and<br>supervision mechanism of artificial intelligence systems.</i>"
          ],
          [
           "Transparency",
           " <i>Trustworthy AI in Aotearoa: AI Principles</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), Non-profit Organization",
           " Oceania",
           " New Zealand",
           " Transparency",
           " <i>The operation and impacts of an AI system should be transparent, traceable,<br>auditable, and generally explainable to a degree appropriate to its use and<br>potential risk profile so outcomes can be understood and challenged,<br>particularly where they relate to people.</i>"
          ],
          [
           "Transparency",
           " <i>Transparency and Trust in the Cognitive Era</i>",
           " 2017",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Transparency",
           " <i>For cognitive systems to fulfill their world-changing potential, it is vital<br>that people have confidence in their recommendations, judgments, and uses.<br>Therefore, the IBM company will make clear: (1) when and for what purposes AI is<br>being applied in the cognitive solutions we develop and deploy; (2) the major<br>sources of data and expertise that inform the insights of cognitive solutions,<br>as well as the methods used to train those systems and solutions.</i>"
          ],
          [
           "Transparency",
           " <i>\"ARCC\": An Ethical Framework for Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Private Corporation",
           " Eastern Asia",
           " China",
           " Transparency",
           " <i>Recommendation - Promote algorithmic transparency and algorithmic audit, to<br>achieve understandable and explainable AI systems. Explain the decisions<br>assisted/made by AI systems when appropriate. Ensure individuals’ right to know,<br>and provide users with sufficient information concerning the AI system’s<br>purpose, function, limitation, and impact.</i>"
          ],
          [
           "Transparency",
           " <i>Fu Ying: Six Principles of Artificial Intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " Eastern Asia",
           " China",
           " Transparency",
           " <i>It is necessary to ensure the security, applicability, and controllability of<br>artificial intelligence systems, protect personal privacy, and prevent data<br>leakage and abuse. Ensure the traceability and transparency of AI algorithms.</i>"
          ],
          [
           "Transparency",
           " <i>A Framework for the Ethical use of advanced Data Science Methodes in the<br>Humanitarian Sector</i>",
           " 2020",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe, Intergovernmental Organization",
           " Netherlands, United Nations",
           " Transparency",
           " <i>For the humanitarian sector, transparency in decision-making and aid delivery<br>are important to improve coordination, efficiency, and accountability to<br>beneficiaries. In the growing context of evidence-based decision-making, it is<br>increasingly necessary that processes and rationale for prioritization and<br>targeting are open.</i>"
          ],
          [
           "Transparency",
           " <i>Technological convergence, artificial intelligence and human rights</i>",
           " 2017",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Transparency",
           " <i>Moreover, the Assembly proposes that guidelines be drawn upon the following<br>issues: strengthening transparency, regulation by public authorities, and<br>operators’ accountability concerning automatic processing operations aimed at<br>collecting, handling, and using personal data; informing the public about the<br>value of the data they generate, consent to the use of those data and the length<br>of time they are to be stored; informing people about the processing of personal<br>data originating from them and about the mathematical and statistical methods<br>making profiling possible.</i>"
          ],
          [
           "Transparency",
           " <i>Decree of the President of the Russian Federation on the Development of<br>Artificial Intelligence in the Russian Federation</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Eastern Europe, Northern Asia",
           " Russia, Russia",
           " Transparency",
           " <i>The basic principles of the development and use of artificial intelligence<br>technologies, the observance of which is obligatory during the implementation of<br>this Strategy, include: the intelligibility of artificial intelligence work and<br>the process whereby it achieves results, as well as nondiscriminatory access by<br>the users of products that have been created based on artificial intelligence<br>technologies to information about the artificial intelligence operating<br>algorithms employed in these products.</i>"
          ],
          [
           "Transparency",
           " <i>Allen Institute for Artificial Intelligence Core Values</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Academic, Non-profit Organization",
           " North America",
           " United States of America",
           " Transparency",
           " <i>We are clear and forthright with our team about our actions, our decisions, and<br>the goals of our institute. We produce and share new research, tools, and<br>resources openly with the wider world. We support open science.</i>"
          ],
          [
           "Transparency",
           " <i>Stanford's Human-Centered AI Initiative Values</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Academic",
           " North America",
           " United States of America",
           " Transparency",
           " <i>In our research and education, we maintain the highest standards, acknowledge<br>mistakes, and are transparent about sources of funding.</i>"
          ],
          [
           "Transparency",
           " <i>Principles and Practices for the Responsible Application of Artificial<br>Intelligence at Motorola Solutions - White Paper</i>",
           " 2019",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Transparency",
           " <i>Motorola Solutions maximizes our ability to explain the operation of our systems<br>by adopting mature, testable AI components that are as simple as possible for<br>the task at hand. We ensure that our systems generate operational performance<br>data that we can monitor and review on a regular basis to assess the efficacy of<br>the operation.</i>"
          ]
         ],
         "hovertemplate": "<b>Document ID </b>=%{customdata[1]}<br><b>Year of Publication </b>=%{customdata[2]}<br><b>Reguation Type </b>=%{customdata[3]}<br><b>Institution Type </b>=%{customdata[4]}<br><b>World Region </b>=%{customdata[5]}<br><b>Country </b>=%{customdata[6]}<br><b>Principle </b>=%{customdata[7]}<br><b>Description </b>=%{customdata[8]}<extra></extra>",
         "legendgroup": "Transparency",
         "marker": {
          "color": "#19d3f3",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Transparency",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          -10.671529,
          -6.6900034,
          -10.840441,
          -8.980414,
          -8.167981,
          -16.062874,
          -13.45277,
          -5.7664733,
          3.641376,
          -18.056435,
          1.9728879,
          -12.897533,
          -9.047069,
          -10.741498,
          -9.190762,
          26.432945,
          -3.1200233,
          -15.850363,
          -12.023842,
          -7.6078277,
          -23.939106,
          7.781169,
          -3.4351768,
          -8.3356905,
          -9.5575075,
          -10.72299,
          -4.6287456,
          -12.376736,
          -14.131412,
          -12.210778,
          -6.7155643,
          -4.748381,
          13.289567,
          -7.5773687,
          -6.3096886,
          -8.050694,
          -7.851776,
          -9.769112,
          -5.451996,
          -5.7089777,
          -10.2140665,
          14.912286,
          -12.5345745,
          -6.4223022,
          24.244495,
          -24.225859,
          12.472327,
          -6.6483026,
          -8.185386,
          -8.804195,
          -22.51118,
          3.6302125,
          -20.88863,
          -8.83193,
          -3.1526797,
          -12.230705,
          -0.25114533,
          -6.9990244,
          -9.338255,
          -9.170278,
          5.01179,
          0.9894834,
          -8.834667,
          -8.9574995,
          -11.976766,
          -1.8808998,
          -9.103331,
          -15.306857,
          -1.36583,
          -6.550949,
          -5.100924,
          -12.52744,
          -2.75373,
          -10.898457,
          -25.231518,
          -2.2122421,
          -13.623496,
          -6.417637,
          -14.880056,
          -13.71593,
          -5.3394084,
          -26.582144,
          -13.597709,
          -8.981498,
          -0.28220564,
          -8.769064,
          -12.962523,
          2.1366856,
          -6.810479,
          -7.115533,
          -10.094889,
          2.4364693,
          -21.933638,
          -0.23220657,
          -11.754616,
          -14.8312025,
          -13.198841,
          -20.333832,
          21.312536,
          -3.5560443,
          -6.2131023,
          -5.3263817,
          -13.870095,
          -4.4492517,
          -10.142634,
          4.242326,
          -4.725356,
          -4.250059,
          -2.5060546,
          4.3371444,
          -5.35122,
          10.919262,
          0.693507,
          -0.7082367,
          5.427005,
          0.120074295,
          -13.489063,
          1.2257593,
          -12.712887,
          -5.6212764,
          -15.951422,
          13.841781,
          -4.6035914,
          -1.2148482,
          -4.744867,
          -12.206336,
          -11.333768,
          -18.10123,
          -15.881966,
          -12.308579,
          -17.923481,
          -10.3991995,
          -3.6211753,
          -1.5818084,
          -17.323433,
          -18.0117,
          -6.895328,
          -6.629685,
          -12.956895,
          -4.135663,
          -11.648867,
          -12.040658,
          -10.878277,
          -11.731645,
          -25.909584,
          8.024766,
          16.918352,
          -3.2442286,
          5.473601,
          -9.961068,
          -23.972706,
          -8.527676,
          -8.478292,
          -14.766706,
          -13.262752,
          -9.743424,
          4.812585,
          -8.688257,
          -14.47898,
          -13.952011,
          -14.551617,
          2.908968,
          3.5704577,
          4.2232013,
          -21.482538
         ],
         "y": [
          -0.9443764,
          -1.8018695,
          -1.4434785,
          -6.498217,
          -3.0867608,
          -6.3698215,
          -22.217665,
          16.592731,
          6.5538387,
          7.0779476,
          -10.399568,
          10.466776,
          -3.76539,
          -3.8340015,
          -0.26821196,
          2.1817436,
          2.7217457,
          -0.4587789,
          -6.565477,
          -9.694744,
          9.508802,
          19.246857,
          -4.347805,
          0.0020030984,
          -6.247306,
          2.7495234,
          1.4065021,
          -9.329157,
          -6.1927047,
          16.759123,
          5.867543,
          3.7742417,
          2.228496,
          -6.2987933,
          2.6736598,
          5.192814,
          -2.802786,
          -4.269094,
          -6.5706353,
          -18.348446,
          -8.586929,
          -17.042084,
          -10.615066,
          -4.598527,
          14.6126585,
          -5.5728264,
          -15.197707,
          19.553642,
          16.263435,
          17.754004,
          13.161529,
          -9.31165,
          0.61000264,
          0.11821741,
          -0.5227777,
          -0.27073053,
          -7.000652,
          -1.8355819,
          18.640812,
          4.087698,
          1.2035235,
          -17.754454,
          -3.5888205,
          -3.6104007,
          8.675936,
          1.0674924,
          1.6261096,
          -0.8012495,
          -23.895943,
          5.458214,
          -1.615532,
          6.168262,
          -11.313859,
          -3.2068627,
          4.0760813,
          -19.470062,
          -3.633056,
          6.381723,
          -4.5181236,
          -0.09664941,
          -6.952384,
          1.9218292,
          5.238509,
          3.2571912,
          3.36289,
          10.598359,
          2.0077481,
          -2.4216359,
          1.6799703,
          1.1665629,
          -22.125765,
          -25.007523,
          -3.838222,
          -6.2044573,
          -5.8944926,
          -6.1097445,
          0.3658413,
          0.90045404,
          14.235881,
          1.3321146,
          -5.429443,
          -5.5627623,
          -8.619322,
          -4.8511515,
          4.563336,
          -1.0339676,
          16.854153,
          -5.8037148,
          -17.531982,
          -15.53457,
          -1.2824503,
          -6.8932924,
          -18.578604,
          -29.0086,
          -4.094452,
          -2.8606532,
          1.7485149,
          15.461851,
          -11.2158785,
          4.463783,
          -4.8063884,
          5.326965,
          -7.225344,
          -18.689423,
          23.320036,
          -8.795777,
          2.23229,
          -18.586866,
          -9.076875,
          -10.236377,
          -9.287761,
          -5.75296,
          8.083634,
          -19.1792,
          -18.062193,
          -17.133339,
          2.5026612,
          1.0036011,
          -0.8530921,
          -4.1207757,
          -5.3635836,
          -3.6579313,
          -1.8642236,
          -3.6238132,
          -8.405594,
          -7.3796167,
          15.345267,
          -21.233673,
          16.750494,
          10.592316,
          -6.7801332,
          -9.046165,
          -3.7648115,
          -3.0231295,
          -4.1965623,
          -3.4739454,
          -21.528435,
          -0.8318392,
          0.68880206,
          5.8402467,
          14.277457,
          -18.888174,
          -19.924858,
          -20.565409,
          -5.9424105
         ],
         "z": [
          -13.801441,
          -9.153082,
          -9.106403,
          -18.542343,
          -11.921985,
          -19.013647,
          7.6672344,
          -5.1592584,
          -14.497558,
          -21.030172,
          -8.182267,
          -15.750937,
          -16.915468,
          -14.646305,
          -15.573183,
          -8.244914,
          -21.683569,
          -7.7074285,
          -11.296679,
          -12.801664,
          8.433611,
          -2.815804,
          -17.29493,
          -18.901386,
          -13.23848,
          -17.281185,
          -18.587803,
          -14.54331,
          -14.015926,
          -15.904808,
          -26.375374,
          -27.609524,
          -20.537577,
          -15.827469,
          -18.971842,
          -19.789614,
          -15.1125765,
          -8.675027,
          -8.928685,
          -4.809409,
          -15.085559,
          -12.109794,
          -14.817798,
          -17.293514,
          3.4394875,
          0.82947844,
          -4.994923,
          -4.1230826,
          -7.2827597,
          -5.0646815,
          -1.2010485,
          -17.422731,
          -10.097693,
          -6.697854,
          -17.65457,
          -17.737963,
          -16.893394,
          -16.55831,
          -8.057809,
          -5.734337,
          -25.143162,
          -9.300189,
          -20.476122,
          -24.095798,
          -16.809229,
          -21.766645,
          -10.4844265,
          -15.276649,
          10.0896015,
          -21.509268,
          -19.7446,
          -18.508356,
          -15.49668,
          -18.627497,
          -0.4536272,
          -6.1987753,
          -17.020288,
          -17.890907,
          -7.499429,
          -6.890781,
          -16.460133,
          1.4476266,
          -17.517796,
          -18.487988,
          -4.3322043,
          12.009372,
          -11.483903,
          -14.700706,
          -20.644012,
          -15.253176,
          -8.2439995,
          -8.395384,
          12.417917,
          -8.773879,
          -13.540641,
          17.444923,
          -14.702843,
          -11.637185,
          -0.5154852,
          9.309032,
          -13.40078,
          -10.560856,
          -11.267443,
          -21.193909,
          -13.926343,
          -3.1042907,
          -3.8239307,
          -20.593153,
          -7.498546,
          -18.692705,
          -12.977392,
          -9.120146,
          -7.3744183,
          -2.8463812,
          -11.694251,
          -0.3788869,
          -16.222464,
          -5.6485963,
          15.7586975,
          -11.402952,
          -14.303132,
          -15.532418,
          -9.832409,
          -5.3693604,
          -15.08696,
          -17.301497,
          -13.676373,
          -1.183542,
          -2.6303482,
          -20.3945,
          -12.983577,
          -16.63238,
          -13.262583,
          -13.360673,
          -3.3368986,
          -3.067323,
          -11.956169,
          -10.870344,
          -22.624462,
          -10.199906,
          -19.239653,
          -14.614296,
          -17.123928,
          -23.086147,
          -2.0957284,
          -5.5441465,
          7.300126,
          -6.7235427,
          -5.3817177,
          -18.981678,
          -7.974013,
          -12.041437,
          4.2891474,
          -2.3943605,
          -9.581654,
          -10.652693,
          12.630331,
          -13.231013,
          -3.4991276,
          -13.611084,
          9.539571,
          20.301437,
          -5.7839065,
          -4.6699286,
          -16.726318
         ]
        },
        {
         "customdata": [
          [
           "Truthfulness",
           " <i>Responsible AI: A Global Policy Framework</i>",
           " 2021",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO), International Organization, Professional Association",
           " North America",
           " United States of America",
           " Truthfulness",
           " <i>Organisations that develop, deploy or use AI systems to filter or promote<br>informational content on internet platforms that are shared or seen by their<br>users should take reasonable measures, consistent with applicable law, to<br>minimize the spread of false or misleading information where there is a material<br>risk that such false or misleading information might lead to significant harm to<br>individuals, groups or democratic institutions.</i>"
          ],
          [
           "Truthfulness",
           " <i>AI at Google: our principles</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Truthfulness",
           " <i>AI also enhances our ability to understand the meaning of content at scale. We<br>will strive to make high-quality and accurate information readily available<br>using AI.</i>"
          ],
          [
           "Truthfulness",
           " <i>Code of Practice on Disinformation</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " International Organization",
           " European Union",
           " European Union",
           " Truthfulness",
           " <i>The Signatories of this Code commit to supporting good faith independent efforts<br>to track Disinformation and understand its impact, including the independent<br>network of fact-checkers facilitated by the European Commission upon its<br>establishment. Relevant Signatories commit to deploying policies and processes<br>to disrupt advertising and monetization incentives for relevant behaviors, such<br>as misrepresenting material information about oneself or the purpose of one’s<br>properties.</i>"
          ],
          [
           "Truthfulness",
           " <i>AI Ethics Principles & Guidelines</i>",
           " 2019",
           " Government-Regulation",
           " Governmental Institution",
           " Middle East",
           " United Arab Emirates",
           " Truthfulness",
           " <i>AI systems should be built to serve and inform, and not to deceive and<br>manipulate.</i>"
          ],
          [
           "Truthfulness",
           " <i>Principles of Robotics</i>",
           " 2017",
           " Recommendation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Truthfulness",
           " <i>Robots are manufactured artifacts. They should not be designed in a deceptive<br>way to exploit vulnerable users; instead, their machine nature should be<br>transparent.</i>"
          ],
          [
           "Truthfulness",
           " <i>Artificial Intelligence at Google: Our Principles</i>",
           " Unspecified",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Truthfulness",
           " <i>We will strive to make high-quality and accurate information readily available<br>using AI while continuing to respect cultural, social, and legal norms in the<br>countries where we operate.</i>"
          ],
          [
           "Truthfulness",
           " <i>AI Now Report 2018</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Truthfulness",
           " <i>Consumer protection agencies should apply “truth-in-advertising” laws to AI<br>products and services. AI vendors should be held to high standards for what they<br>can promise, especially when the scientific evidence to back these promises is<br>inadequate and the longer-term consequences are unknown.</i>"
          ],
          [
           "Truthfulness",
           " <i>Opinion of the Data Ethics Commission</i>",
           " 2018",
           " Recommendation",
           " Civil Society Organization (CSO)/ Non-Governmental Organizaiton (NGO)",
           " Western Europe",
           " Germany",
           " Truthfulness",
           " <i>Protecting human dignity also involves ensuring that the human as a relational<br>being is not misled by technology about the nature of a relationship; for<br>example, it would be wrong for a human to be systematically deceived into<br>thinking that he or she is speaking with another human when it is a bot. The<br>psychological integrity of the individual is a particularly important factor in<br>protecting human dignity. This rules out the use of data-driven systems for<br>manipulative purposes, particularly when the systems draw on comprehensive and<br>highly granular personality profiles.</i>"
          ],
          [
           "Truthfulness",
           " <i>AI in the UK: ready, willing and able?</i>",
           " 2018",
           " Government-Regulation",
           " Governmental Institution",
           " Western Europe",
           " United Kingdom",
           " Truthfulness",
           " <i>The autonomous power to hurt, destroy or deceive human beings should never be<br>vested in artificial intelligence.</i>"
          ],
          [
           "Truthfulness",
           " <i>Preliminary Study on the Ethics of Artificial Intelligence</i>",
           " 2019",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Truthfulness",
           " <i>AI should strengthen freedom of expression, universal access to information, the<br>quality of journalism, and free, independent, and pluralistic media while<br>avoiding the spreading of disinformation. Multi-stakeholder governance should be<br>promoted.</i>"
          ],
          [
           "Truthfulness",
           " <i>Introducing Unity’s Guiding Principles for Ethical AI</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " North America",
           " United States of America",
           " Truthfulness",
           " <i>Develop products responsibly and do not take advantage of your products’ users<br>by manipulating them through AI’s vastly more predictive capabilities derived<br>from user data.</i>"
          ],
          [
           "Truthfulness",
           " <i>ACM Code of Ethics and Professional Conduct</i>",
           " 2018",
           " Recommendation",
           " Non-profit Organization, Professional Association",
           " North America",
           " United States of America",
           " Truthfulness",
           " <i>A computing professional should be honest and trustworthy. Computing<br>professionals should be honest about their qualifications, and about any<br>limitations in their competence to complete a task. Computing professionals<br>should be forthright about any circumstances that might lead to either real or<br>perceived conflicts of interest or otherwise tend to undermine the independence<br>of their judgment. Furthermore, commitments should be honored. Computing<br>professionals should protect confidentiality except in cases where it is<br>evidence of a violation of law, organizational regulations, or the Code. In<br>these cases, the nature or contents of that information should not be disclosed<br>except to appropriate authorities. Computing professionals should respectfully<br>address inaccurate or misleading information related to computing.</i>"
          ],
          [
           "Truthfulness",
           " <i>Montréal declaration for a responsible development of artificial intelligence</i>",
           " 2018",
           " Recommendation",
           " Academic",
           " North America",
           " Canada",
           " Truthfulness",
           " <i>AI must not be developed to spread untrustworthy information, lies, or<br>propaganda, and should be designed to contain their dissemination. The<br>development of AI must avoid creating dependencies through attention-capturing<br>techniques or the imitation of human characteristics (appearance, voice, etc.)<br>in ways that could cause confusion between AI and humans.</i>"
          ],
          [
           "Truthfulness",
           " <i>Position on Robotics and Artificial Intelligence</i>",
           " 2016",
           " Recommendation",
           " International Organization",
           " European Union",
           " European Union",
           " Truthfulness",
           " <i>Robots are manufactured artifacts. They should not be designed in a deceptive<br>way to exploit vulnerable users; instead, their machine nature should be<br>transparent.</i>"
          ],
          [
           "Truthfulness",
           " <i>A Code of Ethics for the Human-Robot Interaction Profession</i>",
           " 2014",
           " Recommendation",
           " Academic",
           " North America",
           " United States of America",
           " Truthfulness",
           " <i>Wizard-of-Oz (i.e., a technique where a person remotely operates a robot and<br>puppeteers many of the robot's attributes) should be employed as judiciously and<br>carefully as possible, and should aim to avoid Turing deceptions (i.e., e a<br>participant cannot determine if they are interacting with a machine, a specific<br>person, or a person masquerading as another person). The tendency for humans to<br>form attachments to and anthropomorphize robots should be carefully considered<br>during design. Humanoid morphology and functionality are permitted only to the<br>extent necessary for the achievement of reasonable design objectives.</i>"
          ],
          [
           "Truthfulness",
           " <i>UNESCO Recommendation on the Ethics of Artificial Intelligence</i>",
           " 2021",
           " Recommendation",
           " International Organization",
           " Intergovernmental Organization",
           " United Nations",
           " Truthfulness",
           " <i>The Member States should invest in and promote digital and media and information<br>literacy skills to strengthen critical thinking and competencies needed to<br>understand the use and implication of AI systems, in order to mitigate and<br>counter disinformation, misinformation, and hate speech. A better understanding<br>and evaluation of both the positive and potentially harmful effects of<br>recommender systems should be part of those efforts.</i>"
          ],
          [
           "Truthfulness",
           " <i>AI UX: 7 Principles of Designing Good AI Products</i>",
           " 2018",
           " Self-Regulation/Voluntary Self-Commitment",
           " Private Corporation",
           " Eastern Europe",
           " Hungary",
           " Truthfulness",
           " <i>We must set the right expectations, especially in a world full of sensational,<br>superficial news about new AI technologies. Set expectations so people will know<br>what they can or can’t achieve with the AI product.</i>"
          ]
         ],
         "hovertemplate": "<b>Document ID </b>=%{customdata[1]}<br><b>Year of Publication </b>=%{customdata[2]}<br><b>Reguation Type </b>=%{customdata[3]}<br><b>Institution Type </b>=%{customdata[4]}<br><b>World Region </b>=%{customdata[5]}<br><b>Country </b>=%{customdata[6]}<br><b>Principle </b>=%{customdata[7]}<br><b>Description </b>=%{customdata[8]}<extra></extra>",
         "legendgroup": "Truthfulness",
         "marker": {
          "color": "#FF6692",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Truthfulness",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          0.22933945,
          -0.039803427,
          -2.9696712,
          -8.988219,
          -10.788981,
          -0.019467557,
          -0.80673134,
          -1.7972769,
          -4.75939,
          12.466643,
          -7.5430818,
          19.785158,
          -7.2859545,
          -10.788981,
          -12.465326,
          15.240096,
          -3.2917855
         ],
         "y": [
          -2.7508385,
          -23.797308,
          3.96626,
          -2.753189,
          -9.370355,
          -22.256138,
          -4.0934753,
          14.913492,
          -1.4100814,
          4.078578,
          0.86337835,
          13.541535,
          -0.6720425,
          -9.370355,
          -8.976923,
          -7.637505,
          -16.433857
         ],
         "z": [
          -6.3549304,
          -3.4594414,
          -27.913427,
          13.219666,
          18.083187,
          -3.371213,
          -10.525432,
          7.8096056,
          16.824268,
          10.929049,
          -2.8384879,
          -1.4272947,
          14.0548525,
          18.083187,
          20.043596,
          0.46669453,
          -18.521442
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "bgcolor": "white",
          "bordercolor": "black",
          "borderwidth": 1,
          "font": {
           "color": "black",
           "size": 12
          },
          "showarrow": false,
          "text": "<b><i>Word embeddings were attained<br>via the OpenAI API using<br>text-embedding-ada-002.</b></i>",
          "textangle": 0,
          "x": 0.05,
          "xanchor": "left",
          "xref": "paper",
          "y": -0.1,
          "yref": "paper"
         }
        ],
        "legend": {
         "title": {
          "text": "<b>Principles</b>"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "scene": {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "xaxis": {
          "showticklabels": false,
          "title": {
           "text": "tsne_1"
          },
          "visible": false
         },
         "yaxis": {
          "showticklabels": false,
          "title": {
           "text": "tsne_2"
          },
          "visible": false
         },
         "zaxis": {
          "showticklabels": false,
          "title": {
           "text": "tsne_3"
          },
          "visible": false
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(51,51,51)"
            },
            "error_y": {
             "color": "rgb(51,51,51)"
            },
            "marker": {
             "line": {
              "color": "rgb(237,237,237)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(237,237,237)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(51,51,51)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(51,51,51)"
            },
            "baxis": {
             "endlinecolor": "rgb(51,51,51)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(51,51,51)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(237,237,237)",
             "ticklen": 6,
             "ticks": "inside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(237,237,237)",
             "ticklen": 6,
             "ticks": "inside"
            },
            "colorscale": [
             [
              0,
              "rgb(20,44,66)"
             ],
             [
              1,
              "rgb(90,179,244)"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(237,237,237)",
             "ticklen": 6,
             "ticks": "inside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(237,237,237)",
             "ticklen": 6,
             "ticks": "inside"
            },
            "colorscale": [
             [
              0,
              "rgb(20,44,66)"
             ],
             [
              1,
              "rgb(90,179,244)"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(237,237,237)",
             "ticklen": 6,
             "ticks": "inside"
            },
            "colorscale": [
             [
              0,
              "rgb(20,44,66)"
             ],
             [
              1,
              "rgb(90,179,244)"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(237,237,237)",
             "ticklen": 6,
             "ticks": "inside"
            },
            "colorscale": [
             [
              0,
              "rgb(20,44,66)"
             ],
             [
              1,
              "rgb(90,179,244)"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(237,237,237)",
             "ticklen": 6,
             "ticks": "inside"
            },
            "colorscale": [
             [
              0,
              "rgb(20,44,66)"
             ],
             [
              1,
              "rgb(90,179,244)"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(237,237,237)",
             "ticklen": 6,
             "ticks": "inside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(237,237,237)",
             "ticklen": 6,
             "ticks": "inside"
            },
            "colorscale": [
             [
              0,
              "rgb(20,44,66)"
             ],
             [
              1,
              "rgb(90,179,244)"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "tickcolor": "rgb(237,237,237)",
            "ticklen": 6,
            "ticks": "inside"
           }
          },
          "colorscale": {
           "sequential": [
            [
             0,
             "rgb(20,44,66)"
            ],
            [
             1,
             "rgb(90,179,244)"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "rgb(20,44,66)"
            ],
            [
             1,
             "rgb(90,179,244)"
            ]
           ]
          },
          "colorway": [
           "#F8766D",
           "#A3A500",
           "#00BF7D",
           "#00B0F6",
           "#E76BF3"
          ],
          "font": {
           "color": "rgb(51,51,51)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "rgb(237,237,237)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "rgb(237,237,237)",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "tickcolor": "rgb(51,51,51)",
            "ticks": "outside"
           },
           "bgcolor": "rgb(237,237,237)",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "tickcolor": "rgb(51,51,51)",
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(237,237,237)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "tickcolor": "rgb(51,51,51)",
            "ticks": "outside",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "rgb(237,237,237)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "tickcolor": "rgb(51,51,51)",
            "ticks": "outside",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "rgb(237,237,237)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "tickcolor": "rgb(51,51,51)",
            "ticks": "outside",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "tickcolor": "rgb(51,51,51)",
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "tickcolor": "rgb(51,51,51)",
            "ticks": "outside"
           },
           "bgcolor": "rgb(237,237,237)",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "tickcolor": "rgb(51,51,51)",
            "ticks": "outside"
           }
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "tickcolor": "rgb(51,51,51)",
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "tickcolor": "rgb(51,51,51)",
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          }
         }
        },
        "title": {
         "text": "<b>t-SNE with 500 components ranked by PCA<br>Total Explained Variance: 96.94%</b>",
         "x": 0.5
        },
        "xaxis": {
         "showticklabels": false
        },
        "yaxis": {
         "showticklabels": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textwrap\n",
    "\n",
    "df = pd.read_parquet('data/embeddings_dataset.parquet')\n",
    "\n",
    "# Number of components to keep during PCA\n",
    "pca_n_components = 500\n",
    "\n",
    "# Perplexity and number of iterations for t-SNE\n",
    "perplexity = 50\n",
    "number_of_iterations = 1_000\n",
    "\n",
    "# Learning rate for t-SNE\n",
    "learning_rate=10\n",
    "\n",
    "# Color to use for the plot\n",
    "color = 'principles' # 'principles', 'document_regulation', 'institution_type', 'world_region', 'country'\n",
    "\n",
    "# Transform the values of our `df.embeddings` column into a 2D numpy array where each row corresponds to an embedding vector.\n",
    "X = np.squeeze(np.transpose(np.dstack(df.embeddings.values)))\n",
    "\n",
    "# Perform PCA on the embeddings\n",
    "pca = PCA(n_components=pca_n_components)\n",
    "pca_result = pca.fit_transform(X)\n",
    "\n",
    "# Perform t-SNE on the embeddings\n",
    "tsne = TSNE(n_components=3, \n",
    "    verbose=1, \n",
    "    perplexity=perplexity, \n",
    "    n_iter=number_of_iterations, \n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "tsne_results = tsne.fit_transform(pca_result)\n",
    "\n",
    "# Create a new dataframe with the t-SNE results\n",
    "tsne_df = pd.DataFrame(tsne_results, columns=['tsne_1', 'tsne_2', 'tsne_3'] )\n",
    "tsne_df = pd.concat([tsne_df, df], axis=1)\n",
    "tsne_df.columns= ['tsne_1', 'tsne_2', 'tsne_3'] + df.columns.tolist()\n",
    "\n",
    "# Plot the t-SNE results as a 3D scatter plot\n",
    "fig = px.scatter_3d(\n",
    "    tsne_df, x='tsne_1', y='tsne_2', z='tsne_3', color=color,\n",
    "    labels={color: \"<b>\" + color.replace('_', ' ').title() + \"</b>\"},\n",
    "    hover_data={'tsne_1': False, \n",
    "                'tsne_2':False,\n",
    "                'tsne_3':False,\n",
    "                color:False,\n",
    "                '<b>Document ID </b>': [\" <i>\" + textwrap.fill(x, width=80).replace('\\n', '<br>') \\\n",
    "                    + \"</i>\" for x in tsne_df['documents_ids']],\n",
    "                '<b>Year of Publication </b>': \" \" + tsne_df['year_of_publication'],\n",
    "                '<b>Reguation Type </b>': \" \" + tsne_df['document_regulation'],\n",
    "                '<b>Institution Type </b>': \" \" + tsne_df['institution_type'],\n",
    "                '<b>World Region </b>': \" \" + tsne_df['world_region'],\n",
    "                '<b>Country </b>': \" \" + tsne_df['country'],\n",
    "                '<b>Principle </b>': \" \" + tsne_df['principles'],\n",
    "                '<b>Description </b>': [\" <i>\" + textwrap.fill(x, width=80).replace('\\n', '<br>') \\\n",
    "                    + \"</i>\" for x in tsne_df['text']] , \n",
    "            }\n",
    ")\n",
    "\n",
    "fig.update_layout(template='ggplot2',\n",
    "                  title=f'<b>t-SNE with {pca_n_components if X.shape[0] > pca_n_components else int(X.shape[0]/2)} \\\n",
    "components ranked by PCA<br>Total Explained Variance: {pca.explained_variance_ratio_.sum() * 100:.2f}%</b>',\n",
    "                  title_x=0.5,\n",
    "                  scene=dict(\n",
    "                    xaxis=dict(showticklabels=False, visible=False),\n",
    "                    yaxis=dict(showticklabels=False, visible=False),\n",
    "                    zaxis=dict(showticklabels=False, visible=False),\n",
    "                  ))\n",
    "fig.update_xaxes(showticklabels=False)\n",
    "fig.update_yaxes(showticklabels=False)\n",
    "\n",
    "fig.add_annotation(dict(font=dict(color='black',size=12),\n",
    "                                        x=0.05,\n",
    "                                        y=-0.1,\n",
    "                                        showarrow=False,\n",
    "                                        text=\"<b><i>Word embeddings were attained<br>via the OpenAI API using<br>text-embedding-ada-002.</b></i>\",\n",
    "                                        textangle=0,\n",
    "                                        xanchor='left',\n",
    "                                        xref=\"paper\",\n",
    "                                        yref=\"paper\",\n",
    "                                        bordercolor='black',\n",
    "                                        borderwidth=1,\n",
    "                                        bgcolor=\"white\"))\n",
    "\n",
    "fig.show()\n",
    "#fig.write_html(\"data/tsne.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow, we create a distance matrix, using the results of the t-SNE analysis as our distance metric. Here, every principle is compared to every other principle (distance of the centroid of a cluster to another cluster) and itself (average distance from all points belonging to the same class to its own centroid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Principle: %{x}<br>Principle: %{y}<br>Distance: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z}",
         "type": "heatmap",
         "x": [
          "Accountability",
          "Autonomy",
          "Beneficence",
          "Children Rights",
          "Cooperation",
          "Dignity",
          "Diversity",
          "Fairness",
          "Human Centeredness",
          "Human Formation",
          "Intellectual Property",
          "Labor Rights",
          "Privacy",
          "Reliability",
          "Sustainability",
          "Transparency",
          "Truthfulness"
         ],
         "xaxis": "x",
         "y": [
          "Accountability",
          "Autonomy",
          "Beneficence",
          "Children Rights",
          "Cooperation",
          "Dignity",
          "Diversity",
          "Fairness",
          "Human Centeredness",
          "Human Formation",
          "Intellectual Property",
          "Labor Rights",
          "Privacy",
          "Reliability",
          "Sustainability",
          "Transparency",
          "Truthfulness"
         ],
         "yaxis": "y",
         "z": [
          [
           21.133638381958008,
           25.951074600219727,
           26.641250610351562,
           32.898956298828125,
           26.665058135986328,
           27.084836959838867,
           27.484384536743164,
           27.31365966796875,
           25.175682067871094,
           29.726848602294922,
           27.17121696472168,
           31.155824661254883,
           25.765409469604492,
           22.67060661315918,
           29.145849227905273,
           22.81501007080078,
           24.702444076538086
          ],
          [
           25.951074600219727,
           24.0212459564209,
           26.66802406311035,
           27.26919937133789,
           27.55238151550293,
           22.73207664489746,
           26.62123680114746,
           25.630435943603516,
           25.83095932006836,
           30.89875602722168,
           27.430625915527344,
           31.519100189208984,
           23.00220489501953,
           26.27573585510254,
           28.104270935058594,
           27.407567977905273,
           26.35931968688965
          ],
          [
           26.641250610351562,
           26.66802406311035,
           25.39348030090332,
           29.583566665649414,
           26.254745483398438,
           24.41042709350586,
           25.269454956054688,
           26.800500869750977,
           23.95442008972168,
           26.436607360839844,
           27.176315307617188,
           26.822511672973633,
           28.404052734375,
           27.427656173706055,
           24.97499656677246,
           29.838802337646484,
           25.706937789916992
          ],
          [
           32.898956298828125,
           27.26919937133789,
           29.583566665649414,
           23.667327880859375,
           31.791019439697266,
           23.25432014465332,
           29.47795867919922,
           28.630155563354492,
           29.27074432373047,
           34.40054702758789,
           31.34041976928711,
           34.476158142089844,
           26.31956672668457,
           32.55609130859375,
           29.315099716186523,
           35.45439147949219,
           30.965791702270508
          ],
          [
           26.665058135986328,
           27.55238151550293,
           26.254745483398438,
           31.791019439697266,
           23.662694931030273,
           26.005952835083008,
           22.98210334777832,
           24.083250045776367,
           25.252084732055664,
           23.893417358398438,
           24.769668579101562,
           24.785703659057617,
           29.600984573364258,
           28.314109802246094,
           25.455793380737305,
           27.891233444213867,
           26.430654525756836
          ],
          [
           27.084836959838867,
           22.73207664489746,
           24.41042709350586,
           23.25432014465332,
           26.005952835083008,
           18.395713806152344,
           23.652124404907227,
           23.781147003173828,
           23.322439193725586,
           28.14357566833496,
           25.84760284423828,
           28.21390724182129,
           22.756372451782227,
           27.30789566040039,
           24.02267074584961,
           30.164106369018555,
           25.296939849853516
          ],
          [
           27.484384536743164,
           26.62123680114746,
           25.269454956054688,
           29.47795867919922,
           22.98210334777832,
           23.652124404907227,
           20.896953582763672,
           22.127784729003906,
           24.262868881225586,
           22.76325225830078,
           23.508981704711914,
           23.35763931274414,
           28.956558227539062,
           28.896167755126953,
           23.6334171295166,
           29.317867279052734,
           26.102066040039062
          ],
          [
           27.31365966796875,
           25.630435943603516,
           26.800500869750977,
           28.630155563354492,
           24.083250045776367,
           23.781147003173828,
           22.127784729003906,
           19.906370162963867,
           26.593923568725586,
           27.155757904052734,
           23.2987003326416,
           28.061405181884766,
           26.08262825012207,
           28.572484970092773,
           27.085033416748047,
           27.05950927734375,
           27.13542366027832
          ],
          [
           25.175682067871094,
           25.83095932006836,
           23.95442008972168,
           29.27074432373047,
           25.252084732055664,
           23.322439193725586,
           24.262868881225586,
           26.593923568725586,
           21.34869384765625,
           24.915544509887695,
           26.492273330688477,
           25.071855545043945,
           28.165311813354492,
           26.080904006958008,
           22.95431900024414,
           28.857275009155273,
           24.168779373168945
          ],
          [
           29.726848602294922,
           30.89875602722168,
           26.436607360839844,
           34.40054702758789,
           23.893417358398438,
           28.14357566833496,
           22.76325225830078,
           27.155757904052734,
           24.915544509887695,
           17.985849380493164,
           26.26112937927246,
           18.16432762145996,
           35.331539154052734,
           31.470237731933594,
           22.75971221923828,
           32.91358947753906,
           27.647523880004883
          ],
          [
           27.17121696472168,
           27.430625915527344,
           27.176315307617188,
           31.34041976928711,
           24.769668579101562,
           25.84760284423828,
           23.508981704711914,
           23.2987003326416,
           26.492273330688477,
           26.26112937927246,
           23.228710174560547,
           27.107452392578125,
           28.539230346679688,
           28.60053825378418,
           26.878395080566406,
           28.08333396911621,
           27.094005584716797
          ],
          [
           31.155824661254883,
           31.519100189208984,
           26.822511672973633,
           34.476158142089844,
           24.785703659057617,
           28.21390724182129,
           23.35763931274414,
           28.061405181884766,
           25.071855545043945,
           18.16432762145996,
           27.107452392578125,
           16.997066497802734,
           36.23580551147461,
           32.72639846801758,
           22.11268424987793,
           34.72093963623047,
           28.47471046447754
          ],
          [
           25.765409469604492,
           23.00220489501953,
           28.404052734375,
           26.31956672668457,
           29.600984573364258,
           22.756372451782227,
           28.956558227539062,
           26.08262825012207,
           28.165311813354492,
           35.331539154052734,
           28.539230346679688,
           36.23580551147461,
           17.964353561401367,
           25.280946731567383,
           31.454986572265625,
           26.24510955810547,
           27.701631546020508
          ],
          [
           22.67060661315918,
           26.27573585510254,
           27.427656173706055,
           32.55609130859375,
           28.314109802246094,
           27.30789566040039,
           28.896167755126953,
           28.572484970092773,
           26.080904006958008,
           31.470237731933594,
           28.60053825378418,
           32.72639846801758,
           25.280946731567383,
           22.8529052734375,
           30.125782012939453,
           24.597145080566406,
           25.58702278137207
          ],
          [
           29.145849227905273,
           28.104270935058594,
           24.97499656677246,
           29.315099716186523,
           25.455793380737305,
           24.02267074584961,
           23.6334171295166,
           27.085033416748047,
           22.95431900024414,
           22.75971221923828,
           26.878395080566406,
           22.11268424987793,
           31.454986572265625,
           30.125782012939453,
           20.748886108398438,
           33.27480697631836,
           26.54373550415039
          ],
          [
           22.81501007080078,
           27.407567977905273,
           29.838802337646484,
           35.45439147949219,
           27.891233444213867,
           30.164106369018555,
           29.317867279052734,
           27.05950927734375,
           28.857275009155273,
           32.91358947753906,
           28.08333396911621,
           34.72093963623047,
           26.24510955810547,
           24.597145080566406,
           33.27480697631836,
           20.335927963256836,
           27.313140869140625
          ],
          [
           24.702444076538086,
           26.35931968688965,
           25.706937789916992,
           30.965791702270508,
           26.430654525756836,
           25.296939849853516,
           26.102066040039062,
           27.13542366027832,
           24.168779373168945,
           27.647523880004883,
           27.094005584716797,
           28.47471046447754,
           27.701631546020508,
           25.58702278137207,
           26.54373550415039,
           27.313140869140625,
           24.278038024902344
          ]
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "bgcolor": "white",
          "bordercolor": "black",
          "borderwidth": 1,
          "font": {
           "color": "black",
           "size": 12
          },
          "showarrow": false,
          "text": "<b><i>This distance matrix was<br>calculated using the Euclidian distance.<br>The matrix represents the mean<br>distance from the cluster<br>centroid for every embedding group.</b></i>",
          "textangle": 0,
          "x": 0.75,
          "xanchor": "left",
          "xref": "paper",
          "y": 0.9,
          "yref": "paper"
         },
         {
          "bgcolor": "white",
          "bordercolor": "black",
          "borderwidth": 1,
          "font": {
           "color": "black",
           "size": 12
          },
          "showarrow": false,
          "text": "<b><i>Word embeddings were attained<br>via the OpenAI API using<br>text-embedding-ada-002.</b></i>",
          "textangle": 0,
          "x": 0.001,
          "xanchor": "left",
          "xref": "paper",
          "y": -0.001,
          "yref": "paper"
         }
        ],
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Distance"
          }
         },
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ],
         "showscale": false
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(51,51,51)"
            },
            "error_y": {
             "color": "rgb(51,51,51)"
            },
            "marker": {
             "line": {
              "color": "rgb(237,237,237)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(237,237,237)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(51,51,51)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(51,51,51)"
            },
            "baxis": {
             "endlinecolor": "rgb(51,51,51)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(51,51,51)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(237,237,237)",
             "ticklen": 6,
             "ticks": "inside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(237,237,237)",
             "ticklen": 6,
             "ticks": "inside"
            },
            "colorscale": [
             [
              0,
              "rgb(20,44,66)"
             ],
             [
              1,
              "rgb(90,179,244)"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(237,237,237)",
             "ticklen": 6,
             "ticks": "inside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(237,237,237)",
             "ticklen": 6,
             "ticks": "inside"
            },
            "colorscale": [
             [
              0,
              "rgb(20,44,66)"
             ],
             [
              1,
              "rgb(90,179,244)"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(237,237,237)",
             "ticklen": 6,
             "ticks": "inside"
            },
            "colorscale": [
             [
              0,
              "rgb(20,44,66)"
             ],
             [
              1,
              "rgb(90,179,244)"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(237,237,237)",
             "ticklen": 6,
             "ticks": "inside"
            },
            "colorscale": [
             [
              0,
              "rgb(20,44,66)"
             ],
             [
              1,
              "rgb(90,179,244)"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(237,237,237)",
             "ticklen": 6,
             "ticks": "inside"
            },
            "colorscale": [
             [
              0,
              "rgb(20,44,66)"
             ],
             [
              1,
              "rgb(90,179,244)"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(237,237,237)",
             "ticklen": 6,
             "ticks": "inside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(237,237,237)",
              "ticklen": 6,
              "ticks": "inside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(237,237,237)",
             "ticklen": 6,
             "ticks": "inside"
            },
            "colorscale": [
             [
              0,
              "rgb(20,44,66)"
             ],
             [
              1,
              "rgb(90,179,244)"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "tickcolor": "rgb(237,237,237)",
            "ticklen": 6,
            "ticks": "inside"
           }
          },
          "colorscale": {
           "sequential": [
            [
             0,
             "rgb(20,44,66)"
            ],
            [
             1,
             "rgb(90,179,244)"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "rgb(20,44,66)"
            ],
            [
             1,
             "rgb(90,179,244)"
            ]
           ]
          },
          "colorway": [
           "#F8766D",
           "#A3A500",
           "#00BF7D",
           "#00B0F6",
           "#E76BF3"
          ],
          "font": {
           "color": "rgb(51,51,51)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "rgb(237,237,237)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "rgb(237,237,237)",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "tickcolor": "rgb(51,51,51)",
            "ticks": "outside"
           },
           "bgcolor": "rgb(237,237,237)",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "tickcolor": "rgb(51,51,51)",
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(237,237,237)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "tickcolor": "rgb(51,51,51)",
            "ticks": "outside",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "rgb(237,237,237)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "tickcolor": "rgb(51,51,51)",
            "ticks": "outside",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "rgb(237,237,237)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "tickcolor": "rgb(51,51,51)",
            "ticks": "outside",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "tickcolor": "rgb(51,51,51)",
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "tickcolor": "rgb(51,51,51)",
            "ticks": "outside"
           },
           "bgcolor": "rgb(237,237,237)",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "tickcolor": "rgb(51,51,51)",
            "ticks": "outside"
           }
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "tickcolor": "rgb(51,51,51)",
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "tickcolor": "rgb(51,51,51)",
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "side": "bottom",
         "tickangle": -45,
         "tickfont": {
          "size": 10
         },
         "title": {
          "text": "Principle"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Principle"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Create a pandas dataframe to store the distance matrix\n",
    "distance_matrix = pd.DataFrame(index=tsne_df.principles.unique(), columns=tsne_df.principles.unique())\n",
    "\n",
    "# Loop through each principle and calculate the average distance from the cluster centroid\n",
    "for principle in tsne_df.principles.unique():\n",
    "    temp_df = tsne_df[tsne_df.principles == principle]\n",
    "\n",
    "    avg_distance = euclidean_distances(temp_df[['tsne_1', 'tsne_2', 'tsne_3']],\n",
    "                                      temp_df[['tsne_1', 'tsne_2', 'tsne_3']]).mean()\n",
    "\n",
    "    distance_matrix.loc[principle, principle] = avg_distance\n",
    "\n",
    "    principles = tsne_df.principles.unique().tolist()\n",
    "    principles.remove(principle)\n",
    "\n",
    "    # Now, calculate the average distance from the cluster centroid for each other principle\n",
    "    for p in principles:\n",
    "        temp_df_2 = tsne_df[tsne_df.principles == p]\n",
    "\n",
    "        distance = euclidean_distances(temp_df[['tsne_1', 'tsne_2', 'tsne_3']],\n",
    "                                      temp_df_2[['tsne_1', 'tsne_2', 'tsne_3']]).mean()\n",
    "\n",
    "        distance_matrix.loc[principle, p] = distance\n",
    "        distance_matrix.loc[p, principle] = distance\n",
    "\n",
    "\n",
    "# Plot the distance matrix as a heatmap\n",
    "fig = px.imshow(distance_matrix.values,\n",
    "                x=distance_matrix.columns,\n",
    "                y=distance_matrix.columns,\n",
    "                text_auto=True,\n",
    "                color_continuous_scale='viridis',\n",
    "                labels=dict(x=\"Principle\", \n",
    "                            y=\"Principle\", \n",
    "                            color=\"Distance\"))\n",
    "\n",
    "fig.update_xaxes(side='bottom', tickangle=-45, tickfont=dict(size=10))\n",
    "fig.update_layout(template='ggplot2',\n",
    "                  coloraxis_showscale=False)\n",
    "\n",
    "fig.add_annotation(dict(font=dict(color='black',size=12),\n",
    "                                        x=0.75,\n",
    "                                        y=0.9,\n",
    "                                        showarrow=False,\n",
    "                                        text=\"<b><i>This distance matrix was<br>calculated using the Euclidian distance.<br>The matrix represents the mean<br>distance from the cluster<br>centroid for every embedding group.</b></i>\",\n",
    "                                        textangle=0,\n",
    "                                        xanchor='left',\n",
    "                                        xref=\"paper\",\n",
    "                                        yref=\"paper\",\n",
    "                                        bordercolor='black',\n",
    "                                        borderwidth=1,\n",
    "                                        bgcolor=\"white\"))\n",
    "\n",
    "fig.add_annotation(dict(font=dict(color='black',size=12),\n",
    "                                        x=0.05,\n",
    "                                        y=-0.1,\n",
    "                                        showarrow=False,\n",
    "                                        text=\"<b><i>Word embeddings were attained<br>via the OpenAI API using<br>text-embedding-ada-002.</b></i>\",\n",
    "                                        textangle=0,\n",
    "                                        xanchor='left',\n",
    "                                        xref=\"paper\",\n",
    "                                        yref=\"paper\",\n",
    "                                        bordercolor='black',\n",
    "                                        borderwidth=1,\n",
    "                                        bgcolor=\"white\"))\n",
    "\n",
    "\n",
    "fig.show()\n",
    "#fig.write_html(\"data/distance-matrix.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these plots are presented in [WAIE website](https://nkluge-correa.github.io/worldwide_AI-ethics/).\n",
    "\n",
    "---\n",
    "\n",
    "Return to the [index](https://github.com/Nkluge-correa/worldwide_AI-ethics)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
