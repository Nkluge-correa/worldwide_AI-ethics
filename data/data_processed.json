[
    {
        "document_name": "An Open Letter to the Global South: Bring the 'rest' in (Uma Carta Aberta ao Sul Global: Tragam o “resto” para dentro)",
        "country": "Brazil",
        "world_region": "Latin America",
        "institution": "AI Robotics Ethics Society at PUCRS (AIRES at PUCRS)",
        "institution_type": [
            "Academic",
            "Non-profit Organization"
        ],
        "year_of_publication": "2021",
        "number_of_male_authors": "13",
        "number_of_female_authors": "5",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This letter was written by the AI Robotics Ethics Society (AIRES) Chapter at the Pontifical Catholic University of Rio Grande do Sul (PUCRS). AIRES is a non-profit/academic organization founded in 2018 at UCLA (USA, Los Angeles) by Aaron Hui. Its mission is to focus on educating tomorrow's AI leaders in ethical AI principles to ensure AI is created ethically and responsibly. The letter provides an argument for the idea of increased diversity and inclusion in the ethical debate on AI governance. Given the strong centralization of published ethical guidelines, which almost hegemonically reflect European and North-American values, the authors seek to \"call upon\" other global actors to engage in the current debate.",
        "document_url": "https://en.airespucrs.org/c%C3%B3pia-carta-aberta",
        "attachments": "https://en.airespucrs.org/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "The valuing of the different ways in which the human entity can come to express itself by whatever group or identity it wishes. AI systems must be developed in a way that protects and values our diversity. The embracing and welcoming of all the ways that the human entity can come to express itself, regardless of specific affiliations, groups, and identities. AI systems should be developed in such a way as to \"include,\" not exclude.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": null,
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Declaration on Ethics and Data Protection in Artifical Intelligence",
        "country": "Belgium",
        "world_region": "Western Europe",
        "institution": "International Conference of Data Protection and Privacy Commissioners (ICDPPC)",
        "institution_type": "International Organization",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by atendents of the 2018 International Conference of Data Protection and Privacy Commissioners (Commission Nationale de l'Informatique et des Libertés, European Data Protection Supervisor, European Union, Garante per la protezione dei dati personali, Italy). The International Conference of Data Protection and Privacy Commissioners (ICDPPC) is a worldwide annual forum at which independent regulators on privacy, data protection, and freedom of information adopt high-level resolutions and recommendations addressed to governments and international organizations. In it, the authors suggest a series of recommendations, summarized as ethical principles to be upheld so that the use and development of AI fully respect human rights.",
        "document_url": "https://www.privacyconference2018.org/system/files/2018-10/20180922_ICDPPC-40th_AI-Declaration_ADOPTED.pdf",
        "attachments": "https://www.privacyconference2018.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "artificial intelligence systems should be ensured, promoting accountability of all relevant stakeholders to individuals, supervisory authorities, and other third parties as appropriate, including through the realization of audit, continuous monitoring, and impact assessment of artificial intelligence systems, and periodic review of oversight mechanisms.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "The 40th International Conference of Data Protection and Privacy Commissioners considers that any creation, development, and use of artificial intelligence systems shall fully respect human rights, particularly the rights to the protection of personal data and to privacy, as well as human dignity, non-discrimination, and fundamental values, and shall provide solutions to allow individuals to maintain control and understanding of artificial intelligence systems.",
            "Diversity": null,
            "Autonomy": "empowerment of every individual should be promoted, and the exercise of individuals' rights should be encouraged, as well as the creation of opportunities for public engagement, recognizing that the right to object or appeal applies to technologies that influence personal development or opinions and guaranteeing, where applicable, individuals' right not to be subject to a decision based solely on automated processing if it significantly affects them and, where not applicable, guaranteeing individuals' right to challenge such decision.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "unlawful biases or discriminations that may result from the use of data in artificial intelligence should be reduced and mitigated, ensuring the respect of international legal instruments on human rights and non-discrimination.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "privacy and data protection are increasingly challenged by the development of artificial intelligence and this development should be complemented by ethical and human rights considerations.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "artificial intelligence systems transparency and intelligibility should be improved, with the objective of effective implementation, investing in public and private scientific research on explainable artificial intelligence, making organizations' practices more transparent, notably by promoting algorithmic transparency and the auditability of systems, while ensuring meaningfulness of the information provided.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Intel's AI Privacy Policy White Paper: Protecting individuals' privacy and data in the artificial intelligence world",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Intel Corporation",
        "institution_type": "Private Corporation",
        "year_of_publication": "2018",
        "number_of_male_authors": "2",
        "number_of_female_authors": "0",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Intel Corporation, an American multinational corporation/technology company headquartered in Santa Clara (California, US). It presents a series of recommendations for policymakers, governments, and businesses in how to mitigate risks associated with privacy breaches and misuse of personal data, along with suggestions for how those recommendations might be adopted, as well as future avenues for research in data privacy.",
        "document_url": "https://www.intel.com/content/dam/www/public/us/en/ai/documents/Intels-AI-Privacy-Policy-White-Paper-2018.pdf",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Responsible risk management practices require that organizations hold themselves accountable to put in place appropriate technical and organizational measures for addressing privacy and data protection concerns of customers, business partners, and society.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Beneficence/Non-Maleficence: Minimize potential adverse impacts for citizens from automated decision-making. Privacy requires that data is both reliable and that it will not be used to harm individuals. Privacy aims to prevent unauthorized access, modification, and loss of personal data. It requires respect for private and family life, home, and confidentiality of communications.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "Privacy: Privacy requires that data is both reliable and that it will not be used to harm individuals. Organizations should embrace risk-based accountability approaches, putting in place technical (privacy-by-design) or organizational measures (product development lifecycles and ethics review boards) to minimize privacy risks in AI.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "AI Policies and Principles",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Information Technology Industry Council (ITI)",
        "institution_type": "Industrial Association",
        "year_of_publication": "2017",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Information Technology Industry Council (ITI), a Washington (DC - US) based trade association that represents companies from the information and communications technology (ICT) industry. In it, the ITI presents its policy principles, outlining specific areas where industry, governments, and others can collaborate, as well as specific opportunities for public-private partnership. The document can be understood as a voluntary self-commitment made by the ITI.",
        "document_url": "https://www.itic.org/dotAsset/50ed66d5-404d-40bb-a8ae-9eeeef55aa76.pdf",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "We recognize our responsibility to integrate principles into the design of AI technologies, beyond compliance with existing laws. AI researchers, subject matter experts, and stakeholders should spend a great deal of time working to ensure the responsible design and deployment of AI systems. Acknowledging existing legal and regulatory frameworks, we are committed to partnering with relevant stakeholders to inform a reasonable accountability framework for all entities in the context of autonomous systems.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "AI systems designed and deployed must be consistent with the international convention that ensures and preserve human dignity, rights, and freedom.",
            "Diversity": "AI systems designers must ensure that they prioritize diversity and inclusion in their systems. AI systems need to leverage large datasets, and the availability of robust and representative data for building and improving AI and machine learning systems is of utmost importance.",
            "Autonomy": null,
            "Human Formation": "Current and future workers need to be prepared with the necessary education and training to help them succeed. We recognize that delivering training is critical and will require significant investment, not only in STEM education but also in understanding human behavior via the humanities and social sciences. To ensure the employability of the workforce of the future, the public and private sectors should work together to design and deliver work-based learning and training systems and advance approaches that provide students with real work experiences and concrete skills.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "To promote the responsible use of data and ensure its integrity at every stage, the industry has a responsibility to understand the parameters and characteristics of the data, to demonstrate the recognition of potentially harmful bias, and to test for potential bias before and throughout the deployment of AI systems. We are committed to partnering with others across government, private industry, academia, and civil society to find ways to mitigate bias, inequity, and other potential harms in automated decision-making systems.",
            "Labor Rights": "We should leverage traditional human-centered resources as well as new career educational models and newly developed AI technologies to assist both the existing workforce and future workforce in successfully navigating career development and job transitions. Additionally, we must have PPPs that significantly improve the delivery and effectiveness of lifelong career education and learning, inclusive of workforce adjustment programs.",
            "Cooperation": null,
            "Privacy": "Since AI flourishing depends on how robust users trust the systems, AI systems should be designed in ways that protect the privacy of individuals by anonymizing data, re-identification, or aggregation to ensure the protection of personal information.",
            "Reliability": "AI researchers, experts, stakeholders, and technicians should ensure that AI systems that are designed and deployed are responsible. This sort of responsibility includes addressing safety and controllable mechanisms in AI systems, using robust and representative data, and stating the risks and solutions in AI systems in the specific context in which the system operates.",
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Artificial Intelligence and Machine Learning: Policy Paper",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Internet Society (ISOC)",
        "institution_type": "Non-profit Organization",
        "year_of_publication": "2017",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Internet Society (ISOC), an American nonprofit advocacy organization founded in 1992 with local chapters around the world. Its mission is to promote the open development, evolution, and use of the Internet for the benefit of all people throughout the world. The document written by the Internet Society presents principles and recommendations about what they believe are the core principles that underpin the value that the Internet provides. Their document points to several relations that AI has with IoT (Internet of Things) and serves as a great introduction to the theme of AI Ethics and AI Safety.",
        "document_url": "https://www.internetsociety.org/resources/doc/2017/artificial-intelligence-and-machine-learning-policy-paper/",
        "attachments": "https://www.internetsociety.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Legal accountability has to be ensured when human agency is replaced by decisions of AI agents.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "The ability of various stakeholders, whether civil society, government, private sector or academia, and the technical community, to inform and participate in the governance of AI is crucial for its safe deployment.",
            "Autonomy": "Any autonomous system must allow for a human to interrupt an activity or shut down the system (an “off-switch”). There may also be a need to incorporate human checks on new decision-making strategies in AI system design, especially where the risk to human life and safety is great.",
            "Human Formation": null,
            "Human-Centeredness": "AI system designers and builders need to apply a user-centric approach to the technology. They need to consider their collective responsibility in building AI systems that will not pose security risks to the Internet and Internet users.",
            "Intellectual Property": null,
            "Fairness": "Stakeholders should shape an environment where AI provides socio-economic opportunities for all.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "AI systems must be data responsible. They should use only what they need and delete it when it is no longer needed (“data minimization”). They should encrypt data in transit and at rest, and restrict access to authorized persons (“access control”). AI systems should only collect, use, share and store data following privacy and personal data laws and best practices.",
            "Reliability": "The capacity of an AI agent to act autonomously, and to adapt its behavior over time without human direction, calls for significant safety checks before deployment, and ongoing monitoring.",
            "Sustainability": null,
            "Transparency": "Decisions made by an AI agent should be possible to understand, especially if those decisions have implications for public safety, or result in discriminatory practices.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Everyday Ethics for Artificial Intelligence",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "IBM Corporation",
        "institution_type": "Private Corporation",
        "year_of_publication": "2019",
        "number_of_male_authors": "1",
        "number_of_female_authors": "2",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the IBM Corporation, an American multinational technology corporation headquartered in Armonk (New York, US). This document serves to help developers of AI technologies to embed ethics in the design and development process from the very beginning of their AI creation. It presents certain focal areas and an intentional framework for establishing an ethical foundation for building and using AI systems. It also recommends a series of practical actions that teams of developers can take to ensure their products are aligned with the cited focal areas.",
        "document_url": "https://www.ibm.com/watson/assets/duo/pdf/everydayethics.pdf",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Given that humans write algorithms and define the success and failures of AI outcomes, everyone involved in the development of AI should be accountable for how AI affects the world. This includes technology developers and the companies that invest in AI development.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "The approach to right and wrong is context-laden; different contexts understand right and wrong differently. AI developers must ensure that they take the diversity of cultural and societal norms seriously. Care is vital to ensure sensitivity towards a wide rand of cultural norms and values.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": "AI should be designed to align with the norms and values of your user group in mind.",
            "Intellectual Property": null,
            "Fairness": "AI must be developed to minimize bias and promote inclusive representation. Designers of AI must ensure that algorithm bias is minimized by collecting data from diverse populations.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "AI companies must be guided by national and international policies and laws on privacy and rights. Therefore, AI must be designed to protect users' data and preserve the user's power over access and uses in these places.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "The principle of explainability in AI development to that users interact and understand the recommendations and conclusions made by AI. AI should be designed to enable users to perceive, detect, and understand its decision process. If this principle is not met, AI should not be deployed to the market.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Icelander Institute for Intelligent Machine Ethics Policy",
        "country": "Iceland",
        "world_region": "Northern Europe",
        "institution": "Icelandic Institute for Intelligent Machine (IIIM)",
        "institution_type": "Non-profit Organization",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Icelandic Institute for Intelligent Machines (IIIM/Vitvélastofnun Íslands). IIIM is a non-profit institute whose mission is to accelerate the rate of innovation in Iceland through automation, bridging strategically between academic research and industrial engineering needs, focusing on all areas of automation and artificial intelligence (AI) – including robotics, machine learning, simulation techniques, and more. The document stands as a voluntary self-commitment from the IIIM to follow an ethical policy for all current and future activities, giving great emphasis to their anti-war (including cooperating with institutions that aid - or receive funds - from military institutions) commitment.",
        "document_url": "https://www.iiim.is/ethics-policy/3/",
        "attachments": null,
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "IIIM's sincere goal is to focus its research towards topics and challenges of obvious benefit to the general public, and for the betterment of society, human livelihood, and life on Earth. IIIM aims to advance scientific understanding of the world and to enable the application of this knowledge for the benefit and betterment of humankind. IIIM will not undertake any project or activity intended to cause bodily injury or severe emotional distress to any person.",
            "Children's Rights": null,
            "Human Rights": "One of the ethical policies of IIIM is to ensure that its project does not cause bodily or emotional distress to any person by, as stipulated in the United Nations Declaration of Human Rights.",
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "One of the ethical policies of IIIM is to ensure that its project does not cause bodily or emotional distress to any person by invading their privacy or violating their human rights as stipulated in the United Nations Declaration of Human Rights.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Responsible AI: A Global Policy Framework",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "International Technology Law Association (ITechLaw)",
        "institution_type": [
            "NGO",
            "International Organization",
            "Professional Association"
        ],
        "year_of_publication": "2021",
        "number_of_male_authors": "32",
        "number_of_female_authors": "18",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the International Technology Law Association (ITechLaw), an international association that provides education and networking opportunities for technology professionals and students in the area of technology-related legal issues. The \"2021 Update to Responsible AI: A Global Policy Framework\" is an updated version of its 2019 format, being written together with a team of 38 specialists from 17 countries. It also presents the Responsible AI Impact Assessment tool (RAIIA), which is designed to help measure, in quantifiable terms, the impact of a proposed AI application.",
        "document_url": "https://www.itechlaw.org/ResponsibleAI2021",
        "attachments": "https://www.itechlaw.org/sites/default/files/ResponsibleAI_PolicyFramework.pdf",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": true,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": true
        },
        "principles_definition": {
            "Accountability": "Organisations that develop, make available, or use AI systems ought to be accountable for the consequences of their actions and shall designate an individual or individuals who are accountable for the organization's compliance with the principles of the Policy Framework for Responsible AI or other adopted principles (including analogous principles that may be developed for a specific industry) to keep humans behind the machines and AI Human-centric.",
            "Beneficence": "Organisations that develop, make available, or use AI systems and any national laws or industry standards that govern such use should require the purposes of such implementation to be identified and ensure that such purposes are consistent with the overall ethical purposes of beneficence and non-maleficence, as well as the other principles of the Policy Framework for Responsible AI.",
            "Children's Rights": null,
            "Human Rights": "Organisations that develop, deploy or use AI systems should do so in a manner compatible with human agency and respect for fundamental human rights.",
            "Diversity": null,
            "Autonomy": "Organisations that develop make available, or use AI systems that surveil human behavior shall put in place appropriate safeguards to promote the right to be let alone (the right not to be subject to arbitrary interference with on” IoT devices (such as personal assistants and smart home devices) shall, to the greatest extent possible, securely store such data, in an encrypted format, only locally on the device in a manner that allows for the maximal level of autonomy and control over the data by the individual(s) to whom it relates.",
            "Human Formation": "Governments should promote educational policies that equip all children with the skills, knowledge, and qualities required by the new economy and that promote life-long learning. Governments should encourage the creation of opportunities for adults to learn new useful skills, especially for those displaced by automation.",
            "Human-Centeredness": null,
            "Intellectual Property": "Organisations that develop, make available, or use AI systems should seek to strike a fair balance between benefiting from adequate protection for the intellectual property rights for both the AI system and the AI output and allowing availability for the wider societal benefit.",
            "Fairness": "Organisations that develop make available, or use AI systems, and any national laws that regulate such use shall ensure the non-discrimination of AI outcomes and shall promote appropriate and effective measures to safeguard fairness in AI use.",
            "Labor Rights": "Organisations that implement AI systems in the workplace should provide opportunities for affected employees to participate in the decision-making process related to such implementation. Organizations that develop, deploy or use AI systems that have an impact on employment should conduct a Responsible AI Impact Assessment to determine the net effects of such implementation.",
            "Cooperation": "Organisations that develop make available, or use AI systems and any national laws that regulate such use shall, without prejudice to normal rules of intellectual property and privacy, foster open access and encourage open-source frameworks and software for AI systems.",
            "Privacy": "Organisations that develop, make available, or use AI systems and any national laws that regulate such use shall endeavor to ensure that AI systems are compliant with privacy norms and regulations, taking into account the unique characteristics of AI systems, and the evolution of standards on privacy.",
            "Reliability": "Organisations that develop make available, or use AI systems and any national laws that regulate such use shall adopt design regimes and standards ensuring high safety and reliability of AI systems on one hand while limiting the exposure of developers and deployers on the other hand.",
            "Sustainability": "Organisations that develop, make available, or use AI systems should assess the overall environmental impact of such AI systems, throughout their implementation, including consumption of resources, energy costs of data storage and processing, and the net energy efficiencies or environmental benefits that they may produce. Organizations should seek to promote and implement the uses of AI systems to achieve overall carbon neutrality or carbon reduction.",
            "Transparency": "Organisations that develop, make available or use AI systems, and any national laws or industry standards that govern such use, shall ensure that such use is transparent and that the decision outcomes of the AI system are explainable.",
            "Truthfulness": "Organisations that develop, deploy or use AI systems to filter or promote informational content on internet platforms that are shared or seen by their users should take reasonable measures, consistent with applicable law, to minimize the spread of false or misleading information where there is a material risk that such false or misleading information might lead to significant harm to individuals, groups or democratic institutions."
        }
    },
    {
        "document_name": "Trusted AI",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "IBM Corporation",
        "institution_type": "Private Corporation",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the IBM Corporation,  an American multinational technology corporation headquartered in Armonk (New York, US). The web document contains a series of publications and programing tools created by the Trusted AI IBM Research Team, which has the aim of developing tools to make AI more explainable, fair, robust, private, and transparent.",
        "document_url": "https://research.ibm.com/teams/trusted-ai",
        "attachments": null,
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "IBM has engaged in several projects such as AI Fairness 360 (a toolkit to check for unwanted biases in datasets and machine learning and state-of-the-art algorithms to minimize unnecessary biases).",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "In IBM, AI systems are designed to protect themselves against attacks and also created to adhere to privacy requirements. The IBM AI systems are designed using mathematical noise to preserve individuals' privacy and confidentiality.",
            "Reliability": "At IBM Research, we're working on a range of approaches to ensure that AI systems built in the future are fair, robust, explainable, accountable, and align with the values of the society they're designed for. We need assurances that AI cannot be tampered with and that the system itself is secure.",
            "Sustainability": null,
            "Transparency": "Systems created in IBM are made so that they can explain the decisions they make and why AI decisions were made. This is done through a wide range of actions such as training highly optimized, directly interpretable models and explanation of black-box models and visualizations of neural network information flow.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "The Japanese Society for Artificial Intelligence Ethical Guidelines",
        "country": "Japan",
        "world_region": "Eastern Asia",
        "institution": "Japanese Society for Artificial Intelligence (JSAI)",
        "institution_type": "Academic",
        "year_of_publication": "2017",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Japanese Society for Artificial Intelligence (JSAI), an academic society based in Japan. In this document, JSAI formalizes a voluntary-self commitment in the form of an ethical guideline. The document serves as a moral foundation for JSAI members to become better aware of their social responsibilities and encourage effective communications with society.",
        "document_url": "http://www.ai-elsi.org/wp-content/uploads/2017/05/JSAI-Ethical-Guidelines-1.pdf",
        "attachments": "https://www.ai-gakkai.or.jp/en/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Members of the JSAI (Japanese Society for Artificial Intelligence) must respect laws and regulations relating to research and development, intellectual property, as well as any other relevant contractual agreements.",
            "Beneficence": "Members of the JSAI will contribute to the peace, safety, welfare, and public interest of humanity.",
            "Children's Rights": null,
            "Human Rights": "Members of the JSAI protect basic human rights and will respect cultural diversity.",
            "Diversity": "AI researchers must listen attentively to the diverse views of society and learn from them with humility. Members of the JSAI understand that there are diverse views of AI within society and will earnestly learn from them. They will strengthen their understanding of society and maintain consistent and effective communication with them, to contribute to the overall peace and happiness of all of humanity.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Members of the JSAI will, to the best of their ability, ensure that AI is developed as a resource that can be used by humanity in a fair and equal manner.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Members of the JSAI will respect the privacy of others concerning their research and the development of AI.",
            "Reliability": "As specialists, members of the JSAI shall recognize the need for AI to be safe and acknowledge their responsibility in keeping AI under control. If potential danger is identified, a warning must be effectively communicated to all of society.",
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Kakao Algorithm Ethics",
        "country": "South Korea",
        "world_region": "Eastern Asia",
        "institution": "Kakao Corporation",
        "institution_type": "Private Corporation",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Kakao Corporation, a South Korean Internet company that was established in 2010. In this web document, Kakao Corporation formalizes a voluntary-self commitment in the form of an ethical guideline. The document serves as a moral foundation for Kakao Corporation's actions related to the use of AI technologies in their services.  Kakao has two other documents (Code of Business Conduct and Code of Ethics) that describe self-regulatory standards that the company commits to follow.",
        "document_url": "https://www.kakaocorp.com/page/responsible/detail/algorithm",
        "attachments": [
            "https://www.kakaocorp.com/ir/managementInformation/codeOfBusinessEthics?lang=en",
            "https://www.kakaocorp.com/upload_resources/data/Daum_Eng_ethics.pdf"
        ],
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": true,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "Kakao's Algorithm Kakao makes all its efforts related to ensuring our algorithms pursue the welfare and happiness of mankind.",
            "Children's Rights": "Kakao strives to help children and adolescents, the future of our society, grow into healthy individuals in a clean and healthy digital world. Kakao will dedicate constant attention and resources to creating an environment to protect children and adolescents from information and risks that can be mentally and physically harmful.",
            "Human Rights": null,
            "Diversity": "Kakao aims for a future where all members of our society can rejoice together through our technologies and services. Algorithms can lead to unintended social alienation due to their inherent nature. Kakao is not only sensitive to these dysfunctions but also pays attention to ways our algorithms can be used to enhance the benefits and happiness of the socially vulnerable.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Kakao aims for a society where diverse values coexist. We will do our best to ensure that the results implemented by our algorithms do not bias specific values or reinforce social discrimination.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "Kakao blocks the possibility that our algorithms may be damaged or distorted under the influence of a specific intention (i.e., robustness to adversarial attacks).",
            "Sustainability": null,
            "Transparency": "Algorithms must be faithfully explained within a scope that does not impair the competitiveness of Kakao.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Hambach Declaration on Artificial Intelligence(Hambacher Erklärung zur Künstlichen Intelligenz)",
        "country": "Germany",
        "world_region": "Western Europe",
        "institution": "The Berlin Commissioner for Data Protection and Freedom of Information, Independent Data Protection Authorities of the Federation, Länder Hambach Castle",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Gov. Reg.",
        "document_normative": "Binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Berlin Commissioner for Data Protection and Freedom of Information (BlnBDI), in conjunction with the Independent Data Protection Authorities of the Federation and the Länder Hambach Castle. The document describes several key concerns relating to the use of AI in sensitive contexts. It provides a framework with conditions for the use of AI so that they can be monitored by legislators and enforced by the supervisory authorities. The document links proposed regulatory measures to existing bodies of law and regulation (e.g., General Data Protection Regulation - GDPR), setting standards to be followed by both regulators and developers.",
        "document_url": "https://www.datenschutz.rlp.de/fileadmin/lfdi/Konferenzdokumente/Datenschutz/DSK/Entschliessungen/097_Hambacher_Erklaerung.pdf",
        "attachments": "https://www.datenschutz-berlin.de/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "The parties involved in the use of an AI system must identify and communicate responsibility and each take the necessary measures to ensure lawful processing, data subjects' rights, security of processing, and controllability of the AI system. The controller must ensure that the principles set out in Article 5 of the General Data Protection Regulation (GDPR) are complied with. AI may only be used for constitutionally legitimized purposes and may not override the purpose limitation requirement. It also applies to AI systems that may only be used for constitutionally legitimized purposes.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "The guarantee of human dignity (Article 1 (1) of the Basic Law, Article 1 of the Charter of Fundamental Rights) requires that, especially in the case of state action utilizing AI, the individual is not turned into an object. Fully automated decisions or profiling by AI systems are only permitted to a limited extent.",
            "Diversity": null,
            "Autonomy": "Only if the protection of fundamental rights and data protection keep pace with the process of digitalization is a future possible in which people, and not machines, ultimately make decisions about people. Data subjects also have the right to the intervention of a person (intervenability), to the presentation of their point of view and to challenge a decision when AI systems are used.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Discriminatory processing operations constitute a violation of the rights and freedoms of data subjects. Among other things, they violate certain requirements of the GDPR, such as the principle of fairness, the linking of processing to legitimate purposes, or the adequacy of the processing.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "For the development and use of AI systems in which personal data are processed, the GDPR contains important legal requirements.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "Personal data must be processed in a way that is comprehensible to the data subject. This requires, in particular, transparent processing in which the information about the process of processing and, where applicable, also about the training data used is easily accessible and comprehensible.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "KI Seal of Approval",
        "country": "Germany",
        "world_region": "Western Europe",
        "institution": "German AI Association (KI Bundesverband e.V.)",
        "institution_type": "NGO",
        "year_of_publication": "2019",
        "number_of_male_authors": "9",
        "number_of_female_authors": "1",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the German AI Association, a  non-governmental organization headquartered in Berlin (DE) committed to ensuring that AI is applied in the spirit of European and democratic values. The document focus on developing an ethical seal of approval. This tool was developed so that German companies can have the opportunity to conjure compliance with basic quality parameters, build trust in society, and strengthen the competitiveness of internationally participating companies.",
        "document_url": "https://ki-verband.de/wp-content/uploads/2019/02/KIBV_Guetesiegel.pdf",
        "attachments": "https://ki-verband.de/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "Artificial intelligence should lead to more freedom, equality, justice, solidarity, tolerance, and pluralism to ensure that it is not used for discrimination, or against democracy or human rights.",
            "Diversity": null,
            "Autonomy": "In human-machine interactions, humans always can intervene or always can stop or interrupt a system.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Artificial intelligence should lead to more freedom, equality, justice, solidarity, tolerance, and pluralism to ensure that it is not used for discrimination or against democracy or human rights.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "An AI system requires confidentiality and integrity of data processing. These include secure and privacy-compliant collection, storage, and processing of large amounts of training data; robustness to adversarial input data; preventing degeneration and manipulation of self-learning systems; Safeguarding against new, non-human failure modes; unauthorized access to personal data through neural network mining.",
            "Sustainability": null,
            "Transparency": "Each step concerning the data should be documented as part of a transparent procedure. The results of bias detection shall be documented at regular intervals, regardless of how a company decides to deal with bias. AI procedures shall be accompanied by known and appropriate analysis procedures.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "AI at Google: our principles",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Google LLC",
        "institution_type": "Private Corporation",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by Google (Google LLC), an American multinational technology company that specializes in Internet-related services and products, which include a search engine, online advertising technologies, cloud computing, software, and hardware. In this web document, the company presents it's core guiding ethical principles when it comes to AI. According to Google, \"these are not theoretical concepts; they are concrete standards that will actively govern our research and product development and will impact our business decisions.\" This document can be understood as Google's voluntary-self commitment to chosen ethical and safety standards.",
        "document_url": "https://www.blog.google/technology/ai/ai-principles/",
        "attachments": null,
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": true
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "As we consider potential development and uses of AI technologies, we will take into account a broad range of social and economic factors, and will proceed where we believe that the overall likely benefits substantially exceed the foreseeable risks and downsides.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "We will design AI systems that provide appropriate opportunities for feedback, relevant explanations, and appeal. Our AI technologies will be subject to appropriate human direction and control.",
            "Human Formation": "we will responsibly share AI knowledge by publishing educational materials, best practices, and research that enable more people to develop useful AI applications.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "We will seek to avoid unjust impacts on people, particularly those related to sensitive characteristics such as race, ethnicity, gender, nationality, income, sexual orientation, ability, and political or religious belief.",
            "Labor Rights": null,
            "Cooperation": "We will continue to thoughtfully evaluate when to make our technologies available on a non-commercial basis.",
            "Privacy": "We will incorporate our privacy principles in the development and use of our AI technologies. We will give opportunity for notice and consent, encourage architectures with privacy safeguards, and provide appropriate transparency and control over the use of data.",
            "Reliability": "We will continue to develop and apply strong safety and security practices to avoid unintended results that create risks of harm. We will design our AI systems to be appropriately cautious, and seek to develop them following best practices in AI safety research. Many technologies have multiple uses. We will work to limit potentially harmful or abusive applications.",
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": "AI also enhances our ability to understand the meaning of content at scale. We will strive to make high-quality and accurate information readily available using AI."
        }
    },
    {
        "document_name": "Directive on Automated Decision-Making",
        "country": "Canada",
        "world_region": "North America",
        "institution": "Treasury Board of Canada",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Binding",
        "document_impact": "Short",
        "abstract": "This document (Directive) was written by the Treasury Board of Canada, a Cabinet committee of the Queen's Privy Council, established in 1867 and given statutory powers in 1869, being responsible for accountability and ethics, financial, personnel, and administrative management, comptrollership, approving regulations and most Orders-in-Council. This directive set objectives and expected results for the use of AI applications by the Canadian public sector. The document also links to a practical tool, the \"Algorithmic Impact Assessment Tool.\" This tool is a mandatory risk assessment tool intended to support the Treasury Board's Directive on Automated Decision-Making. The tool is a questionnaire that determines the impact level of an automated decision system.",
        "document_url": "https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=32592",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "The Assistant Deputy Minister responsible for the program using the Automated Decision System, or any other person named by the Deputy Head, is responsible for: Consulting with the institution's legal services, from the concept stage of a project, to ensure that the use of the Automated Decision System is compliant with applicable legal requirements.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "The Assistant Deputy Minister responsible for the program using the Automated Decision System, or any other person named by the Deputy Head, is responsible for: Ensuring that an Automated Decision System allows for human intervention, when appropriate.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "The expected results of this Directive are as follows: Decisions made by federal government departments are data-driven, responsible, and comply with procedural fairness and due process requirements.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "The expected results of this Directive are as follows: Impacts of algorithms on administrative decisions are assessed and negative outcomes are reduced, when encountered.",
            "Sustainability": null,
            "Transparency": "The expected results of this Directive are as follows: Data and information on the use of Automated Decision Systems in federal institutions are made available to the public, where appropriate.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Responsible use of artificial intelligence (AI)",
        "country": "Canada",
        "world_region": "North America",
        "institution": "Government of Canada",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2021",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Government of Canada, and it provides requirements and guidance to automated decision systems. It presents a practical tool, the \"Algorithmic Impact Assessment Tool (AIA),\" to better understand and manage the risks associated with automated decision systems. The document also promotes some ethical and legal requirements for the use and development of automated decision systems.",
        "document_url": "https://www.canada.ca/en/government/system/digital-government/modern-emerging-technologies/responsible-use-ai.html",
        "attachments": null,
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": "To ensure the effective and ethical use of AI the government will: provide sufficient training so that government employees developing and using AI solutions have the responsible design, function, and implementation skills needed to make AI-based public services better.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": "To ensure the effective and ethical use of AI the government will: be as open as we can by sharing source code, training data, and other relevant information, all while protecting personal information, system integration, and national security and defense.",
            "Privacy": null,
            "Reliability": "To ensure the effective and ethical use of AI the government will: understand and measure the impact of using AI by developing and sharing tools and approaches.",
            "Sustainability": null,
            "Transparency": "To ensure the effective and ethical use of AI the government will: be transparent about how and when we are using AI, starting with a clear user need and public benefit. Provide meaningful explanations about AI decision-making, while also offering opportunities to review results and challenge these decisions.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "10 ethical guidelines for the digitalisation of companies (10 ethische Leitlinien für die Digitalisierung von Unternehmen)",
        "country": "Germany",
        "world_region": "Western Europe",
        "institution": "Stuttgart Media University (Hochschule der Medien)",
        "institution_type": "Academic",
        "year_of_publication": "2017",
        "number_of_male_authors": "3",
        "number_of_female_authors": "7",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Stuttgart Media University (Hochschule der Medien), a state university of media studies in Stuttgart (DE). The document sets general principles and guidelines for AI technologies and digital adoption and transformation. These guidelines seek to establish modes of conduct so companies can become aware of their social and ecological responsibility.",
        "document_url": "https://www.hdm-stuttgart.de/digitale-ethik/digitalkompetenz/ethische_unternehmensleitlinien;%20https:/www.hdm-stuttgart.de/grimm/material/ethische_unternehmensleitlinien/material/UN_Regeln_booklet",
        "attachments": null,
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": true,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": "Online content, services, and offerings shall be designed and optimized in the context of the responsibility to protect and optimize in such a way that children, adolescents, and people with low digital sovereignty are not endangered or deliberately exploited.",
            "Human Rights": "Artificial intelligence should be designed in a value-oriented way. Intelligent systems should be designed in such a way that the fundamental rights of people are rights and enable them to lead a good and successful life.",
            "Diversity": "The exclusion of people with low online affinity and of offline users is to be, as far as possible, irrespective of the technical capabilities of the individual.",
            "Autonomy": "To prevent automated decisions from paternalistic effects occurring, which restrict the freedom of action of humans, there is a need for constant system control and the possibility to intervene in the system.",
            "Human Formation": "The training and further education, as well as the digital competencies of employees, are to be promoted. Preparing employees for digitization and providing them with training accordingly, is regarded as a duty.",
            "Human-Centeredness": "In the development and deployment of artificial intelligence (AI), ethical principles must be taken into (value-based design).",
            "Intellectual Property": null,
            "Fairness": "Equal opportunities should be promoted and discrimination avoided. The principle of equal opportunity applies equally to online and offline users.",
            "Labor Rights": "A good work-life balance is strived for; employees are not expected to be available outside working hours. Their performance should not be evaluated solely based on quantitative data. Machines should\nnot make autonomous decisions about employees. When using crowd working, fair and equitable working conditions are offered. Employees are to be involved in decision-making and processes and there is room for innovative suggestions.",
            "Cooperation": null,
            "Privacy": "Privacy shall be protected. All data of customers, employees, as well as third parties, shall be handled with care and to protect their privacy.",
            "Reliability": "The security and quality of the data shall be guaranteed. The quality of personal data must be checked and faulty collection, processing, and linking of data must be avoided. Adequate security technologies shall protect the company from hacking. In the event of security breaches or a hacking attack, the affected parties and the public must be informed immediately.",
            "Sustainability": "Digitization should be used to conserve natural resources. The aim is to exploit the potential of intelligent systems and digital technologies to conserve natural resources and minimize environmental impact.",
            "Transparency": "Ethical principles that aim on creating trust should be mandatory. These include the creation of Information symmetry between customers and companies (such as transparency), information fairness (such as data economy), and information autonomy (such as the right to data deletion).",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Ethics Guidelines for Trustworthy AI",
        "country": "European Union",
        "world_region": "European Union",
        "institution": "High-Level Expert Group on AI (AI HLEG)",
        "institution_type": "International Organization",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the High-Level Expert Group on AI (AI HLEG), an independent expert group that was set up by the European Commission in June 2018. This document aims to promote Trustworthy AI, i.e., systems that throughout the system's entire life cycle should be lawful, ethical, and robust. Stakeholders committed to achieving Trustworthy AI can voluntarily opt to use these Guidelines as a method to operationalize their commitment. The document also provides a practical tool, the Trustworthy AI assessment list, made to operationalize Trustworthy AI.",
        "document_url": "https://www.aepd.es/sites/default/files/2019-12/ai-ethics-guidelines.pdf",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "It necessitates that mechanisms be put in place to ensure responsibility and accountability for AI systems and their outcomes, both before and after their development, deployment, and use.",
            "Beneficence": "AI systems should neither cause nor exacerbate harm or otherwise adversely affect human beings. This entails the protection of human dignity as well as mental and physical integrity. AI systems and the environments in which they operate must be safe and secure.",
            "Children's Rights": null,
            "Human Rights": "AI systems should hence be developed in a manner that respects, serves, and protects humans' physical and mental integrity, personal and cultural sense of identity, and satisfaction of their essential needs. Moreover, mechanisms should be put into place to receive external feedback regarding AI systems that potentially infringe on fundamental rights.",
            "Diversity": "Pay particular attention to situations involving more vulnerable groups such as children, persons with disabilities, and others that have historically been disadvantaged or are at risk of exclusion, and to situations that are characterized by asymmetries of power or information, such as between employers and workers, or between businesses and consumers. AI systems should not have a one-size-fits-all approach and should consider Universal Design principles addressing the widest possible range of users, following relevant accessibility standards.",
            "Autonomy": "Freedom of the individual. Human beings should remain free to make life decisions for themselves. AI systems should serve to maintain and foster democratic processes and respect the plurality of values and life choices of individuals. AI systems should not unjustifiably subordinate, coerce, deceive, manipulate, condition, or herd humans. Instead, they should be designed to augment, complement and empower human cognitive, social, and cultural skills.",
            "Human Formation": "Communication, education, and training play an important role, both to ensure that knowledge of the potential impact of AI systems is widespread, and to make people aware that they can participate in shaping societal development.",
            "Human-Centeredness": "To do this, AI systems need to be human-centric, resting on a commitment to their use in the service of humanity and the common good, intending to improve human welfare and freedom.",
            "Intellectual Property": null,
            "Fairness": "To achieve Trustworthy AI, we must enable inclusion and diversity throughout the entire AI system's life cycle. Besides the consideration and involvement of all affected stakeholders throughout the process, this also entails ensuring equal access through inclusive design processes as well as equal treatment. This requirement is closely linked with the principle of fairness.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "AI systems must guarantee privacy and data protection throughout a system's entire lifecycle. This includes the information initially provided by the user, as well as the information generated about the user throughout their interaction with the system (e.g. outputs that the AI system generated for specific users or how users responded to particular recommendations).",
            "Reliability": "A crucial component of achieving Trustworthy AI is technical robustness, which is closely linked to the principle of prevention of harm. Technical robustness requires that AI systems be developed with a preventative approach to risks and in a manner such that they reliably behave as intended while minimizing unintentional and unexpected harm, and preventing unacceptable harm.",
            "Sustainability": "In line with the principles of fairness and prevention of harm, the broader society, other sentient beings, and the environment should be also considered as stakeholders throughout the AI system's life cycle. Sustainability and ecological responsibility of AI systems should be encouraged, and research should be fostered into AI solutions addressing areas of global concern, such as instance the Sustainable Development Goals. Ideally, AI systems should be used to benefit all human beings, including future generations.",
            "Transparency": "Explicability is crucial for building and maintaining users' trust in AI systems. This means that processes need to be transparent, the capabilities and purpose of AI systems openly communicated, and decisions – to the extent possible –explainable to those directly and indirectly affected.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Declaration of Ethical Principles for AI in Latin America (Declaración de Principios Éticos para la IA de Latinoamérica)",
        "country": "Unspecified",
        "world_region": "Latin America",
        "institution": "AI Latam (IA Latam)",
        "institution_type": "NGO",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by AI Latam (IA Latam), an Artificial Intelligence community for Latin America. Its mission is to encourage and contribute to an integrated ecosystem that allows the union of companies, innovators, leaders, and institutions motivated by artificial intelligence and development in Latin America and the world. The document presents a set of recommendations for the use and development of AI technologies in Latin America.",
        "document_url": "https://ia-latam.com/etica-ia-latam/",
        "attachments": "https://ia-latam.com",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": true,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "AI developers are responsible for their projects and must take into consideration the impact that each project may have on society. We will work to prevent potentially harmful or abusive applications. As we develop and implement AI technologies, we will assess likely uses in light of the following factors: Purpose, Nature, and Impact. The development of AI technologies and their effects must always be following current legislation and respect local cultural and social norms.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "Ensure the development of an AI at the service of individuals and society. Developed AI technology must obey its creators, as long as they do not conflict with human autonomy, the individual good, and the common good.",
            "Human Formation": "Labor transformation is a reality, the development of AI must also, as a principle, collaborate in the retraining and placement of the workforce that it replaces, through education and the complement of the new necessary skills and competencies.",
            "Human-Centeredness": null,
            "Intellectual Property": "Justice/Equity/Fairness/Non-discrimination: Avoid bias and unfair impacts on people, particularly those related to sensitive characteristics such as race, ethnicity, gender, nationality, income, sexual orientation, ability, and political or religious beliefs.",
            "Fairness": "Intellectual Property: Respect and protect intellectual property at all levels and to the highest standard. All the actors involved in the creation will receive the corresponding compensation for their work.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Protect the right of each person regarding the privacy of their data (sensitive personal information) and in the same way give an ethical use to the information of each individual, always with the prior consent of its owner. Consent will be required from each person about the use of the generation of new data created from the AI.",
            "Reliability": "Given the non-deterministic nature of intelligent systems, constant testing, and validation system must be established, which includes the inputs made to the system and its global behavior. The architecture of AI systems must set behavioral limits. Allocate resources and focus on the security of systems and data. Cyber security must be a priority for everyone, not only to maintain and improve services but also as a fundamental part of creating the necessary trust.",
            "Sustainability": "The development of AI technology must take care of the effects on the environment. The impact that each creation may have cannot represent a threat to our environment.",
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "IBM's Principles for Trust and Transparency",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "IBM Corporation",
        "institution_type": "Private Corporation",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by IBM Corporation, an American multinational technology corporation headquartered in Armonk (New York, US). The document aims to establish IBM's principles to guarantee data responsibility towards their client's data information. The document serves as IBM's voluntary self-commitment to their use and development of AI technologies.",
        "document_url": "https://www.ibm.com/blogs/policy/trust-principles/",
        "attachments": "https://www.ibm.com/blogs/policy/wp-content/uploads/2018/06/IBM_Principles_SHORT.V4.3.pdf",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": "The purpose of AI and cognitive systems developed and applied by IBM is to augment – not replace – human intelligence. Our technology is and will be designed to enhance and extend human capability and potential. At IBM, we believe AI should make ALL of us better at our jobs, and that the benefits of the AI era should touch the many, not just the elite few. To that end, we are investing in initiatives to help the global workforce gain the skills needed to work in partnership with these technologies.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": "IBM views the free movement of data across borders as essential to 21st century commerce.",
            "Privacy": "IBM is fully committed to protecting the privacy of our client's data, which is fundamental in a data-driven society. IBM has not provided client data to any government agency under any surveillance program involving bulk collection of content or metadata.",
            "Reliability": "IBM is devoting our powerful engines of innovation to creating tools to protect our clients, their data, and global trade from cyber threats. We are also convening a broader discussion on balancing security, privacy, and freedom.",
            "Sustainability": null,
            "Transparency": "For the public to trust AI, it must be transparent. Technology companies must be clear about who trains their AI systems, what data was used in that training and, most importantly, what went into their algorithm's recommendations. If we are to use AI to help make important decisions, it must be explainable.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "China's Artificial Intelligence Industry Alliance Self-discipline Convention",
        "country": "China",
        "world_region": "Eastern Asia",
        "institution": "China’s Artificial Intelligence Industry Alliance (AIIA)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by China's Artificial Intelligence Industry Alliance (AIIA). AIIA was established in October 2017 by a group of institutions led by the National Development and Reform Commission, the Ministry of Science and Technology, the Ministry of Industry and Information Technology, and the Cyberspace Administration of China to further implement the AIDP and “‘Internet Plus' and AI Three Year Implementation Plan.” AIIA's membership is divided into regular members (more than 250), council members (more than 125), and council vice-chairs (29). The final category includes the leading tech companies Baidu, Alibaba, Tencent, Huawei, ZTE, 360, etc., plus Tsinghua University, Zhejiang University, and the Harbin Institute of Technology. The document is a voluntary self-commitment made by AIIA's members.",
        "document_url": "https://mp.weixin.qq.com/s/x7HTx4AR6oNBWwWxUpnSuQ",
        "attachments": "http://www.aiiaorg.cn/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Make clear the rights and obligations at each stage in artificial intelligence research and development (R&D), design, manufacturing, operation, services, etc., to be able to determine the responsible party promptly when harm occurs. Advocate for relevant enterprises and organizations to innovate in insurance mechanisms under the existing legal framework, to distribute the social risks brought about by the development of the artificial intelligence industry.",
            "Beneficence": "The development of artificial intelligence should advance the progress of society and human civilization, create more intelligent modes of working and lifestyles, and enhance people's livelihood and well-being. (...) The development of artificial intelligence should avoid harming the interests of society and the public; existing dangers should not be aggravated, nor new dangers caused, through the abuse of artificial intelligence.",
            "Children's Rights": null,
            "Human Rights": "The development of artificial intelligence should uphold basic rights such as human freedom and dignity, follow the principle of human-centeredness, and prevent artificial intelligence from weakening and replacing humanity's position.",
            "Diversity": "Promote the inclusiveness, diversity, and universality of artificial intelligence systems. Strengthen cross-domain, interdisciplinary, and cross-border cooperation and exchange, and solidify an artificial intelligence governance consensus. Strive to achieve diversification of R&D personnel and comprehensive training data for artificial intelligence systems. Continually test and validate algorithms, so that they do not discriminate against users based on race, gender, nationality, age, religious beliefs, etc.",
            "Autonomy": null,
            "Human Formation": "Actively participate in universal education on artificial intelligence for the public, morals and ethics education for relevant practitioners, and digital labor skills retraining for personnel whose jobs have been replaced; alleviate public concerns about artificial intelligence technology; raise public awareness about safety and prevention, and actively respond to questions about current and future workforce challenges.",
            "Human-Centeredness": "The development of artificial intelligence should uphold basic rights, such as human freedom and dignity, follow the principle of human centeredness, and prevent artificial intelligence from weakening and replacing humanity's position.",
            "Intellectual Property": null,
            "Fairness": "Justice/Equity: The development of artificial intelligence should ensure fairness and justice, avoid bias or discrimination against specific groups or individuals, and avoid placing disadvantaged people in an even more unfavorable position.",
            "Labor Rights": null,
            "Cooperation": "Encourage open source and open resources such as platforms, tools, data, and science and education; share artificial intelligence development dividends and governance experience; strive to break data islands and platform monopolies; continuously narrow the intelligence gap, and advance the deep integration of artificial intelligence and the real economy.",
            "Privacy": "Adhere to the principles of legality, legitimacy, and necessity when collecting and using personal information. Strengthen privacy protections for special data subjects such as minors. Strengthen technical methods, ensure data security, and be on guard against risks such as data leaks.",
            "Reliability": "Ensure that AI systems operate securely/safely, reliably, and controllably throughout their lifecycle. Evaluate system security/safety and potential risks, and continuously improve system maturity, robustness, and anti-tampering capabilities. Ensure that the system can be supervised and promptly taken over by humans to avoid the negative effects of loss of system control.",
            "Sustainability": null,
            "Transparency": "Continuously improve the transparency of artificial intelligence systems. Regarding system decision-making processes, data structures, and the intent of system developers and technological implementers: be capable of accurate description, monitoring, and reproduction; and realize explainability, predictability, traceability, and verifiability or algorithmic logic, system decisions, and action outcomes.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Mid- to Long-Term Master Plan in Preparation for the Intelligent Information Society Managing the Fourth Industrial Revolution",
        "country": "South Korea",
        "world_region": "Eastern Asia",
        "institution": "Korean Ministry of Science, ICT and Future Planning (MSIP)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2016",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Korean Ministry of Science, ICT and Future Planning (MSIP), a ministry of the Government of South Korea. Its purpose is to set, manage, and evaluate science and technology policy, support scientific research and development, develop human resources, conduct R&D leading to the production and consumption of Atomic power, plan national informatization and information protection strategies, manage radio frequency bands, oversee the information and communications technology (ICT) industry, and operate Korea Post. In this document, the South Korean government announces its strategic plan concerning the Fourth Industrial Revolution, focusing on the mid to long-term prospects related to intelligent information technology (Intelligent IT). The document provides a detailed road map of how to rip the benefits and avoid the pitfalls of an Intelligent-IT-powered South Korea, citing several ethical principles that fit in the scope of South Korea's Master Plan.",
        "document_url": "https://k-erc.eu/wp-content/uploads/2017/12/Master-Plan-for-the-intelligent-information-society.pdf",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": true,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Reform and improve the entire legal system to grant rights and responsibilities to “electronic persons” in preparation for the dissemination of AI and self-learning machines.",
            "Beneficence": "Intelligent IT is expected to enhance consumer welfare by preventing diseases, increasing the efficacy of healthcare, improving people's living environments, reducing accidents, and facilitating progress in other areas. It is also necessary to raise public awareness of the negative impacts of technological innovation, such as threats to privacy, socioeconomic polarization, and human alienation, and establish a structure for broad public discourses on identifying and managing these risks.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "Channel technological innovation toward supporting and assisting human activities (eating, using the bathroom, moving about, etc.) to solve many of the daily problems and difficulties faced by the elderly and people with disabilities.",
            "Autonomy": "It may be necessary to establish a systemic process through which people may raise formal objections to the evaluations made by AI systems and have AI-based decisions reviewed and tested.",
            "Human Formation": "It is important to tailor education, employment, and welfare services in response to changes to ensure that all citizens can enjoy the benefits of the intelligent information society. Provide education for the underprivileged to minimize the information gap and foster and spread a human-centered technological culture that accords due respect to technology and the humanities alike.",
            "Human-Centeredness": "Establish human-centered ethics to govern data-collection processes and AI algorithms.",
            "Intellectual Property": "Labor Rights: It is important to tailor education, employment, and welfare services in response to changes to ensure that all citizens can enjoy the benefits of the intelligent information society. Provide workers hoping to make career transitions with education and training on founding new technology businesses.",
            "Fairness": "Intellectual Property: Secure the rights ad access to intellectual properties available worldwide through R&D, M&A, and strategic alliances.",
            "Labor Rights": "Justice/Equity/Fairness/Non-discrimination: Apply Intelligent IT to people's daily lives to achieve an open, discrimination-free society in which everyone can enjoy the benefits of technological innovation and maintain stable livelihoods despite job losses or transitions and the rising cost of healthcare.",
            "Cooperation": "Minimize the monopolistic and oligopolistic practices of platforms using the networking effect by finding and fostering an appropriate environment of fair competition.",
            "Privacy": "Find and differentiate measures to support the distribution and utilization of data under data type.",
            "Reliability": "Establish a public-private partnership council tasked with monitoring, researching, and preventing technological trends and risks that may perpetuate the negative impacts of new technologies. Develop AI-based cyber immunity and automated defense systems.",
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Charlevoix Common Vision for the Future of Artificial Intelligence",
        "country": "G7",
        "world_region": "Intergovernmental Organization",
        "institution": "Leaders of the G7",
        "institution_type": "International Organization",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Leaders of the G7. The Group of Seven (G7) is an inter-governmental political forum consisting of Canada, France, Germany, Italy, Japan, the United Kingdom, and the United States. The document contains a set of voluntary self-commitment made by the leaders of the G7, which encompasses their shared vision for the future of AI.",
        "document_url": "https://www.mofa.go.jp/files/000373837.pdf",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": true,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "We, the leaders of the G7, commit to safeguarding privacy including through the development of appropriate legal regimes;",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "We, the leaders of the G7, commit to supporting and involving women, underrepresented populations, and marginalized individuals as creators, stakeholders, leaders, and decision-makers at all stages of the development and implementation of AI applications.",
            "Autonomy": "We, the leaders of the G7, commit to fostering initiatives that promote safety and transparency and guide human intervention in AI decision-making processes.",
            "Human Formation": "Support lifelong learning, education, training and reskilling, and exchange information on workforce development for AI skills, including apprenticeships, computer science, and STEM (science, technology, engineering, and mathematics) education, especially for women, girls and those at risk of being left behind.",
            "Human-Centeredness": "We, the leaders of the G7, commit to promoting human-centric AI and commercial adoption of AI, and continue to advance appropriate technical, ethical, and technologically neutral approaches.",
            "Intellectual Property": "We, the leaders of the G7, recognize the need for effective protection and enforcement of intellectual property rights.",
            "Fairness": "We, the leaders of the G7, encourage industry to invest in developing and deploying AI that supports economic growth and women's economic empowerment while addressing issues related to accountability, assurance, liability, security, safety, gender, and other biases and potential misuse.",
            "Labor Rights": "We, the leaders of the G7, will seek to promote active labor market policies, workforce development, and reskilling programs to develop the skills needed for new jobs and for those at risk of being left out, including policies specifically targeting the needs of women and underrepresented populations to increase labor participation rates for those groups.",
            "Cooperation": "We, the leaders of the G7, commit to supporting an open and fair market environment including the free flow of information while respecting applicable frameworks for privacy and data protection for AI innovation by addressing discriminatory trade practices, such as forced technology transfer.",
            "Privacy": "We, the leaders of the G7, commit to safeguarding privacy, ensuring AI design and implementation respect, and promoting applicable frameworks for privacy and personal data protection.",
            "Reliability": "We, the leaders of the G7, commit to investing in cybersecurity, promoting research and development by industry in safety, assurance, data quality, and data security.",
            "Sustainability": null,
            "Transparency": "We, the leaders of the G7, commit to exploring the use of other transformative technologies to protect personal privacy and transparency.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Governance Recommendations - Use of Artificial Intelligence by Public Authorities",
        "country": "Brazil",
        "world_region": "Latin America",
        "institution": "Transparência Brasil (TB)",
        "institution_type": "NGO",
        "year_of_publication": "2021",
        "number_of_male_authors": "2",
        "number_of_female_authors": "3",
        "document_size": "Large (>10.000 Words, <20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Transparência Brasil (TB), an independent, autonomous Brazilian organization whose main objective is the fight against corruption in Brazil. This document presents several recommendations made by TB for the use and development of AI technology by the Brazilian public sector, also giving an account of the AI tools currently used by the Brazilian Executive, Legislative, and Judiciary branches. The document also presents a risk analysis tool for AI systems used by the government, which is a qualitative tool in Q&A format developed by TB.",
        "document_url": "https://www.transparencia.org.br/downloads/publicacoes/Governance_Recommendations.pdf",
        "attachments": [
            "https://www.transparencia.org.br/",
            "https://www.transparencia.org.br/downloads/publicacoes/Estrutura_Avaliacao_Risco.pdf"
        ],
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Accountability is a necessary guarantee to enable the exercise of civilian oversight of Artificial Intelligence tools employed by public authorities, minimizing risks of fundamental rights violation.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "This constraint is a challenge to ensure safeguards on the obligation for human revision in automated decisions, because if interpreted in an extremely restrictive way, it may impair the fundamental right of individuals to control how their data are used and the impacts they may have in their lives.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "During data collection, it is important to ensure the data selected for training the algorithms is representative of the groups and populations affected by them. It is also important to check for subtle discriminations embedded in data creation that might replicate discriminatory patterns further down the line.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "People, as data subjects, need to be clearly informed of the purpose of personal data collection. It is important to understand how these government bodies store and use their data on their AI tools. Otherwise, this type of service is not compliant with principles established by the General Law of Personal Data Protection.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "The government must ensure that algorithms are explained well enough: allowing citizens to understand how they work, how decisions have been made with their support, their purpose and reason, besides the data used in processing.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "The Ethics of Artificial Intelligence",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Machine Intelligence Research Institute (MIRI)",
        "institution_type": "Non-profit Organization",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "2",
        "number_of_female_authors": "0",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": "Descriptive",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Long",
        "abstract": "This document was written by the Machine Intelligence Research Institute (MIRI), a non-profit research institute focused on identifying and managing potential existential risks from artificial general intelligence. This document takes an unusual approach to AI Ethics, raising questions related both to ensuring that AI does not harm humans and other morally relevant beings and to the moral status of artificial agents themselves (most of the literature doesn't even entertain this hypothesis). The document also cites the pitfalls of developing unaligned AGI (Artificial General Intelligence), giving some theoretical background for \"what AGI would look like\" and \"how we have no strong theoretical background to predict the behavior of such a hypothetical agent.\"",
        "document_url": "https://intelligence.org/files/EthicsofAI.pdf",
        "attachments": "https://intelligence.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Another important social criterion for dealing with organizations is being able to find the person responsible for getting something done. When does an AI system fail at its assigned task, who takes the blame? The programmers? The end-users? Modern bureaucrats often take refuge in established procedures that distribute responsibility so widely that no one person can be identified to blame for the catastrophes that result.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "It will also become increasingly important that AI algorithms be robust against manipulation. Robustness against manipulation is an ordinary criterion in information security; nearly the criterion.",
            "Sustainability": null,
            "Transparency": "It will become increasingly important to develop AI algorithms that are not just powerful and scalable, but also transparent to inspection—to name one of many socially important properties. It is also important that AI algorithms taking over social functions be predictable to those they govern.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Next-Generation AI Governance Principles - Develop responsible artificial intelligence",
        "country": "China",
        "world_region": "Eastern Asia",
        "institution": "Ministry of Science and Technology (MOST)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the  Ministry of Science and Technology (MOST), the government ministry of the Republic of China for the promotion and funding of academic research, development of science and technology, and science parks. This document proposes a framework and action guidelines for artificial intelligence governance in China. In addition, the document highlights the need to pay attention to the future long-term artificial intelligence development and its social impact.",
        "document_url": "https://mp.weixin.qq.com/s/JWRehPFXJJz_mu80hlO2kQ",
        "attachments": "https://www.newamerica.org/cybersecurity-initiative/digichina/blog/translation-chinese-expert-group-offers-governance-principles-responsible-ai/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "AI developers, users, and other interested parties should possess a strong sense of social responsibility and self-discipline, and strictly abide by laws, regulations, ethics, morals, standards, and norms. Establish an AI accountability mechanism to clarify the responsibilities of developers, users, beneficiaries, etc. The AI application process should ensure the human right to know and give notice of possible risks and impacts. Prevent the use of AI for illegal activities.",
            "Beneficence": "AI development should begin from the objective of enhancing the common well-being of humanity; it should conform to human values, ethics, and morality, promote human-machine harmony, and serve the progress of human civilization; it should be based on the premise of safeguarding societal security and respecting human rights, avoid misuse, and prohibit abuse and malicious application.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "AI development should improve the adaptability of disadvantaged groups, and strive to erase the digital divid",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "AI development should promote fairness and justice, protect the rights and interests of stakeholders, and promote equality of opportunity. Through continuously raising the level of technology and improving management methods, eliminate bias and discrimination in the process of data acquisition, algorithm design, technology development, product R&D, and application.",
            "Labor Rights": null,
            "Cooperation": "Encourage exchanges and cooperation across disciplines, domains, regions, and borders; promote coordination and interaction between international organizations, government departments, research institutions, educational institutions, enterprises, social organizations, and the public for the development and governance of AI. Launch international dialogue and cooperation; with full respect for each country's principles and practices for AI governance, promote the formation of a broad consensus on an international AI governance framework, standards, and norms.",
            "Privacy": "AI development should respect and protect personal privacy and fully protect the individual's right to know and right to choose. In personal information collection, storage, processing, use, and other aspects, boundaries should be set and standards should be established. Improve personal data authorization and revocation mechanisms to combat any theft, tampering, disclosure, or other illegal collection or use of personal information.",
            "Reliability": "It's necessary to pay close attention to the safety/security of AI systems, improve the robustness and tamper-resistance of AI, and form AI security assessment and management capabilities.",
            "Sustainability": "AI should promote green development and meet the requirements of environmental friendliness and resource conservation.",
            "Transparency": "AI systems should continuously improve transparency, explainability, reliability, and controllability, and gradually achieve audibility, traceability, and trustworthiness.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "MIT Schwarzman College of Computing Task Force Working Group on Social Implications and Responsibilities of Computing Final Report",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Massachusetts Institute of Technology (MIT)",
        "institution_type": "Academic",
        "year_of_publication": "2019",
        "number_of_male_authors": "0",
        "number_of_female_authors": "2",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Descriptive",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Long",
        "abstract": "This document was written by the Massachusetts Institute of Technology (MIT), a private land-grant research university in Cambridge (Massachusetts, US). The authors of the document propose a new angle to think about the role of computer scientists and engineers, making it explicit the need to shape the curriculum and formation of such agents in a way that increases their ability to critically evaluate and reflect on the societal implications of their work. Ideally, this would introduce the notion of \"Humanities\" (e.g., the study of Ethics, Philosophy, Critical Theory, Sociology) into the \"Hard Sciences\" (e.g., Software Development). For this, the document also points to the need to make computer science research a more interdisciplinary field. The document also presents a clear roadmap (i.e., organizational framework) on how to implement the educational changes recommended in the Schwarzman College of Computing and MIT ecosystem.",
        "document_url": "http://web.mit.edu/comptfreport/sirc.pdf",
        "attachments": null,
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": "As a leading engineering institution with world-class social science and humanities and a tradition of multidisciplinary collaboration, MIT has a pivotal opportunity to make leadership contributions to the social, ethical, and policy challenges facing the world by integrating consideration of these issues with the development of new computing technologies. Establishing and prioritizing interdisciplinary structures, which include rigorous methodologies derived from the liberal arts, humanities, social sciences, and other disciplines, will prove critical in activating and sustaining habits of mind and action. The SCoC must catalyze and facilitate complex interdisciplinary actions.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": null,
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Draft AI R&D Guidelines for International Discussions",
        "country": "Japan",
        "world_region": "Eastern Asia",
        "institution": "Institute for Information and Communication Policy (IICP)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2017",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Institute for Information and Communication Policy (IICP), an initiative of the Ministry of Internal Affairs and Communications (MIC) of Japan. The IICP is engaged in advanced and fundamental research to plan and formulate future information and communications policies. This document was prepared as a basis for international discussions at G7 and OECD regarding matters expected to be considered in R&D activities for promoting the benefits and reducing the AI risks. The document also presents a set of AI R&D Principles that concern the sound development of AI networking and the promotion of the benefits of AI systems.",
        "document_url": "https://www.soumu.go.jp/main_content/000507517.pdf",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "AI designers must ensure that they are accountable to their stakeholders and users to gain their trust. In this way, AI designers must ensure that they provide all the information and explanation about their systems to users.",
            "Beneficence": "AI developers must ensure that their systems need not posit any harm to the lives and properties of users.",
            "Children's Rights": null,
            "Human Rights": "AI developers must ensure that they respect their users' dignity and individual autonomy. Developers must avoid unfair discrimination resulting from prejudices through AI data learning. AI must not infringe human values and must be made to respect the International Human Rights Law.",
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": "Privacy: Developers of AI systems must ensure that AI systems will not and do not infringe the privacy of AI users. The privacy referred to in this document is spatial: peace of personal life, personal data, and secrecy of communications. To ensure this, developers must always ensure that they follow international guidelines on privacy, such as the \"OECD Guidelines on the Protection of Privacy and Transborder Flows of Personal Data”.",
            "Privacy": "Open source/Fair Competition/Cooperation: AI developers are obliged to ensure interconnectivity and interoperability between AI systems that have been developed and other AI systems.",
            "Reliability": "AI developers must ensure that they verify and validate their systems in advance to control relatable risk. They must ensure that there is the quality of experiment done before applying the systems in society. Furthermore, developers must ensure that trustworthy humans or other AI systems new supervise these systems. AI designers must ensure that they pay attention to the security of AI systems. In this sense, they ought to follow the security guidelines and international security standards to mitigate risks.",
            "Sustainability": null,
            "Transparency": "AI developers must ensure verifiability of inputs/outputs of their systems and the explainability of their judgment. The attention paid to verifiability and explainability ought to be in line with the reasonable scope in light of the characteristics of the technology and trust from users in society.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Responsible bots: 10 guidelines for developers of conversational AI",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Microsoft Corporation",
        "institution_type": "Private Corporation",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Descriptive",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Microsoft Corporation, an American multinational technology corporation that produces computer software, consumer electronics, personal computers, and related services. This document presents a series of recommendations for creating bots (conversational AIs) that are trustworthy. Its recommendations are all made with the application of chatbots in mind. In this way, all ethical principles are presented within this context.",
        "document_url": "https://www.microsoft.com/en-us/research/uploads/prod/2018/11/Bot_Guidelines_Nov_2018.pdf",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Accept responsibility; Developers are accountable for the bots they deploy.",
            "Beneficence": "Before beginning design work, carefully specify how your bot will benefit the user or the entity deploying the bot.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "Design your bot so that it respects relevant cultural norms and guards against misuse; Strive for diversity amongst your development team. If you are developing a bot, consider how your bot complies with commonly used accessibility standards; Have people with disabilities test your bots; Design bots to respect the full range of human abilities.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": "Develop metrics to assess user satisfaction.",
            "Intellectual Property": null,
            "Fairness": "Ensure your bot treats people fairly; Systematically assess the data used for training your bot.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Ensure your bot respects user privacy; Inform users upfront about the data that is collected and how it is used and obtain their consent beforehand; Collect no more personal data than you need, limit access to it, and store it for no longer than needed; Provide privacy-protecting user controls; Obtain legal and privacy review.",
            "Reliability": "Assess whether the bot's intended purpose can be performed responsibly; Establish how the bot can help and the limitations associated with its use; Apply machine learning techniques and keyword filtering mechanisms to enable your bot to detect and — critically — respond appropriately to sensitive or offensive input from users; Your bot should be resilient; Obtain security review.",
            "Sustainability": null,
            "Transparency": "Be transparent about the fact that you use bots as part of your product or service; It should be apparent to the user that they are not having an interaction with another person; Be transparent about bot reliability.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Facial recognition: It's time for action",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Microsoft Corporation",
        "institution_type": "Private Corporation",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Microsoft Corporation, an American multinational technology corporation that produces computer software, consumer electronics, personal computers, and related services. The document addresses the need for government regulation and responsible industry measures to address advances in facial recognition technology (e.g., CNNs). In it, Microsoft points to the need for governments to start adopting laws to regulate this technology and provides some initial pointers for legislation to be based. The document also proposes that as much as legislations are indispensable, \"they are not a substitute for the responsibility that needs to be exercised by tech companies.\" Thus, to fill this gap of self-accountability, the document presents a set of ethical principles to govern Microsoft's facial recognition work.",
        "document_url": "https://blogs.microsoft.com/on-the-issues/2018/12/06/facial-recognition-its-time-for-action/",
        "attachments": null,
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "We will encourage and help our customers to deploy facial recognition technology in a manner that ensures an appropriate level of human control for uses that may affect people in consequential ways. We will advocate for safeguards for people's democratic freedoms in law enforcement surveillance scenarios, and will not deploy facial recognition technology in scenarios that we believe will put these freedoms at risk.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "We will work to develop and deploy facial recognition technology in a manner that strives to treat all people fairly. We will prohibit in our terms of service the use of facial recognition technology to engage in unlawful discrimination.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "The law should require that entities that use facial recognition to identify consumers place conspicuous notice that clearly conveys that these services are being used. The law should specify that consumers consent to the use of facial recognition services when they enter premises or proceed to use online services that have this type of clear notice. Legislation should limit the use of facial recognition technology for monitor and surveillance of specified individuals.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "We will document and clearly communicate the capabilities and limitations of facial recognition technology.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Toward a G20 Framework for Artificial Intelligence in the Workplace",
        "country": "Canada",
        "world_region": "North America",
        "institution": "Centre for International Governance Innovation (CIGI)",
        "institution_type": "NGO",
        "year_of_publication": "2018",
        "number_of_male_authors": "1",
        "number_of_female_authors": "0",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Centre for International Governance Innovation (CIGI), an independent, non-partisan think tank on global governance headquartered in Waterloo, Canada. CIGI builds bridges from knowledge to power by conducting world-leading research and analysis to offer innovative policy solutions for the digital era. Building on the 2017 “Hamburg Statement” of the Group of Twenty (G20) and the G20 Roadmap for Digitalisation, this document recommends a G20 framework for artificial intelligence (AI) in the workplace. It proposes high-level principles for such a framework for G20 governments, to enable the\nsmoother, internationally broader and more socially acceptable introduction of big data and AI.",
        "document_url": "https://www.cigionline.org/static/documents/documents/Paper%20No.178.pdf",
        "attachments": "https://www.cigionline.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "People and corporations who design and deploy AI systems must be accountable for how their systems are designed and operated. The development of AI must be responsible, safe, and useful. AI must maintain the legal status of tools, and legal persons need to retain control over, and responsibility for, these tools at all times.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "AI should adopt inclusive design efforts to anticipate any potential deployment issues that could unintentionally exclude people.",
            "Autonomy": "Employees and contractors should be fully informed when either internal or external data (or both) has been used in a decision affecting their career. Any data processing of present or prospective employees' or contractors' data should be transparent and the PII (personally identifiable information) available for their review. The right to understand and appeal against both the rationale employed and the data used to achieve that rationale is essential to safeguard present or prospective workers against poor or inaccurate input data or discriminative decisions. Human control of AI should be mandatory and testable by regulators.",
            "Human Formation": "Ongoing training in the workplace should be reinforced to help workers adapt.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Employers should be required to test AI in the workplace regularly to ensure that the system is built for purpose and is not harmfully influenced by biases of any kind — gender, race, sexual orientation, age, religion, income, family status and so on. Workplace AI should be tested to ensure that it does not discriminate against vulnerable individuals or communities. In particular, the impact of overlapping AI systems toward profiling and marginalization should be identified and countered",
            "Labor Rights": "Governments should plan for transition support as jobs disappear or are significantly changed.",
            "Cooperation": "AI should benefit as many people as possible. Access to AI technologies should be open to all countries. The wealth created by AI should benefit workers and society as a whole, as well as the innovators.",
            "Privacy": "Data should be anonymized where possible. Big data collection and AI must comply with laws that regulate privacy and data collection, use, and storage. AI data and algorithms must be protected against theft, and employers or AI providers need to inform employees, customers, and partners of any breach of information, in particular PII (personally identifiable information), as soon as possible.",
            "Reliability": "AI should be designed within explicit operational requirements and undergo exhaustive testing to ensure that it responds safely to unanticipated situations and does not evolve in unexpected ways.",
            "Sustainability": null,
            "Transparency": "There should be a clear and testable explanation of the type and purpose of the data being sourced. Workers and contractors with experience in the work processes and data environment of the firm should be incorporated into the review of data sources.  Workers, customers, and vendors need to have information about how AI systems operate so that they can understand how decisions are made.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Digital ethics: a guide for professionals of the digital age",
        "country": "France",
        "world_region": "Western Europe",
        "institution": "CIGREF, Syntec Numérique",
        "institution_type": "Industrial Association",
        "year_of_publication": "2018",
        "number_of_male_authors": "14",
        "number_of_female_authors": "4",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by CIGREF,  a network of major French corporations created in 1970, and Syntec Numérique,  a trade body representing digital service companies, IT suppliers, and technology consulting companies. This document consists of a practical tool/guide created for the education of digital professionals. The proposed tool consists of a qualitative self-assessment Q&A. The questions of the guide are focused on three main approaches to ethics: ethics by design, ethics of use, and societal ethics.",
        "document_url": "https://www.cigref.fr/wp/wp-content/uploads/2019/02/Cigref-Syntec-Digital-Ethics-Guide-for-Professionals-of-Digital-Age-2018-October-EN.pdf",
        "attachments": [
            "https://www.cigref.fr/",
            "https://gnius.esante.gouv.fr/en/players/player-profiles/syntec-numerique"
        ],
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "Draw up an HR (Human Resources) policy ensuring social and gender diversity in the workplace. By default, design solutions that are accessible for people with disabilities.",
            "Autonomy": null,
            "Human Formation": "Set up training workshops and/or skills refresher courses within the IT Department.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Carry out a DIA (discrimination impact assessment) as suggested in the Villani report (p.148), inspired by the PIA (privacy impact assessment) introduced with the GDPR, to analyze the possible design-induced discriminatory impacts of algorithms. Put in place checks and balances at each stage of development to ensure there is no bias in the results.",
            "Labor Rights": "Forecast, with the help of teams specialising in forwardplanning and strategy, the impacts of technological change on the company's jobs and activities. Include the impacts of automation and more broadly of digital technology in strategic workforce planning.",
            "Cooperation": null,
            "Privacy": "Adopt a privacy by design approach, following the requirements of the GDPR: this means building the protection of personal data into products and services by design, but also by default (notably by abiding by the data minimization principle introduced by the GDPR); this is also a cultural challenge because this concept needs to be factored into a project early on.",
            "Reliability": "Ensure that digital applications and solutions have not been designed in such a way as to deliberately manipulate users by exploiting cognitive biases.",
            "Sustainability": "Factor in environmental impact when entering into any contract that has consequences for the environmental footprint of the IT system. Conduct a regular assessment of the environmental footprint of the IT system (at least every two years), based on recognised and auditable indicators (Green IT or WWF France).",
            "Transparency": "Have a systems explainability policy encompassing the whole chain (data provenance, explanation of the reasoning followed). Develop algorithms that are transparent by design, to make it easier to explain them and to analyse how they reason. Ensure that the information given to users is clear and transparent.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "The Future Computed – Artificial intelligence and its role in society",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Microsoft Corporation",
        "institution_type": "Private Corporation",
        "year_of_publication": "2018",
        "number_of_male_authors": "20",
        "number_of_female_authors": "20",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Microsoft Corporation, an American multinational technology corporation that produces computer software, consumer electronics, personal computers, and related services. In this document, we find a series of recommendations made by Microsoft, which also presents the principles that are upheld in the way that Microsoft develops its applications. Such principles are the pillars of the AI and Ethics in Engineering and Research (AETHER) Committee, a division of Microsoft focused on the proactive formulation of internal policies and on how to respond to specific issues as they arise.",
        "document_url": "https://news.microsoft.com/wp-content/uploads/2018/02/The-Future-Computed_2.8.18.pdf",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "The people who design and deploy AI systems must be accountable for how their systems operate. To establish accountability norms for AI, we should draw upon experience and practices in other areas, including healthcare and privacy. Governments must also balance support for innovation with the need to ensure consumer safety by holding the makers of AI systems responsible for harm caused by unreasonable practices.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "AI systems should empower everyone and engage people. People around the world can benefit from AI — but only if AI technologies are available for them. We believe that the people designing AI systems should reflect the diversity of the world in which we live.",
            "Autonomy": "AI system should seek human input during critical situations, and how a system controlled by AI should transfer control to a human in a manner that is meaningful and intelligible.",
            "Human Formation": "Equitable access to rigorous and engaging computer science courses must be a top priority. If equitable access is left unaddressed, we will exclude entire populations from fully participating in this new world of work. The goal of equitable access should be computer science classrooms that are diverse across race, gender, disability, and socioeconomic status.",
            "Human-Centeredness": "We believe that AI offers incredible opportunities to drive widespread economic and social progress. The key to attaining these benefits is to develop AI in such a way that it is human-centered. AI should augment and amplify human capabilities. AI systems should be designed to understand the context, needs, and expectations of the people who use them. Goals for educational attainment should include outcomes related to employment, skills, and advancement.",
            "Intellectual Property": null,
            "Fairness": "AI systems should treat everyone in a fair and balanced manner and not affect similarly situated groups of people in different ways.",
            "Labor Rights": "The public and private sectors should seek to meet the needs of people at all stages of the workforce continuum — from students entering the workforce to unemployed and underemployed workers, to people currently in the workforce who need help gaining new skills to ensure their long-term employability. Businesses should engage in discussions about the importance of next-generation versions of unemployment insurance and employment services that take into account newer models of work; anticipate that individuals may move in and out of the workforce with greater frequency; promote greater labor mobility, and help workers gain new skills and connect with new opportunities.",
            "Cooperation": null,
            "Privacy": "AI systems should be secure and respect privacy.AI systems should be designed so that private information is used following privacy standards and protected from bad actors who might seek to steal private information or inflict harm.",
            "Reliability": "AI systems should perform reliably and safely. Design and testing should also anticipate and protect against the potential for unintended system interactions or bad actors to influence operations, such as through cyberattacks.",
            "Sustainability": null,
            "Transparency": "AI systems should be understandable. Industry groups and others should build off these principles to create detailed best practices for key aspects of the development of AI systems, such as the nature of the data used to train AI systems, the analytical techniques deployed, and how the results of AI systems are explained to people using those systems.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "How Can Humans Keep The Upper Hand? The Ethical Matters Raised By Algorithms And Artificial Intelligence",
        "country": "France",
        "world_region": "Western Europe",
        "institution": "Commission nationale de l'informatique et des libertés (CNIL)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2017",
        "number_of_male_authors": "2",
        "number_of_female_authors": "0",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Commission nationale de l'informatique et des libertés (CNIL), a French institution focused on raising awareness and sharing information on data protection culture. The CNIL analyses the consequences of new technologies on citizens' private life. This document is the result of a public debate organized by CNIL. The document provides a pragmatic definition of algorithms and artificial intelligence (AI),  main ethical issues involving AI technologies, and practical policy recommendations intended for the public authorities,  the general public, businesses, and associations.",
        "document_url": "https://www.cnil.fr/sites/default/files/atoms/files/cnil_rapport_ai_gb_web.pdf",
        "attachments": "https://www.cnil.fr/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "To end, introducing an obligation in terms of accountability or organizing liability could be a way of addressing the phenomenon of diminishing accountability which algorithms and AI are tending to encourage. The idea would be that the roll-out of an algorithmic system systematically must give rise to a clear attribution of the liabilities that should be assumed in its operation.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "If we are to guarantee that artificial intelligence does not foster forms of ethnocentrism, it is vital to encourage cultural, social, and gender diversification in the occupations involved in designing algorithms.",
            "Autonomy": "Improve the design of algorithmic systems in the interests of human freedom. We need to be promoting a design conducive to empowering individuals with more autonomy and scope to think; a design to righting the imbalance that algorithms can create to our detriment; overall a design that enables us to make clear and informed decisions.",
            "Human Formation": "Fostering education of all players involved in the “algorithmic chain” (designers, professionals, citizens) in the subject of ethics. There could be merits to including the social and human sciences approach (sociology, anthropology, management, history of science and technology, information and communication sciences, philosophy, and ethics) to these issues in engineer and data scientist training. It would be advisable to educate public stakeholders in the need for a balanced and symmetrical deployment of algorithms.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "A fair algorithm should not end up generating, replicating, or aggravating any form of discrimination, even if this were to happen without its designers being aware.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Data processing shall be at the service of every citizen. It shall develop in the context of international cooperation. It shall infringe neither human identity, nor the rights of man, nor privacy, nor individual or public liberties.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "Given the opacity of algorithmic systems, transparency is an oft-cited requirement, with the idea that it could be a condition for fairness. It should be possible for everyone to understand this logic, which must therefore be explained in words rather than in lines of code. Public authorities must do their utmost to open up the source code of deterministic algorithms.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Statement on Algorithmic Transparency and Accountability",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Association for Computing Machinery (ACM)",
        "institution_type": [
            "Non-profit Organization",
            "Professional Association"
        ],
        "year_of_publication": "2017",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Association for Computing Machinery (ACM) (US Public Policy Council), a US-based international learned society for computing, headquartered in New York City. In this document, the ACM presents a set of principles, consistent with the ACM Code of Ethics, intended to support the benefits of algorithmic decision-making while addressing general concerns. According to ACM, these principles should be addressed during every phase of system development and deployment to the extent necessary to minimize potential harms while realizing the benefits of algorithmic decision-making.",
        "document_url": "https://www.acm.org/binaries/content/assets/public-policy/2017_usacm_statement_algorithms.pdf",
        "attachments": "https://www.acm.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Institutions should be held responsible for decisions made by the algorithms that they use, even if it is not feasible to explain in detail how the algorithms produce their results.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "Regulators should encourage the adoption of mechanisms that enable questioning and redress for individuals and groups that are adversely affected by algorithmically informed decisions.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Owners, designers, builders, users, and other stakeholders of analytic systems should be aware of the possible biases involved in their design, implementation, and use and the potential harm that biases can cause to individuals and society.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "Institutions should use rigorous methods to validate their models and document those methods and results. In particular, they should routinely perform tests to assess and determine whether the model generates discriminatory harm. Institutions are encouraged to make the results of such tests public.",
            "Sustainability": null,
            "Transparency": "Systems and institutions that use algorithmic decision-making are encouraged to produce explanations regarding both the procedures followed by the algorithm and the specific decisions that are made. This is particularly important in public policy contexts. A description of how the training data was collected should be maintained by the builders of the algorithms, accompanied by an exploration of the potential biases induced by the human or algorithmic data-gathering process. Models, algorithms, data, and decisions should be recorded so that they can be audited in cases where harm is suspected.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Responsible AI - Microsoft AI principles",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Microsoft Corporation",
        "institution_type": "Private Corporation",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Microsoft Corporation, an  American multinational technology corporation that produces computer software, consumer electronics, personal computers, and related services. This document is a webpage where Microsoft presents its AI Principles for AI development. According to Microsoft, these responsible AI principles are put into practice through the Office of Responsible AI (ORA), the AI Ethics and Effects in Engineering and Research (Aether) Committee, and Responsible AI Strategy in Engineering (RAISE), i.e., Microsoft's AI Ethics and Safety R&D groups. A more in-depth exploration of Microsoft's approach to AI Ethics can be found in the \"Future Computed – Artificial intelligence and its role in society,\" another one of Microsoft's documents on AI Ethics.",
        "document_url": "https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6",
        "attachments": "https://news.microsoft.com/wp-content/uploads/2018/02/The-Future-Computed_2.8.18.pdf",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "People should be accountable for AI systems.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "AI systems should empower everyone and engage people.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "AI systems should treat all people fairly.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "AI systems should be secure and respect privacy.",
            "Reliability": "AI systems should perform reliably and safely.",
            "Sustainability": null,
            "Transparency": "AI systems should be understandable.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "For a meaningful Artificial Intelligence - Towards a French and European strategy",
        "country": "France",
        "world_region": "Western Europe",
        "institution": "The National Strategy for AI - The Villani Mission",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2018",
        "number_of_male_authors": "6",
        "number_of_female_authors": "1",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was commissioned by France's prime minister (Édouard Philippe, 2017 to 2020), and produced by Cédric Villani (which was at the time member of the French Parliament) plus a task force of experts/researchers. The document contains a detailed recommendation for the artificial intelligence strategy for France and Europe.  The document executive summary focus on mainly six parts: (1) building a data-focused economic policy; (2) promoting agile and enabling research; (3) assessing the effects of AI on the future of work and the labor market; (4) AI working for a more ecological economy; (5) ethical considerations of AI; and (6) inclusive and diverse AI. The authors also bring to the discussion a topic that is usually forgotten in AI Ethical Guidelines, lethal autonomous weapons systems (LAW).",
        "document_url": "https://www.aiforhumanity.fr/pdfs/MissionVillani_Report_ENG-VF.pdf",
        "attachments": "https://www.intelligence-artificielle.gouv.fr/fr/strategie-nationale/la-mission-villani",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "We need to ensure that organizations that deploy and utilize these systems remain legally responsible for any damages caused.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "AI must first and foremost help us to promote our fundamental rights, improve social cohesion, and strengthen solidarity.",
            "Diversity": "We must support investment efforts focused on AI projects within the sphere of dependence and disability. Given the important nature of the ethical questions that confront future developments in AI, it would be prudent to create a genuinely diverse and inclusive social forum for discussion, to enable us to democratically determine which forms of AI are appropriate for our society. Given the extent of future AI-led transformation, we have a collective responsibility to ensure that no one gets left behind.",
            "Autonomy": "The protection of our rights and freedoms needs to be adapted to accommodate the potential for abuse involved in the use of machine learning systems.",
            "Human Formation": "Formal education and lifelong learning should be overhauled in order to promote experimental teaching methods that can help graduates and staff develop the creative skills that are becoming increasingly vital.",
            "Human-Centeredness": "We need to formulate ways in which humans and intelligent systems can work together.",
            "Intellectual Property": null,
            "Fairness": "In a world marked by inequality, artificial intelligence should not end up reinforcing the problems of exclusion and the concentration of wealth and resources. The development of this technology does not contribute to an increase in social and economic inequality and using AI to help genuinely reduce these problems.",
            "Labor Rights": "The labor market is undergoing vast changes, but it is not yet fully equipped to address them. Legislation could be implemented to deal with working conditions at a time of increasing automation in order to factor in new risks.",
            "Cooperation": "As regards questions of technological and economic sovereignty and questions of efficiency and performance alike, it is essential to prioritize the use of open technologies (“open source” and “open hardware”) as much as possible, so as not to fall victim to close shop mindsets.",
            "Privacy": "It is recommended that aspects relating to data ethics, privacy, and data protection form an integral part of artificial intelligence courses.",
            "Reliability": "Public authorities must act to develop and implement standards, tests, and measurement methods in a bid to make AI technology more secure, more reliable, useable, and interoperable.",
            "Sustainability": "We need to ensure that the artificial intelligence being developed makes the most economical use of energy and resources possible.",
            "Transparency": "AI should be explainable. Our digital society could not be governed by black-box algorithms. It should be possible to open these black boxes.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Principles to Promote Fairness, Ethics, Accountability and Transparency (FEAT) in the Use of Artificial Intelligence and Data Analytics in Singapore's Financial Sector",
        "country": "Singapore",
        "world_region": "Southeast Asia",
        "institution": "Monetary Authority of Singapore",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Monetary Authority of Singapore (MAS), which is the central bank of Singapore. Its mission is to promote sustained non-inflationary economic growth. This document was commissioned by the Monetary Authority of Singapore and written in conjunction with industry stakeholders, mainly to provide a set of governance principles to aid the industry in developing AI applications responsibly and build public trust towards the AI industry. The authors state that the document should not be used in a \"prescriptive/normative\" manner but rather as a set of recommendations for further considerations and discussions.",
        "document_url": "https://www.mas.gov.sg/~/media/MAS/News%20and%20Publications/Monographs%20and%20Information%20Papers/FEAT%20Principles%20Final.pdf",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Firms using AIDA should be accountable for both internally developed and externally sourced AIDA models.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "Data subjects should be provided with channels to enquire about, submit appeals for, and request reviews of AIDA-driven decisions that affect them.",
            "Human Formation": null,
            "Human-Centeredness": "The use of AIDA should be aligned with the firm's ethical standards, values, and codes of conduct. AIDA-driven decisions should be held to at least the same ethical standards as human-driven decisions.",
            "Intellectual Property": null,
            "Fairness": "Individuals or groups of individuals should not be systematically disadvantaged through AIDA-driven decisions unless these decisions can be justified. Data and models used for AIDA-driven decisions should be regularly reviewed and validated for accuracy and relevance, and to minimize unintentional bias.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "To increase public confidence, the use of AIDA should be proactively disclosed to data subjects as part of general communication. Data subjects should be provided, upon request, with clear explanations on what data is used to make AIDA-driven decisions about the data subject and how the data affects the decision. Data subjects should be provided, upon request, with clear explanations on the consequences that AIDA-driven decisions may have on them.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Facebook and Google: This is What an Effective Ad Archive API Looks Like",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Mozilla Foundation",
        "institution_type": "Non-profit Organization",
        "year_of_publication": "2019",
        "number_of_male_authors": "8",
        "number_of_female_authors": "4",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "Thi document was written by the Mozilla Foundation, an American non-profit organization that exists to support and collectively lead the open-source Mozilla project (a free software community founded in 1998 by members of Netscape). In this document, the Mozilla Foundation details key traits for an effective ad archive API for more transparent elections and prevention of misinformation spread. The document points out five guidelines that APIs should meet to truly support election influence monitoring, empowering researchers to better understand and document how disinformation spreads, how it influences elections, and how it impacts society. The requirements cited by the document are: (1) comprehensive political advertising content; (2) open access to advertisement content and information about targeting criteria; (3) functionality to empower research and analysis; (4) up-to-date and historical data access; and (5) public access.",
        "document_url": "https://blog.mozilla.org/en/mozilla/facebook-and-google-this-is-what-an-effective-ad-archive-api-looks-like/",
        "attachments": "https://foundation.mozilla.org",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "In the spirit of upholding the EU Code of Practice on Disinformation, we expect you to empower the research community by implementing open, functional APIs of the quality outlined in this letter — just as we expect elected officials and public authorities to fully support the release of such data in a privacy-compliant fashion to enable independent research and inform public debate. Your action on this is essential to ensuring the integrity of the upcoming European Parliamentary elections — as well as elections happening all around the globe — is upheld.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": "A functional, open API should have itself and any data collected from the API should be accessible to and shareable with the general public.",
            "Privacy": null,
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "A functional, open API should have information about how much an advertiser paid to place the ad; information about microtargeting, including whether the ad was tested and the different versions of the ad; if the ad used a lookalike audience; the features (race, gender, geography, etc.) used to create that audience; if the ad was directed at platform-defined user segments or interests, and the segments or interests used, or if the ad was targeted based on a user list the advertiser already possessed.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Code of Practice on Disinformation",
        "country": "European Union",
        "world_region": "European Union",
        "institution": "European Commission (EC)",
        "institution_type": "International Organization",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Normative",
            "Practical"
        ],
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was produced by the European Commission (EC), which is the executive branch of the European Union (EU). This document is the first time worldwide voluntary industry agreement for self-regulatory standards to fight disinformation, setting a wide range of commitments, from transparency in political advertising to the closure of fake accounts and demonetization of purveyors of disinformation. The document was signed by online platforms like Facebook, Google, Twitter, Mozilla, Microsoft, TikTok,  advertisers, and parts of the advertising industry. The document also includes an annex document identifying best practices and practical implementations that signatories apply to implement their commitments.",
        "document_url": "https://digital-strategy.ec.europa.eu/en/policies/code-practice-disinformation",
        "attachments": null,
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": true
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "The Signatories of this Code commit to investing in products, technologies, and programs to help people make informed decisions when they encounter online news that may be false, including by supporting efforts to develop and implement effective indicators of trustworthiness in collaboration with the news ecosystem.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "The Signatories of this Code recognize that transparency should be ensured with a view to enabling users to understand why they have been targeted by a given political or issue-based advertisement.",
            "Truthfulness": "The Signatories of this Code commit to supporting good faith independent efforts to track Disinformation and understand its impact, including the independent network of fact-checkers facilitated by the European Commission upon its establishment. Relevant Signatories commit to deploying policies and processes to disrupt advertising and monetization incentives for relevant behaviors, such as misrepresenting material information about oneself or the purpose of one's properties."
        }
    },
    {
        "document_name": "It's Time to Do Something: Mitigating the Negative Impacts of Computing Through a Change to the Peer Review Process",
        "country": [
            "Turkey",
            "Turkey"
        ],
        "world_region": [
            "Eastern Asia",
            "Central Europe"
        ],
        "institution": "Association for Computing Machinery's Council on Women in Computing (ACM-W Europe)",
        "institution_type": [
            "Non-profit Organization",
            "Professional Association"
        ],
        "year_of_publication": "2018",
        "number_of_male_authors": "7",
        "number_of_female_authors": "4",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Association for Computing Machinery's Council on Women in Computing (ACM-W Europe). ACM is a US-based international learned society for computing, headquartered in New York City. ACM-W supports, celebrates, and advocates internationally for the full engagement of women in all aspects of the computing field. The document proposes a recommendation for the peer-review process of scientific publications made by academic journals. It recommends that peer reviewers should require that papers and proposals rigorously consider all reasonable broader impacts, both positive and negative. The document proposes that the prospection of possible impacts should be a standard norm in scientific computing literature, to help shape our future technological development to a more beneficial outcome.",
        "document_url": "https://brenthecht.com/papers/FCADIscussions_NegativeImpactsPost_032918.pdf",
        "attachments": "https://acmweurope.acm.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "An initial threshold for a “reasonable technology” might emerge from the nature of recommendation as a means of making computing research more accountable to the public.",
            "Beneficence": "The research community should more actively evaluate its members on their ethical decision-making when it comes to research project selection.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "The researcher who develops any technology would be required under our recommendations to include benefits to accessibility.",
            "Autonomy": "Papers that advance generative models would be required to discuss the potentially deleterious effects to democratic discourse.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "For a technology with greater societal benefit, the researchers could be incentivized to change the technologies they create to tilt the scales towards more positive outcomes. A paper would need to acknowledge and discuss its potential impact on privacy, security, and discrimination in a rigorous fashion.",
            "Labor Rights": "Under our recommendations, researchers engaged in developing crowd work frameworks should find ways to engineer its framework such that negative externalities (incentivizing very low pay) are structurally mitigated. Alternatively or additionally, they should advocate for minimum wage laws to be adapted to a contingent labor context.",
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "Peer reviewers should require that papers and proposals rigorously consider all reasonable broader impacts, both positive and negative. Reviewers should not only require that potential positive and negative impacts simply be mentioned, but also that they are strongly motivated.",
            "Sustainability": null,
            "Transparency": "One recommendation is that if the research community makes decision-making processes clearer and more transparent, then this will make the expected positive and negative impacts of the research more prominent.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Digital Technology and Healthcare which ethical issues for which regulations?",
        "country": "France",
        "world_region": "Western Europe",
        "institution": "Comité Consultatif National d'Ethique (CCNE)",
        "institution_type": "NGO",
        "year_of_publication": "2018",
        "number_of_male_authors": "12",
        "number_of_female_authors": "11",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Comité Consultatif National d'Ethique (CCNE). CCNE is a French consultative body with the status of an independent administrative authority, whose mission is to give opinions on ethical problems and social issues raised by advances in knowledge in the fields of biology, medicine, and health. In this document, the CCNE presents a report on the current forms of interaction between digital technology and healthcare, also mentioning directions for research on this subject, strengths/weaknesses of our current technological position, and underlying ethical issues. The document proposes ideas for substantive regulation on the spread of digital technology in healthcare in both the legal and operational domains, giving specif attention to the spread of robotization and artificial intelligence.",
        "document_url": "https://www.allistene.fr/files/2019/05/rapportCCNE-CERNA-Version-anglaise.pdf",
        "attachments": "https://www.ccne-ethique.fr/en",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "The implementation of a flexible normative system of regulation at the European level will require a strong initiative on the part of governments to support the joint construction of regulatory tools appropriate to national needs.",
            "Beneficence": "Given the potential scale of the issue in coming years, it would be desirable if a framework specifically designed to cover injury caused by digital objects were developed at least at the European level.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "Concerning the next Bioethics Act, the fundamental principle of a Human Warranty of digital technology in healthcare should be entrenched in law.",
            "Human Formation": "Public and private actors should be further encouraged to adapt the training — both initial training and continuing professional development — of the healthcare workforce to the challenges of digital technology and to support the emergence of new professions associated with the spread of digital technology in the health and medico-social sectors.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "The uptake of digital technology in healthcare can have potentially significant effects on health inequalities, both reducing and, in certain cases, exacerbating them. It is therefore indispensable to monitor the implementation of digital technology in healthcare in order to ensure that its adoption contributes to reducing these inequalities.",
            "Labor Rights": null,
            "Cooperation": "The sharing of research data according to ‘FAIR' (findable, accessible, interoperable, reusable) principles is a crucial factor for the development of world-class scientific research in healthcare and in helping to guarantee the reproducibility and validity of results.",
            "Privacy": "It would therefore be good practice, as far as possible, to have a consent procedure that enables people to authorize the sharing of their data in the knowledge of how they will be shared (sharing plan), rather than why (by whom and for what research). It is also important to acquire the scientific, technical, and regulatory resources to control the risks of people being re-identified from databases in which direct identifying information has been removed and to support the development of ethical tools for the regulation of access to sensitive data.",
            "Reliability": "The ethical issues of digital technology in healthcare are dealt differently at the European or international level, but there is a consensus on the need to take practical measures, which will be as responsive to change as possible, to ensure the reliability of digital applications and control of their use.",
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Business Ethics and Artificial Intelligence",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "Institute for Business Ethics (IBE)",
        "institution_type": [
            "Non-profit Organization",
            "Professional Association"
        ],
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Institute of Business Ethics (IBE), a non-profit professional organization based in London (UK), which encourages high standards of business behavior based on ethical values. This IBE document sets forth a framework of fundamental values and principles for the use of Artificial Intelligence (AI) in business. Its primary goal is to encourage organizations to engage in a multi-stakeholder dialogue that always considers commitment to values in the application and impact of AI developments.",
        "document_url": "https://www.ibe.org.uk/uploads/assets/5f167681-e05f-4fae-ae1bef7699625a0d/ibebriefing58businessethicsandartificialintelligence.pdf",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Companies must ensure that they establish a line of responsibility for actions and who has to answer for the consequences of their AI systems. Companies must take responsibility for the outcome of the decision-making process of their AI systems since machines are not moral agents and cannot be held responsible for their actions.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": "To maximize the potential of AI, people need to learn how it works and what are the most efficient and effective ways to use it. Employees and other stakeholders need to be empowered to take personal responsibility for the consequences of their use of AI and they need to be provided with the skills to do so.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Justice and fairness should be considered paramount when dealing with AI. This includes fairness to the public and the stakeholders. Designers of AI systems must ensure that their algorithms are free from systematic errors and biases.",
            "Labor Rights": "Companies must look at the best approaches to minimize the potential disruption of jobs while innovation and competition are still encouraged. AI companies must be conscious of how AI systems will affect both employees and customers since there is an existing fear that AI will automate many jobs.",
            "Cooperation": "Opening sourcing material in computer science, when appropriate, is an important step. It helps the development community to understand better how AI works and therefore be able to explain it more accurately to the public and the media. This is particularly important as better information within the general public improves trust and prevents unjustified fears. Moreover, the more people have access to the code, the more likely it is that bugs and long-term opportunities and risks can be worked out.",
            "Privacy": "AI designers and companies must ensure that they adhere to ethical guidelines relating to the protection and respect of privacy. They must consult documents that stipulate personal data protection, such as the General Data Protection Regulation (GDPR).",
            "Reliability": "AI designers and companies must ensure that we can rely on AI to perform the task it is created to perform. Designers of AI systems must ensure that their systems produce correct, precise, and reliable results. Designers must ensure that we can rely on AI to perform its designed task.",
            "Sustainability": null,
            "Transparency": "Designers of AI systems must ensure that their systems are transparent by providing an explanation to the public on how AI works and enable that people have access to their codes. By so, the public can understand, trust, and effectively manage intelligent machines. Furthermore, designers of AI must ensure that their models are simple to explain and understand.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Digital Decisions",
        "country": [
            "Belgium",
            "United States of America"
        ],
        "world_region": [
            "Western Europe",
            "North America"
        ],
        "institution": "Center for Democracy & Technology (CDT)",
        "institution_type": "Non-profit Organization",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Center for Democracy & Technology (CDT), a Washington (D.C., US) based nonprofit organization. CDT focuses on topics such as the rights of individual users about technology policy and architecture. In this document, the CDT describes the implications of the use of AI, showing certain instances that could lead to harmful outcomes, also defending a set of core ethical principles to mitigate them. The authors refer to the document as a framework of principles that describe the first step to developing actionable solutions.",
        "document_url": "https://cdt.org/wp-content/uploads/2018/09/Digital-Decisions-Library-Printer-Friendly-as-of-20180927.pdf",
        "attachments": "https://cdt.org/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "In the case of algorithms, we must acknowledge and draw from civil rights traditions to develop an adequate definition of fair. A fair system or design is demonstrably not biased against individuals or groups of people.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "Transparency/Explainability/Auditability: Institutions must ensure that algorithmic decisions, as well as any data driving those decisions, can be explained to end-users and other stakeholders in non-technical terms. Creating a system that can be audited creates accountability and credibility, particularly if the result of an audit can be reviewed externally",
            "Sustainability": null,
            "Transparency": "Reliability/Safety/Security/Trustworthiness: A system must be able to be trusted to behave as is expected and anticipated by its designers. Rather than requiring designers to understand the specific reason for an outcome, reliable systems can be trusted to deliver consistent results.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Big Data, Artificial Intelligence, Machine Learning, and Data Protection",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "Information Commissioner's Office (ICO)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2017",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Information Commissioner's Office (ICO), UK's independent authority set up to uphold information rights in the public interest, promoting openness by public bodies and data privacy for individuals. This document looks at the implications of big data, artificial intelligence (AI), and machine learning for data protection, and explains the ICO's views on these. The document also provides a series of recommendations, together with a practical tool: the Privacy impact assessments (PIA) for big data analytics.",
        "document_url": "https://ico.org.uk/media/for-organisations/documents/2013559/big-data-ai-ml-and-data-protection.pdf",
        "attachments": "https://ico.org.uk/",
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "Organisations should define the benefits of the analytics. They should not incur the risks of big data analytics if the benefits could be achieved by less risky means.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "If an organisation can identify potential benefits from using personal data in big data analytics, it should be able to explain these to users and seek consent, if that is the condition it chooses to rely on. Where possible, the controller should be able to provide remote access to a secure system which would provide the data subject with direct access to his or her personal data.",
            "Human Formation": "Data protection should be part of the higher education curriculum for people going into these roles.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "The data controller should use “appropriate mathematical or statistical procedures for the profiling” and take measures to prevent discrimination based on race or ethnic origin, political opinions, religion or beliefs, trade union membership, genetic or health status or sexual orientation.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "It should also be noted that under the GDPR if a data controller is relying on legitimate interests, it will have to explain what these are in its privacy notice. Data protection legislation embodies the concept of data minimisation – that is, organisations should minimise the amount of data they collect and process, and the length of time they keep the data.",
            "Reliability": "It may not be possible to establish with absolute certainty that an individual cannot be identified from a particular dataset, taken together with other data that may exist elsewhere. Organisations should focus on mitigating the risks to the point where the chance of reidentification is extremely remote. Organisations using anonymised data need to be able to show they have robustly assessed the risk of re-identification, and have adopted solutions proportionate to the risk.",
            "Sustainability": null,
            "Transparency": "Information addressed to the public or the data subject should be concise, easily accessible and easy to understand, and that clear and plain language. Even if it is difficult to explain in simple terms how the analytics works, it should be possible to explain the purposes in a way that does not deceive or mislead. Auditability should be ‘baked in' to algorithms in the development stage to enable third parties to check, monitor, review and critique their behaviour.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Ethical, Social, and Political Challenges of Artificial Intelligence in Health",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "Future Advocacy",
        "institution_type": "NGO",
        "year_of_publication": "2018",
        "number_of_male_authors": "2",
        "number_of_female_authors": "1",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Future Advocacy, a nonpartisan consultancy agency and think tank working at the intersection of advocacy, global affairs, and technology. In this document, Future Advocacy categorizes key areas for the potential use of AI in healthcare, together with several ethical, social, and political challenges.",
        "document_url": "https://wellcome.org/sites/default/files/ai-in-health-ethical-social-political-challenges.pdf",
        "attachments": "https://futureadvocacy.com/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "Research focusing on these ethical, social, and political challenges must be multidisciplinary, drawing on the expertise of those who develop AI tools, those who will use and be impacted by these tools, and those who have knowledge and experience of addressing other major ethical, social and political challenges in health. Most importantly, it is vital that the voices of patients and their relatives are heard, and that their needs - clinical, pastoral, spiritual, and more - are kept in mind at all stages of such research.",
            "Autonomy": "The issue of consent runs through the entirety of this work. This is unsurprising given the crucial importance the concept of consent has in biomedical ethics and its interaction with the central principle of personal autonomy.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": null,
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Model AI Governance Framework",
        "country": "Singapore",
        "world_region": "Southeast Asia",
        "institution": "Personal Data Protection Commission (PDPC)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2020",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Personal Data Protection Commission (PDPC) of the Government of Singapore. The PDPC serves as Singapore's main authority in matters relating to personal data protection, representing the Singapore Government internationally on data protection-related issues. The Model Framework provides detailed and readily-implementable guidance to private sector organizations to address key ethical and governance issues when deploying AI solutions. Its first edition was published in 2019, and a reviewed second edition was made public in 2020. The document provides a practical tool: ISAGO (Implementation and Self Assessment Guide for Organisations). Intended as a companion guide to the Model Framework, ISAGO aims to help organizations assess the alignment of their AI governance practices with the Model Framework. It also provides an extensive list of examples and practices to help organizations implement the Model Framework. Complementing the Model Framework and ISAGO is a Compendium of Use Cases (Compendium Volume I & Volume II) that demonstrates how local and international organizations across different sectors and sizes implemented or aligned their AI governance practices with all sections of the Model Framework. As a final addition, this collection of documents also comes with a guide (A Guide to Job Redesign in the Age of AI) to help organizations and employees understand how existing job roles can be redesigned to harness the potential of AI.",
        "document_url": "https://www.pdpc.gov.sg/-/media/Files/PDPC/PDF-Files/Resource-for-Organisation/AI/SGModelAIGovFramework2.pdf",
        "attachments": [
            "https://www.pdpc.gov.sg/-/media/Files/PDPC/PDF-Files/Resource-for-Organisation/AI/SGIsago.pdf",
            "https://www.pdpc.gov.sg/-/media/Files/PDPC/PDF-Files/Resource-for-Organisation/AI/SGAIGovUseCases.pdf",
            "https://file.go.gov.sg/ai-gov-use-cases-2.pdf",
            "https://file.go.gov.sg/ai-guide-to-jobredesign.pdf"
        ],
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Responsibility for and oversight of the various stages and activities involved in AI deployment should be allocated to the appropriate personnel and/or departments.",
            "Beneficence": "As AI is used to amplify human capabilities, the protection of the interests of human beings, including their well-being and safety, should be the primary considerations in the design, development, and deployment of AI.",
            "Children's Rights": null,
            "Human Rights": "Ensure that the design, development, and implementation of technologies do not infringe internationally recognized human rights.",
            "Diversity": "Ensure that AI is accessible to all.",
            "Autonomy": null,
            "Human Formation": "It is important to create and raise awareness of the latest AI technologies and start educating employees on the opportunities and benefits, should their job roles be enhanced.",
            "Human-Centeredness": "AI solutions should be human-centric.",
            "Intellectual Property": null,
            "Fairness": "There are many types of bias relevant to AI. The Model Framework focuses on inherent bias in datasets, which may lead to undesired outcomes such as unintended discriminatory decisions. Organizations should be aware that the data which they provide to AI systems could contain inherent biases and are encouraged to take steps to mitigate such bias.",
            "Labor Rights": "This Guide suggests that organizations can consider adopting a practical and humancentric approach in redesigning jobs when implementing AI so as to augment their employees' cognitive capacity. Although there are certain tasks that could be fully automated by AI, it is important to avoid deskilling humans and recognize the value of retaining human experience.",
            "Cooperation": null,
            "Privacy": "Adopting this voluntary Model Framework will not absolve organizations from compliance with current laws and regulations. However, as this is an accountability-based framework, adopting it will assist organizations in demonstrating that they had implemented accountability-based practices in data management and protection, e.g., the PDPA and OECD Privacy Principles.",
            "Reliability": "Organisations can consider implementing a sound system of risk management and internal controls that specifically addresses the risks involved in the deployment of the selected AI model.",
            "Sustainability": "Favour implementations that effectively predict future behavior and generate beneficial insights over a reasonable period.",
            "Transparency": "Organizations using AI in decision-making should ensure that the decision-making process is explainable, transparent, and fair. Explainability is achieved by explaining how deployed AI models' algorithms function and/or how the decision-making process incorporates model predictions.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Artificial Intelligence Ethics and Safety: practical tools for creating \"good\" models",
        "country": "Brazil",
        "world_region": "Latin America",
        "institution": "AI Robotics Ethics Society at PUCRS (AIRES at PUCRS)",
        "institution_type": [
            "Academic",
            "Non-profit Organization"
        ],
        "year_of_publication": "2021",
        "number_of_male_authors": "1",
        "number_of_female_authors": "0",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the AI Robotics Ethics Society (AIRES) Chapter at the Pontifical Catholic University of Rio Grande do Sul (PUCRS). AIRES is a non-profit/academic organization founded in 2018 at UCLA (USA, Los Angeles) by Aaron Hui. Its mission is to focus on educating tomorrow's AI leaders in ethical AI principles to ensure AI is created ethically and responsibly. The author of the document proposes that \"as there are still few proposals for how we should implement ethical principles and normative guidelines in the practice of AI system development, the goal of this work is to try to bridge this gap between discourse and praxis.\" In this document, the reader can find an introduction to the topic of AI Ethics and Safety, together with several tools to help developers of AI systems to develop \"good\" models.",
        "document_url": "https://arxiv.org/abs/2112.11208",
        "attachments": "https://www.airespucrs.org/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "This is one of the roles of the AI safety engineer. Not only to evaluate the possible biases and problems that may arise during the training of a model and after its implementation in a given context but to seek to mitigate new problems that may arise. For this, we need quantitative methods to evaluate, stress, and attack our models.",
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Data, Responsibly (Vol. 1) Mirror, Mirror",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Data, Responsibly",
        "institution_type": "Academic",
        "year_of_publication": "2020",
        "number_of_male_authors": "0",
        "number_of_female_authors": "2",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Falaah Arif Khan and Julia Stoyanovich, the authors of the \"Data, Responsibly\" Comics. \"Data, Responsibly\" is a comic series about Responsible AI. In this document (series), the authors seek to spread the debate on AI Ethics to a broader audience. In it, the reader can find an entertaining take on the subject, being an excellent tool for disseminating information among younger audiences.",
        "document_url": "https://dataresponsibly.github.io/comics/",
        "attachments": "https://dataresponsibly.github.io/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "We need to agree on how to go about regulating technology, and so we must start educating ourselves and partake in this lofty enterprise in good faith.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "In our reality, digital accessibility is focused on making sure web platforms are easily navigable and usable for people with any kind of disability. Accessibility needs to be a fundamental design principle for building websites and software. We should focus on harnessing the power of Learning Technologies to positively impact people. And not one, affluent, highly influential demographic of persons, but truly all persons, of all social strata, classes, genders, and races.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": "Maybe what we need instead is to ground the design of AI systems in people. Using the data of the people, collected and deployed with an equitable methodology as determined by the people, to create technology that is beneficial for the people.",
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": null,
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Asilomar AI Principles",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Future of Life Institute",
        "institution_type": "Non-profit Organization",
        "year_of_publication": "2017",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Future of Life Institute (FLI), an independent nonprofit that works to reduce extreme, large-scale risks from transformative technologies, as well as steer the development and use of these technologies to benefit life (the Institute has primarily focused on risks related to Artificial General Intelligence). In this document, the FLI provides a set of AI principles to help steer the development of AI into beneficial future outcomes for humanity.",
        "document_url": "https://futureoflife.org/2017/08/11/ai-principles/",
        "attachments": "https://futureoflife.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Designers and builders of advanced AI systems are stakeholders in the moral implications of their use, misuse, and actions, with a responsibility and opportunity to shape those implications.",
            "Beneficence": "The goal of AI research should be to create not undirected intelligence, but beneficial intelligence. An arms race in lethal autonomous weapons should be avoided. Superintelligence should only be developed in the service of widely shared ethical ideals, and for the benefit of all humanity rather than one state or organization.",
            "Children's Rights": null,
            "Human Rights": "AI systems should be designed and operated to be compatible with ideals of human dignity, rights, freedoms, and cultural diversity.",
            "Diversity": "AI systems should be designed and operated to be compatible with ideals of human dignity, rights, freedoms, and cultural diversity.",
            "Autonomy": "The application of AI to personal data must not unreasonably curtail people's real or perceived liberty. Humans should choose how and whether to delegate decisions to AI systems, to accomplish human-chosen objectives. The power conferred by control of highly advanced AI systems should respect and improve, rather than subvert, the social and civic processes on which the health of society depends.",
            "Human Formation": null,
            "Human-Centeredness": "Highly autonomous AI systems should be designed so that their goals and behaviors can be assured to align with human values throughout their operation.",
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": "A culture of cooperation, trust, and transparency should be fostered among researchers and developers of AI. Teams developing AI systems should actively cooperate to avoid corner-cutting on safety standards. AI technologies should benefit and empower as many people as possible. The economic prosperity created by AI should be shared broadly, to benefit all of humanity.",
            "Privacy": "People should have the right to access, manage and control the data they generate, given AI systems' power to analyze and utilize that data.",
            "Reliability": "AI systems should be safe and secure throughout their operational lifetime, and verifiably so where applicable and feasible. Risks posed by AI systems, especially catastrophic or existential risks, must be subject to planning and mitigation efforts commensurate with their expected impact.",
            "Sustainability": null,
            "Transparency": "If an AI system causes harm, it should be possible to ascertain why. Any involvement by an autonomous system in judicial decision-making should provide a satisfactory explanation auditable by a competent human authority.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Unfairness by Algorithm: Distilling the Harms of Automated Decision-making",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Future of Privacy Forum (FPF)",
        "institution_type": "NGO",
        "year_of_publication": "2017",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Practical",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Future of Privacy Forum (FPF),  a Washington DC-based (US) think tank and advocacy group focused on issues of data privacy. In this document, FPF identifies, articulates, and categorizes the types of harm that may result from automated decision-making. These harms, together with potential mitigation strategies identified in the literature, are distilled into two charts. Both charts are practical tools for identifying and mitigating the harms generated by automated decision-making systems.",
        "document_url": "https://fpf.org/wp-content/uploads/2017/12/FPF-Automated-Decision-Making-Harms-and-Mitigation-Charts.pdf",
        "attachments": "https://fpf.org/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Recent discussions have highlighted legal and ethical issues raised by the use of sensitive data for hiring, policing, benefits determinations, marketing, and other purposes. These conversations can become mired in definitional challenges that make progress towards solutions difficult. There are few easy ways to navigate these issues, but if stakeholders hold frank discussions, we can do more to promote fairness, encourage responsible data use, and combat discrimination.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": null,
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Code of Ethics",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "IEEE Computer Society",
        "institution_type": "Professional Association",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "20",
        "number_of_female_authors": "4",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the IEEE Computer Society, a professional society of the Institute of Electrical and Electronics Engineers (IEEE), headquartered in Washington DC (US). In this document, the IEEE Computer Society lays ethical foundations for software engineers in the form of a voluntary self-commitment. The document contains several principles related to the behavior of and decisions made by professional software engineers, including practitioners, educators, managers, supervisors, policymakers, as well as trainees and students of the profession. Every principle is tied to a series of obligations. The IEEE Computer Society prescribes these obligations to anyone claiming to be or aspiring to be a software engineer.",
        "document_url": "https://www.computer.org/education/code-of-ethics",
        "attachments": "https://www.computer.org/",
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "Software engineering managers and leaders shall subscribe to and promote an ethical approach to the management of software development and maintenance. Software engineers shall act consistently with the public interest. Software engineers shall act in a manner that is in the best interests of their client and employer consistent with the public interest.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": "Software engineers shall participate in lifelong learning regarding the practice of their profession and shall promote an ethical approach to the practice of the profession.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": "Software engineers shall be fair to and supportive of their colleagues.",
            "Privacy": null,
            "Reliability": "Software engineers shall ensure that their products and related modifications meet the highest professional standards possible.",
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "G20 Ministerial Statement on Trade and Digital Economy",
        "country": "G20",
        "world_region": "Intergovernmental Organization",
        "institution": "Group of Twenty (G20)",
        "institution_type": "International Organization",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Group of Twenty (G20), an intergovernmental forum comprising 19 countries and the European Union (EU). It works to address major issues related to the global economy, such as international financial stability, climate change mitigation, and sustainable development. In this document, the G20 Ministerial Meeting on Trade and Digital Economy discussed how they can work together toward the realization of a sustainable and innovative global society, by making full use of digital technologies (e.g., AI, IoT, Blockchain). They also lay the G20 AI Principles for responsible stewardship of Trustworthy AI.",
        "document_url": "https://www.mofa.go.jp/files/000486596.pdf",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "AI actors should be accountable for the proper functioning of AI systems and the respect of the above principles, based on their roles, the context, and consistent with the state of art.",
            "Beneficence": "Stakeholders should proactively engage in responsible stewardship of trustworthy AI in pursuit of beneficial outcomes for people and the planet.",
            "Children's Rights": null,
            "Human Rights": "AI actors should respect human rights.",
            "Diversity": "Stakeholders should proactively engage in responsible stewardship of trustworthy AI in pursuit of beneficial outcomes for people and the planet, such as advancing the inclusion of underrepresented populations.",
            "Autonomy": "AI actors should respect democratic values. AI actors should implement mechanisms and safeguards, such as the capacity for human determination.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Stakeholders should proactively engage in responsible stewardship of trustworthy AI in pursuit of beneficial outcomes for people and the planet, such as reducing economic, social, gender, and other inequalities.",
            "Labor Rights": "AI actors should respect internationally recognized labor rights.",
            "Cooperation": null,
            "Privacy": "AI actors should respect privacy and data protection.",
            "Reliability": "AI systems should be robust, secure, and safe throughout their entire lifecycle.",
            "Sustainability": "Stakeholders should proactively engage in responsible stewardship of trustworthy AI in pursuit of beneficial outcomes for people and the planet, such as protecting natural environments.",
            "Transparency": "AI Actors should commit to transparency and responsible disclosure regarding AI systems. To this end, they should provide meaningful information, appropriate to the context, and consistent with the state of art.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Philips AI Principles",
        "country": "Netherlands",
        "world_region": "Western Europe",
        "institution": "Philips (Koninklijke Philips N.V. )",
        "institution_type": "Private Corporation",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Philips (Koninklijke Philips N.V. ), a Dutch multinational conglomerate corporation that was founded in Eindhoven in 1891. This document presents the AI principles upheld by Philips. Philips AI Principles can be understood as Philips's self-commitment to the ethical and beneficial use of AI technologies.",
        "document_url": "https://www.philips.com/a-w/about/artificial-intelligence/philips-ai-principles.html",
        "attachments": null,
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "We design our solutions to benefit the health and well-being of individuals and to contribute to the sustainable development of society.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "We design AI-enabled solutions to augment and empower people, with appropriate human supervision.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "We develop and validate solutions using data that is representative of the target group for the intended use, and we aim to avoid bias or discrimination.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "We develop AI-enabled solutions that are intended to do no harm, with the appropriate protection against deliberate or inadvertent misuse.",
            "Sustainability": null,
            "Transparency": "We disclose which functions and features of our offerings are AI-enabled, the validation process, and the responsibility for ultimate decision-making.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Philips Data Principles",
        "country": "Netherlands",
        "world_region": "Western Europe",
        "institution": "Philips (Koninklijke Philips N.V. )",
        "institution_type": "Private Corporation",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Philips (Koninklijke Philips N.V. ), a Dutch multinational conglomerate corporation that was founded in Eindhoven in 1891. This document presents the Philips Data Principles,  i.e., Philips foundations for the beneficial use of data, protection of privacy, and security. Philips Data Principle can be understood as Philips's self-commitment to the ethical and beneficial use of collected data.",
        "document_url": "https://www.philips.com/a-w/about/philips-data-principles.html",
        "attachments": null,
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "We aim to create innovative solutions that benefit our customers, patients, and society as a whole. We use your personal data in line with your reasonable expectations.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "We handle all personal data with integrity in compliance with all applicable privacy regulations of the countries in which we operate. We adhere to the Philips Code of Conduct – our binding corporate rules – that govern data transfers and processing within our company. When our business partners process personal data on our behalf, we ensure that they comply with our security and privacy requirements.",
            "Reliability": "We ensure the security of all data entrusted to us. We operate under global security policies that guide our activities to protect against vulnerabilities and manage any incidents.",
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "AI 4People 's Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations",
        "country": "European Union",
        "world_region": "European Union",
        "institution": "AI4People",
        "institution_type": "NGO",
        "year_of_publication": "2018",
        "number_of_male_authors": "7",
        "number_of_female_authors": "6",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by AI4People, a multi-stakeholder forum that seeks to bring together actors interested in shaping the social impact of new applications of AI. The document presents core opportunities and risks of AI for society, together with ethical principles that should undergird its development and adoption. The document also offers a series of recommendations to assess, develop, incentivize, and support good AI.",
        "document_url": "https://www.eismd.eu/wp-content/uploads/2019/02/Ethical-Framework-for-a-Good-AI-Society.pdf",
        "attachments": "https://www.eismd.eu/ai4people/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Those developing AI should assume responsibility for their creations. Stakeholders should develop appropriate legal procedures and improve the IT infrastructure of the justice system to permit the scrutiny of algorithmic decisions in court.",
            "Beneficence": "The development of AI should ultimately promote the well-being of all sentient creatures. AI should be developed for the common good and the benefit of humanity. Stakeholders should assess the capacity of existing institutions, such as national civil courts, to redress the mistakes made or harms inflicted by AI systems.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "autonomous systems must not impair [the] freedom of human beings to set their own standards and norms and be able to live according to them. Humans should choose how and whether to delegate decisions to AI systems, to accomplish human-chosen objectives.",
            "Human Formation": "Stakeholders should support the creation of educational curricula and public awareness activities around the societal, legal, and ethical impact of Artificial Intelligence.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "The development of AI should promote justice and seek to eliminate all types of discrimination. Stakeholders should develop auditing mechanisms for AI systems to identify unwanted consequences, such as unfair bias, and (for instance, in cooperation with the insurance sector) a solidarity mechanism to deal with severe risks in AIintensive sectors.",
            "Labor Rights": "Stakeholders should develop legal instruments and contractual templates to lay the foundation for a smooth and rewarding human-machine collaboration in the work environment.",
            "Cooperation": "AI developers should respect the interests of all parties that may be impacted by AI advances. Stakeholders should incentivize financially cross-disciplinary and cross-sectoral cooperation and debate concerning the intersections between technology, social issues, legal studies, and ethics.",
            "Privacy": "AI technology must be in line with ensuring the prevention of infringements on personal privacy",
            "Reliability": "Those developing AI should assume their responsibility by working against the risks arising from their technological innovations.",
            "Sustainability": "AI technology must be in line with ensuring the basic preconditions for life on our planet, continued prospering for mankind, and the preservation of a good environment for future generations. Stakeholders should incentivize financially, at the EU level, the development and use of AI technologies within the EU that are socially preferable (not merely acceptable) and environmentally friendly (not merely sustainable but favorable to the environment).",
            "Transparency": "AI systems should be understandable and interpretable. Stakeholders should develop a framework to enhance the explicability of AI systems that make socially significant decisions",
            "Truthfulness": null
        }
    },
    {
        "document_name": "AI & Data Topical Guide Series",
        "country": "South Africa",
        "world_region": "Southern Africa",
        "institution": "Policy Action Network (PAN)",
        "institution_type": "NGO",
        "year_of_publication": "2020",
        "number_of_male_authors": "9",
        "number_of_female_authors": "5",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This series of documents were written by the Policy Action Network (PAN), an initiative of the Human Sciences Research Council (HSRC), supported by the Department of Science and Innovation. The Human Sciences Research Council (HSRC) of South Africa is Africa's largest dedicated social science and humanities research agency and policy think tank. These documents seek to provide key research insights and policy considerations for policy-makers, and other interested stakeholders, on how these technologies can be developed, used, and safeguarded in a manner that aligns with the transformation objectives of South Africa.",
        "document_url": "https://policyaction.org.za/ai-data-topical-guide-series",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "In developing South Africa's national strategy on AI, specific attention should be paid to developing strong accountability mechanisms for the use of AI in line with the principles of governance set out in the Constitution and, for businesses, under the King Codes.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "Universities and research institutions should seek to develop engagement processes that enroll diverse participants and perspectives as part of AI and data research projects, and carefully consider how industry partnerships may lead to conflicting commercial and ethical interests. The private sector, government, and academic organizations can increase public engagement with and awareness of data-driven technologies and AI, particularly insofar as it can affect and shape the lives of individuals and communities.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "In developing South Africa's national strategy on AI, specific attention should be paid to the ways in which, and literature around how AI and data use can reinforce discriminatory social categories and produce unfair biases that have a material effect on how people chose to live their lives.",
            "Labor Rights": null,
            "Cooperation": "In developing South Africa's national strategy on AI, specific attention should be paid to how data and AI can be used to address South Africa's socio-economic inequalities, and economically empower disadvantaged individuals and communities, which includes taking proactive measures against the economic monopolization of data-driven technologies and enabling infrastructure, through consultation with the Competition Commission.",
            "Privacy": "Rapidly seek to bring into effect the Protection of Personal Information Act and equip the Information Regulator with all necessary resources to provide effective oversight over the processing of personal data in South Africa.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "In developing South Africa's national strategy on AI, specific attention should be paid to developing strong transparency mechanisms for the use of AI in line with the principles of governance set out in the Constitution and, for businesses, under the King Codes.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Rome Call for AI Ethics",
        "country": "Vatican City State",
        "world_region": "Southern Europe",
        "institution": "Pontifical Academy for Life",
        "institution_type": "Religious Institution",
        "year_of_publication": "2020",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Pontifical Academy for Life. The Pontifical Academy for Life is a Pontifical Academy of the Roman Catholic Church dedicated to promoting the Church's consistent life ethic, doing research related to bioethics and Catholic moral theology. This document was signed by private companies (e.g., Microsoft, IBM, FAO), and the Ministry of Innovation (i.e., a part of the Italian Government). The document seeks to promote a sense of shared responsibility among international organizations, governments, institutions, and the private sector to create a future in which digital innovation and technological progress grant mankind its centrality, focusing on three specific areas of impact: ethics, education, and rights.",
        "document_url": "https://www.romecall.org/the-call/#",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Those who design and deploy the use of AI must proceed with responsibility and transparency.  There must always be someone who takes responsibility for what a machine does.",
            "Beneficence": "The development of AI in the service of humankind and the planet must be reflected in regulations and principles that protect people – particularly the weak and the underprivileged – and natural environments.",
            "Children's Rights": null,
            "Human Rights": "Human Formation/Education: Transforming the world through the innovation of AI means undertaking to build a future for and with younger generations.",
            "Diversity": "Dignity/Human Rights: All human beings are born free and equal in dignity and rights. This fundamental condition of freedom and dignity must also be protected and guaranteed when producing and using AI systems.",
            "Autonomy": "Diversity/Inclusion/Pluralism/Accessibility: The needs of all human beings must be taken into consideration so that everyone can benefit and all individuals can be offered the best possible conditions to express themselves and develop. These systems must not discriminate against anyone because every human being has equal dignity.",
            "Human Formation": "Freedom/Autonomy/Democratic Values/Technological Sovereignty: All human beings are born free and equal in dignity and rights. This fundamental condition of freedom and dignity must also be protected and guaranteed when producing and using AI systems.",
            "Human-Centeredness": "We must guarantee an outlook in which AI is developed with a focus not on technology, but rather for the good of humanity and of the environment, of our common and shared home, and of its human inhabitants, who are inextricably connected.",
            "Intellectual Property": null,
            "Fairness": "Do not create or act according to bias, thus safeguarding fairness and human dignity. AI systems must not follow or create biases.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "AI systems must work securely and respect the privacy of users.",
            "Reliability": "AI systems must be able to work reliably.",
            "Sustainability": "For technological advancement to align with true progress for the human race and respect for the planet it must be mindful of the complex reality of our ecosystem and be characterized by how it cares for and protects the planet (our “common and shared home”) with a highly sustainable approach.",
            "Transparency": "AI systems must be understandable to all.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "A practical guide to Responsible Artificial Intelligence (AI)",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "PricewaterhouseCoopers (PwC)",
        "institution_type": "Private Corporation",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by PricewaterhouseCoopers (PwC), a multinational professional services network of firms, operating as partnerships under the PwC brand, headquartered in London (UK). The document seeks to ground the ethical discourse that revolves around AI Ethics in a practical approach that can be incorporated by organizations developing AI-based products. In it, PwC presents the Responsible AI Framework and Toolkit, a practical tool to help companies focus on and address five key dimensions when designing and deploying responsible AI applications: governance, ethics & regulation, interpretability & explainability, robustness & security, bias & fairness. Their tool also provides a clear, step-by-step, governance framework to help developers and business owners better incorporate responsible AI development into their organizations.",
        "document_url": "https://www.pwc.com/gx/en/issues/data-and-analytics/artificial-intelligence/what-is-responsible-ai/responsible-ai-practical-guide.pdf",
        "attachments": "https://www.pwc.com/gx/en/issues/data-and-analytics/artificial-intelligence/what-is-responsible-ai.html",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Organizations should strive to develop, implement, and use AI solutions that are both morally responsible and also legal and ethically defensible. Organizations also must monitor the regulatory environment in which they operate and understand how emerging regulations will shape future business practices.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Bias is often identified as one of the biggest risks associated with AI. However, it is possible to tune AI systems to mitigate bias and enable decisions that are as fair as possible and adhere to an organization's corporate code of ethics, as well as follow anti-discrimination regulations.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "To be effective and reliable, AI systems need to be resilient, secure, and safe. Above all, though, AI systems must be safe for the people whose lives they affect, whether they are users of AI or the subjects of AI-enabled decisions.",
            "Sustainability": null,
            "Transparency": "To instill trust in AI systems, people must be enabled to look “under the hood” at their underlying models, explore the data used to train them, expose the reasoning behind each decision, and provide coherent explanations to all stakeholders promptly. These explanations should be tailored to the different stakeholders, including regulators, data scientists, business sponsors, and end consumers.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Ethical Guidelines of the German Informatics Society",
        "country": "Germany",
        "world_region": "Western Europe",
        "institution": "German Informatics Society (GI)",
        "institution_type": [
            "Non-profit Organization",
            "Professional Association"
        ],
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the German Informatics Society (GI), a professional society, and registered non-profit organization, for computer science, with around 20,000 personnel and 250 corporate members. The document presents the Ethical Guidelines of GI, which can be understood as their voluntary self-commitment to ethical practice and standards. The guidelines are designed to offer a point of orientation not only to members of the GI association but to all persons involved in the design, manufacture, operation, or use of IT systems.",
        "document_url": "https://gi.de/ethicalguidelines",
        "attachments": "https://gi.de/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "GI members are familiar with and observant of pertinent legal regulations concerning the design, manufacture, operation, and use of IT systems. GI members, in conjunction with their expertise and professional competencies, participate actively in drafting legislative regulations.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "To assess the consequences of IT systems in the application environment and to propose suitable solutions, there must be a willingness to understand and take into account the rights, needs, and interests of those parties who are impacted by them. GI members staunchly advocate for the protection and safeguarding of human dignity, even when this is not explicitly mandated by laws, contracts or other norms, or when these stand in direct opposition to the protection and safeguarding of human dignity.",
            "Diversity": null,
            "Autonomy": "GI members work toward ensuring that those people impacted by the usage and conditions of use of IT systems are granted adequate opportunity to participate in the design of these systems. This is especially pertinent with regard to systems whose application involves the exerting influence over, monitoring, or surveillance of said populations.",
            "Human Formation": "GI members stay abreast of the current state of science and technology in their respective areas of specialization; they take new developments into account and provide constructive criticism. GI members are constantly working to improve their professional competencies. GI members who are computer science instructors foster in their students the capacity for critical thinking; they prepare learners to accept their own individual and collective responsibility, and they act as role models in this regard.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "GI members advocate for organizational structures which foster and facilitate socially equitable contractual agreements concerning terms of employment.",
            "Labor Rights": "GI members are active proponents of socially equitable contractual agreements concerning terms of employment, inclusive of opportunities for professional development and shared governance.",
            "Cooperation": null,
            "Privacy": null,
            "Reliability": null,
            "Sustainability": "In the design, manufacture, operation and use of IT systems, GI members should contribute to the betterment of local and global living conditions. GI members are responsible for the social and societal consequences of their work. Their influence on positioning, marketing and further development of IT systems should contribute to the socially acceptable and sustainable application of these technologies.",
            "Transparency": "GI members who conduct research in the field of computer science adhere to the rules of best practices in scientific research. Of particular importance in this regard is openness and transparency in dealing with criticism and conflicts of interest, the ability to express and to accept criticism as well as the willingness to allow the impact of one's own scientific work in the research process to become the subject of discussion. Scientific research breaches boundaries. These must be clearly articulated.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems, Version 2",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Institute of Electrical and Electronics Engineers Standards Association (IEEE SA)",
        "institution_type": "Professional Association",
        "year_of_publication": "2017",
        "number_of_male_authors": "17",
        "number_of_female_authors": "14",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the  Institute of Electrical and Electronics Engineers Standards Association (IEEE SA), an operating unit within IEEE (a professional association for electronic engineering and electrical engineering) that develops global standards in a broad range of industries, including power and energy, artificial intelligence systems, internet of things, robotics, telecommunication nanotechnology, and many more. This document has been created by committees of the IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems (A/IS), composed of several hundred participants from six continents, who are thought leaders from academia, industry, civil society, policy, and government in the related technical and humanistic disciplines to identify and find consensus on timely issues. The document's purpose is to advance a public discussion about how we can establish ethical and social implementations for intelligent and autonomous systems and technologies, aligning them to defined values and ethical principles that prioritize human well-being in a given cultural context. The document also presents some practical tools (and how to use them) to be applied in the ethical design of A/IS (e.g., Maslow's Hierarchy of Needs for well-being impact assessment).",
        "document_url": "https://standards.ieee.org/wp-content/uploads/import/documents/other/ead_v2.pdf",
        "attachments": "https://standards.ieee.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": true,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": true,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Legislatures/courts should clarify issues of responsibility, culpability, liability, and accountability for A/IS where possible during development and deployment (so that manufacturers and users understand their rights and obligations).",
            "Beneficence": "A/IS should prioritize human well-being as an outcome in all system designs, using the best available, and widely accepted, well-being metrics as their reference point.",
            "Children's Rights": "Additional protections must be put in place for vulnerable populations, such as children, when informed consent cannot be obtained, or when it may not be a sufficient safeguard.",
            "Human Rights": "A/IS should be designed and operated in a way that both respects and fulfills human rights, freedoms, human dignity, and cultural diversity.",
            "Diversity": "Designers and developers of A/IS should remain aware of, and take into account when relevant, the diversity of existing cultural norms among the groups of users of these A/IS.",
            "Autonomy": "For the foreseeable future, A/IS should not be granted rights and privileges equal to human rights: A/IS should always be subordinate to human judgment and control.",
            "Human Formation": "Ethics and ethical reflection need to be a core subject for aspiring engineers and technologists beginning at the earliest appropriate level and for all advanced degrees. Empowering the education sector with advanced courses on A/IS is the first step toward creating a nation that can handle the new economic and power shifts.",
            "Human-Centeredness": "We need to establish societal and policy guidelines for such systems to remain human-centric, serving humanity's values and ethical principles.",
            "Intellectual Property": "It is understood that specifics relating to algorithms or systems contain intellectual property that cannot be released to the general public. Nonetheless, standards providing oversight of the manufacturing process of intelligent and autonomous technologies need to be created to avoid harm and negative consequences of the use of these technologies.  It is understood that specifics relating to algorithms or systems contain intellectual property that cannot be released to the general public. Nonetheless, standards providing oversight of the manufacturing process of intelligent and autonomous technologies need to be created to avoid harm and negative consequences of the use of these technologies.",
            "Fairness": "Evaluation of A/IS must carefully assess potential biases in the system's performance that disadvantage specific social groups. The evaluation process should integrate members of potentially disadvantaged groups to diagnose and correct such biases.",
            "Labor Rights": "Make sure workers can improve their adaptability to fast technological changes by providing them with adequate training programs. Those training programs could be available to any worker with special attention to low-skilled workforce members. Those programs can be private (sponsored by the employer) or public (offered freely through specific public channels and policies), and they should be open while the worker is in-between jobs or still employed.",
            "Cooperation": "Funding models and institutional incentive structures should be reviewed and revised to prioritize projects with interdisciplinary ethics components to encourage the integration of ethics into projects at all levels. Encourage global standardization/ harmonization and open source software for A/IS.",
            "Privacy": "The ethics of creating secret and proprietary A/IS from people's personally identifiable information (PII) need to be considered based on the potential impact on the human condition. To preserve human dignity, policies, protections, and practices must provide all individuals the same agency and control over their digital personas and identity they exercise in their real-world iterations no matter what A/IS may be in place to monitor, assist, or interact with their data.",
            "Reliability": "A/IS must be verifiably safe and secure throughout their operational lifetime. Because designers cannot anticipate all possible operating conditions and potential failures of A/IS, multiple additional strategies to mitigate the chance and magnitude of harm must be in place. Teams working on developing AGI systems should be aware that much technical robustness and safety issues are even present in today's systems and that, given more research, some corrective techniques for those can likely scale with more complex problem manifestations.",
            "Sustainability": "We are motivated by a desire to create ethical principles for A/IS that prioritize benefits to humanity and the natural environment from the use of A/IS. Note that these should not be at odds — one depends on the other. Prioritizing human well-being does not mean degrading the environment.",
            "Transparency": "To maximize effective evaluation by third parties (e.g., regulators, accident investigators), A/IS should be designed, specified, and documented to permit the use of strong verification and validation techniques for assessing the system's safety and norm compliance, to possibly achieve accountability to the relevant communities.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Privacy and Freedom of Expression In the Age of Artificial Intelligence",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "Privacy International, Article 19",
        "institution_type": [
            "NGO",
            "Non-profit Organization"
        ],
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Large (>10.000 Words, <20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was jointly written by two UK-based, non-profit, non-governmental organizations: Article 19 and Privacy International. Article 19 is a global human rights organization, which works around the world to protect and promote the right to freedom of expression and information, and Privacy International is an organization dedicated to defending the right to privacy around the world. This paper particularly addresses the problems related to AI and the impact it will have on the right to privacy, and the right to freedom of expression and information. In this document, the reader can find key technical definitions in which AI impacts the right to freedom of expression and the right to privacy, a review of the current landscape of AI governance, and several proposed suggestions for rights-based solutions which can be pursued by civil society organizations and other stakeholders in AI advocacy.",
        "document_url": "https://www.article19.org/wp-content/uploads/2018/04/Privacy-and-Freedom-of-Expression-In-the-Age-of-Artificial-Intelligence-1.pdf",
        "attachments": [
            "https://privacyinternational.org/",
            "https://artigo19.org/"
        ],
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Different types of AI and different domains of application raise specific ethical and regulatory human rights issues. To ensure that they protect individuals from the risks posed by AI, existing laws must be reviewed, and if necessary amended, to address the effects of new and emerging threats to privacy and freedom of expression.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "The development, use, research, and development of AI must be subject to the minimum requirement of respecting, promoting, and protecting international human rights standards.",
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": "It is important to emphasize the need to develop knowledge-exchange programs and facilitate joint-strategy development between civil society organizations. So far, academia and industry have taken the lead in moving the debate on the societal impact of AI forward. While civil society actors play a crucial role in these debates, it is important to strengthen the voice of those working on technology in the public interest.",
            "Privacy": "The right to freedom of expression and the right to privacy are mutually reinforcing – all the more so in the digital age. Privacy is a prerequisite to the exercise of freedom of expression: without it, individuals lack the space to think, speak and develop their voice. Without freedom of expression, individuals would be unable to develop their sense of self.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "Corporate, technical, and state actors must allow for meaningful multi-stakeholder participation, including civil society actors, in setting technical standards, regulation, and industry guidelines for AI systems, technology policy, and industry standards to ensure transparent processes and legitimacy of outcomes. In particular, non-binding frameworks must be accompanied by strong accountability and oversight measures.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Užupis Principles for Trustworthy AI Design",
        "country": "Lithuania",
        "world_region": "Eastern Europe",
        "institution": "Republic of Užupis",
        "institution_type": "NGO",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Republic Of Užupis, a collective work of the local community as a cultural, artistic, civic, and social movement, located in Užupis, a district of Vilnius, the capital of Lithuania. The Užupis Principles for Trustworthy AI Design serves as a complementary to the European Union's recommendations on trustworthy AI. According to the authors, these are the first principles, which rely on trust in the people designing AI, support an ongoing process of readjusting the AI, and foster adoption to diverse and dynamic conceptions of ethics. The principles defend by the document come in a form of a voluntary self-commitment to help \"find the right way for you and all the living beings affected by your wonderful work on AI.\"",
        "document_url": "http://uzhupisembassy.eu/wp-content/uploads/2019/07/Uzupis-Principles-for-Trustworthy-AI.pdf",
        "attachments": "https://www.uzupiorespublika.com/en/home/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "I promise to make everybody happy again if my AI made somebody sad for any reason.",
            "Beneficence": "I trust myself that I will use AI to strive for the common good whenever possible.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "I promise to discuss my opinion about what is common good with the various groups affected by my AI.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "I promise to do my best to identify anybody and anything affected by my AI and that I will research and anticipate its impact, its uses, and its possible misuses. I promise to continuously monitor the impact of my AI and regularly seek feedback from the various groups affected by it. I promise to revise or even discard my AI if I discover that it did or could cause harm to anybody or anything.",
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "The Ethics of Code: Developing AI for Business with Five Core Principles",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "Sage Group plc",
        "institution_type": "Private Corporation",
        "year_of_publication": "2017",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Sage Group plc (Sage), a British multinational enterprise software company based in England (UK). In this document, Sage states that its mission is to use AI to \"make admin invisible by 2020, so our customers can spend more time doing what they love.\" To promote the responsible and ethical use of AI in business, Sage advocates for a series of guiding principles when it comes to developing AI for business users. The document can be understood as Sage's voluntary self-commitment to the development of responsible and ethical AI for the business sector.",
        "document_url": "https://www.sage.com/~/media/group/files/business-builders/business-builders-ethics-of-code.pdf?la=en",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "AI must be held to account—and so must users. AI needs to be held accountable for its actions and decisions, just like humans. Technology should not be allowed to become too clever to be accountable.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "AI should level the playing field. AI should reflect the diversity of the users it serves. We need to create innately diverse AI.",
            "Autonomy": "AI will replace, but it must also create. The best use case for AI is automation, being very good at repetitive, mundane tasks, and in the long term, is cheaper than humans. There will be new opportunities created by the automation of tasks, and we need to train humans for these prospects—allowing people to focus on what they are good at, building relationships, and caring for customers. Never forgetting the need for human empathy in core professions like law enforcement, nursing, caring, and complex decision-making.",
            "Human Formation": null,
            "Human-Centeredness": "Any AI system learning from bad examples could end up becoming socially inappropriate—we have to remember that most AI today has no cognition of what it is saying/doing. Reinforcement learning measures should be built not just based on what AI or robots do to achieve an outcome, but also on how AI and robots align with human values to accomplish that particular result.",
            "Intellectual Property": null,
            "Fairness": "As an industry and tech community, we must develop effective mechanisms to filter our bias as well as any negative sentiment in the data that AI learns from and ensure AI does not perpetuate stereotypes. Unless we build AI using diverse teams, data sets, and design, we are at risk of repeating the inequality of previous revolutions.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": null,
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Hippocratic Oath for Data Scientists",
        "country": "France",
        "world_region": "Western Europe",
        "institution": "Data For Good France",
        "institution_type": "Non-profit Organization",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Data For Good, a law association (100% voluntary and non-profit) created in 2014 which brings together a community of 2500+ tech volunteers (Data, Dev, Designers) wishing to put their skills to good use for associations and NGOs and engage in the general interest. The Data for Good community brings together those who want to shape concrete and tailor-made projects in response to challenges involving health, the environment, social inclusion, education, or citizenship. The document presents principles of scientific integrity, transparency, fairness, respect, and responsibility towards the use of data. It can be understood as voluntary self-commitment, with the objective to increase the individual and collective responsibility of data scientists by encouraging reflection and discussion on the social impact of their professional activity. Many of its principles and recommendations are tied to the General Data Protection Regulation (GDPR).",
        "document_url": "https://dataforgood.fr/hippocrate",
        "attachments": "https://dataforgood.fr",
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "Ensure that the metrics to be optimized are relevant and do not lead the project to have a negative social and environmental impact.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Be careful, when eliminating or imputing missing or outlying values, not to introduce additional biases that would lead to partial or false results. Do not create characteristic data (“features”) which would amount to sensitive personal data if their use can lead to illegal or illegitimate discriminatory effects. Measure bias and variance to control the accuracy and dispersion of the result and document the error metrics retained.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Do not collect or use unnecessary personal and/or sensitive data.",
            "Reliability": "Configure and test several models by not stopping at the first model and configuration that seems good to me. Ensure that the data for which I am responsible is managed and stored securely.",
            "Sustainability": "Question the purpose of the project, its legality, and its possible social and environmental impact.",
            "Transparency": "Communicate, or otherwise remind the competent teams, of the need to communicate to the persons concerned, the use that will be made of their data, in the clearest, explicit and transparent way possible. Ensure that the consent of the people whose data I collect is obtained under fair and transparent conditions for them. Ensure that the person in charge of the system can explain the results of the algorithmic model to the people concerned as much as possible, and this is all the more so if he is legally required to explain these decisions.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Artificial intelligence and Privacy",
        "country": "Norway",
        "world_region": "Northern Europe",
        "institution": "Norwegian Data Protection Authority (DPA)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Large (>10.000 Words, <20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": [
            "Binding",
            "Non-binding"
        ],
        "document_impact": "Short",
        "abstract": "This document was written by the Norwegian Data Protection Authority (DPA), a public authority financed by the Norwegian government and administratively subordinated to the Ministry of Local Government and Regional Development. In this document, the DPA, as the supervisory body for AI applications, provides examples of methods, practical tools (Data Protection Impact Assessment - DPIA), and recommendations for safeguarding privacy in the development and use of AI.",
        "document_url": "https://www.datatilsynet.no/globalassets/global/english/ai-and-privacy.pdf",
        "attachments": "https://www.datatilsynet.no/en/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "Ensure that you have good systems for protecting the rights of data subjects, such as the right to information, access, and deletion. If consent is the legal basis of processing, the system must also include functionality enabling consent to be given and to be withdrawn.",
            "Diversity": "Adopt a multidisciplinary approach. AI is more than just technology. It is important to put together multi-disciplinary teams that can consider the consequences for society of the systems developed.",
            "Autonomy": "When automated decisions are applied, measures must be implemented to protect the data subject's rights, freedoms, and rightful interests. The data subject must be able to demand that a human being takes the final decision, and she must have the right of appeal.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "The principle also requires the data controller to implement measures to prevent the arbitrary discriminatory treatment of individual persons.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "The Data Protection Authority believes that the principle of data minimization should play a major role in the development of artificial intelligence so that the rights of data subjects are protected and general confidence in the models is retained.",
            "Reliability": "Anyone processing personal data must assess the risks involved. If an enterprise believes that a planned process is likely to pose a high risk to natural persons' rights and freedoms, it must conduct a data protection impact assessment (DPIA). This is described in Article 35 of the GDPR.",
            "Sustainability": null,
            "Transparency": "Data subjects must be informed about how the information will be used, whether this information is collected by the data subjects themselves or by others (GDPR Articles 13 and 14).",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Safety & Ethics",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "DeepMind Technologies Limited (DeepMind)",
        "institution_type": "Private Corporation",
        "year_of_publication": "2021",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Descriptive",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by DeepMind Technologies (DeepMind ), a British artificial intelligence research laboratory subsidiary of Alphabet Inc, the parent company of Google, and several former Google subsidiaries. This document presents DeepMind's approach in developing AI technologies and can be understood as a voluntary self-commitment to safety and ethics in the development of their research.",
        "document_url": "https://deepmind.com/safety-and-ethics#overview",
        "attachments": "https://deepmind.com/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "AI systems can only benefit the world if we make them reliable and safe. Technical safety is a core element of our research. Our goal is to ensure that AI systems of the future are proven to be safe - because we've built them that way. Just as software engineering has a set of best practices for security and reliability, our AI safety teams develop approaches to specification, robustness, and assurance for AI systems both now and in the future. Our team of ethicists and policy researchers works closely with our AI research team to understand how technological advances will impact society, and find ways to reduce risk.",
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Code of conduct for data-driven health and care technology",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "Department of Health & Social Care",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2021",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Department of Health & Social Care (UK), a governmental institution that supports ministers in leading the nation's health and social care to help people live more independent, healthier lives for longer. This document was designed to support innovators in understanding what the NHS (National Health Service) is looking for when it buys digital and data-driven technology for use in health and care so that these principles of good practice can be built into the strategy and product development by design. This document is an update to the Code of Conduct for Data-Driven Health and Care Technologies. The document also presents a practical tool: the Data Ethics Framework.",
        "document_url": "https://www.gov.uk/government/publications/code-of-conduct-for-data-driven-health-and-care-technology/initial-code-of-conduct-for-data-driven-health-and-care-technology",
        "attachments": "https://www.gov.uk/government/organisations/department-of-health-and-social-care",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Ensure that the product meets all relevant regulatory requirements. Establish if the data-driven technology that is being developed falls under the definition of a medical device or in vitro diagnostic tool and follow the required regulatory conformance route required to place the product on the market (currently CE marking, soon to change to UKCA). Software that meets the definition of a medical device will be regulated as such by the MHRA). The Care Quality Commission (CQC) regulates providers of clinical services, defined by 14 regulated activities. Any organization using its products in a way that constitutes carrying out any of these regulated activities must register with CQC. Organizations using products involved in the delivery of pharmacy services should register with the General Pharmaceutical Council (GPhC).",
            "Beneficence": "Generate evidence that the product achieves clinical, social, economic, or behavioral benefits. When building or developing the technology, consider what function the product delivers – this will inform the evidence generation plan. It's advisable to consider the generation of evidence as something that happens in parallel with the development of the product and builds throughout the product's life.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "Health and care services are for everyone, including people with different physical, mental health, social, cultural, or learning needs. Health technology designers should consider the needs of a diverse set of users to ensure the product is accessible to as many people as possible.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "It is crucial to eliminate your project's potential to have unintended discriminatory effects on individuals and social groups. You should aim to mitigate biases that may influence your model's outcome and ensure that the project and its outcomes respect the dignity of individuals, are just, nondiscriminatory, and consistent with the public interest, including human rights and democratic values.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Demonstrate that the product collects, stores, and processes users' information in a safe, fair and lawful way.  Innovators must comply with the law. They are responsible for not only ensuring their innovation complies with relevant legislation such as GDPR/Data Protection Act 2018 but also demonstrating this. They should also ensure the legal basis for processing confidential patient information.",
            "Reliability": "Ensure that the product is appropriately tested and is fit for its purpose. All health technology should be sufficiently tested across a range of domains as appropriate and listed below, to evidence that it is suitable for its stated purpose and will provide a robust and stable service. All digital health technologies must be clinically safe to use. To sell into the NHS, manufacturers must demonstrate compliance with the Clinical Safety Standards referred to as DCB0129 and DCB0160. This is mandated under the Health and Social Care Act 2012.",
            "Sustainability": null,
            "Transparency": "Be fair, transparent, and accountable about what data is being used. Individuals have the right to be informed about the collection and use of their personal data. This is a key transparency requirement under the Data Protection Act 2018.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Digital Ethics Guidelines on AI",
        "country": "Germany",
        "world_region": "Western Europe",
        "institution": "Deutsche Telekom AG",
        "institution_type": "Private Corporation",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Deutsche Telekom AG, a German telecommunications company headquartered in Bonn and by revenue the largest telecommunications provider in Europe. In this document, the company defines a framework with several self-binding guidelines. They describe how Deutsche Telekom AG should use and develop AI-based products and services in the future.",
        "document_url": "https://www.telekom.com/en/company/digital-responsibility/details/artificial-intelligence-ai-guideline-524366",
        "attachments": "https://www.telekom.com/de",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "The human always remains responsible. Our solutions come with a clear definition of who is responsible for which AI system or feature. We are in charge of our products and services. And, we know who is in charge of partner or third-party solutions.",
            "Beneficence": "We take great care in the initial algorithm of our own AI solutions to prevent so called 'Black Boxes' and to make sure that our systems shall not unintentionally harm the users.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "We act in tune with our company values. Our systems and solutions must be subordinate to human-defined rules and laws. Therefore, in addition to our technical requirements, our systems and solutions have to obey the rules and laws that we as Deutsche Telekom, our employees – and human beings as such – follow.",
            "Human Formation": "We acknowledge the transformative power of AI for our society. We will support people and society in preparing for this future world. We live our digital responsibility by sharing our knowledge, pointing out the opportunities of the new technology without neglecting its risks. We will engage with our customers, other companies, policy makers, education institutions and all other stakeholders to ensure we understand their concerns and needs and can setup the right safeguards. We will engage in AI and ethics education. Hereby preparing ourselves, our colleagues and our fellow human beings for the new tasks ahead.",
            "Human-Centeredness": "We recognize the widespread fear, that AI enabled machines will outsmart the human intelligence. We as Deutsche Telekom think differently. We know and believe in the human strengths like inspiration, intuition, sense making and empathy. But we also recognize the strengths of AI like data recall, processing speed and analysis. By combining both, AI systems will help humans to make better decisions and accomplish objectives more effective and efficient.",
            "Intellectual Property": null,
            "Fairness": "We take responsibility for a diverse and appropriate data input. In case of inconsistencies, we rather stop the AI system than pursue with potentially manipulated data. We are also able to “reset” our AI systems to remove false or biased data. By this, we install a lever to reduce (unintended) unsuitable decisions or actions to a minimum.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "We never process privacy-relevant data without legal permission. This policy applies to our AI systems just as much as it does to all of our activities. Additionally, we limit the usage to appropriate use cases and thoroughly secure our systems to obstruct external access and ensure data privacy.",
            "Reliability": "Data security is a prime quality of Deutsche Telekom. To maintain this asset, we ensure that our security measures are up to date while having a full overview of how customer related data is used and who has access to which kind of data.",
            "Sustainability": null,
            "Transparency": "In no case do we hide it when the customer's counterpart is an AI. And, we are transparent about how we use customer data. As Deutsche Telekom, we always have the customer's trust in mind – trust is what we stand for.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Artificial intelligence and the work of tomorrow (Künstliche Intelligenz und die Arbeit von Morgen)",
        "country": "Germany",
        "world_region": "Western Europe",
        "institution": "German Trade Union Confederation",
        "institution_type": "Industrial Association",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the  German Trade Union Confederation, an umbrella organization for eight German trade unions, in total representing more than 6 million people. In this document, the authors debate about the necessities for implementing AI-based assistance systems to increase the quality of work.",
        "document_url": "https://www.dgb.de/uber-uns/dgb-heute/arbeit-der-zukunft/++co++3efc0928-cd76-11e9-81dd-52540088cada",
        "attachments": "https://www.dgb.de/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "A prerequisite for good design is a broad participation process that begins with the definition of the objectives for AI and its application and includes an impact assessment. Employees and their interest groups must be involved.",
            "Autonomy": "Employees and their interest groups must be involved in defining the objectives and goals of AI systems that influence working conditions and employment prospects as well as training and continuing education options. The same also applies to the development, implementation, realization, and evaluation, in which the dynamics of change of the learning systems, in particular, must be taken into account. The guiding goal here must be that the machine supports the human being. The final decision-making right must always lie with the individual. In addition, the consequences for employees under labor law, which could theoretically result from \"digital management\" or monitoring, must be ruled out.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": "The aim should be to formulate the requirements for the design of AI for good work and to identify ways of implementing it. After all, machine learning is not just about the automatic elimination of jobs, but about a broad spectrum of possibilities for organizing work more intelligently. The goal should be to promote AI-based assistance systems to increase the quality of work and create new, high-value employment opportunities in conjunction with the appropriate education and training.",
            "Cooperation": "Relevant stakeholders for these processes - developers as well as employers and employees - should already work together at the beginning of the development of AI systems to jointly agree on and document the optimization goals for operational use, including work design. In this way, possible conflicting goals should be explored at this early stage.",
            "Privacy": "When introducing AI systems in a company context, the personal rights of employees (privacy) must be protected. To this end, the requirements of the European General Data Protection Regulation (GDPR) and the Federal Data Protection Act [New] must first be observed.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "When purchasing external systems, the active participation of employees and their representatives should also be ensured when formulating the requirements for the AI system. These processes are the basis for a technical and social impact assessment (impact assessment) of learning systems in the operational context. This also includes transparency of comprehensible and verifiable information as well as clarification of implementation responsibility and intervention mechanics.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Ethics Framework - Responsible AI",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "Digital Catapult, Machine Intelligence Garage",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2021",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Digital Catapult, a British government innovation agency for the digital and software industry. The document provides a practical tool (Digital Catapult's Ethics Framework.) for assessing AI applications according to seven concepts with a corresponding list of questions for each concept. This framework was created by Digital Catapult's Ethics Committee.",
        "document_url": "https://migarage.digicatapult.org.uk/ethics/ethics-framework/",
        "attachments": "https://migarage.digicatapult.org.uk",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Care must be taken to operate within the company's areas of competence, and to actively engage with third-party evaluation and questions. Things can go wrong, despite best efforts. Companies should put in place procedures to report, investigate, take responsibility for, and resolve issues. Help should be accessible and timely.",
            "Beneficence": "Benefits should be clear, likely, and outweigh potential, reasonable risks. They should be evaluated for different user groups and for any affected non-user groups (especially when there are competing values or interests between these groups) and with consideration of plausible future trends or changes (such as greater compute capacity, a solution coming to dominate the market, etc).",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "Companies should consider the impact and utility of their product for individuals, larger groups, and society as a whole, including its impact on widening or narrowing inequality, enabling or constraining discrimination, and other political, cultural and environmental factors.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Other considerations arise from data-driven products, such as the aptness of data for use in situations that were not encountered in the training data, or whether data contains unfair biases, that must be taken into account when assessing the ethical implications of an AI product or service.",
            "Labor Rights": null,
            "Cooperation": "The value exchange between those who provide the data (or label it), directly or otherwise, and the company, should be considered for fairness. If data are used from public sources (e.g., open data collected by a public body or NGO) the company should consider whether it may contribute back or support the work of ongoing data maintenance, perhaps by providing cleaned or corrected data. Integrity and fair dealing should be an integral part of organizational culture. Companies should consider what structures and processes are being employed to drive revenue or other material value to the organization as certain business models or pricing strategies can result in discrimination. Where possible and appropriate, companies should consider whether part of the product, service, or data can be made available to the public.",
            "Privacy": "Compliance with legislation (such as the GDPR) is a good starting point for an ethical assessment of data and privacy.",
            "Reliability": "Safety and potential harm should be considered, both in consequence of the product's intended use and other reasonably foreseeable uses. There should be processes in place to monitor and evaluate the integrity of the system over time, with clarity over what the quality measures are, and how chosen.",
            "Sustainability": null,
            "Transparency": "Companies should be able to explain the purpose and limitations of their solutions so that users are not misled or confused. Companies must be able to communicate clearly the benefits and potential risks of their products and the actions they have taken to deliver benefits and avoid, minimize, or mitigate the risks. They must ensure that processes are in place to address the concerns and complaints of users and other parties and that these are transparent.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "AI Ethics Principles & Guidelines",
        "country": "United Arab Emirates",
        "world_region": "Middle East",
        "institution": "Digital Dubai",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by Digital Dubai, a governmental institution from the United Arab Emirates. Digital Dubai was established by His Highness Sheikh Mohammed Bin Rashid Al Maktoum, Vice-President & Prime Minister of the UAE, and Ruler of Dubai, in June 2021 to develop and oversee the implementation of policies and strategies that govern all matters related to Dubai's information technology, data, digital transformation, and cyber-security. This document gives guidelines for achieving the ethical design and deployment of AI systems in both the public and private sectors. The document also presents Dubai's Ethical AI Toolkit, a (self-assessment) tool created to provide practical help for the industry, academia, and individuals in understanding how AI systems can be used responsibly.",
        "document_url": "https://www.digitaldubai.ae/docs/default-source/ai-principles-resources/ai-ethics.pdf?sfvrsn=d4184f8d_6",
        "attachments": "https://www.digitaldubai.ae/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": true
        },
        "principles_definition": {
            "Accountability": "Accountability for the outcomes of an AI system lies not with the system itself but is apportioned between those who design, develop and deploy it.",
            "Beneficence": "Government will support the research of the beneficial use of AI.",
            "Children's Rights": null,
            "Human Rights": "AI systems should conform to international norms and standards with respect to human values and people's rights and acceptable behavior. Surveillance or other AI-driven technologies should not be deployed to the extent of violating internationally and/or UAE's accepted standards of privacy and human dignity and people's rights.",
            "Diversity": "Data ingested should, where possible, be representative of the affected population.",
            "Autonomy": "AI systems should have built-in appeals procedures whereby users can challenge significant decisions. AGI and superintelligence, if developed, should serve humanity as a whole. Humanity should retain the power to govern itself and make the final decision, with AI in an assisting role.",
            "Human Formation": "Access to training, opportunity and tools should be made available. Education should evolve and reflect the latest developments in AI, enabling people to adapt to societal change",
            "Human-Centeredness": "AI should be developed to align with human values and contribute to human flourishing.",
            "Intellectual Property": null,
            "Fairness": "Algorithms should avoid non-operational bias. Steps should be taken to mitigate and disclose the biases inherent in datasets. Significant decisions should be provably fair.",
            "Labor Rights": null,
            "Cooperation": "Nations should collaborate to avoid an arms race in lethal autonomous weapons, and such weapons should be tightly controlled. Active cooperation should be pursued to avoid corner-cutting on safety standards. Global cooperation should be encouraged to ensure the safe governance of AI.",
            "Privacy": "AI systems should respect privacy and use the minimum intrusion necessary. AI systems should uphold high standards of data governance and security, protecting personal information.",
            "Reliability": "Developers should make efforts to mitigate the risks inherent in the systems they design. AI systems should be verifiably secure and controllable throughout their operational lifetime, to the extent permitted by technology. Recursively self-improving AI development should be disclosed and tightly monitored and controlled for risk. Long-term risks of AI should be identified and planned for.",
            "Sustainability": null,
            "Transparency": "Developers should build systems whose failures can be traced and diagnosed. People should be told when significant decisions about them are being made by AI. Within the limits of privacy and the preservation of intellectual property, those who deploy AI systems should be transparent about the data and algorithms they use.",
            "Truthfulness": "AI systems should be built to serve and inform, and not to deceive and manipulate."
        }
    },
    {
        "document_name": "Data for the Benefit of the People: Recommendations from the Danish Expert Group on Data Ethics",
        "country": "Denmark",
        "world_region": "Northern Europe",
        "institution": "Danish Expert Group on Data Ethics",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2018",
        "number_of_male_authors": "8",
        "number_of_female_authors": "4",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Danish Expert Group on Data Ethics, a group appointed by the Danish government to look into whether Danish companies can make responsible data use a competitive advantage. In this document, the Expert Group focuses on how companies can handle the ethical challenges of using data, presenting several recommendations, together with a practical self-assessment tool in the form of an oath: the data ethics oath.",
        "document_url": "https://em.dk/media/12190/dataethics-v2.pdf?utm_campaign=Background&",
        "attachments": "https://eng.em.dk/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Responsibility is a company's “due diligence” about data collection and processing. Responsibility and co-responsibility must therefore exist in all links of the data processing chain. This includes co-responsibility from business partners and third-party processing and any future data storage. Every year, companies should declare their data ethics policy in accordance with the Danish Financial Statements Act.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "Human dignity must be respected in all data processes, i.e. data should not be used to exploit knowledge against the user's long-term interests. This includes, for example, the use of the latest new technology and encryption methods to protect privacy data from leaks and misuse, and organizational processes and data analysis and correlation that protect people from discrimination and misuse of their data.",
            "Diversity": "Diversity (demographic and professional) in teams working with data systems is essential. Diversity helps ensure a mix of skills, beyond the purely technical, for identifying and tackling the social and ethical consequences of data processing and to ensure that a representative section of the needs, values, and interests of population groups in society is taken into account right from the start when data systems are designed.",
            "Autonomy": "People's self-determination must be prioritized in all data processes. It is the person who should have the ultimate control over what their data is used for and in which contexts.",
            "Human Formation": "It is recommended that science education be increased, with a focus on ethics and philosophy, across all educations and levels of education, right from primary school where pupils need to learn to navigate responsibly when using new technology, to students who, via an interdisciplinary approach to learning, need to understand that they are contributing to a digital society with many data ethics pitfalls.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Strive for a fair balance in the data processing. When using machine learning and algorithms for processing data, active work is being done to prevent undesired bias in data (such as when manually sorting and tidying data), as well as to work towards designs that avoid categorization that discriminates between e.g. population groups. In regard to this, the rationale and criteria for methods that reduce bias and discrimination will always be explicit and open to revision.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": null,
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Principles of Robotics",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "Engineering and Physical Sciences Research Council",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2017",
        "number_of_male_authors": "8",
        "number_of_female_authors": "6",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Engineering and Physical Sciences Research Council, a British Research Council that provides government funding for grants to undertake research and postgraduate degrees in engineering and the physical sciences, mainly to universities in the United Kingdom. In this document, the authors present rules/recommendations for robotics, i.e.,  rules advising those who design, sell and use robots about how they should act.",
        "document_url": "https://webarchive.nationalarchives.gov.uk/ukgwa/20210701125353/https://epsrc.ukri.org/research/ourportfolio/themes/engineering/activities/principlesofrobotics/",
        "attachments": "https://epsrc.ukri.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": true
        },
        "principles_definition": {
            "Accountability": "The person with legal responsibility for a robot should be attributed.",
            "Beneficence": "Robots should not be designed solely or primarily to kill or harm humans, except in the interests of national security",
            "Children's Rights": null,
            "Human Rights": "Humans, not robots, are responsible agents. Robots should be designed; operated as far as is practicable to comply with existing laws & fundamental rights & freedoms, including privacy.",
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "Robots are products. They should be designed using processes that assure their safety and security.",
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": "Robots are manufactured artifacts. They should not be designed in a deceptive way to exploit vulnerable users; instead, their machine nature should be transparent."
        }
    },
    {
        "document_name": "Algo.Rules: Rules for the Design of Algorithmic Systems",
        "country": "Germany",
        "world_region": "Western Europe",
        "institution": "Bertelsmann Stiftung, iRights.Lab",
        "institution_type": [
            "NGO",
            "Private Corporation"
        ],
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by Bertelsmann Stiftung,  an independent foundation under private law, based in Gütersloh (DE), and iRights.Lab, a German independent think tank (headquartered in Berlin, DE) that works with public institutions, foundations, companies, the research community, and policymakers, helping them master the challenges associated with digitalization. The document presents a catalog of formal criteria for enabling the socially beneficial design and oversight of algorithmic systems. It provides the basis for ethical considerations as well as the implementation and enforcement of legal frameworks.",
        "document_url": "https://algorules.org/fileadmin/files/alg/Algo.Rules_EN_2.pdf",
        "attachments": [
            "https://algorules.org/en/home",
            "https://algorules.org/fileadmin/files/alg/From_Principles_to_Practice.pdf"
        ],
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "A natural or legal person must always be held responsible for the effects involved with the use of an algorithmic system. Accountability must be assigned. The accountable person must be aware of the responsibilities associated with their tasks. This also applies to responsibilities that are shared by several people or organizations. The allocation of responsibility must be fully documented and transparent for internal and external parties. Responsibility may not be transferred to the algorithmic system itself, users, or people who are affected by the system.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "Those affected algorithmic systems must be able to request appropriate and detailed information regarding a specific decision and the considerations that have fed into it. If an algorithmic system results in a questionable decision or a decision that affects an individual's rights, it must be possible to request an explanation and file a complaint.",
            "Human Formation": "Sharing individual and institutional knowledge as well as promoting interdisciplinary exchange across task areas are just as crucial as ensuring appropriate skills development. These approaches should be integrated into the education, training, and onboarding of new employees. In addition, an interdisciplinary exchange should be an ongoing endeavor that remains open to those who are interested and/or affected.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "The risk of discrimination and other consequences affecting individuals and the common good must be taken into consideration.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "The security of an algorithmic system must be tested before and during its implementation. The reliability and robustness of an algorithmic system, as well as its underlying data concerning attacks, access, and manipulation, must be guaranteed. Security must be built into the architecture of the algorithmic system (security by design). The system must be tested in a protected environment before implementation. Security precautions must be documented.",
            "Sustainability": null,
            "Transparency": "The function and potential effects of an algorithmic system must be understood. The objectives of an algorithmic system must be clearly defined and information regarding its use must be documented. People interacting with algorithmic systems must be able to identify that a decision or prediction is based on an algorithm. The decision-making processes within an algorithmic system must always be comprehensible.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "From Principles to Practice: An interdisciplinary framework to operationalise AI ethics",
        "country": "Germany",
        "world_region": "Western Europe",
        "institution": "VDE Association for Electrical, Electronic & Information Technologies, Bertelsmann Stiftung",
        "institution_type": [
            "NGO",
            "Professional Association"
        ],
        "year_of_publication": "2020",
        "number_of_male_authors": "14",
        "number_of_female_authors": "5",
        "document_size": "Large (>10.000 Words, <20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the VDE Association for Electrical, Electronic & Information Technologies,  one of Europe's largest technical-scientific associations, and Bertelsmann Stiftung, an independent foundation under private law, based in Gütersloh (DE). This document offers concrete guidance to decision-makers in organizations developing and using AI on how to incorporate values into algorithmic decision-making, and how to measure the fulfillment of values using criteria, observables, and indicators combined with a context-dependent risk assessment. In it, the authors present the VCIO Model, a practical tool for implementing values into algorithmic decision-making.",
        "document_url": "https://algorules.org/fileadmin/files/alg/From_Principles_to_Practice.pdf",
        "attachments": "https://www.researchgate.net/publication/340378463_From_Principles_to_Practice_-_An_interdisciplinary_framework_to_operationalise_AI_ethics",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "The value of accountability refers to problems that arise in connection with the complex allocation or clarification of responsibility relationships in the use of AI. The various dimensions of accountability range from retrospective to prospective organizational measures for assigning responsibilities. They also include technical means or specific ways of dealing with organizational and technical errors.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "The criteria subsumed under the value of justice in this example pertain to classic aspects of algorithmic fairness such as bias prevention and assessment but emphasize a process perspective to include a broader set of ethical considerations. These aspects are, for example, inclusion, represented by criteria such as participatory procedures, or social justice considerations, and a criterion for the assessment of trade-offs generated by the employment of the AI system in question. In this sense, justice refers to a broader set of ethical considerations than the often-used term fairness, which mostly focuses on algorithmic outcomes themselves.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Safeguarding an individual's private sphere is not only a necessary precondition for the protection of individual autonomy and agency but also serves vital interests in self-development, self-realization, engaging in intimate social relations as well as participating in democratic public deliberation.",
            "Reliability": "The consequences of erroneous outcomes, accidents, or misuse of AI systems can affect individuals, parts of a system, or an entire society. Because of the different dimensions of harm, adequate strategies to build a reliable and trustworthy infrastructure have to be developed. As reliability is not only the precondition for trust in and/or predictability of the AI system but also a significant factor in the prevention of individual and societal harm, it is not only a technical but also an ethical principle.",
            "Sustainability": "Environmental sustainability is a form of intergenerational justice and describes the obligation towards future generations to ensure and preserve their living conditions. This obligation is typically geared towards a careful use of natural resources, e.g., to combat pollution and to preserve biodiversity as well as mitigate the worst effects of climate change. Within the field of AI, this includes setting up resource-saving infrastructures for information technology, primarily through building power-efficient data centers as well as developing less power-consuming machine learning models.",
            "Transparency": "For this rating, the value of transparency is understood as explainability and interpretability of the algorithmic system, including the model and data used. The question is here how or in how far transparency is being achieved. Transparency, therefore, refers to disclosing the data's origin and properties of the AI model in use as well as access to and comprehensibility of the information disclosed. In this sense, we aim for transparency in both the general operating principle and each output of the AI system. Transparency furthermore must be tailored to the requirements of the target groups such as users and persons affected, i.e. the system must be comprehensible to them.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Beijing AI Principles",
        "country": "China",
        "world_region": "Eastern Asia",
        "institution": "Beijing Academy of Artificial Intelligence (BAAI)",
        "institution_type": [
            "Academic",
            "Non-profit Organization"
        ],
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Beijing Academy of Artificial Intelligence (BAAI), a non-profit research institute dedicated to promoting collaboration among academia and industries, as well as fostering top talents and a focus on long-term research on the fundamentals of AI technology. The document recommends several principles that should guide the research and development of AI technologies.",
        "document_url": "https://link.springer.com/content/pdf/10.1007/s11623-019-1183-6.pdf",
        "attachments": "https://www-pre.baai.ac.cn/en",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Researchers and developers of AI should have sufficient considerations for the potential ethical, legal, and social impacts and risks brought in by their products and take concrete actions to reduce and avoid them.",
            "Beneficence": "AI should be designed and developed to promote the progress of society and human civilization, to promote the sustainable development of nature and society, to benefit all humankind and the environment, and to enhance the well-being of society and ecology.  AI should not be used against, utilize or harm human beings.",
            "Children's Rights": null,
            "Human Rights": "Human privacy, dignity, freedom, autonomy, and rights should be sufficiently respected.",
            "Diversity": "Te development of AI should reflect diversity and inclusiveness, and be designed to benefit as many people as possible, especially those who would otherwise be easily neglected or underrepresented in AI applications.",
            "Autonomy": "Human privacy, dignity, freedom, autonomy, and rights should be sufficiently respected.",
            "Human Formation": "Stakeholders of AI systems should be able to receive education and training to help them adapt to the impact of AI development in psychological, emotional, and technical aspects.",
            "Human-Centeredness": "The R&D of AI should serve humanity and conform to human values as well as the overall interests of humankind.",
            "Intellectual Property": null,
            "Fairness": "AI R&D should take ethical design approaches to make the system trustworthy. This may include, but is not limited to: making the system as fair as possible, reducing possible discrimination and biases, improving its transparency, explainability, and predictability, and making the system more traceable, auditable, and accountable.",
            "Labor Rights": "An inclusive attitude should be taken towards the potential impact of AI on human employment. A cautious attitude should be taken towards the promotion of AI applications that may have huge impacts on human employment. Explorations on Human-AI coordination and new forms of work that would give full play to human advantages and characteristics should be encouraged.",
            "Cooperation": "It is encouraged to establish AI open platforms to avoid data/platform monopolies, to share the benefits of AI development to the greatest extent, and to promote equal development opportunities for different regions and industries. : Cooperation should be actively developed to establish an interdisciplinary, cross-domain, cross-sectoral, cross-organizational, cross-regional, global, and comprehensive AI governance ecosystem, to avoid malicious AI race, to share AI governance experience, and to jointly cope with the impact of AI with the philosophy of “Optimizing Symbiosis”.",
            "Privacy": "Human privacy, dignity, freedom, autonomy, and rights should be sufficiently respected.",
            "Reliability": "Continuous efforts should be made to improve the maturity, robustness, reliability, and controllability of AI systems, to ensure the security for the data, the safety and security for the AI system itself, and the safety for the external environment where the AI system deploys. Continuous research on the potential risks of Augmented Intelligence, Artificial General Intelligence (AGI), and Superintelligence should be encouraged. Strategic designs should be considered to ensure that AI will always be beneficial to society.",
            "Sustainability": "AI should be designed and developed to promote the progress of society and human civilization, to promote the sustainable development of nature and society, to benefit all humankind and the environment, and to enhance the well-being of society and ecology.",
            "Transparency": "AI R&D should take ethical design approaches to make the system trustworthy. This may include, but is not limited to: making the system as fair as possible, reducing possible discrimination and biases, improving its transparency, explainability, and predictability, and making the system more traceable, auditable, and accountable.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Artificial Intelligence: opportunities, risks and recommendations for the financial sector",
        "country": "Luxembourg",
        "world_region": "Western Europe",
        "institution": "Commission de Surveillance du Secteur Financier (CSSF)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Commission de Surveillance du Secteur Financier (CSSF),  a public institution that supervises the professionals and products of the Luxembourg financial sector. This document presents a CSSF research study that provides basic knowledge about Artificial Intelligence, describes the different types of AI, and some practical use cases for the financial sector.",
        "document_url": "https://www.cssf.lu/wp-content/uploads/files/Publications/Rapports_ponctuels/CSSF_White_Paper_Artificial_Intelligence_201218.pdf",
        "attachments": "https://www.cssf.lu/en/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Institutions should assume clear responsibility and accountability for the actions and decisions taken by automated AI//ML systems and processes. Ultimate responsibility should rely on senior management of the institution which integrates the AI/ML logic into its business processes. Whenever off-the-shelf packages are acquired, clear liability provisions should be defined at the contractual level.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "Institutions should carefully review the integration of AI/ML into the business process and establish controls performed by humans whenever there is a critical decision step. Humans should be able to receive appropriate information to make informed decisions. This analysis should also consider the need for accountability, which cannot be delegated to a machine.",
            "Human Formation": "Institutions should ensure a sufficient level of internal AI skills to understand, develop or supervise the solution, including via specific training and knowledge transfer from external consultants when required. Institutions willing to implement off-the-shelf packages integrating AI/ML technology should carefully evaluate the skills required internally to maintain the solution once in production.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Institutions should aim at building systems respecting the principle of fairness and nondiscrimination.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Institutions should limit the use of personal data in their AI/ML projects and apply protection measures.",
            "Reliability": "Institutions should perform impact assessments to determine the possible (physical or psychological) impacts that the solution may have on humans and consider the level of autonomy of the AI/ML solution. Whenever appropriate, institutions should embed adequate safety protections into the design of the AI/ML product.",
            "Sustainability": null,
            "Transparency": "Institutions should implement measures to ensure the explainability of their AI/ML systems from the design phase. Even when full transparency cannot be achieved due to the intrinsic nature of the algorithm employed (e.g. deep neural networks), steps can be taken to identify and isolate in a human-understandable format the main factors contributing to the final decision.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Data protection and Big Data (Datenschutz und Big Data)",
        "country": "Germany",
        "world_region": "Western Europe",
        "institution": "Handelsblatt Research Institute",
        "institution_type": "Private Corporation",
        "year_of_publication": "2017",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Handelsblatt Research Institute, an independent research institute under the umbrella of the Handelsblatt publishing group. The document provides information on the legal prerequisites for the relationship between companies and customers in the Big Data age. The document also recommends the use of Privacy Impact Assessment (PIA) tools (in compliance with the EU General Data Protection Regulation).",
        "document_url": "https://www.umweltdialog.de/de-wAssets/docs/2014-Dokumente-zu-Artikeln/leitfaden_unternehmen.pdf",
        "attachments": "https://research.handelsblatt.com/de/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "It must be made clear in a declaration of consent who is responsible for the collection of the data. The complete name of the company as the \"responsible party\" within the meaning of the BDSG and its address must be stated. As a matter of principle, a declaration of consent must be made in writing and bear a handwritten signature, see Section 4a (1) sentence 3 BDSG. Therefore, declarations by e-mail, copy, or scan are not sufficient.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "The user must have the possibility to revoke a declared consent at any time. In this case, you must immediately delete or block the personal data collected. If stored personal data proves to be incorrect or incomplete, you must correct it immediately following Section 35 (1) BDSG. You must also delete personal data immediately if the collection or processing was not permissible, the processing or use proves to be impermissible due to circumstances that have subsequently arisen, or knowledge of the data is no longer necessary for the responsible body.",
            "Human Formation": "The essential differences of Big Data compared to previously known data processing require new competencies in the company. They require new knowledge and skills among all employees involved from all affected departments, i.e., especially in the areas of corporate development and IT. There are various ways of building up these competencies. First and foremost, of course, training of the employees concerned should be considered. Such training is particularly recommended for the professional groups of application developers, data architects, business intelligence analysts, database administrators, and system administrators.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "In principle, personal data may only be collected, processed, or used if this is permitted or ordered by the Federal Data Protection Act (BDSG) or an overriding legal provision, or if the data subject has consented following Section 4a BDSG. Thus, the prohibition with reservation of permission applies. If the above-mentioned permissions do not allow the collection, processing, or use of personal data, a company always requires the consent of the data subject (Section 4 BDSG), which must always be given in writing. This consent must be following\n§ Section 4a of the BDSG must explicitly refer to the data collected and the purpose of the collection.",
            "Reliability": "If certain personal data is unlawfully disclosed to third parties and this seriously affects the data subjects, companies must report the data breach to the responsible supervisory authority and the data subjects themselves (Section 42a BDSG). No computer used for business should be connected to the Internet without protection by a suitable firewall. IT systems should be regularly maintained. An action plan for security updates and regular and comprehensive security backups are also recommended.",
            "Sustainability": null,
            "Transparency": "Data subjects have the right to request information about the data that companies have collected about them at any time, see § 34 BDSG. The company must disclose what personal data is stored, where this data was collected, to whom this data is disclosed, and for what purpose it was stored. The type, scope, and content of the data collection must be recognizable to the data subject. You should be transparent with your customers on this point and not try to \"trick\" consent. This is neither legally permitted nor does it strengthen the basis of trust between a company and its customers.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Responsible Artificial Intelligence in the Government of Canada (whitepaper)",
        "country": "Canada",
        "world_region": "North America",
        "institution": "Treasury Board of Canada",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Treasury Board of Canada. The Treasury Board is a Cabinet committee of the Queen's Privy Council of Canada, being responsible for accountability and ethics, financial, personnel and administrative management, comptrollership, approving regulations, and most Orders-in-Council. This document proposes a set of principles that will be expressed in all future Treasury Board policies on the use of AI systems in the Canadian government. The scope of this document is limited to the specific use of AI applications by Canadian federal institutions for their use only, and it does not touch on the Canadian Government's response to automation in the private sector and its effect on society.",
        "document_url": "https://docs.google.com/document/d/1Sn-qBZUXEUG4dVk909eSg5qvfbpNlRhzIefWPtBwbxY/edit",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Organizations are accountable for the actions of AI systems, and should build auditable systems.",
            "Beneficence": "The Treasury Board of Canada Secretariat actively encourages institutions to explore this technology for the benefit of the populations that we serve. Ethical and responsible design of these systems will drive a virtuous cycle of acceptance, which in turn will drive further development.",
            "Children's Rights": null,
            "Human Rights": "As these agents grow to operate in increasingly sophisticated spaces, they act on behalf of the Crown, and should be subject to similar values, ethics, and laws as public servants and adherence to international human rights obligations.",
            "Diversity": "AI systems should be developed in a diverse team that includes individuals capable of assessing the ethical and socioeconomic implications of the system.",
            "Autonomy": "People should always be governed – and perceived to be governed – by people.",
            "Human Formation": null,
            "Human-Centeredness": "AI systems deployed on behalf of the government should be trained to reflect the Values and Ethics of the Public Sector as well as Canadian and international human rights obligations; they should be used to reinforce these values where possible.",
            "Intellectual Property": null,
            "Fairness": "AI needs to be trained with datasets and oriented towards preferable outcomes. Both the training process and the selection of preferable outcomes carry with it the bias of the humans that collected and tagged the data, as well as the programmers that designed the algorithm.",
            "Labor Rights": "AI systems should be deployed in a manner that minimizes negative impact to employees where possible, and should, where feasible, be created alongside the employees that will work with them. Federal institutions should also be reminded that some collective bargaining agreements contain specific sections on workforce adjustment due to technological change. To ensure that these requirements are honored, TBS recommends that unions and non-represented staff alike are engaged early in the planning phases. Staff and unions will be useful partners to help automate processes in a way that is both most useful to the user as well as least affecting of positions.",
            "Cooperation": null,
            "Privacy": "Understanding the need to protect the privacy and national security, AI systems should be deployed in the most transparent manner possible.",
            "Reliability": "Organizations should ensure that reliable contingencies are in place for when AI systems fail, or to provide services to those unable to access these systems.  If AI is going to make decisions, recommendations, or help design policy, there needs to be a sufficient level of social trust that these systems work, and work to the population's benefit. If trust and support do not exist, then these tools will fail.",
            "Sustainability": null,
            "Transparency": "Understanding the need to protect privacy and national security, AI systems should be deployed in the most transparent manner possible.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Artificial Intelligence in Healthcare",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "Academy of Medical Royal Colleges (AoMRC)",
        "institution_type": "Academic",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Large (>10.000 Words, <20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Academy of Medical Royal Colleges (AoMRC), which is the coordinating body for the United Kingdom and Ireland's 23 Medical Royal Colleges and Faculties. The scope of this document encompasses the possible implications of AI in future healthcare, focusing on the likely clinical impact of AI for doctors and patients shortly. In this document, the AoMRC also provides recommendations for politicians, policymakers, and service providers on the use of AI applications in healthcare.",
        "document_url": "https://www.aomrc.org.uk/wp-content/uploads/2019/01/Artificial_intelligence_in_healthcare_0119.pdf",
        "attachments": "https://www.aomrc.org.uk/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Joined up-regulation is key to making sure that AI is introduced safely, as currently there is too much uncertainty about accountability, responsibility, and the wider legal implications of the use of this technology.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": "Clinicians can and must be part of the change that will accompany the development and use of AI. This will require changes in behavior and attitude including rethinking many aspects of doctors' education and careers. More doctors will be needed who are as well versed in data science as they are in medicine.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Artificial intelligence should be used to reduce, not increase, health inequality – geographically, economically, and socially.",
            "Labor Rights": null,
            "Cooperation": "For those who meet information handling and governance standards, data should be made more easily available across the private and public sectors.",
            "Privacy": null,
            "Reliability": "As with traditional clinical activity, patient safety must remain paramount and AI must be developed in a regulated way in partnership between clinicians and computer scientists.",
            "Sustainability": null,
            "Transparency": "External critical appraisal and transparency of tech companies are necessary for clinicians to be confident that the tools they are providing are safe to use.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "SAP's guiding principles for Artificial Intelligence",
        "country": "Germany",
        "world_region": "Western Europe",
        "institution": "System Analysis Program Development (SAP)",
        "institution_type": "Private Corporation",
        "year_of_publication": "2018",
        "number_of_male_authors": "10",
        "number_of_female_authors": "4",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Practical"
        ],
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by System Analysis Program Development (Systemanalyse Programmentwicklung), also known as SAP. SAP is a German private company that develops software solutions for the management of business processes. This document was produced by SAP's AI Ethics Steering Committee and AI Ethics Advisory Panel, and it seeks to present the companies' principles and values that guide the development of their AI-driven products as a form of voluntary self-commitment.",
        "document_url": "https://www.sap.com/documents/2018/09/940c6047-1c7d-0010-87a3-c30de2ffd8ff.html#page=1&zoom=auto,-121,426",
        "attachments": null,
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "In developing AI software, we will remain true to our human rights commitment statement, the UN guiding principles on business and human rights, laws, and widely accepted international norms.",
            "Diversity": "We strive to create AI software systems that are inclusive and that seek to empower and augment the talents of our diverse users.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": "By providing human­centered user experiences through augmented and intuitive technologies, we leverage AI to support people in maximizing their potential. To achieve this, we design our systems closely with users in a collaborative, multidisciplinary, and demographically diverse environment.",
            "Intellectual Property": null,
            "Fairness": "We seek to increase the diversity and inter­disciplinarity of our teams, and we are investigating new technical methods for mitigating biases. We are also deeply committed to supporting our customers in building even more diverse businesses by leveraging AI to build products that help move businesses beyond bias.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Data protection and privacy are a corporate requirement and at the core of every product and service. We communicate clearly how, why, where, and when customer and anonymized user data is used in our AI software.",
            "Reliability": "As with any of our products, our AI software is subject to our quality assurance process, which we continuously adapt when necessary. Our AI software undergoes thorough testing under real-world scenarios to firmly validate that they are fit for purpose and that the product specifications are met.",
            "Sustainability": null,
            "Transparency": "Our systems are held to specific standards following their level of technical ability and intended usage. Their input, capabilities, intended purpose, and limitations will be communicated clearly to our customers, and we provide means for oversight and control by customers and users. They are, and will always remain, in control of the deployment of our products. We actively support industry collaboration and will research to further system transparency.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "People + AI Guidebook",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Google PAIR",
        "institution_type": "Private Corporation",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Google PAIR, a multidisciplinary team at Google that explores the human side of AI by doing fundamental research, building tools, creating design frameworks, and working with diverse communities. This document presents a set of methods, tools, best practices, and examples for designing with AI (e.g., Facets, WIT, PAIR's Explorables). It provides a series of instructional chapters, paired with worksheets, to aid developers to design their applications.",
        "document_url": "https://pair.withgoogle.com/guidebook/chapters",
        "attachments": "https://pair.withgoogle.com/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "Your training data should reflect the diversity and cultural context of the people who will use it. Use tools like Facets and WIT to explore your dataset and better understand its biases.",
            "Autonomy": "When building your AI-powered feature or product, feedback and user control are critical to developing communication and trust between your user and the system, and for developing a product that fulfills your users' needs consistently over time.",
            "Human Formation": null,
            "Human-Centeredness": "Aligning your product with user needs is step one in any successful AI product. Once you've found a need, you should evaluate whether using AI will uniquely address the need. From there, consider whether some parts of the experience should be automated or augmented. Lastly, design your reward function to create a great user experience for all your users over the long run.",
            "Intellectual Property": null,
            "Fairness": "It is important to identify whether or not machine learning can help provide an adequate solution to the specific problem at hand. If it can, just as there is no single “correct” model for all ML tasks, there is no single technique that ensures fairness in every situation. In practice, researchers and developers should consider using a variety of approaches to iterate and improve. Before using an existing dataset, take the time to thoroughly explore it using tools like Facets to better understand any gaps or biases. Real data is often messy, so you should expect to spend a fair amount of time cleaning it up.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "As with any product, protecting user privacy and security is essential. Set up the infrastructure, training, and guidance programs for privacy protection and plan for situations where an adversary might get a hold of the data.",
            "Reliability": "When dealing with a probabilistic, dynamic system, a user could perceive a failure in situations where the system is working as intended. Acknowledging that a product is a work-in-progress can help encourage the adoption and feedback that designers and engineers need to continue improving the AI. The inherent complexity of AI-powered systems can make identifying the source of an error challenges. It's important to discuss as a team how you'll discover errors and discern their sources.",
            "Sustainability": null,
            "Transparency": "Telling the user what data are being used in the AI's prediction can help your product avoid contextual surprises and privacy suspicion and help the user know when to apply their judgment.  In some cases, there may be no way to offer an explicit, comprehensive explanation. The calculations behind an output may be inscrutable, even to the developers of those systems. In other cases, it may be possible to surface the reasoning behind a prediction, but it may not be easy to explain to users in terms they will understand. In these cases, use partial explanations.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Responsible AI practices",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Google AI",
        "institution_type": "Private Corporation",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Google AI, a division of Google LLC dedicated to artificial intelligence. The document presents Google's commitment to making progress in the responsible development of AI and the sharing of knowledge, research, tools, datasets, and other resources with the larger community. The document contains a series of recommendations for responsible AI practices. These recommendations are linked with practical tools to aid the design of responsible AI applications (e.g., People + AI Guidebook, CleverHans).",
        "document_url": "https://ai.google/responsibilities/responsible-ai-practices/",
        "attachments": "https://ai.google/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "Design your model using concrete goals for fairness and inclusion. Engage with social scientists, humanists, and other relevant experts for your product to understand and account for various perspectives. Consider how the technology and its development over time will impact different use cases: Whose views are represented? What types of data are represented? What's being left out? What outcomes does this technology enable and how do these compare for different users and communities? What biases, negative experiences, or discriminatory outcomes might occur?",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": "Reliable, effective user-centered AI systems should be designed following general best practices for software systems, together with practices that address considerations unique to machine learning. The way actual users experience your system is essential to assessing the true impact of its predictions, recommendations, and decisions. Engage with a diverse set of users and use-case scenarios, and incorporate feedback before and throughout project development. This will build a rich variety of user perspectives into the project and increase the number of people who benefit from the technology.",
            "Intellectual Property": null,
            "Fairness": "Design your model using concrete goals for fairness and inclusion. Set goals for your system to work fairly across anticipated use cases: for example, in X different languages, or to Y different age groups. Monitor these goals over time and expand as appropriate. Design your algorithms and objective function to reflect fairness goals.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Collect and handle data responsibly. Identify whether your ML model can be trained without the use of sensitive data. If it is essential to process sensitive training data, strive to minimize the use of such data. Anonymize and aggregate incoming data using best practice data-scrubbing pipelines.",
            "Reliability": "Identify potential threats to the system. Consider whether anyone would have an incentive to make the system misbehave. Identify what unintended consequences would result from the system making a mistake, and assess the likelihood and severity of these consequences. Test the performance of your systems in the adversarial setting.",
            "Sustainability": null,
            "Transparency": "Design the model to be interpretable. Use the smallest set of inputs necessary for your performance goals to make it clearer what factors are affecting the model. Constrain your model to produce input-output relationships that reflect domain expert knowledge. Use the simplest model that meets your performance goals. Provide explanations that are understandable and appropriate for the user.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Artificial Intelligence at Google: Our Principles",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Google AI",
        "institution_type": "Private Corporation",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by Google AI, a division of Google LLC dedicated to artificial intelligence. This document represents Google's voluntary self-commitment to developing technology responsibly, also establishing specific application areas they will not pursue.",
        "document_url": "https://ai.google/principles/",
        "attachments": "https://ai.google/",
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": true
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "We believe that AI should be socially beneficial. As we consider potential development and uses of AI technologies, we will take into account a broad range of social and economic factors, and will proceed where we believe that the overall likely benefits substantially exceed the foreseeable risks and downsides. We will not pursue technologies that cause or are likely to cause overall harm.",
            "Children's Rights": null,
            "Human Rights": "We will not pursue Technologies whose purpose contravenes widely accepted principles of international law and human rights.",
            "Diversity": null,
            "Autonomy": "We believe that AI should be accountable to people. We will design AI systems that provide appropriate opportunities for feedback, relevant explanations, and appeal. Our AI technologies will be subject to appropriate human direction and control.",
            "Human Formation": "We believe that AI should uphold high standards of scientific excellence. We will responsibly share AI knowledge by publishing educational materials, best practices, and research that enable more people to develop useful AI applications.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "We believe that AI should avoid creating or reinforcing unfair bias. We will seek to avoid unjust impacts on people, particularly those related to sensitive characteristics such as race, ethnicity, gender, nationality, income, sexual orientation, ability, and political or religious beliefs.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "We believe that AI should Incorporate privacy design principles. We will incorporate our privacy principles in the development and use of our AI technologies. We will give opportunity for notice and consent, encourage architectures with privacy safeguards, and provide appropriate transparency and control over the use of data. We will not pursue technologies that gather or use information for surveillance violating internationally accepted norms.",
            "Reliability": "We believe that AI should be built and tested for safety. We will continue to develop and apply strong safety and security practices to avoid unintended results that create risks of harm. We will design our AI systems to be appropriately cautious, and seek to develop them in accordance with best practices in AI safety research. In appropriate cases, we will test AI technologies in constrained environments and monitor their operation after deployment.",
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": "We will strive to make high-quality and accurate information readily available using AI while continuing to respect cultural, social, and legal norms in the countries where we operate."
        }
    },
    {
        "document_name": "Universal principles of data ethics: 12 guidelines for developing ethics codes",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "Accenture plc",
        "institution_type": "Private Corporation",
        "year_of_publication": "2016",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Accenture plc, an Ireland-based multinational professional services company that specializes in information technology (IT) services and consulting. In this document, the authors discuss the dynamics involved in generating a code of ethics that could guide the profession of data science as it grows and evolves. In it, a broad set of principles is proposed and intended to inform the development of domain-specific codes of ethics for specific organizations or industries.",
        "document_url": "https://docplayer.net/23613932-Universal-principles-of-data-ethics-12-guidelines-for-developing-ethics-codes.html",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Always follow the law, but understand that the law is often a minimum bar. To excel in data ethics, leaders must define their own compliance frameworks that outperform legislated requirements. Data professionals should develop practices for holding themselves and peers accountable to shared standards",
            "Beneficence": "The highest priority is to respect the persons behind the data. When insights derived from data could impact the human condition, the potential harm to individuals and communities should be the paramount consideration. Big data can produce compelling insights about populations, but those same insights can be used to unfairly limit an individual's possibilities.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Data professionals should strive to mitigate the disparate impacts of their products and listen to the concerns of affected communities.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Strive to match privacy and security safeguards with privacy and security expectations. Data subjects hold a range of expectations about the privacy and security of their data and those expectations are often context-dependent. Designers and data professionals should give due consideration to those expectations and align safeguards and expectations as much as possible.",
            "Reliability": "Strive to match privacy and security safeguards with privacy and security expectations. Data subjects hold a range of expectations about the privacy and security of their data and those expectations are often context-dependent. Designers and data professionals should give due consideration to those expectations and align safeguards and expectations as much as possible.",
            "Sustainability": null,
            "Transparency": "Aspire to design practices that incorporate transparency, accountability, and audibility. Products and research practices should be subject to internal, and potentially external ethical review. Maximizing transparency at the point of data collection can minimize more significant risks as data travels through the data supply chain.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Artificial Intelligence: Australia's Ethics Framework - A Discussion Paper",
        "country": "Australia",
        "world_region": "Oceania",
        "institution": "Australian Government Department of Industry Innovation and Science (IISA)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2019",
        "number_of_male_authors": "4",
        "number_of_female_authors": "4",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": [
            "Binding",
            "Non-binding"
        ],
        "document_impact": "Mid",
        "abstract": "This document was written by the Australian Government Department of Industry Innovation and Science (IISA), a department that provides the Australian Government with strategic, cohesive whole-of-government advice on industry, innovation, science, and research matters. This document identifies principles and measures that can be used to achieve the best possible results from AI technologies while keeping the well-being of Australians as the top priority. The document also provides a toolkit for ethical AI, which consists of several tools to aid developers and other stakeholders to implement AI ethics in AI development (e.g., Algorithmic impact assessments, Social Impact Statement, Risk Assessment Framework for AI Systems).",
        "document_url": "https://ai.bsa.org/wp-content/uploads/2019/09/ArtificialIntelligenceethicsframeworkdiscussionpaper.pdf",
        "attachments": "https://www.industry.gov.au/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "The AI system must comply with all relevant international, Australian Local, State/Territory, and Federal government obligations, regulations, and laws. People and organizations responsible for the creation and implementation of AI algorithms should be identifiable and accountable for the impacts of that algorithm, even if the impacts are unintended.",
            "Beneficence": "The AI system must generate benefits for people that are greater than the costs. Civilian AI systems must not be designed to harm or deceive people and should be implemented in ways that minimize any negative outcomes.",
            "Children's Rights": null,
            "Human Rights": "Under Australia's Human Rights (Parliamentary Scrutiny) Act 2011, new bills must be accompanied by a statement of compatibility that demonstrates how they align with the seven aforementioned human rights agreements. The Parliamentary Joint Committee on Human Rights scrutinizes laws to confirm they are compatible with Australia's human rights obligations. Any future Australian legislation will need to abide by these principles amid change occurring due to AI.",
            "Diversity": "The Government has recognized that Australia must have a deeper STEM talent pool and this is why it has supported the development of a Decadal Plan for Women in STEM to provide a roadmap for sustained increases in women's participation in STEM over the next decade. The benefits of greater diversity in the ICT workforce will be felt across many dimensions of the Australian economy, including AI.",
            "Autonomy": "When an algorithm impacts a person there must be an efficient process to allow that person to challenge the use or output of the algorithm.",
            "Human Formation": "An ethical approach to AI development requires helping people who are negatively impacted by automation transition their careers. This could involve training, reskilling and new career pathways. Improved information on risks and opportunities can help workers take proactive action. Incentives can be used to encourage the right type of training at the right times. Overall, acting early improves the chances of avoiding job loss or ongoing unemployment.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "The development or use of the AI system must not result in unfair discrimination against individuals, communities, or groups.",
            "Labor Rights": "An ethical approach to widespread AI-based automation of tasks performed by human workers requires helping the workers transition smoothly and proactively into new jobs and new careers.",
            "Cooperation": null,
            "Privacy": "Any system, including AI systems, must ensure people's private data is protected and kept confidential plus prevent data breaches that could cause reputational, psychological, financial, professional, or other types of harm. The Australian Privacy Act 1988 (Privacy Act) regulates how personal information is handled.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "People must be informed when an algorithm is being used that impacts them and they should be provided with information about what information the algorithm uses to make decisions.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Universal Guidelines for Artificial Intelligence",
        "country": "Belgium",
        "world_region": "Western Europe",
        "institution": "Public Voice",
        "institution_type": "NGO",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Public Voice,  an organization that promotes public participation in decisions regarding the future of the Internet and other related technologies. The Public Voice project seeks to increase the presence of NGOs at meetings across the globe. In this document, the Public Voice presents Universal Guidelines for Artificial Intelligence (UGAI), which combines the elements of human rights doctrine, data protection law, as well as ethical guidelines.",
        "document_url": "https://thepublicvoice.org/ai-universal-guidelines/",
        "attachments": "https://thepublicvoice.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "An AI system should be deployed only after an adequate evaluation of its purpose and objectives, its benefits, as well as its risks. Institutions must be responsible for decisions made by an AI system.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "All individuals have the right to a final determination made by a person. An institution that has established an AI system has an affirmative obligation to terminate the system if human control of the system is no longer possible.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Institutions must ensure that AI systems do not reflect unfair bias or make impermissible discriminatory decisions.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "No institution shall establish or maintain a secret profiling system. No national government shall establish or maintain a general-purpose score on its citizens or residents.",
            "Reliability": "Institutions must ensure the accuracy, reliability, and validity of decisions. Institutions must establish data provenance, and assure quality and relevance for the data input into algorithms. Institutions must assess the public safety risks that arise from the deployment of AI systems that direct or control physical devices, and implement safety controls. Institutions must secure AI systems against cybersecurity threats.",
            "Sustainability": null,
            "Transparency": "All individuals have the right to know the basis of an AI decision that concerns them. This includes access to the factors, logic, and techniques that produced the outcome. The institution responsible for an AI system must be made known to the public.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "The Future Society, Law & Society Initiative, Principles for the Governance of AI",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "The Future Society",
        "institution_type": "Non-profit Organization",
        "year_of_publication": "2017",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Future Society, an independent nonprofit think-and-do tank. Its activities include policy research, educational & leadership development programs, advisory services, seminars & summits, and other special projects to advance the responsible adoption of Artificial Intelligence (AI) and other emerging technologies. In this document, the authors seek to present a framework for the governance of AI, based on foundational universal and overarching values.",
        "document_url": "https://thefuturesociety.org/2017/07/15/principles-law-and-society-initiative/",
        "attachments": "https://thefuturesociety.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Manufacturers and operators of AI shall be accountable. Accountability means the ability to assign responsibility for the effects caused by AI or its operators.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "The norms of the delegation of decisions to AI systems shall be codified through thoughtful, inclusive dialogue with civil society.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "AI shall not impair, and, where possible, shall advance the equality in rights, dignity, and freedom to flourish of all humans.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "AI's effectiveness shall be measurable in the real-world applications for which it is intended. Measurability means the ability for both expert users and ordinary citizens to gauge concretely whether AI or hybrid intelligence systems are meeting their objectives. Operators of AI systems shall have appropriate competencies. When our health, our rights, our lives, or our liberty depend on hybrid intelligence, such systems should be designed, executed, and measured by professionals with the requisite expertise.",
            "Sustainability": null,
            "Transparency": "AI shall be transparent. Transparency is the ability to trace cause and effect in the decision-making pathways of algorithms and, in hybrid intelligence systems, of their operators.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Sony Group AI Ethics Guidelines",
        "country": "Japan",
        "world_region": "Eastern Asia",
        "institution": "Sony Group Corporation (Sony)",
        "institution_type": "Private Corporation",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Sony Group Corporation (Sony), a Japanese multinational conglomerate corporation headquartered in Kōnan, Minato, Tokyo (Japan). In the document, Sony presents its AI Engagement within Sony Group, which states that \"Through the utilization of artificial intelligence (AI), Sony aims to contribute to the development of a peaceful and sustainable society while delivering \"kando\" - a sense of excitement, wonder or emotion - to the world.\" The Sony Group AI Ethics Guidelines is a voluntary commitment made by the Sony Group to ensure that the research and development of AI within Sony is aligned with their AI engagement.",
        "document_url": "https://www.sony.com/en/SonyInfo/csr_report/humanrights/AI_Engagement_within_Sony_Group.pdf",
        "attachments": null,
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "Through advancing its AI-related R&D and promoting the utilization of AI in a manner harmonized with society, Sony aims to support the exploration of the potential for each individual to empower their lives, and to contribute to the enrichment of our culture and push our civilization forward by providing novel and creative types of kando. Sony will be cognizant of the effects and impact of products and services that utilize AI on society and will proactively work to contribute to developing AI to create a better society and foster human talent capable of shaping our collective bright future through R&D and/or utilization of AI.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "To solve the challenges arising from the use of AI while striving for better AI utilization, Sony will seriously consider the interests and concerns of various stakeholders including its customers and creators, and proactively advance dialogue with related industries, organizations, academic communities, and more.",
            "Autonomy": null,
            "Human Formation": "People's lives have continuously changed with the advance in technology across history. Sony will be cognizant of the effects and impact of products and services that utilize AI on society and will proactively work to contribute to developing AI to create a better society and foster human talent capable of shaping our collective bright future through R&D and/or utilization of AI.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "In its utilization of AI, Sony will respect the diversity and human rights of its customers and other stakeholders without any discrimination while striving to contribute to the resolution of social problems through its activities in its own and related industries.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Sony, in compliance with laws and regulations as well as applicable internal rules and policies, seeks to enhance the security and protection of customers' data acquired via products and services utilizing AI, and build an environment where said personal data is processed in ways that respect the intention and trust of customers.",
            "Reliability": "Sony understands the need for safety when dealing with products and services utilizing AI and will continue to respond to security risks such as unauthorized access. AI systems may utilize statistical or probabilistic methods to achieve results. In the interest of Sony's customers and to maintain their trust, Sony will design whole systems with an awareness of the responsibility associated with the characteristics of such methods.",
            "Sustainability": "Sony will engage in sustainable social development and endeavor to utilize the power of AI for contributing to global problem-solving and for the development of a peaceful and sustainable society.",
            "Transparency": "During the planning and design stages for its products and services that utilize AI, Sony will strive to introduce methods of capturing the reasoning behind the decisions made by AI utilized in said products and services. Additionally, it will endeavor to provide intelligible explanations and information to customers about the possible impact of using these products and services.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Principles for the safe and effective use of data and analytics",
        "country": "New Zealand",
        "world_region": "Oceania",
        "institution": "Office of the Privacy Commissioner (OPC), Stats New Zealand (Stats NZ)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Office of the Privacy Commissioner (OPC), a governmental department that works to develop and promote a culture in which personal information is protected and respected in New Zealand, and Stats New Zealand (Stats NZ), which is New Zealand's official data agency. In this document, both governmental institutions describe the principles that support government agencies on best practices for the use of data and analytics for decision-making.",
        "document_url": "https://www.stats.govt.nz/assets/Uploads/Data-leadership-fact-sheets/Principles-safe-and-effective-data-and-analytics-May-2018.pdf",
        "attachments": [
            "https://www.privacy.org.nz/",
            "https://www.stats.govt.nz/"
        ],
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "To ensure accountability, decisions based on analytical methods or automated processes affecting people should be openly disclosed, and appropriate review and feedback mechanisms developed to preserve fundamental rights and freedoms. Transparency supports collaboration, partnership, and shared responsibility, and is essential for accountability. This includes ensuring New Zealanders know what data is held about them; how it's kept secure; who has access to it; and how it's used.",
            "Beneficence": "The use of data and analytics must have clear benefits for New Zealanders.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "Data and data analytics are tools that support decision-making and it's essential that in collecting and using public data, government agencies consider, and can demonstrate positive public benefits. This includes: considering the views of all relevant stakeholders; embedding a te ao Māori perspective through a Treaty-based partnership approach.",
            "Autonomy": "Analytical processes are a tool to inform human decision-making and should never entirely replace human oversight. Ensure significant decisions based on data involve human judgment and evaluation, and that automated decision-making processes are regularly reviewed to make sure they're still fit for purpose.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Data and data analytics are tools that support decision-making and it's essential that in collecting and using public data, government agencies consider, and can demonstrate positive public benefits. This includes: ensuring all associated policies and decisions have been evaluated for fairness and potential bias and have a solid grounding in law.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Keep in mind the people behind the data and how to protect them against misuse of information. It‘s essential to consider the privacy and ethical implications of any analytical process that draws on data collected about people, as using data and analytics for decision-making can have real-life impacts. Personal information should only be kept for as long as necessary.",
            "Reliability": "Decision-makers need to be aware of how data is collected and analyzed, including the accuracy, precision, consistency, and completeness of data quality, and take special care when re-using data that was originally collected for another purpose. Regular assessments to check for bias and other harmful elements, and address any over-reliance on correlations, are essential in the development and operation of analytical processes. Feeding assessment outcomes back into the design of systems and processes can help ensure unfair or discriminatory outcomes aren't generated.",
            "Sustainability": null,
            "Transparency": "Data use and analytical processes should be well documented and in line with all relevant legislation, and state sector guidelines. Explanations of decisions – and the analytical activities behind them – should be in clear, simple, easy-to-understand language.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Recommendations for the responsible use of AI and automated decision-making - Corporate Digital Responsibility and Decision Making (Empfehlungen für den verantwortlichen Einsatz von KI und automatisierten Entscheidungen - Corporate Digital Responsibility and Decision Making)",
        "country": "Germany",
        "world_region": "Western Europe",
        "institution": "Bitkom",
        "institution_type": "Industrial Association",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Bitkom,  an industry association for the German information and telecommunications industry. It was developed with the cooperation of companies that successfully use machine learning algorithms and artificial intelligence systems and have already demonstrated their commitment through numerous initiatives for transparency and understanding with users. The document is intended to show ways in which assisted decision-making through algorithms, machine learning, and AI can be used for the benefit of our society and the national economy.",
        "document_url": "https://www.bitkom.org/sites/main/files/file/import/180202-empfehlungskatalog-online-2.pdf",
        "attachments": "https://www.bitkom.org/Bitkom/Publikationen/Empfehlungen-fuer-den-verantwortlichen-Einsatz-von-KI-und-automatisierten-Entscheidungen-Corporate-Digital-Responsibility-and-Decision-Making.html",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "The development of internal company and industry-specific guidelines for the fair and ethical use of algorithms and AI should be increasingly promoted. Guidelines are valuable aids that both facilitate the analysis of processes and provide a framework for action. A process should be established that also regularly adapts existing guidelines to new technologies and the associated issues.",
            "Beneficence": "When decision-support technologies are used, the consequences for the user should be examined in advance and compared with the benefits of their use. Unreasonable disadvantages should be ruled out.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "Particularly responsible decision-making processes must be designed in such a way that the ultimate decision-making authority remains with the human being until the quality of control reaches a level accepted by all stakeholders.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Companies should sensitize and train their employees to address and reduce susceptibility to machine bias. Particular attention should also be paid to the data feed. Here, for example, internal and external testing processes can be developed to detect patterns of discrimination.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "As part of the ethical guidelines, it must be ensured that the algorithms can make the prediction precisely and accurately. Companies should carefully review the data to be used, data categories, and the use of data before deploying an AI system, and the criteria according to which data is introduced, especially in self-learning systems, should be reviewed with a view to sources of error and documented as comprehensibly as possible.",
            "Sustainability": null,
            "Transparency": "Companies take effective (self-imposed and thus trust-building) measures to make the \"if\" and the \"how\" of the use of algorithms understandable for the user. This may include the use of automated decisions, the use of specific groups of data, and the reason or goal of the technology used. The user should be enabled to have a basic understanding of the decisions supported by algorithms, machine learning, or AI.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Code of Ethics for Data-Based Value Creation",
        "country": "Switzerland",
        "world_region": "Western Europe",
        "institution": "Swiss Alliance for Data-Intensive Services",
        "institution_type": "NGO",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was produced by the Data Innovation Alliance, a network of Industrial organizations and academic institutions that aims to help companies develop new products and services related to technologies surrounding data science, artificial intelligence, blockchain, and others. This document is intended for organizations that offer services or products based on data, to help these organizations develop products and services that are consistent with the ethical expectations of customers, employees, or society. To this end, Data Innovation Alliance presents a Code of Ethics. The purpose of this code is to systematically address the ethical issues that arise when creating or using data-based products and services. The document also offers tools to assist companies in self-assessing the extent to which the Data Innovation Alliance Code of Ethics can be applied.",
        "document_url": "https://data-innovation.org/data-ethics/",
        "attachments": "https://data-innovation.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "You should define clear responsibilities for the handling of data and take responsibility in case of violations of rules. This is particularly intended to counteract the tendency for responsibilities to become blurred and unclear in the course of the digitization of processes.",
            "Beneficence": "You should not harm individuals or communities.",
            "Children's Rights": null,
            "Human Rights": "You should enable individuals and communities to act in a self-determined manner. This basic orientation includes, among other things, the value of dignity (e.g., through information practices taking the customer seriously).",
            "Diversity": null,
            "Autonomy": "You should enable individuals and communities to act in a self-determined manner.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "You should consider a fair distribution of benefits and burdens. This basic orientation includes, among other things, the values of equality (e.g., protection against discrimination) and fairness (e.g., by giving something in return for collecting customer data).",
            "Labor Rights": null,
            "Cooperation": "You should consider a fair distribution of benefits and burdens. This basic orientation includes, among other things, the value of solidarity (e.g., by making data available to the public for collective use).",
            "Privacy": "You should enable individuals and communities to act in a self-determined manner. This basic orientation includes, among other things, the value of privacy (e.g., by not collecting certain data). Personal data must be processed lawfully.",
            "Reliability": "You should not harm individuals or communities. This basic orientation includes the values of protection (e.g., against data loss) and security (e.g., of data against hackers).",
            "Sustainability": "You should not harm individuals or communities. This basic orientation includes sustainability (i.e., minimizing negative effects on the environment, e.g., through energy-efficient data processing).",
            "Transparency": "You should document and communicate what happens to data and how it is done. The focus of transparency is both the customer and, for example, an auditor; the concrete requirements for transparency differ according to these target groups.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Guidelines for the responsible use of artificial intelligence and other digital technologies in human resources work",
        "country": "Germany",
        "world_region": "Western Europe",
        "institution": "HR Tech, Software & Innovation",
        "institution_type": "Private Corporation",
        "year_of_publication": "2019",
        "number_of_male_authors": "12",
        "number_of_female_authors": "5",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the HR-Tech Ethics Advisory Board, i.e., the ethics board of the HR Tech, Software & Innovation. This board is formed by scientists and experts from the fields of behavioral economics, human resources management, psychology, business ethics, law, HR (Human Resources) executives from established companies, experienced HR practitioners, founders, CEOs, stakeholders from successful HR startups, and representatives from civil society. The HR-Tech Ethics Advisory Board aims to give all people, and in particular HR managers who have contact with digital innovations in HR work, orientation for responsible use of such. To achieve this goal, the HR-Tech Ethics Advisory Board has developed ten guidelines for the responsible use of artificial intelligence and other digital technologies in HR work in a broad iterative discourse, together with a step-by-step practical guide to be followed by those who wish to adopt their guidelines. An updated and distilled version (2021) can be found on the HR-Tech Ethics Advisory Board website (the same ethical principles are addressed in both versions).",
        "document_url": "https://www.ethikbeirat-hrtech.de/wp-content/uploads/2019/09/Ethikbeirat_und_Richtlinien_Konsultationsfassung_final.pdf",
        "attachments": "https://www.ethikbeirat-hrtech.de/wp-content/uploads/2021/09/Richtlinien_Download_2021.pdf",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Organizations that use AI solutions are accountable for the results of their use.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "Those who use AI solutions must ensure that the power of people to make important personnel decisions is not restricted. Before or when using an AI solution, the people affected by it must be informed about its use, its purpose, its logic, the data collected, and the types of data used. No data may be collected and used for use in AI solutions that are fundamentally beyond the willful control of those affected.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Anyone who develops or uses AI solutions must ensure that the underlying data have a high quality and system-related discriminations are excluded.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Anyone who uses personal data for AI solutions must define in advance the purposes for which these are used and ensure that these data are only collected, stored, and used for the intended purpose.",
            "Reliability": "Anyone offering or using AI solutions must make sure that they are empirically evaluated are and have a theoretical basis. Those who introduce AI solutions following these guidelines should transparently ensure that the guidelines are also observed during operational implementation and further development.",
            "Sustainability": null,
            "Transparency": "Before introducing an AI solution, the objective for its use must be clarified. In this process, all relevant stakeholders should be identified and involved. Anyone who uses AI solutions in their organization must be able to understand and explain their logic.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Telefónica´s Approach to the Responsible Use of AI (Enfoque de Telefónica para un uso responsable de la IA)",
        "country": "Spain",
        "world_region": "Western Europe",
        "institution": "Telefónica S.A",
        "institution_type": "Private Corporation",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Normative",
            "Practical"
        ],
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by Telefónica S.A., a Spanish multinational telecommunications company headquartered in Madrid (Spain), being one of the largest telephone operators and mobile network providers in the world. This document describes Telefónica´s Responsible Use of AI, which is a part of the broader Responsibility by Design-Approach of Telefónica. The document also provides a practical tool for all products and services that use AI or Big Data, where a responsible manager needs to complete the self-assessment questionnaire where for each principle, several questions must be answered. The questionnaire is available online in Spanish and English and integrated into the global Responsibility by Design initiative of Telefónica.",
        "document_url": "https://www.telefonica.com/en/wp-content/uploads/sites/5/2021/08/ia-responsible-governance.pdf",
        "attachments": null,
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "Telefonica is strongly committed to respecting Human Rights, as is stated in its Business Principles and Human Rights Policy. AI used in products and services should in no way lead to a negative impact on human rights or the achievement of the UN's Sustainable Development Goals.",
            "Diversity": "Technology should contribute to making society more inclusive and offer better opportunities for all, and AI can contribute to these goals.",
            "Autonomy": null,
            "Human Formation": "It is of utmost importance to explain to employees what AI is, how it works and how it might lead to undesired consequences. Telefónica has therefore developed courses related to AI & Ethics that are accessible to all employees through the standard corporate portals in three languages (Spanish, English, and Portuguese).",
            "Human-Centeredness": "Human-centric AI means that AI should be at the service of society and generate tangible benefits for people. AI systems should always stay under human control and be driven by value-based considerations.",
            "Intellectual Property": null,
            "Fairness": "Fair AI seeks to ensure that the applications of AI technology lead to fair results. This means that they should not lead to discriminatory impacts on people concerning race, ethnic origin, religion, gender, sexual orientation, disability, or any other personal condition. When optimizing a machine learning algorithm, we must take into account not only the performance in terms of error optimization but also the impact of the algorithm in the specific domain.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Privacy and Security by Design mean that when creating AI systems, which are fueled by data, privacy, and security aspects are an inherent part of the system's lifecycle.",
            "Reliability": "Privacy and Security by Design mean that when creating AI systems, which are fueled by data, privacy, and security aspects are an inherent part of the system's lifecycle.",
            "Sustainability": "AI used in products and services should in no way lead to a negative impact on human rights or the achievement of the UN's Sustainable Development Goals.",
            "Transparency": "Transparent and Explainable AI mean to be explicit about the kind of personal and/or non-personal data the AI systems uses as well as about the purpose the data is used for. When people directly interact with an AI system, it should be clear to the users that this is the case. When AI systems take, or support, decisions, a certain level of understanding of how the conclusions are arrived at needs to be ensured, by generation explanations about how they reached that decision like is illustrated in for the particular case of supervised machine learning. Those explanations should always consider the user profile to adjust them to the transparency level required. This also applies in the case of using third-party AI technology.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Automated and connected automated driving (Automatisiertes und Vernetztes Fahren)",
        "country": "Germany",
        "world_region": "Western Europe",
        "institution": "Federal Ministry for Digital and Transport Ethics Committee (Bundesministerium für Digitales und Verkehr Ethik-Kommission)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2017",
        "number_of_male_authors": "13",
        "number_of_female_authors": "1",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Ethics Committee on Automated and Connected Driving appointed by the Federal Ministry for Digital and Transport (Bundesministerium für Digitales und Verkehr), a cabinet-level ministry of the Federal Republic of Germany. The ministry, together with its subordinate agencies, is responsible for all federal portfolio tasks which touch the mobility of people, goods, services, and data. The Ethics Committee on Automated and Connected Driving is an interdisciplinary and plural expert commission, with representatives of philosophy, law and social sciences, technology assessment, consumer protection, the automotive industry, and software development. The document addresses many technical and ethical questions related to the use of autonomous vehicles, proposing regulations for automated and connected vehicle traffic.",
        "document_url": "https://www.bmvi.de/SharedDocs/DE/Publikationen/DG/bericht-der-ethik-kommission.pdf?__blob=publicationFile",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "In hazardous situations that prove to be unavoidable despite all technical precautions, the protection of human life has the highest priority in a weighing of legal interests. Programming must therefore be designed within the bounds of what is technically feasible. The operator must be prepared to accept damage to animals or property in the event of a conflict if the personal injury can be prevented. It must be clearly distinguishable whether a driverless system is used or a driver with the possibility of \"overruling\" retains responsibility. In the case of non-driverless systems, the human/machine interface must be designed in such a way that it is clearly regulated and recognizable at all times which responsibilities lie on which side, in particular on which side the control lies.",
            "Beneficence": "The protection of people takes precedence over all other utilitarian considerations. The goal is to reduce harm up to and including complete prevention. The approval of automated systems is only justifiable if, in comparison with humans, the new system promises at least a reduction in damage in the sense of a positive risk balance.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "The autonomous decision of the individual is an expression of a society in which the individual person with his or her claim to development and his or her need for protection is at the center. Every state and political decision, therefore, serves the free development and protection of the individual.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "In unavoidable accident situations, any qualification according to personal characteristics (age, sex, physical or mental constitution) is strictly prohibited. Offsetting of victims is prohibited. General programming to minimize the number of personal injuries may be justifiable.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Permitted business models that make use of the data generated by automated and connected driving, which may or may not be relevant for vehicle control, are limited by the autonomy and data sovereignty of road users. Vehicle owners or users decide in principle on the transfer and use of data.",
            "Reliability": "Partially and fully automated traffic systems serve first and foremost to improve the safety of all road users. In addition, the aim is to increase mobility opportunities and enable other benefits. Manufacturers or operators are obliged to continuously optimize their systems and also to monitor and improve systems that have already been delivered, where this is technically possible and permissible. Automated driving is only justifiable to the extent that conceivable attacks, in particular manipulation of the IT system or inherent system weaknesses, do not lead to such damage as to cause a lasting loss of confidence in road traffic.",
            "Sustainability": null,
            "Transparency": "The public has a right to sufficiently differentiate information about new technologies and their use. For the concrete implementation of the principles developed here, guidelines for the use and programming of automated vehicles should be derived in as transparent a form as possible and communicated to the public.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Telia Company Guiding Principles on trusted AI ethics",
        "country": "Sweden",
        "world_region": "Northern Europe",
        "institution": "Telia Company AB",
        "institution_type": "Private Corporation",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Telia Company AB (also known as Telia Company), a Swedish multinational telecommunications company and mobile network operator present in Sweden, Finland, Norway, Denmark, Lithuania, Latvia, and Estonia. In this document, Telia Company provides the Guiding Principles to its operations and employees for proactive design, implementation, testing, use, and follow-up of AI. These Guiding Principles lay out Telia Company's aspirations to build Trusted AI ethics. According to the document, \"Telia Company's strategy, as well as our statement of materiality and significant audiences, commit the company to work actively towards the United Nation's Sustainable Development Goals. We embrace the value and opportunity of AI as an accelerator for realizing the 2030 Agenda for Sustainable Development. We aspire to integrate sustainable, responsible business practices into all parts of business and strategy to harness AI for good.\"",
        "document_url": "https://www.teliacompany.com/globalassets/telia-company/documents/about-telia-company/public-policy/2021/tc-guiding-principles-on-trusted-ai_jan11.pdf",
        "attachments": "https://www.teliacompany.com/en/about-the-company/public-policy/ai-ethics/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": true,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "We always remain responsible. Our solutions come with a clear definition of who is responsible for which AI solution. We are in charge of our products and services. And, we know who is in charge of partner or third-party solutions.",
            "Beneficence": "Our mission is to create value for customers and other stakeholders with a positive impact on society. We aspire to act with care and in a responsible way. We explore opportunities in tandem with potential risks.",
            "Children's Rights": "We aim to know and show how we respect human rights. We seek to identify, prevent, mitigate and account for how we address our impacts on human rights and how we manage human rights risks and opportunities, such as privacy, children's rights, and anti-discrimination.",
            "Human Rights": "We aim to know and show how we respect human rights. We seek to identify, prevent, mitigate and account for how we address our impacts on human rights and how we manage human rights risks and opportunities, such as privacy, children's rights, and anti-discrimination.",
            "Diversity": null,
            "Autonomy": "We monitor AI solutions so that we are continuously ready to intervene into AI, datasets, and algorithms, to identify needs for improvements and to prevent and/or reduce damage.",
            "Human Formation": null,
            "Human-Centeredness": "AI is used to simplify and enhance our customers' lives. Employees' issues are recognized and respected. We acknowledge the advantages of a cooperative and complementary model of human-machine interactions and seek to use this sustainably. Our preference and intention are for AI to extend and complement human abilities rather than lessen or restrict them.",
            "Intellectual Property": null,
            "Fairness": "We aspire to embed the principles of fairness and equality in datasets and algorithms - applied in all phases of AI design, implementation, testing, and usage – fostering fairness and diversity and avoiding unfair bias both at the input and output levels of AI.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "We aim to know and show how we respect human rights. We seek to identify, prevent, mitigate and account for how we address our impacts on human rights and how we manage human rights risks and opportunities, such as privacy, children's rights, and anti-discrimination.",
            "Reliability": "We monitor AI solutions so that we are continuously ready to intervene into AI, datasets, and algorithms, to identify needs for improvements and to prevent and/or reduce damage. Our solutions are built and tested to prevent possible misuse and reduce the risk of being compromised or causing harm.",
            "Sustainability": null,
            "Transparency": "We strive towards transparency and proactively explain the use of AI in our operations to customers, employees, and other stakeholders in a user-friendly way, based on applicable industry best practices and relevant standards.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Responsible AI and robotics: An ethical framework",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "Accenture plc",
        "institution_type": "Private Corporation",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Accenture plc, an Ireland-based multinational professional services company that specializes in information technology (IT) services and consulting. In this document, the authors present an Ethical Framework for Responsible AI and Robotics, where ethical challenges are reviewed and fundamental principles for AI/Robotics development are recommended.",
        "document_url": "https://www.accenture.com/gb-en/company-responsible-ai-robotics",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "It must be clear where liability lies when systems make mistakes. General principles should guide accountability.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Steps must be made to stop systemic bias. Core values such as equality, diversity, and lack of discrimination must be promoted. The codes should confront what obligations rest on actors who deploy AI to mitigate the social dislocation that results.",
            "Labor Rights": null,
            "Cooperation": "The government should encourage discussion on the ethics of AI, and ensure all relevant parties are involved. Bringing together the private sector, consumer groups, and academia would allow the development of an ethical code that keeps up with technological, social, and political developments. Government efforts should be collaborative with existing efforts to research and discuss ethics in AI.",
            "Privacy": "the importance of data protection, IP ownership, and cyber security must be recognized and balanced against the need to use data to promote innovation.",
            "Reliability": "As more reliance is placed on AI, the importance of cybersecurity will increase. Security must be a top priority for all actors if trust is to be maintained. the need for strong protection against hacking will increase as AI systems take a heightened role in society.",
            "Sustainability": null,
            "Transparency": "It must be clear when AI systems need to explain their actions to humans to show why a decision was made, and when, if ever, such transparency is not necessary.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "European ethical Charter on the use of Artificial Intelligence in judicial systems and their environment",
        "country": "European Union",
        "world_region": "European Union",
        "institution": "European Commission For the Efficiency of Justice (CEPEJ)",
        "institution_type": "International Organization",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the European Commission For the Efficiency of Justice (CEPEJ), a judicial body composed of experts from all the 47 member States of the Council of Europe. The objective of this Council is to develop tools aimed at improving the efficiency and the functioning of justice in Europe (also granting observer status to and consultations with non-governmental organizations outside of Europe). This document is intended for public and private stakeholders responsible for the design and deployment of artificial intelligence tools and services that involve the processing of judicial decisions and data. It also concerns public decision-makers in charge of the legislative or regulatory framework, of the development, audit, or use of such tools and services. Fort this, the CEPEJ recommends the adoption of five guiding principles for the use and development of AI in judicial systems. They also provide an in-depth study on the use of AI in judicial systems.",
        "document_url": "https://rm.coe.int/ethical-charter-en-for-publication-4-december-2018/16808f699c",
        "attachments": null,
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "ensure that the design and implementation of artificial intelligence tools and services are compatible with fundamental rights.",
            "Diversity": null,
            "Autonomy": "preclude a prescriptive approach and ensure that users are informed actors and in control of the choices made.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "specifically prevent the development or intensification of any discrimination between individuals or groups of individuals.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "concerning the processing of judicial decisions and data, use certified sources and intangible data with models elaborated in a multi-disciplinary manner, in a secure technological environment.",
            "Sustainability": null,
            "Transparency": "make data processing methods accessible and understandable, authorize external audits.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "AI Now Report 2018",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "AI Now Institute",
        "institution_type": "Academic",
        "year_of_publication": "2018",
        "number_of_male_authors": "4",
        "number_of_female_authors": "6",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the AI Now Institute,  an American interdisciplinary research institute dedicated to understanding the social implications of AI technologies. It is the first university research center focused specifically on AI's social significance. Building on 2016 and 2017 reports, the AI Now 2018 Report addresses the following key issues: the growing accountability gap in AI, the use of AI to maximize and amplify surveillance, increasing government use of automated decision systems that directly impact individuals and communities without established accountability structures, unregulated and unmonitored forms of AI experimentation on human populations, and the limits of technological solutions to problems of fairness, bias, and discrimination. The document also provides a series of recommendations to address the pointed issues.",
        "document_url": "https://ainowinstitute.org/AI_Now_2018_Report.pdf",
        "attachments": "https://ainowinstitute.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": true
        },
        "principles_definition": {
            "Accountability": "Governments need to regulate AI by expanding the powers of sector-specific agencies to oversee, audit, and monitor these technologies by domain. The AI industry urgently needs new approaches to governance. As this report demonstrates, internal governance structures at most technology companies are failing to ensure accountability for AI systems",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "Technology companies and the AI field as a whole have focused on the “pipeline model,” looking to train and hire more diverse employees. While this is important, it overlooks what happens once people are hired into workplaces that exclude, harass, or systemically undervalue people based on gender, race, sexuality, or disability.",
            "Autonomy": "Communities should have the right to reject the application of these technologies in both public and private contexts. Mere public notice of their use is not sufficient, and there should be a high threshold for any consent, given the dangers of oppressive and continual mass surveillance.",
            "Human Formation": "University AI programs should expand beyond computer science and engineering disciplines. AI began as an interdisciplinary field, but over the decades has narrowed to become a technical discipline. With the increasing application of AI systems to social domains, it needs to expand its disciplinary orientation. That means centering forms of expertise from the social and humanistic disciplines.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Technology companies must go beyond the “pipeline model” and commit to addressing the practices of exclusion and discrimination in their workplaces.",
            "Labor Rights": "Technology companies need to protect workers' ability to organize, whistleblow, and make ethical choices about what projects they work on. This should include clear policies accommodating and protecting conscientious objectors, ensuring workers the right to know what they are working on, and the ability to abstain from such work without retaliation or retribution. Workers raising ethical concerns must also be protected, as should whistleblowing in the public interest. More funding and support are needed for litigation, labor organizing, and community participation on AI accountability issues. The people most at risk of harm from AI systems are often those least able to contest the outcomes. We need increased support for robust mechanisms of legal redress and civic participation.",
            "Cooperation": "Vendors and developers who create AI and automated decision systems for use in government should agree to waive any trade secrecy or other legal claim that inhibits full auditing and understanding of their software.",
            "Privacy": null,
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "Fairness, accountability, and transparency in AI require a detailed account of the “full stack supply chain.” For meaningful accountability, we need to better understand and track the parts of an AI system and the full supply chain on which it relies: that means accounting for the origins and use of training data, test data, models, application program interfaces (APIs), and other infrastructural components over a product life cycle. We call this accounting for the “full stack supply chain” of AI systems, and it is a necessary condition for a more responsible form of auditing.",
            "Truthfulness": "Consumer protection agencies should apply “truth-in-advertising” laws to AI products and services. AI vendors should be held to high standards for what they can promise, especially when the scientific evidence to back these promises is inadequate and the longer-term consequences are unknown."
        }
    },
    {
        "document_name": "Report on Artificial Intelligence and Human Society",
        "country": "Japan",
        "world_region": "Eastern Asia",
        "institution": "Advisory Board on Artificial Intelligence and Human Society",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2017",
        "number_of_male_authors": "7",
        "number_of_female_authors": "5",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Advisory Board on Artificial Intelligence and Human Society, a Japanese Government initiative of the Minister of State for Science and Technology Policy to assess different societal issues that could be raised by the development and deployment of AI and to discuss its implication for society. The document provides a summary of issues to be addressed regarding AI and human society.",
        "document_url": "https://www8.cao.go.jp/cstp/tyousakai/ai/summary/aisociety_en.pdf",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Determining the locus of responsibility for accidents involving AI technology along with preparing insurance for probabilistic risks contributes to social acceptance and helps users understand the risks of utilizing AI technologies. In-depth analysis and basic research (e.g., social sciences) play an important role in reconsidering fundamental concepts, such as human responsibilities, that the modern law is based on.",
            "Beneficence": "Advancing AI technologies that are beneficial for human society requires basic sciences, including social sciences to study societal issues that may arise in the future, observe the social acceptance of their stochastic behaviors such as deep learning, and create an environment that supports open science to enhance the diversity of AI technologies. Scientists and engineers should collaborate with researchers in the humanities and social sciences for pursuing socially beneficial AI technologies.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "There is a need to create space for dialogue among people with different visions and ideas and to consider common, fundamental social values. The government needs to promote basic sciences and create an environment that supports open science to enhance R&D in AI technology diversity. This will contribute to the advancement, robustness, and safety of AI technologies. Such technological diversity seems suited for social diversity",
            "Autonomy": "A significant action is to consider the balance between human decisions and AI-based decisions depending on the situations and objects to be judged. The balance change causes the emergence of a new sense of ethics. If users confirm AI services that enable them to manipulate someone's mind and/or to evaluate people, discussions of ethics might especially be needed.",
            "Human Formation": "The significant issues are understanding the advantages and limitations of the present AI technologies, properly utilizing AI technologies, and performing creative activities in collaboration with AI technologies. Educational policy functions according to discussions of how to efficiently reform curriculums based on evidence that shows the technologies' limitations, the critical human abilities differentiated from present AI technologies, and the essential human abilities to be acquired. It is important to consider what abilities should be still learned by humans for proper brain development even though the activities enabled by said abilities can be performed instead by AI technologies.",
            "Human-Centeredness": "We also consider addressing the fundamental question, “What values are shared by humans all over the world,” to be unavoidable.",
            "Intellectual Property": null,
            "Fairness": "One of the fundamental issues is the need to facilitate provisions against the \"AI divide,\" unbalanced social costs relative to AI, and discrimination that occurs because of the technologies' procession. Continuous assessments of social pathology, conflict, and dependence on AI technologies will offer solutions to these issues. Potential discrimination based on the output of personal profiling by AI technologies must be prevented",
            "Labor Rights": "Individuals changing their work style and updating their abilities propose to harmonize each person's abilities with a creative job/task. These changes also require that companies reconsider their decision-making techniques and staff (re)assignment to take advantage of work flexibility. At the government level, combining educational and employment policies is one of the effective procedures for mobilizing labor, revitalizing the economy, and preventing economic disparities.",
            "Cooperation": null,
            "Privacy": "Technologies for cyber security and privacy protection must be advanced. It is especially essential to develop technology that enables us to choose how much personal data to share, the level of individual privacy to be protected, and what kind of information can be used publicly.",
            "Reliability": "Technologies for cyber security and privacy protection must be advanced. R&D should be conducted to develop technologies that enable people to control the safety features of AI technologies, to explain the processes and logics of calculations inside AI technologies, to provide interfaces that smoothly perform transitions of control from AI to human, especially in emergencies.",
            "Sustainability": null,
            "Transparency": "Basic research to ensure that AI technologies are controllable and transparent by explaining the processes and logic of calculations made by AI technologies contribute to their social implications.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Tokyo Statement - Useful Artificial Intelligence- Beneficial AI -Cooperation for Realization",
        "country": "Japan",
        "world_region": "Eastern Asia",
        "institution": "Beneficial AI Japan (BAI Japan)",
        "institution_type": "NGO",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Beneficial AI Japan (BAI Japan), a Non-Governmental Organization (NGO) founded based on the Japanese Society for Artificial Intelligence (JSAI) and the International Society for Artificial Life (ISAL). This document contains a statement urging AI stakeholders to address the challenges of ensuring the benefits of artificial intelligence in a spirit of cooperation rather than competition.",
        "document_url": "http://bai-japan.org/tokyo_statement/",
        "attachments": "http://bai-japan.org/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": "Artificial intelligence must be proven to be safe, reliable, robust, and developed in line with the values of the society in which it is utilized.",
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": "We urge you to address the challenges of ensuring the benefits of artificial intelligence in a spirit of cooperation rather than competition. We should work together to ensure that artificial intelligence contributes to the sustainable prosperity of humankind around the world.  Collaboration must be global. Artificial intelligence has a great impact on all cultures and nations. Therefore, all cultures and nations should speak about how artificial intelligence is developed and used. Artificial intelligence has the potential to be one of the best achievements humanity can achieve. We must work together to make it a reality.",
            "Privacy": null,
            "Reliability": "Artificial intelligence must be proven to be safe, reliable, robust, and developed in line with the values of the society in which it is utilized.",
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Understanding artificial intelligence ethics and safety: A guide for the responsible design and implementation of AI systems in the public sector",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "The Alan Turing Institute",
        "institution_type": [
            "Academic",
            "Non-profit Organization"
        ],
        "year_of_publication": "2019",
        "number_of_male_authors": "1",
        "number_of_female_authors": "0",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Alan Turing Institute, which is the United Kingdom's national institute for data science and artificial intelligence, founded in 2015. The Alan Turing Institute is an independent private-sector legal entity, operating not-for-profit and as a charity. The document provides end-to-end guidance on how to apply principles of AI ethics and safety to the design and implementation of algorithmic systems in the public sector, containing exercises and practical tools to help strengthen the process-based governance of an AI project.",
        "document_url": "https://www.turing.ac.uk/sites/default/files/2019-06/understanding_artificial_intelligence_ethics_and_safety.pdf",
        "attachments": "https://www.turing.ac.uk/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "All AI systems must be designed to facilitate end-to-end answerability and audibility. This requires both responsible humans-in-the-loop across the entire design, implementation, and activity monitoring of the system.",
            "Beneficence": "Care for the wellbeing of each and all (i.e., do no harm with these technologies and minimize the risks of their misuse or abuse).",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "Connect with each other sincerely, openly, and inclusively (i.e., prioritize diversity, participation, and inclusion at all points in the design, development, and deployment processes of AI innovation).",
            "Autonomy": "Respect the dignity of individual persons (i.e., ensure their abilities to make free and informed decisions about their own lives).",
            "Human Formation": null,
            "Human-Centeredness": "The demand for sensitivity to human factors should inform your approach to devising delivery and implementation processes from start to finish. To provide clear and effective explanations about the content and rationale of algorithmic outputs, you will have to begin by building from the human ground up. By taking a deliberate and human-centered approach to the delivery process, you should be able to find the most effective way to convey your model's statistical results to users and decision subjects in a non-technical and socially meaningful language that enables them to understand and evaluate the rational justifiability of those results.",
            "Intellectual Property": null,
            "Fairness": "Protect the priorities of social values, justice, and the public interest (i.e., treat all individuals equally and protect social equity). All AI systems that process social or demographic data about features of human subjects must be designed to meet a minimum threshold of discriminatory non-harm.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "Beyond safeguarding the sustainability of your AI project as it relates to its social impacts on individual wellbeing and public welfare, your project team must also confront the related challenge of technical sustainability or safety. A technically sustainable AI system is safe, accurate, reliable, secure, and robust.",
            "Sustainability": "Think big-picture about the wider impacts of the AI technologies you are conceiving and developing. Think about the ramifications of their effects and externalities for others around the globe, for future generations, and the biosphere as a whole. Designers and users of AI systems must remain aware that these technologies have transformative effects on individuals and society.",
            "Transparency": "Designers and implementers of AI systems must be able (1) to explain to affected stakeholders in everyday language how and why a model performed the way it did in a specific context and (2) to justify the ethical permissibility, the discriminatory non-harm, and the public trustworthiness both of its outcome and the processes behind its design and use. Your project team must ensure that every step of the process of designing and implementing your AI project is accessible for audit, oversight, and review. A successful audit requires builders and implementers of algorithmic systems to keep records and to make accessible information that enables monitoring of the soundness and diligence of the innovation processes that produced the AI system.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Safety First for Automated Driving – Proposed technical standards for the development of Automated Driving",
        "country": "Germany",
        "world_region": "Western Europe",
        "institution": "Mercedes-Benz Group",
        "institution_type": "Private Corporation",
        "year_of_publication": "2019",
        "number_of_male_authors": "38",
        "number_of_female_authors": "6",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Mercedes-Benz Group, a German multinational automotive corporation headquartered in Stuttgart, Baden-Württemberg (DE). This document is the collaboration of many industry leaders across the automotive and automated driving technology spectrum (e.g., Aptiv, Audi, Baidu, BMW, Continental, Fiat Chrysler Automobiles, HERE, Infineon, Intel, Volkswagen), and covers all relevant safety methods for Level 3/4 SAE automated driving (i.e., conditional/high automation). The authors also propose a series of guiding principles for tackling the risks introduced by automated vehicles.",
        "document_url": "https://www.heise.de/downloads/18/2/7/0/8/1/7/0/safety-first-for-automated-driving.pdf",
        "attachments": "https://group.mercedes-benz.com/innovation/case/autonomous/safety-first-for-automated-driving-2.html?r=dai",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "Engaging and disengaging the automated driving system shall require an explicit interaction from the vehicle operator, indicating high confidence of intent.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Automated vehicles shall record the relevant data about the status of the automated driving system when an event or incident is recognized in manner that complies with the applicable data privacy laws.",
            "Reliability": "If safety-related functions or system components become hazardous (e.g. unavailable), the automated driving system shall: be capable of compensating and transferring the system to a safe condition/state (with acceptable risk), ensuring a sufficient time frame for the safe transition of control to the vehicle operator. The loss of safety-related functions or system components shall not lead to a safety-related situation.",
            "Sustainability": null,
            "Transparency": "The aspects of the driving task which remain under the user's responsibility must be clear to the user. The automated function must ensure that the currently active driving mode can be recognized explicitly and unmistakably at any time. In addition, a change in driving mode must be clearly apparent to the user as well. The behavior of the automated function needs to not only be easy-to-understand for surrounding (vulnerable) road users, but also predictable and manageable.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Data Ethics Framework",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "Central Digital & Data Office",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2020",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Practical",
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Central Digital & Data Office, which is the office that leads the digital, data, and technology function for the UK government. The document was developed to guide appropriate and responsible data use in government and the wider public sector, helping public servants understand ethical considerations, address these within their projects, and encourage responsible innovation. It is a practical tool (i.e., a data ethics self-assessment tool) to aid the process of planning, implementing, and evaluating projects that use, directly or indirectly, data in the public sector.",
        "document_url": "https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/923108/Data_Ethics_Framework_2020.pdf",
        "attachments": "https://www.gov.uk/government/publications/data-ethics-framework",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Accountability means that there are effective governance and oversight mechanisms for any project. Public accountability means that the public or its representatives are able to exercise effective oversight and control over the decisions and actions taken by the government and its officials, in order to guarantee that government initiatives meet their stated objectives and respond to the needs of the communities they are designed to benefit.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "It is crucial to eliminate your project's potential to have unintended discriminatory effects on individuals and social groups. You should aim to mitigate biases that may influence your model's outcome and ensure that the project and its outcomes respect the dignity of individuals, are just, nondiscriminatory, and consistent with the public interest, including human rights and democratic values.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "Transparency means that your actions, processes, and data are made open to inspection by publishing information about the project in a completely open, understandable, easily accessible, and free format.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Opinion of the Data Ethics Commission",
        "country": "Germany",
        "world_region": "Western Europe",
        "institution": "Data Ethics Commission",
        "institution_type": "NGO",
        "year_of_publication": "2018",
        "number_of_male_authors": "9",
        "number_of_female_authors": "7",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Data Ethics Commission, a German independent expert body, set up by Germany's Federal Government, that operates on its own authority. This document provides ethical benchmarks and guidelines as well as specific recommendations for action, aiming at protecting the individual, preserving social cohesion, and safeguarding and promoting prosperity in the information age. The document also presents a practical tool for assessing the degree of criticality of algorithmic systems: the Criticality pyramid. The degree of criticality should guide legislators and society when seeking suitable regulatory thresholds and instruments, but can also provide developers and operators with guidance for assessing their products and systems themselves and finally also be used in basic, advanced, and further training to educate and increase awareness amongst various stakeholders.",
        "document_url": "https://www.bmi.bund.de/SharedDocs/downloads/EN/themen/it-digital-policy/datenethikkommission-abschlussgutachten-lang.pdf;jsessionid=BFECC67205ED627EE2F6B000AAC7B5DB.1_cid373?__blob=publicationFile&v=4",
        "attachments": "http://www.datenethikkommission.de/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": true,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": true
        },
        "principles_definition": {
            "Accountability": "Another vital aspect of self-determination is that people must not only be allowed to assume responsibility but must do so and do justice to the task. Responsibility always lies with a human – institutionally enshrined, if necessary – never with a machine. Even if a technical system is used to apply inferences based on automated evaluations (i.e. whether or not a loan should be granted), the responsibility for developing and using this system in an ethically sound manner must lie with humans.",
            "Beneficence": "The Data Ethics Commission recommends that measures be taken against ethically indefensible uses of data. Examples of these uses include total surveillance, profiling that poses a threat to personal integrity, the targeted exploitation of vulnerabilities, addictive designs and dark patterns, methods of influencing political elections that are incompatible with the principle of democracy, vendor lock-in, and systematic consumer detriment, and many practices that involve trading in personal data.",
            "Children's Rights": "The Data Ethics Commission calls for action against the significant enforcement gap that exists with regard to the statutory protection of children and young people in the digital sphere. Particular attention should be paid to the development and mandatory provision of technologies (including effective identity management) and default settings that not only guarantee reliable protection of children and young people but that are also family-friendly, i.e. that neither demand too much of parents or guardians nor allow or even encourage excessive surveillance in the home environment.",
            "Human Rights": "Human dignity, which from an ethical viewpoint is synonymous with the unconditional value of every human being and which is enshrined as a “fundamental constitutional principle” in the constitutional order, is of foundational and supreme importance. It follows from the principle of human dignity that every individual merits respect, regardless of his or her attributes and achievements. As far as possible, a culture of “incorporating” the basic principles of democracy, the rule of law, and fundamental rights into the system architecture should be established for the process of designing technology.",
            "Diversity": "It must be ensured by means of a wide range of different measures, which may also and in particular involve inclusion and participation in the development of algorithmic systems.",
            "Autonomy": "Acknowledging human dignity involves recognizing that humans must always be “superior to technology”, i.e. that they must not be completely or irrevocably subordinated to technical systems. The opportunities for configuration and intervention may be localized at different levels in each specific application, but the principle of human sovereignty of action must be upheld. Humans hold responsibility in human/machine interactions, and must not be regarded as defective beings that need to be optimized or perfected by the machine.",
            "Human Formation": "Education and training must also play a prominent role in safeguarding the free democratic basic order, since they influence, in a wide variety of ways, the participation of citizens in the shaping of society – a process that is of critical and fundamental importance for democracy, these citizens' understanding and appraisal of socially relevant interrelationships and developments, and – ultimately – their level of confidence in a future that can be shaped and that is founded on values. Education and training must impart not only technical and mathematical skills but also skills in the fields of ethics, law, economics, and the social sciences.",
            "Human-Centeredness": "At the center is the requirement to strive for algorithmic systems with a human-centered and value-oriented design that takes fundamental rights and freedoms into consideration. The Data Ethics Commission believes that the human-centered approach must permeate the entire design process.",
            "Intellectual Property": null,
            "Fairness": "Protecting human dignity also rules out the use of algorithmic systems to discriminate systematically against individuals or groups, for example by “downgrading” them, preventing them from using certain services for ethically untenable reasons, or systematically misleading them as they participate in the democratic discourse. A key aim in regulating algorithmic systems is to ensure that the decision-making patterns upon which the algorithmic systems are based do not have any systematic distortions (bias) leading to discriminatory and unfair decisions.",
            "Labor Rights": null,
            "Cooperation": "In the world, as it stands today, access to digital resources via the Internet is a fundamental requirement for digital and thus also social participation. As part of its public provision remit, the State is obliged to ensure that its citizens can access up-to-date Internet infrastructure anywhere in the country and to an adequate extent, using either a fixed or a mobile connection. As part of its educational remit, it must provide its citizens with the skills needed for self-determined navigation of the digital world and for an accurate appraisal of the opportunities and risks of Internet use.",
            "Privacy": "The individual's right to determine who may access which personal information relating to him or her, and when and for what purpose they may do so, is justified by the supreme ethical importance of the ability to prevent intrusions into one's private sphere and also to appear in public in the certainty that one's privacy is protected. Efforts to protect human dignity must include legislative measures to regulate the responsible use of personal data.",
            "Reliability": "Guaranteeing security entails compliance with stringent requirements, e.g. in relation to human/machine interaction or system resilience to attacks and misuse. Algorithmic systems must be robust and secure, otherwise, the legitimate goals they are used to pursuing will not be achieved or will be achieved only at the expense of potential harm to ethically and legally protected rights and interests.",
            "Sustainability": "The principle of security relates not only to the physical and emotional safety of humans but also to environmental protection, and as such involves the preservation of vitally important assets.  Malfunctions of algorithmically controlled public infrastructures, e.g. traffic or energy and water supply infrastructures, may cause enormous amounts of damage. The pursuit of sustainability goals set by the United Nations should be a particular focus of public investments into the data economy and algorithmic systems. When allocating government funding, priority should be given not to economic gains which are only short-term in nature, but to the development of data and algorithmic systems for purposes such as recording and monitoring environmental impacts and developments, or systems for optimizing and reducing energy and resource consumption.",
            "Transparency": "An adequate level of transparency and explainability is an essential prerequisite for auditing algorithmic systems appropriately on the basis of their real potential for harm. In order to be able to carry out a reliable ethical and legal assessment of an algorithmic system, it is essential that enough information be available about its scope, functionality, pool of data, and data analysis. Only a truly transparent system can be examined to determine whether it is pursuing a legitimate purpose.",
            "Truthfulness": "Protecting human dignity also involves ensuring that the human as a relational being is not misled by technology about the nature of a relationship; for example, it would be wrong for a human to be systematically deceived into thinking that he or she is speaking with another human when it is a bot. The psychological integrity of the individual is a particularly important factor in protecting human dignity. This rules out the use of data-driven systems for manipulative purposes, particularly when the systems draw on comprehensive and highly granular personality profiles."
        }
    },
    {
        "document_name": "Artificial Intelligence and Data Protection",
        "country": "European Union",
        "world_region": "European Union",
        "institution": "Council of Europe",
        "institution_type": "International Organization",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Large (>10.000 Words, <20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Council of Europe, an international organization founded in the wake of World War II to uphold human rights, democracy, and the rule of law in Europe. The document provides a set of baseline measures that governments, AI developers, manufacturers, and service providers should follow to ensure that AI applications do not undermine the human dignity and the human rights and fundamental freedoms of every individual, in particular concerning the right to data protection.",
        "document_url": "https://rm.coe.int/2018-lignes-directrices-sur-l-intelligence-artificielle-et-la-protecti/168098e1b7",
        "attachments": "https://www.coe.int/en/web/portal/home",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "AI developers, manufacturers, and service providers should adopt forms of algorithm vigilance that promote the accountability of all relevant stakeholders throughout the entire life cycle of these applications, to ensure compliance with data protection and human rights law and principles.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "The protection of human dignity and safeguarding of human rights and fundamental freedoms, in particular the right to the protection of personal data, are essential when developing and adopting AI applications that may have consequences on individuals and society. This is especially important when AI applications are used in decision-making processes.",
            "Diversity": null,
            "Autonomy": "In line with the guidance on a risk assessment provided in the Guidelines on Big Data, adopted by the Committee of Convention 108 in 2017, a wider view of the possible outcomes of data processing should be adopted. This view should consider not only human rights and fundamental freedoms but also the functioning of democracies and social and ethical values. AI applications should allow meaningful control by data subjects over the data processing and related effects on individuals and society.",
            "Human Formation": "Policymakers should invest resources in digital literacy and education to increase data subjects' awareness and understanding of AI applications and their effects. They should also encourage professional training for AI developers to raise awareness and understanding of the potential effects of AI on individuals and society. They should support research in human rights-oriented AI.",
            "Human-Centeredness": "AI developers, manufacturers, and service providers should adopt a values-oriented approach in the design of their products and services, consistent with Convention 108+, in particular with Article 10.2, and other relevant instruments of the Council of Europe.",
            "Intellectual Property": null,
            "Fairness": "In all phases of the processing, including data collection, AI developers, manufacturers, and service providers should adopt a human rights by-design approach and avoid any potential biases, including unintentional or hidden, and the risk of discrimination or other adverse impacts on the human rights and fundamental freedoms of data subjects.",
            "Labor Rights": null,
            "Cooperation": "AI developers, manufacturers, and service providers are encouraged to set up and consult independent committees of experts from a range of fields, as well as engage with independent academic institutions, which can contribute to designing human rights-based and ethically and socially-oriented AI applications, and to detecting potential bias. Such committees may play a particularly important role in areas where transparency and stakeholder engagement can be more difficult due to competing interests and rights, such as in the fields of predictive justice, crime prevention, and detection. Individuals, groups, and other stakeholders should be informed and actively involved in the debate on what role AI should play in shaping social dynamics and in decision-making processes affecting them.",
            "Privacy": "The Parties to Convention 108 will ensure and enable that AI development and use respect the rights to privacy and data protection (Article 8 of the European Convention on Human Rights), thereby enhancing human rights and fundamental freedoms.",
            "Reliability": "An approach focused on avoiding and mitigating the potential risks of processing personal data is a necessary element of responsible innovation in the field of AI. AI developers, manufacturers, and service providers should assess the possible adverse consequences of AI applications on human rights and fundamental freedoms, and, considering these consequences, adopt a precautionary approach based on appropriate risk prevention and mitigation measures.",
            "Sustainability": null,
            "Transparency": "Without prejudice to confidentiality safeguarded by law, public procurement procedures should impose on AI developers, manufacturers, and service providers specific duties of transparency, prior assessment of the impact of data processing on human rights and fundamental freedoms, and vigilance on the potential adverse effects and consequences of AI applications (hereinafter referred to as algorithm vigilance).",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Statement on Artificial Intelligence, Robotics and 'Autonomous‘ Systems",
        "country": "European Union",
        "world_region": "European Union",
        "institution": "European Group on Ethics in Science and New Technologies (EGE)",
        "institution_type": "NGO",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was produced by the European Group on Ethics in Science and New Technologies (EGE). The EGE provides the European Commission with independent advice on all aspects of EU legislation and policies, where ethical, societal, and fundamental rights issues intersect with the development of science and new technologies. The EGE is an independent advisory body of the President of the European Commission, founded in 1991 and formed by members appointed for their expertise in the fields of law, natural and social sciences, philosophy, and ethics. In this document, besides providing a review of some of the main issues debated in AI Ethics, the EGE proposes a set of basic principles and democratic prerequisites, based on the fundamental values laid down in the EU Treaties and in the EU Charter of Fundamental Rights.",
        "document_url": "http://lefis.unizar.es/wp-content/uploads/EGE_Artificial-Intelligence_Statement_2018.pdf",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Rule of law, access to justice and the right to redress and a fair trial provide the necessary framework for ensuring the observance of human rights standards and potential AI-specific regulations. Governments and international organizations ought to increase their efforts in clarifying with whom liabilities lie for damages caused by undesired behavior of ‘autonomous' systems. Moreover, effective harm mitigation systems should be in place.",
            "Beneficence": "The principle of responsibility must be fundamental to AI research and application. ‘Autonomous' systems should only be developed and used in ways that serve the global social and environmental good, as determined by outcomes of deliberative democratic processes. This implies that they should be designed so that their effects align with a plurality of fundamental human values and rights.",
            "Children's Rights": null,
            "Human Rights": "The principle of human dignity, understood as the recognition of the inherent human state of being worthy of respect, must not be violated by ‘autonomous' technologies. This means, for instance, that there are limits to determinations and classifications concerning persons, made based on algorithms and ‘autonomous' systems, especially when those affected by them are not informed about them. It also implies that there have to be (legal) limits to how people can be led to believe that they are dealing with human beings while they are dealing with algorithms and smart machines.",
            "Diversity": "Key decisions on the regulation of AI development and application should be the result of democratic debate and public engagement. A spirit of global cooperation and public dialogue on the issue will ensure that they are taken in an inclusive, informed, and farsighted manner. The right to receive education or access information on new technologies and their ethical implications will facilitate that everyone understands risks and opportunities and is empowered to participate in decisional processes that crucially shape our future.",
            "Autonomy": "The principle of autonomy implies the freedom of the human being. This translates into human responsibility and thus control over and knowledge about ‘autonomous' systems as they must not impair the freedom of human beings to set their own standards and norms and be able to live according to them. All ‘autonomous' technologies must, hence, honor the human ability to choose whether, when, and how to delegate decisions and actions to them.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "AI should contribute to global justice and equal access to the benefits and advantages that AI, robotics, and ‘autonomous' systems can bring. Discriminatory biases in data sets used to train and run AI systems should be prevented or detected, reported, and neutralized at the earliest stage possible.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "‘Autonomous' systems must not interfere with the right to private life which comprises the right to be free from technologies that influence personal development and opinions, the right to establish and develop relationships with other human beings, and the right to be free from surveillance.",
            "Reliability": "Safety and security of ‘autonomous' systems materialize in three forms: (1) external safety for their environment and users, (2) reliability and internal robustness, e.g., against hacking, and (3) emotional safety concerning human-machine interaction. All dimensions of safety must be taken into account by AI developers and strictly tested before release to ensure that ‘autonomous' systems do not infringe on the human right to bodily and mental integrity and a safe and secure environment.",
            "Sustainability": "AI technology must be in line with the human responsibility to ensure the basic preconditions for life on our planet, continued prospering for mankind, and preservation of a good environment for future generations. Strategies to prevent future technologies from detrimentally affecting human life and nature are to be based on policies that ensure the priority of environmental protection and sustainability.",
            "Transparency": "All ‘autonomous' technologies must, hence, honor the human ability to choose whether, when, and how to delegate decisions and actions to them. This also involves the transparency and predictability of ‘autonomous' systems, without which users would not be able to intervene or terminate them if they would consider this morally required.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Report with recommendations to the Commission on Civil Law Rules on Robotics",
        "country": "European Union",
        "world_region": "European Union",
        "institution": "European Parliament",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2017",
        "number_of_male_authors": "2",
        "number_of_female_authors": "1",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the European Parliament (EP). The EP is one of three legislative branches of the European Union and one of its seven institutions. The Parliament is composed of 705 members (MEPs), being the second-largest democratic electorate in the world and the largest trans-national democratic electorate in the world. In this document, the European Parliament proposes a series of recommendations to the European Council regarding the regulation, use, and development of robots and AI. The author proposes a series of definitions for the concepts of \"Robot\" and \"Artificial Intelligence\", as well as recommendations for the use and development of these types of technology to be in line with European values. The document covers topics such as research and innovation, intellectual property rights and the flow of data, ethics (e.g., ethical conduct for robotics engineers), autonomous means of transport, remotely piloted aircraft systems, care/medical robots, human repair and enhancement, education and employment, environmental impact, transport and tourism, and many others.",
        "document_url": "https://www.europarl.europa.eu/doceo/document/A-8-2017-0005_EN.pdf",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": true,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": true,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "The European Parliament considers that the civil liability for damage caused by robots is a crucial issue that also needs to be analyzed and addressed at the Union level to ensure the same degree of efficiency, transparency, and consistency in the implementation of legal certainty throughout the European Union for the benefit of citizens, consumers and businesses alike. Robotics engineers should remain accountable for the social, environmental, and human health impacts that robotics may impose on present and future generations.",
            "Beneficence": "The European Parliament points out that the guiding ethical framework should be based on the principles of beneficence, non-maleficence. Beneficence – robots should act in the best interests of humans; Non-maleficence – the doctrine of ‘first, do not harm', whereby robots should not harm a human.",
            "Children's Rights": "The European Parliament underlines the need to address the psychological and societal impact of human-robot interaction as well as the dual character of the impact of technology on human capabilities, with special attention for vulnerable groups, in particular children, to avoid creating harmful dependence on robots, e.g., through the evocation of emotional response, or isolation of these humans from reality.",
            "Human Rights": "The European Parliament notes that the potential for empowerment through the use of robotics is nuanced by a set of tensions or risks and should be seriously assessed from the point of view of integrity, dignity, and on the principles and values enshrined in Article 2 of the Treaty on European Union and the Charter of Fundamental Rights.",
            "Diversity": "Robotics engineers guarantee transparency and respect for the legitimate right of access to information by all stakeholders. Inclusiveness allows for participation in decision-making processes by all stakeholders involved in or concerned by robotics research activities.",
            "Autonomy": "The European Parliament stresses that the development of robot technology should focus on complementing human capabilities and not on replacing them. The European Parliament considers it essential, in the development of robotics and AI, to guarantee that humans have control over intelligent machines at all times.",
            "Human Formation": "The European Parliament draws attention to the Commission's forecast that by 2020 Europe might be facing a shortage of up to 825 000 ICT professionals and that 90 % of jobs will require at least basic digital skills; welcomes the Commission's initiative of proposing a roadmap for the possible use and revision of a Digital Competence framework and descriptors of Digital Competencies for all levels of learners, and calls upon the Commission to provide significant support for the development of digital abilities in all age groups and irrespective of employment status, as the first step towards better-aligning labor market shortages and demand; stresses that the growth in the robotics requires the Member States to develop more flexible training and education systems so as to ensure that skill strategy matches the needs of the robot economy.",
            "Human-Centeredness": null,
            "Intellectual Property": "The European Parliament calls on the Commission to support a horizontal and technologically neutral approach to intellectual property applicable to the various sectors in which robotics could be employed.",
            "Fairness": "The European Parliament notes that the potential for empowerment through the use of robotics is nuanced by a set of tensions or risks and should be seriously assessed from the point of view of non-discrimination. Justice – the fair distribution of the benefits associated with robotics and affordability of home care and healthcare robots in particular.",
            "Labor Rights": "The European Parliament calls on the Commission to start analyzing and monitoring medium- and long-term job trends more closely, with a special focus on the creation, displacement, and loss of jobs in the different fields/areas of qualification in order to know in which fields jobs are being created and those in which jobs are being lost as a result of the increased use of robots.",
            "Cooperation": "The European Parliament stresses the importance of measures to help small and medium-sized enterprises and start-ups in the robotics sector that create new market segments in this sector or make use of robots.",
            "Privacy": "The European Parliament notes that the potential for empowerment through the use of robotics is nuanced by a set of tensions or risks and should be seriously assessed from the point of view of privacy and data protection. The European Parliament calls on the Commission and the Member States to ensure that civil law regulations in the robotics sector are consistent with the General Data Protection Regulation. The European Parliament emphasizes that the right to the protection of private life and of personal data as enshrined in Article 7 and 8 of the Charter and Article 16 of the Treaty on the Functioning of the European Union (TFEU) apply to all areas of robotics and that the Union legal framework for data protection must be fully complied with.",
            "Reliability": "The European Parliament notes that the potential for empowerment through the use of robotics is nuanced by a set of tensions or risks and should be seriously assessed from the point of view of human safety, health and security. The European Parliament stresses that a high level of security in robotics systems, including their internal data systems and data flows, is crucial to the appropriate use of robots and AI. The European Parliament emphasizes that the protection of networks of interconnected robots and artificial intelligence has to be ensured to prevent potential security breaches.",
            "Sustainability": "The European Parliament notes that the development of robotics and artificial intelligence should be done in such a manner that the environmental impact is limited through effective energy consumption, energy efficiency by promoting the use of renewable energy and scarce materials, and minimal waste, such as electric and electronic waste, and reparability.",
            "Transparency": "The European Parliament highlights the principle of transparency, namely that it should always be possible to supply the rationale behind any decision taken with the aid of AI that can have a substantive impact on one or more persons' lives. The European Parliament considers that it must always be possible to reduce the AI system´s computations to a form comprehensible by humans.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Preparing for the future of Artificial Intelligence",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "National Science and Technology Council (NSTC)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2016",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was produced by the National Science and Technology Council Subcommittee on Machine Learning and Artificial Intelligence. The National Science and Technology Council (NSTC) is the principal means by which the Executive Branch coordinates science and technology policy across the diverse entities that make up the United States Federal research and development (R&D) enterprise. One of the NSTC's primary objectives is establishing clear national goals for Federal science and technology investments. In this document, the authors survey the current state of AI, its existing and potential applications, and the questions that are raised for society and public policy by progress in AI. The report also makes recommendations for specific further actions by Federal agencies and other actors. A companion document called the National Artificial Intelligence Research and Development Strategic Plan lays out a strategic plan for Federally-funded research and development in AI (a 2019 updated version of this plan is also available).",
        "document_url": "https://obamawhitehouse.archives.gov/sites/default/files/whitehouse_files/microsites/ostp/NSTC/preparing_for_the_future_of_ai.pdf",
        "attachments": [
            "https://www.nitrd.gov/pubs/national_ai_rd_strategic_plan.pdf",
            "https://www.nitrd.gov/pubs/National-AI-RD-Strategy-2019.pdf"
        ],
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Agencies should draw on appropriate technical expertise at the senior level when setting regulatory policy for AI-enabled products. Effective regulation of AI-enabled products requires collaboration between agency leadership, staff knowledgeable about the existing regulatory framework and regulatory practices generally, and technical experts with knowledge of AI. Agency leadership should take steps to recruit the necessary technical talent, or identify it in existing agency staff, and should ensure that there are sufficient technical “seats at the table” in regulatory policy discussions.",
            "Beneficence": "Private and public institutions are encouraged to examine whether and how they can responsibly leverage AI and machine learning in ways that will benefit society. Social justice and public policy institutions that do not typically engage with advanced technologies and data science in their work should consider partnerships with AI researchers and practitioners that can help apply AI tactics to the broad social problems these institutions already address in other ways.",
            "Children's Rights": null,
            "Human Rights": "The U.S. Government should complete the development of a single, government-wide policy, consistent with international humanitarian law, on autonomous and semi-autonomous weapons.",
            "Diversity": "The NSTC Subcommittees on MLAI and NITRD, in conjunction with the NSTC Committee on Science, Technology, Engineering, and Education (CoSTEM), should initiate a study on the AI workforce pipeline to develop actions that ensure an appropriate increase in the size, quality, and diversity of the workforce, including AI researchers, specialists, and users. NSF and the Department of Education are working with the private sector and across government to advance education quality, flexibility, and domain impact, to address goals such as sustained economic development, increased inclusion and diversity, and improved outcome measures.",
            "Autonomy": null,
            "Human Formation": "The NSTC Subcommittees on MLAI and NITRD, in conjunction with the NSTC Committee on Science, Technology, Engineering, and Education (CoSTEM), should initiate a study on the AI workforce pipeline in order to develop actions that ensure an appropriate increase in the size, quality, and diversity of the workforce, including AI researchers, specialists, and users.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Federal agencies that use AI-based systems to make or provide decision support for consequential decisions about individuals should take extra care to ensure the efficacy and fairness of those systems, based on evidence-based verification and validation.",
            "Labor Rights": null,
            "Cooperation": "Federal agencies should prioritize open training data and open data standards in AI. The government should emphasize the release of datasets that enable the use of AI to address social challenges. Potential steps may include developing an “Open Data for AI” initiative to release a significant number of government data sets to accelerate AI research and galvanize the use of open data standards and best practices across government, academia, and the private sector.",
            "Privacy": "In light of the future importance of AI in surface and air, Federal actors should focus in the near term on developing increasingly rich sets of data, consistent with consumer privacy, that can better inform policy-making as these technologies mature.",
            "Reliability": "The Department of Transportation should work with industry and researchers on ways to increase sharing of data for safety, research, and other purposes. Schools and universities should include ethics, and related topics in security, privacy, and safety, as an integral part of curricula on AI, machine learning, computer science, and data science. AI professionals, safety professionals, and their professional societies should work together to continue progress toward a mature field of AI safety engineering.",
            "Sustainability": null,
            "Transparency": "Federal agencies that make grants to state and local governments in support of the use of AI-based systems to make consequential decisions about individuals should review the terms of grants to ensure that AI-based products or services purchased with Federal grant funds produce results in a sufficiently transparent fashion and are supported by evidence of efficacy and fairness.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Vienna Manifesto on Digital Humanism",
        "country": "Austria",
        "world_region": "Central Europe",
        "institution": "Digital Humanism Initiative",
        "institution_type": "Academic",
        "year_of_publication": "2019",
        "number_of_male_authors": "22",
        "number_of_female_authors": "10",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Digital Humanism Initiative (DIGHUM), a TU Wien Informatics initiative. TU Wien Informatics is one of Europe's leading research, teaching, and innovation institutions in computer science and Austria's largest faculty of Informatics. DIGHUM is an international collaboration seeking to build a community of scholars, policymakers, and industrial players who are focused on ensuring that technology development remains centered on human interests. This document/manifesto is a call to deliberate and to act on current and future technological development, focusing primarily on the importance of creating human-centric technologies. It proposes several recommendations for the use and development of digital technologies (e.g., AI).",
        "document_url": "https://dighum.ec.tuwien.ac.at/wp-content/uploads/2019/07/Vienna_Manifesto_on_Digital_Humanism_EN.pdf",
        "attachments": "https://dighum.ec.tuwien.ac.at/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Effective regulations, rules, and laws, based on a broad public discourse, must be established. They should ensure prediction accuracy, fairness and equality, accountability, and transparency of software programs and algorithms.",
            "Beneficence": "Practitioners everywhere ought to acknowledge their shared responsibility for the impact of information technologies. They need to understand that no technology is neutral and be sensitized to see both potential benefits and possible downsides. Education on computer science/informatics and its societal impact must start as early as possible. Students should learn to combine information-technology skills with an awareness of the ethical and societal issues at stake.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "Digital technologies should be designed to promote democracy and inclusion. This will require special efforts to overcome current inequalities and to use the emancipatory potential of digital technologies to make our societies more inclusive.",
            "Autonomy": "Decisions with consequences that have the potential to affect individual or collective human rights must continue to be made by humans. Decision-makers must be responsible and accountable for their decisions. Automated decision-making systems should only support human decision-making, not replace it.",
            "Human Formation": "Education on computer science/informatics and its societal impact must start as early as possible. Students should learn to combine information-technology skills with an awareness of the ethical and societal issues at stake. A vision is needed for new educational curricula, combining knowledge from the humanities, the social sciences, and engineering studies. In the age of automated decision-making and AI, creativity and attention to human aspects are crucial to the education of future engineers and technologists.",
            "Human-Centeredness": "We must shape technologies under human values and needs instead of allowing technologies to shape humans. Our task is not only to rein in the downsides of information and communication technologies but to encourage human-centered innovation.",
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": "Regulators need to intervene with tech monopolies. It is necessary to restore market competitiveness as tech monopolies concentrate market power and stifle innovation. Governments should not leave all decisions to markets.",
            "Privacy": "Privacy and freedom of speech are essential values for democracy and should be at the center of our activities. Therefore, artifacts such as social media or online platforms need to be altered to better safeguard the free expression of opinion, the dissemination of information, and the protection of privacy.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Principles for Accountable Algorithms and a Social Impact Statement for Algorithms",
        "country": "Unspecified",
        "world_region": "Unspecified",
        "institution": "Fairness, Accountability, and Transparency in Machine Learning (FAT/ML)",
        "institution_type": "NGO",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "12",
        "number_of_female_authors": "1",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Fairness, Accountability, and Transparency in Machine Learning (FAT/ML), a civil society of researchers and practitioners concerned with fairness, accountability, and transparency in machine learning. From 2014 to 2018, FAT/ML provided an annual event where researchers could present computationally rigorous methods to address issues related to fairness, accountability, and transparency. In this document, the author proposes several core ethical principles that should guide the use and development of AI technologies. The authors also provide a practical tool to help developers create a \"Social Impact Statement for Algorithms,\" which is a statement that should accompany the release of AI models created under the guiding principles proposed by FAT/ML.",
        "document_url": "https://www.fatml.org/resources/principles-for-accountable-algorithms",
        "attachments": "https://www.fatml.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Make available externally visible avenues of redress for adverse individual or societal effects of an algorithmic decision system, and designate an internal role for the person who is responsible for the timely remedy of such issues.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Ensure that algorithmic decisions do not create discriminatory or unjust impacts when comparing across different demographics (e.g. race, sex, etc).",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "Identity, log, and articulate sources of error and uncertainty throughout the algorithm and its data sources so that expected and worst-case implications can be understood and inform mitigation procedures. Enable interested third parties to probe, understand, and review the behavior of the algorithm through disclosure of information that enables monitoring, checking, or criticism, including through the provision of detailed documentation, technically suitable APIs, and permissive terms of use.",
            "Sustainability": null,
            "Transparency": "Ensure that algorithmic decisions, as well as any data driving those decisions, can be explained to end-users and other stakeholders in non-technical terms.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Artificial Intelligence: Economic importance, social challenges, human responsibility",
        "country": "Germany",
        "world_region": "Western Europe",
        "institution": "Bitkom",
        "institution_type": "Industrial Association",
        "year_of_publication": "2017",
        "number_of_male_authors": "49",
        "number_of_female_authors": "6",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by Bitkom, an industry association for the German information and telecommunications industry. The document aims to present and enable discussions on the author's views about the corporate and social responsibility of increased AI use in decision-making processes. The document also presents several recommendations to policy makers and public administrations.",
        "document_url": "https://www.bitkom.org/sites/default/files/file/import/171101-PP-Artificial-Intelligence-ENG-Web.pdf",
        "attachments": "https://www.bitkom.org/EN",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": true,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "The use of algorithms and self-learning systems must be ethically evaluated. Recommendations for legislators, regulators, the economy, and the public sector must be developed. This also includes guidelines on which AI applications are desired and which are not accepted. These challenges should be addressed by policymakers. At the EU level, clarification should be given as to which AI areas are approved and which are not, so that individual countries do not suffer from location disadvantages.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "Particularly responsible decision-making processes ‒ e. g. autonomous driving or in medical diagnostics ‒ should be designed in such a way that the ultimate decision-making authority remains with the responsible actors until the quality of the control system reaches a level that is accepted by all parties involved. Regarding critical processes, the human being should be the ultimate decision-making authority in case of doubt.",
            "Human Formation": "Germany needs an investment spurt in all areas of research, development, and education, especially in AI. The mobilization of AI potential requires focused efforts in many areas. This applies to the entire research landscape, school education, the system of continuing education, and retraining. From now on, massive investments at all levels must be made in digital education, information literacy, and the courage to make one's judgments and decisions.",
            "Human-Centeredness": "Intelligent machines must serve people. People and machines should be able to communicate with each other in the same way as people do with each other ‒ in some respects even better.",
            "Intellectual Property": "The protection of intellectual property is fundamental for technological innovations and must be designed to promote innovations. It must not become a stumbling block for investment and research. This requires a balanced approach and careful consideration.",
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": "One focus should lay on interdisciplinary applied research. Domain-specific knowledge from areas such as medicine, law, manufacturing technology, financial services, logistics, etc. must be more closely connected with AI knowledge. Cooperation between universities and the industry should be intensified to develop practical training and education modules. To apply AI's potential for improving life in a digital society, we will require a digital ethics agenda, for which policymakers should collaborate with scientists.",
            "Privacy": "Where restrictions and impediments to the further development of AI applications based on data protection regulations are identified, which are not necessary for the protection of personal data, amendments must be made, or special legal regulations are created.",
            "Reliability": "When introducing AI-based decision-making processes, it is important to ensure and respect the appropriate level of accuracy concerning documentation and quality assurance.",
            "Sustainability": "All stakeholders in business, politics, and society must accept the ethical and data-ecological responsibility concerning sustainable data economies.",
            "Transparency": "It is desirable that results of IT systems ‒ e. g. calculations, forecasts, follow-up processes, and decisions ‒ are transparent and comprehensible. This particularly applies to AI-based systems, which are often perceived as black-boxes. Comprehensive documentation, including objectives, methods, data, tests, and approval processes, must ensure the highest possible degree of transparency and quality assurance.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Machine learning: the power and promise of computers that learn by example",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "The Royal Society",
        "institution_type": "Academic",
        "year_of_publication": "2017",
        "number_of_male_authors": "17",
        "number_of_female_authors": "15",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Royal Society, a learned (academic) society, and the United Kingdom's national academy of sciences. This document touches on how the Machine Learning (ML) area is developing, together with the societal repercussions of using ML in healthcare, retail, law, and banking. The document also makes a series of recommendations on how to create a data environment to support ML in the UK.",
        "document_url": "https://royalsociety.org/~/media/policy/projects/machine-learning/publications/machine-learning-report.pdf",
        "attachments": "https://royalsociety.org/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": "Schools need to ensure that key concepts in machine learning are taught to those who will be users, developers, and citizens. Government, mathematics and computing communities, businesses, and education professionals should help ensure that relevant insights into machine learning are built into the current education curriculum and associated enrichment activity in schools over the next five years and that teachers are supported in delivering these activities. Government should consider introducing a newly funded program of master's courses in machine learning, potentially in parallel with encouragement for approaches to training in machine learning via Massive Open Online Courses (MOOCs), to increase the pool of informed users of machine learning.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": "Good progress in increasing the accessibility of public sector data has positioned the UK as a leader in this area; continued efforts are needed in a new wave of ‘open data for machine learning' by Government to enhance the availability and usability of public sector data while recognizing the value of strategic datasets.",
            "Privacy": null,
            "Reliability": "Progress in some areas of machine learning research will impact directly on the social acceptability of machine learning in applications and hence on public confidence and trust. Funding bodies should encourage and support research applications in these areas, though not to the exclusion of other areas of machine learning research. These areas include algorithm interpretability, robustness, privacy, fairness, inference of causality, human-machine interactions, and security.",
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Guidance for Regulation of Artificial Intelligence Applications",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "The White House",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2019",
        "number_of_male_authors": "1",
        "number_of_female_authors": "0",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": [
            "Binding",
            "Non-binding"
        ],
        "document_impact": "Short",
        "abstract": "This document was written by the White House, which is the official residence and workplace of the president of the United States. This document sets out policy considerations that should guide, to the extent permitted by law, regulatory and non-regulatory oversight of AI applications developed and deployed outside of the Federal government of the US. The document also provides tools for AI stakeholders to access the compliance of their products whit US regulations: the n OMB Circular A-4, “Regulatory Analysis.\"",
        "document_url": "https://www.whitehouse.gov/wp-content/uploads/2020/01/Draft-OMB-Memo-on-Regulation-of-AI-1-7-19.pdf",
        "attachments": "https://www.whitehouse.gov/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Consistent with law, agencies should take into consideration the following principles when formulating regulatory and non-regulatory approaches to the design, development, deployment, and operation of AI applications, both general and sector-specific. These principles, many of which are interrelated, reflect the goals and principles in Executive Order 13859. When developing regulatory and non-regulatory approaches, agencies should pursue performance-based and flexible approaches that can adapt to rapid changes and updates to AI applications. Rigid, design-based regulations that attempt to prescribe the technical specifications of AI applications will in most cases be impractical and ineffective, given the anticipated pace with which AI will evolve and the resulting need for agencies to react to new information and evidence.",
            "Beneficence": "Consistent with law, agencies should take into consideration the following principles when formulating regulatory and non-regulatory approaches to the design, development, deployment, and operation of AI applications, both general and sector-specific. These principles, many of which are interrelated, reflect the goals and principles in Executive Order 13859. AI is expected to have a positive impact across sectors of social and economic life, including employment, transportation, education, finance, healthcare, personal security, and manufacturing. At the same time, AI applications could pose risks to privacy, individual rights, autonomy, and civil liberties that must be carefully assessed and appropriately addressed.",
            "Children's Rights": null,
            "Human Rights": "A regulatory analysis should begin with a clear explanation of the need for the regulatory action, including a description of the problem that the agency seeks to address. The analysis of these alternatives should also evaluate, where relevant and appropriate, and consistent with Executive Order 13859, impacts to equity, human dignity, fairness, potential distributive impacts, privacy, civil liberties, and personal freedom. The agency's analysis should be based on the best available scientific, technical, and economic information.",
            "Diversity": null,
            "Autonomy": "Consistent with law, agencies should take into consideration the following principles when formulating regulatory and non-regulatory approaches to the design, development, deployment, and operation of AI applications, both general and sector-specific. These principles, many of which are interrelated, reflect the goals and principles in Executive Order 13859. Agencies should provide ample opportunities for the public to provide information and participate in all stages of the rulemaking process, to the extent feasible and consistent with legal requirements (including legal constraints on participation in certain situations, for example, national security preventing imminent threat to or responding to emergencies).",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Consistent with law, agencies should take into consideration the following principles when formulating regulatory and non-regulatory approaches to the design, development, deployment, and operation of AI applications, both general and sector-specific. These principles, many of which are interrelated, reflect the goals and principles in Executive Order 13859. Agencies should consider, in accordance with the law, issues of fairness and non-discrimination with respect to outcomes and decisions produced by the AI application at issue, as well as whether the AI application at issue may reduce levels of unlawful, unfair, or otherwise unintended discrimination as compared to existing processes.",
            "Labor Rights": null,
            "Cooperation": "Consistent with law, agencies should take into consideration the following principles when formulating regulatory and non-regulatory approaches to the design, development, deployment, and operation of AI applications, both general and sector-specific. These principles, many of which are interrelated, reflect the goals and principles in Executive Order 13859. Agencies should coordinate with each other to share experiences and to ensure consistency and predictability of AI-related policies that advance American innovation and growth in AI, while appropriately protecting privacy, civil liberties, and American values and allowing for the sector- and application-specific approaches when appropriate.",
            "Privacy": null,
            "Reliability": "Consistent with law, agencies should take into consideration the following principles when formulating regulatory and non-regulatory approaches to the design, development, deployment, and operation of AI applications, both general and sector-specific. These principles, many of which are interrelated, reflect the goals and principles in Executive Order 13859. Agencies should promote the development of AI systems that are safe, secure, and operate as intended, and encourage the consideration of safety and security issues throughout the AI design, development, deployment, and operation process.",
            "Sustainability": null,
            "Transparency": "Consistent with law, agencies should take into consideration the following principles when formulating regulatory and non-regulatory approaches to the design, development, deployment, and operation of AI applications, both general and sector-specific. These principles, many of which are interrelated, reflect the goals and principles in Executive Order 13859. Agencies should carefully consider the sufficiency of existing or evolving legal, policy, and regulatory environments before contemplating additional measures for disclosure and transparency. What constitutes appropriate disclosure and transparency is context-specific, depending on assessments of potential harms, the magnitude of those harms, the technical state of the art, and the potential benefits of the AI application.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Tieto's AI ethics guidelines",
        "country": "Finland",
        "world_region": "Northern Europe",
        "institution": "Tietoevry Corporation",
        "institution_type": "Private Corporation",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Tietoevry Corporation (Tieto), a Finnish IT software, and service company providing IT and product engineering services. This document presents Tieto's ethical guidelines, which serve as a foundation for all Tieto employees who develop or use AI in any capacity. The document can be understood as Tieto's voluntary self-commitment to the ethical development and use of AI.",
        "document_url": "https://www.tietoevry.com/en/newsroom/all-news-and-releases/press-releases/2018/10/tieto-strengthens-commitment-to-ethical-use-of-ai/",
        "attachments": "https://www.tietoevry.com/en/",
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "At Tieto, we are committed to harnessing AI for good, for the planet, and for humankind.",
            "Children's Rights": null,
            "Human Rights": "At Tieto, we are committed to ensuring the freedom and liberty of people to serve the social good.",
            "Diversity": "At Tieto, we are committed to unbiased, fair, and inclusive AI fostering diversity and equality among people.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "At Tieto, we are committed to unbiased, fair, and inclusive AI fostering diversity and equality among people.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "At Tieto, we are committed to building AI systems that prevent misuse and reduce the risk of being compromised.",
            "Sustainability": null,
            "Transparency": "At Tieto, we are committed to striving towards AI that can be explained and explain itself.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "A guide to using artificial intelligence in the public sector",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "Government Digital Service (GDS), Office for Artificial Intelligence (OAI)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": [
            "Binding",
            "Non-binding"
        ],
        "document_impact": "Short",
        "abstract": "This document was written by the Government Digital Service (GDS),  a unit of the Government of the United Kingdom's Cabinet Office tasked with transforming the provision of online public services, and the Office for Artificial Intelligence (OAI), a part of the Department for Digital, Culture, Media & Sport and the Department for Business, Energy & Industrial Strategy responsible for overseeing the implementation of the National AI Strategy. This document is a part of a wider collection about using AI in the public sector. This document cover questions on how to assess if using AI will help you meet user needs, how the public sector can best use AI, and how to implement AI ethically, fairly, and safely. The collection brings a practical tool to guide the design of appropriate data use in the public sector: the Data Ethics Framework.",
        "document_url": "https://www.gov.uk/government/publications/understanding-artificial-intelligence/a-guide-to-using-artificial-intelligence-in-the-public-sector",
        "attachments": "https://www.gov.uk/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "With an AI project you should consider several factors, including AI ethics and safety. hese factors span safety, ethical, legal and administrative concerns and include: accountability - consider who is responsible for each element of the model's output and how the designers and implementers of AI systems will be held accountable.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "With an AI project you should consider several factors, including AI ethics and safety. hese factors span safety, ethical, legal and administrative concerns and include: fairness - are the models trained and tested on relevant, accurate, and generalisable datasets and is the AI system deployed by users trained to implement them responsibly and without bias.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "With an AI project you should consider several factors, including AI ethics and safety. hese factors span safety, ethical, legal and administrative concerns and include: privacy - complying with appropriate data policies, for example the General Data Protection Regulations (GDPR) and the Data Protection Act 2018.",
            "Reliability": "With an AI project you should consider several factors, including AI ethics and safety. hese factors span safety, ethical, legal and administrative concerns and include: data quality - the success of your AI project depends on the quality of your data.",
            "Sustainability": null,
            "Transparency": "With an AI project you should consider several factors, including AI ethics and safety. hese factors span safety, ethical, legal and administrative concerns and include: explainability and transparency - so the affected stakeholders can know how the AI model reached its decision.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "AI in the UK: ready, willing and able?",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "House of Lords",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2018",
        "number_of_male_authors": "10",
        "number_of_female_authors": "3",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Select Committee on Artificial Intelligence, a body appointed by the House Of Lords, which is the upper house of the Parliament of the United Kingdom. The document presents a thorough review of the AI research field, its history, paradigms, and current repercussions in our society, together with a list of recommendations and suggested principles (\"AI Code\"). It also presents practical tools (e.g., DPIA's - Data Protection Impact Assessments) for implementing ethical principles in AI development.",
        "document_url": "https://publications.parliament.uk/pa/ld201719/ldselect/ldai/100/100.pdf",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": true
        },
        "principles_definition": {
            "Accountability": "We recommend that the Law Commission consider the adequacy of existing legislation to address the legal liability issues of AI and, where appropriate, recommend to Government appropriate remedies to ensure that the law is clear in this area.",
            "Beneficence": "Artificial intelligence should be developed for the common good and benefit of humanity. The autonomous power to hurt, destroy or deceive human beings should never be vested in artificial intelligence.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "We recommend that a specific challenge be established within the Industrial Strategy Challenge Fund to stimulate the creation of authoritative tools and systems for auditing and testing training datasets to ensure they are representative of diverse populations, and to ensure that when used to train AI systems they are unlikely to lead to prejudicial decisions.",
            "Autonomy": "We recommend that the Government and Ofcom commission research into the possible impact of AI on conventional and social media outlets, and investigate measures that might counteract the use of AI to mislead or distort public opinion as a matter of urgency.",
            "Human Formation": "All citizens have the right to be educated to enable them to flourish mentally, emotionally, and economically alongside artificial intelligence.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Artificial intelligence should operate on principles of intelligibility and fairness. The Government must outline its plans to tackle any potential societal or regional inequality caused by AI, and this must be explicitly addressed as part of the implementation of the Industrial Strategy",
            "Labor Rights": null,
            "Cooperation": "We recommend that wherever possible and appropriate, and with regard to its potential commercial value, publicly-held data be made available to AI researchers and developers.",
            "Privacy": "Artificial intelligence should not be used to diminish the data rights or privacy of individuals, families, or communities.",
            "Reliability": "We recommend that universities and research councils providing grants and funding to AI researchers must insist that applications for such money demonstrate an awareness of the implications of the research and how it might be misused, and include details of the steps that will be taken to prevent such misuse before any funding is provided. We recommend that the Cabinet Office's final Cyber Security Science & Technology Strategy take into account the risks as well as the opportunities of using AI in cybersecurity applications, and applications more broadly.",
            "Sustainability": null,
            "Transparency": "Artificial intelligence should operate on principles of intelligibility and fairness. The Government must understand the need to build public trust and confidence in how to use artificial intelligence, as well as explain the risks. The industry should take the lead in establishing voluntary mechanisms for informing the public when artificial intelligence is being used for significant or sensitive decisions concerning consumers.",
            "Truthfulness": "The autonomous power to hurt, destroy or deceive human beings should never be vested in artificial intelligence."
        }
    },
    {
        "document_name": "Fairwork Principles",
        "country": [
            "Germany",
            "United Kingdom"
        ],
        "world_region": "Western Europe",
        "institution": "Oxford Internet Institute, WZB Berlin Social Science Center",
        "institution_type": "Academic",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Fairwork,  a project based at the Oxford Internet Institute (a multi-disciplinary department of social and computer science dedicated to the study of information, communication, and technology) and the WZB Berlin Social Science Centre (an internationally renowned research institute for the social sciences). The Fairwork project evaluates the working conditions of digital platforms and ranks them based on our five principles of fair work. The Fairwork Principles were developed through a collaborative process that reflects the insights of our international network and the voices of workers around the world.",
        "document_url": "https://fair.work/en/fw/principles/",
        "attachments": "https://fair.work/en/fw/homepage/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": true,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": "Workers, irrespective of their employment classification, should earn a decent income in their home jurisdiction after taking account of work-related costs and active hours worked. They should be paid on time, and for all work completed. Platforms should have policies in place to protect workers from foundational risks arising from the processes of work and should take proactive measures to protect and promote the health and safety of workers. Terms and conditions should be transparent, concise, and always accessible to workers. The party contracting with the worker must be subject to local law and must be identified in the contract. Workers are notified of proposed changes in a reasonable timeframe before changes come into effect. The contract is free of clauses that unreasonably exclude liability on the part of the platform, and which prevent workers from seeking redress for grievances. Contracts should be consistent with the terms of workers' engagement on the platform. There should be a documented due process for decisions affecting workers. Workers must have the ability to appeal decisions affecting them, such as disciplinary actions and deactivation, and be informed of the reasons behind those decisions. The use of algorithms is transparent and results in equitable outcomes for workers. There should be an identifiable and documented policy that ensures equity in the way workers are managed on a platform (for example, in the hiring, disciplining, or firing of workers). Platforms should provide a documented process through which worker voice can be expressed. Irrespective of their employment classification, workers have the right to organize in collective bodies, and platforms should be prepared to cooperate and negotiate with them.",
            "Cooperation": null,
            "Privacy": null,
            "Reliability": null,
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Preliminary Study on the Ethics of Artificial Intelligence",
        "country": "United Nations",
        "world_region": "Intergovernmental Organization",
        "institution": "United Nations Educational, Scientific and Cultural Organization (UNESCO)",
        "institution_type": "International Organization",
        "year_of_publication": "2019",
        "number_of_male_authors": "11",
        "number_of_female_authors": "4",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the United Nations Educational, Scientific and Cultural Organization (UNESCO),  a specialized agency of the United Nations (UN) aimed at promoting world peace and security through international cooperation in education, arts, sciences, and culture. The document builds on the work of COMEST on Robotics Ethics (2017) and the Ethical Implications of the Internet of Things (IoT), being a preliminary study prepared by a COMEST Extended Working Group on AI Ethics. It presents UNESCO's perspective on AI Ethics, which according to the authors: \"the most central ethical issues regarding Artificial Intelligence concern its implications for culture and cultural diversity, education, scientific knowledge, and communication and information.\" The author of the document also suggests several generic principles for the development, implementation, and use of AI.",
        "document_url": "https://unesdoc.unesco.org/ark:/48223/pf0000367823",
        "attachments": "https://www.unesco.org/en",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": true
        },
        "principles_definition": {
            "Accountability": "Developers and companies should take into consideration ethics when developing autonomous intelligent systems. Arrangements should be developed that will make it possible to attribute accountability for AI-driven decisions and the behavior of AI systems.",
            "Beneficence": "AI should be developed to enhance the quality of life.",
            "Children's Rights": null,
            "Human Rights": "AI should be developed and implemented in accordance with international human rights standards. AI should be developed, implemented, and used in line with democratic principles.",
            "Diversity": "AI should foster cultural diversity, inclusiveness, and the flourishing of human experience, avoiding a deepening of the digital divide. A multilingual approach should be promoted.",
            "Autonomy": "AI should respect human autonomy by requiring human control at all times.",
            "Human Formation": "Algorithm awareness and a basic understanding of the workings of AI are needed to empower citizens. AI requires that education fosters AI literacy, critical thinking, resilience in the labor market, and education ethics for engineers.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "AI should be inclusive, aiming to avoid bias and allowing for diversity, and avoiding a new digital divide. Gender bias should be avoided in the development of algorithms, in the datasets used for their training, and in their use in decision-making.",
            "Labor Rights": null,
            "Cooperation": "AI should be integrated into national development policies and strategies by drawing on endogenous cultures, values, and knowledge to develop African economies.  To contribute to peace, AI could be used to obtain insights into the drivers of conflict, and should never operate out of human control.",
            "Privacy": null,
            "Reliability": null,
            "Sustainability": "For all AI applications, the potential benefits need to be balanced against the environmental impact of the entire AI and IT production cycle. AI should be developed in a sustainable manner taking into account the entire AI and IT production cycle. AI can be used for environmental monitoring and risk management, and to prevent and mitigate environmental crises.",
            "Transparency": "AI should be explainable, able to provide insight into its functioning. The data used to train AI systems should be transparent.",
            "Truthfulness": "AI should strengthen freedom of expression, universal access to information, the quality of journalism, and free, independent, and pluralistic media while avoiding the spreading of disinformation. Multi-stakeholder governance should be promoted."
        }
    },
    {
        "document_name": "Report of COMEST on robotics ethics",
        "country": "United Nations",
        "world_region": "Intergovernmental Organization",
        "institution": "United Nations Educational, Scientific and Cultural Organization (UNESCO)",
        "institution_type": "International Organization",
        "year_of_publication": "2017",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the United Nations Educational, Scientific and Cultural Organization (UNESCO), a specialized agency of the United Nations (UN) aimed at promoting world peace and security through international cooperation in education, arts, sciences, and culture. In this document, the authors address the topic of ethics in robotics, as well as the ethics of nanotechnologies and converging technologies (e.g., AI). It also provides a list of ethical principles and recommendations for ethics in robotics.",
        "document_url": "https://unesdoc.unesco.org/ark:/48223/pf0000253952?posInSet=3&",
        "attachments": "https://www.unesco.org/en",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Deterministic robots, and even sophisticated cognitive robots, cannot take any ethical responsibility, which lies with the designer, manufacturer, seller, user, and the State. Therefore, human beings should always be in the loop and find ways to control robots by different means (e.g., traceability, off switch, etc.) to maintain human moral and legal responsibility.",
            "Beneficence": "‘Do not harm' principle is a red line for robots. Like many technologies, a robot has the potential for ‘dual-use'. Robots are usually designed for good and useful purposes (to diminish the harmfulness of work for example), to help human beings, not to harm or kill them. In this regard, Isaac Asimov's formulation of this principle (three laws) is still accurate (see paragraph 18. If we are morally serious about this ethical principle, then we have to ask ourselves whether armed drones and autonomous weapons should be banned.",
            "Children's Rights": null,
            "Human Rights": "Human dignity is a core value related to the Universal Declaration of Human Rights (UN, 1948). It recognizes that being free and equal, all human beings “are endowed with reason and conscience and should act towards one another in a spirit of brotherhood” (Art. 1). Dignity is inherent to human beings, not to machines or robots. Therefore, robots and humans are not to be confused even if an android robot has the seductive appearance of a human, or if a powerful cognitive robot has a learning capacity that exceeds individual human cognition. Robots are not humans – they are the result of human creativity and they still need a technical support system and maintenance to be effective and efficient tools or mediators.",
            "Diversity": "A greater sensitivity to cultural and gender issues should drive research and innovation in robotics. Due to the diversity of cultures, robots – especially social robots – may be accepted in certain settings and not in others.",
            "Autonomy": "Human Formation/Education: The appropriate educational system and additional training of existing workers need to be established and adjusted so that this latest technological revolution does not result in producing a mass of unemployable workers due to their lack of skills with the latest technologies.",
            "Human Formation": "Human-Centeredness/Alignment: When designing robotic technologies, ethical considerations should be taken into account. Robots use algorithms to make decisions, which embody ethical values and frameworks. In addition, robots have ethical implications for the practices in which they are used, like health care, education, and social interactions. To address these ethical dimensions of robots, ethics needs to be part of the design process, building on approaches like the Value Sensitive Design approach. This approach should also be adapted to consider animal welfare.",
            "Human-Centeredness": "Freedom/Autonomy/Democratic Values/Technological Sovereignty: The recognition of human dignity implies that the value of autonomy does not solely concern the respect for individual autonomy, which can go as far as to refuse to be under the charge of a robot. The value of autonomy also expresses the recognition of the interdependency of the relationship between humans, between humans and animals, and between humans and the environment.",
            "Intellectual Property": null,
            "Fairness": "The value of justice is also related to non-discrimination. Roboticists should be sensitized to the reproduction of gender bias and sexual stereotypes in robots. The issue of discrimination and stigmatization through data mining collected by robots is not trivial. Adequate measures need to be taken by States. Particular attention should be paid to gender issues and stereotyping concerning all types of robots described in this report, and in particular, toy robots, sex companions, and job replacements.",
            "Labor Rights": "Robots will increasingly displace humans in a wide range of areas and so lead to a significant reduction in job opportunities in certain sectors. It will also give rise to new job opportunities. States, professional organizations, and educational institutions should therefore consider the implications of this, paying particular attention to those sections of society likely to be most vulnerable to the changes, and make appropriate provisions for retraining and retooling of the workforce to enable the potential advantages to be realized.",
            "Cooperation": null,
            "Privacy": "The value of privacy is related to Article 12 of the Universal Declaration of Human Rights (UN, 1948) which states that: No one shall be subjected to arbitrary interference with his privacy, family, home, or correspondence, nor to attacks upon his honor and reputation. Everyone has the right to the protection of the law against such interference or attacks.",
            "Reliability": "The private use of drones should be under license, and their areas of operation are subject to strict control for safety, privacy, and legal reasons. It should be unlawful to equip domestic drones with either lethal or non-lethal weapons.",
            "Sustainability": "Interdependency implies that robots are part of our technical creations (part of the technocosm that we construct) and they also have environmental impacts (e-waste, energy consumption and CO2 emissions, ecological footprint) that must be considered and evaluated in the balance of benefit and risk. While constructing robots (nano, micro, or macro), efforts should be made to use degradable materials and environmentally friendly technology and to improve the recycling of materials.",
            "Transparency": "Given the complexity of the design, construction, and programming of robots, a central ethical issue is ‘traceability': the possibility to track the causes of all past actions (and omissions) of a robot.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Top 10 Principles for Ethical Artificial Intelligence",
        "country": "Switzerland",
        "world_region": "Western Europe",
        "institution": "UNI Global Union",
        "institution_type": "International Organization",
        "year_of_publication": "2020",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by UNI Global Union,  a global union federation representing more than 20 million workers in the services sectors in 150 countries. The document offers several principles and specific points of action, which unions, shop stewards and global alliances must implement in collective agreements, global framework agreements, and multinational alliances. According to the authors, taking these recommendations into action will ensure workers' rights and influence in the age of digitalization.",
        "document_url": "http://www.thefutureworldofwork.org/media/35420/uni_ethical_ai.pdf",
        "attachments": "https://uniglobalunion.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "An absolute precondition is that the development of AI must be responsible, safe, and useful, where machines maintain the legal status of tools, and legal persons retain control over, and responsibility for, these machines at all times. UNI Global Union asserts that legal responsibility for a robot should be attributed to a person. Robots are not responsible parties under the law.",
            "Beneficence": "Lethal autonomous weapons, including cyber warfare, should be banned.",
            "Children's Rights": null,
            "Human Rights": "Throughout their entire operational process, AI systems remain compatible and increase the principles of human dignity, integrity, freedom, privacy, and cultural and gender diversity, as well as fundamental human rights.",
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": "As AI systems develop and augmented realities are formed, workers and work tasks will be displaced. To ensure a just transition, as well as sustainable future developments, it is vital that corporate policies are put in place that ensure corporate accountability in relation to this displacement, such as retraining programs and job change possibilities. Governmental measures to help displaced workers retrain and find new employment are additionally required. AI systems coupled with the wider transition to the digital economy will require that workers on all levels and in all occupations have access to social security and to continuous lifelong learning to remain employable. It is the responsibility of states and companies to find solutions that provide all workers, in all forms of work, the right to and access to both.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "In the design and maintenance of AI, it is vital that the system is controlled for harmful human-bias, and that any bias—be it gender, race, sexual orientation, age, etc.—is identified and is not propagated by the system.",
            "Labor Rights": "In a world where the casualization or individualization of work is rising, all workers in all forms of work must have the same, strong social and fundamental rights. All AI systems must include a check and balance on whether their deployment and augmentation go hand in hand with workers' rights as laid out in human rights laws, ILO conventions, and collective agreements. An algorithm “8798” reflecting the core ILO conventions 87 and 98 that are built into the system could serve that very purpose. Upon failure, the system must be shut down.",
            "Cooperation": "AI technologies should benefit and empower as many people as possible. The economic prosperity created by AI should be distributed broadly and equally, to benefit all of humanity. Global as well as national policies aimed at bridging the economic, technological, and social digital divide are therefore necessary. UNI recommends the establishment of multi-stakeholder Decent Work and Ethical AI governance bodies on global and regional levels. The bodies should include AI designers, manufacturers, owners, developers, researchers, employers, lawyers, CSOs, and trade unions. Whistleblowing mechanisms and monitoring procedures to ensure the transition to, and implementation of, ethical AI must be established.",
            "Privacy": null,
            "Reliability": null,
            "Sustainability": "Transparency/Explainability/Auditability: A transparent artificial intelligence system is one in which it is possible to discover how, and why, the system made a decision, or in the case of a robot, acted the way it did. Workers must be consulted on AI systems' implementation, development, and deployment. Workers must have the right to demand transparency in the decisions and outcomes of AI systems as well as the underlying algorithms. This includes the right to appeal decisions made by AI/algorithms and have them reviewed by a human being.",
            "Transparency": "Sustainability: AI systems must protect and even improve our planet's ecosystems and biodiversity.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Introducing Unity's Guiding Principles for Ethical AI",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Unity Technologies",
        "institution_type": "Private Corporation",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Unity Technologies, a video game software development company based in San Francisco (US). In this document, Unity presents principles meant as a blueprint for the responsible use of AI for its developers, community, and company. The document can be understood as Unity's voluntary self-commitment to the ethical use and development of their AI applications.",
        "document_url": "https://blog.unity.com/technology/introducing-unitys-guiding-principles-for-ethical-ai",
        "attachments": "https://unity.com/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": true
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "Do not develop AI tools aimed at the suppression of human rights, as defined by the Universal Declaration of Human Rights, such as the right to free expression.",
            "Diversity": "Design AI tools to complement the human experience in a positive way. Consider all types of human experiences in this pursuit. Diversity of perspective will lead to AI complementing experiences for everybody, as opposed to a select few.",
            "Autonomy": "Do not knowingly develop AI tools and experiences that interfere with normal, functioning democratic systems of government.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "Reliability/Safety/Security/Trustworthiness: Consider the potential negative consequences of the AI tools we build. Anticipate what might cause potential direct or indirect harm and engineer to avoid and minimize these problems. Guard the AI-derived data as if it were handed to you by your customer directly in trust to only be used as directed under the other principles found in this guide.",
            "Truthfulness": "Transparency/Explainability/Auditability: Trust the users of the technology to understand the product's purpose so they can make informed decisions about whether to use the product. Be clear and be transparent."
        }
    },
    {
        "document_name": "ACM Code of Ethics and Professional Conduct",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Association for Computing Machinery (ACM)",
        "institution_type": [
            "Non-profit Organization",
            "Professional Association"
        ],
        "year_of_publication": "2018",
        "number_of_male_authors": "15",
        "number_of_female_authors": "11",
        "document_size": "Large (>10.000 Words, <20.000 Words)",
        "document_nature": [
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Association for Computing Machinery (ACM). ACM is a US-based international non-profit professional membership group based in New York City (US). The ACM Code of Ethics and Professional Conduct seeks to guide professionals into acting responsibly and consistently with the support of the public good. The Code is composed of 25 rules of conduct that approach general ethical principles, professional responsibilities, professional leadership principles, and rules of compliance with the Code. The document also provides fictional case studies to illustrate how computing professionals can apply the Code as a framework for analyzing ethical dilemmas, suggesting also a practical methodology for analyzing such situations (i.e., CARE - Consider, Analyze, Review, Evaluate.)",
        "document_url": "https://www.acm.org/binaries/content/assets/about/acm-code-of-ethics-booklet.pdf",
        "attachments": "https://www.acm.org/",
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": true,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": true
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "A computing professional should contribute to society and human well-being, acknowledging that all people are stakeholders in computing.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": "A computing professional should ensure that the public good is the central concern during all professional computing work. People—including users, customers, colleagues, and others affected directly or indirectly—should always be the central concern in computing.",
            "Intellectual Property": "A computing professional should respect the work required to produce new ideas, inventions, creative works, and computing artifacts. Computing professionals should therefore credit the creators of ideas, inventions, work, and artifacts, and respect copyrights, patents, trade secrets, license agreements, and other methods of protecting authors' works.",
            "Fairness": "A computing professional should be fair and take action not to discriminate. Computing professionals should foster the fair participation of all people, including those of underrepresented groups. Prejudicial discrimination based on age, color, disability, ethnicity, family status, gender identity, labor union membership, military status, nationality, race, religion or belief, sex, sexual orientation, or any other inappropriate factor is an explicit violation of the Code. Harassment, including sexual harassment, bullying, and other abuses of power and authority, is a form of discrimination that, amongst other harms, limits fair access to the virtual and physical spaces where such harassment takes place.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "A computing professional should respect privacy. Computing professionals should only use personal information for legitimate ends and without violating the rights of individuals and groups. This requires taking precautions to prevent re-identification of anonymized data or unauthorized data collection, ensuring the accuracy of data, understanding the provenance of the data, and protecting it from unauthorized access and accidental disclosure.",
            "Reliability": "Computing professionals should perform due diligence to ensure the system functions as intended, and take appropriate action to secure resources against accidental and intentional misuse, modification, and denial of service.",
            "Sustainability": "Computing professionals should promote environmental sustainability both locally and globally.",
            "Transparency": "A computing professional should accept and provide an appropriate professional review. High-quality professional work in computing depends on professional review at all stages. Whenever appropriate, computing professionals should seek and utilize peer and stakeholder reviews. Computing professionals should also provide constructive, critical reviews of others' work.",
            "Truthfulness": "A computing professional should be honest and trustworthy. Computing professionals should be honest about their qualifications, and about any limitations in their competence to complete a task. Computing professionals should be forthright about any circumstances that might lead to either real or perceived conflicts of interest or otherwise tend to undermine the independence of their judgment. Furthermore, commitments should be honored. Computing professionals should protect confidentiality except in cases where it is evidence of a violation of law, organizational regulations, or the Code. In these cases, the nature or contents of that information should not be disclosed except to appropriate authorities. Computing professionals should respectfully address inaccurate or misleading information related to computing."
        }
    },
    {
        "document_name": "Montréal declaration for a responsible development of artificial intelligence",
        "country": "Canada",
        "world_region": "North America",
        "institution": "University of Montréal",
        "institution_type": "Academic",
        "year_of_publication": "2018",
        "number_of_male_authors": "9",
        "number_of_female_authors": "9",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the University of Montréal, a French-language public research university in Montreal, Quebec (Canada). The document presents an ethical framework for the development and deployment of AI, identifying ethical principles and values that promote the fundamental interests of people and groups.",
        "document_url": "https://www.montrealdeclaration-responsibleai.com/_files/ugd/ebc3a3_506ea08298cd4f8196635545a16b071d.pdf",
        "attachments": "https://www.montrealdeclaration-responsibleai.com/the-declaration",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": true
        },
        "principles_definition": {
            "Accountability": "The development and use of AI must not contribute to lessening the responsibility of human beings when decisions must be made. Only human beings can be held responsible for decisions stemming from recommendations made by AI, and the actions that proceed therefrom.",
            "Beneficence": "AI must help individuals improve their living conditions, their health, and their working conditions. AI must allow individuals to pursue their preferences, so long as they do not cause harm to other sentient beings.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "The development and use of AI must be compatible with maintaining social and cultural diversity and must not restrict the scope of lifestyle choices or personal experiences. From the moment algorithms are conceived, AIS development and deployment must take into consideration the multitude of expressions of social and cultural diversity present in society.",
            "Autonomy": "AI must allow individuals to fulfill their moral objectives and their conception of a life worth living. AI must not be developed or used to impose a particular lifestyle on individuals, whether directly or indirectly, by implementing oppressive surveillance and evaluation of incentive mechanisms. People must have extensive control over information regarding their preferences. AI must not create individual preference profiles to influence the behavior of the individuals without their free and informed consent.",
            "Human Formation": "It is crucial to empower citizens regarding digital technologies by ensuring access to the relevant forms of knowledge, promoting the learning of fundamental skills (digital and media literacy), and fostering the development of critical thinking.",
            "Human-Centeredness": "AI must be developed with the goal of collaborating with humans on complex tasks and should foster collaborative work between humans.",
            "Intellectual Property": null,
            "Fairness": "The development and use of AI must contribute to the creation of a just and equitable society. AI must be designed and trained so as not to create, reinforce, or reproduce discrimination based on — among other things — social, sexual, ethnic, cultural, or religious differences. AI development must help eliminate relationships of domination between groups and people based on differences in power, wealth, or knowledge.",
            "Labor Rights": "Industrial AI development must be compatible with acceptable working conditions at every step of their life cycle, from natural resources extraction to recycling, including data processing.",
            "Cooperation": "The development of AIS must be compatible with maintaining the bonds of solidarity among people and generations. Artificial intelligence research should remain open and accessible to all. We should support the development of commons algorithms — and of open data needed to train them — and expand their use, as a socially equitable objective.",
            "Privacy": "Personal spaces in which people are not subjected to surveillance or digital evaluation must be protected from the intrusion of AI and data acquisition and archiving systems (DAAS). The intimacy of thoughts and emotions must be strictly protected from AI and DAAS uses capable of causing harm, especially uses that impose moral judgments on people or their lifestyle choices. DAAS must guarantee data confidentiality and personal profile anonymity.",
            "Reliability": "Every person involved in AI development must exercise caution by anticipating, as far as possible, the adverse consequences of AIS use and by taking the appropriate measures to avoid them. Before being placed on the market and whether they are offered for a charge or for free, AI must meet strict reliability, security, and integrity requirements and be subjected to tests that do not put people's lives in danger, harm their quality of life, or negatively impact their reputation or psychological integrity. These tests must be open to the relevant public authorities and stakeholders.",
            "Sustainability": "The development and use of AIS must be carried out so as to ensure a strong environmental sustainability of the planet. AIS hardware, its digital infrastructure, and the relevant objects on which it relies such as data centers, must aim for the greatest energy efficiency and to mitigate greenhouse gas emissions over its entire life cycle",
            "Transparency": "AI must meet intelligibility, justifiability, and accessibility criteria, and must be subjected to democratic scrutiny, debate, and control. AI processes that make decisions affecting a person's life, quality of life, or reputation must be intelligible to their creators",
            "Truthfulness": "AI must not be developed to spread untrustworthy information, lies, or propaganda, and should be designed to contain their dissemination. The development of AI must avoid creating dependencies through attention-capturing techniques or the imitation of human characteristics (appearance, voice, etc.) in ways that could cause confusion between AI and humans."
        }
    },
    {
        "document_name": "Ethical Framework for Artificial Intelligence in Colombia (Marco Ético para la Inteligencia Artificial en Colombia)",
        "country": "Colombia",
        "world_region": "Latin America",
        "institution": "Departamento Administrativo de la Presidencia de la República",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2021",
        "number_of_male_authors": "2",
        "number_of_female_authors": "2",
        "document_size": "Large (>10.000 Words, <20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document is an updated version of the Ethical Framework for Artificial Intelligence in Colombia 2020. It was written by the Administrative Department of the Presidency of the Republic of Colombia, which assists the President of the Republic in his capacity as Head of Government. The Colombia Ethical Framework seeks to ensure that Colombian people (especially the younger population) are protected from the potential negative impacts of AI, that they can take full advantage of the opportunities of this technology, and have the skills necessary to shape both the future development of AI technologies and the policies surrounding these technologies. The document also seeks to provide recommendations and suggestions to Public Entities (but not limited to them) to address the formulation and management of projects that include the use of Artificial Intelligence (AI), together with some applicable tools for the implementation of these recommendations.",
        "document_url": "https://inteligenciaartificial.gov.co/static/img/MARCO_ETICO.pdf",
        "attachments": "https://inteligenciaartificial.gov.co/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": true,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "The people who design an algorithm are responsible for the results it generates and the criteria used to arrive at certain answers. Those involved in the development of this technology must establish clear responsibilities in the design, production, and implementation chain.",
            "Beneficence": "Artificial intelligence systems must not affect the integrity and physical and mental health of the human beings with whom they interact. Codes of conduct should generate parameters to avoid activities that endanger the integrity and physical safety of people. Artificial intelligence systems implemented in Colombia must allow or be directly related to an activity that generates a clear and determinable social benefit.",
            "Children's Rights": "It is necessary to create guidelines that protect and materialize the best interests of the child in this particular context. Artificial intelligence systems must recognize, respect, and privilege the rights of children and adolescents.",
            "Human Rights": null,
            "Diversity": "The State must use artificial intelligence systems that have complied with inclusion criteria and respond to the specific needs of historically marginalized and diverse populations.",
            "Autonomy": "Artificial intelligence systems should not be used to interact with the citizenry without the control of a human being. Automated response and conversation systems should have mechanisms for humans to intervene and participate at any time. Human control must be proportional to the level of risk. Technology applications with a higher probability and severity must have greater human control than those with a lower risk. The most transcendental decisions can only be taken by human beings, and, in any case, the algorithms will serve as models to guide the decisions that humans make regarding the life and integrity of others.",
            "Human Formation": "Training and education programs should be generated to enable children and adolescents to know and understand the characteristics of this technology and its implications, highlighting ethical training.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Artificial intelligence systems cannot have results or responses that undermine the welfare of a specific group or limit the rights of historically marginalized populations. There must be a constant analysis of this impact and even consider mechanisms for immediately withdrawing systems that have discriminatory effects.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Artificial intelligence must be preceded by respect for the privacy of individuals and their private sphere that prevents the use of information that they have not authorized.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "This principle should be understood as the openness to provide meaningful and understandable information on the design, operation, and impact of artificial intelligence systems both for the developers and users of the system and for those individuals who may be affected by its decisions and results. The information should be easily accessible and understandable, to promote the active participation of citizens in the design, implementation, and evaluation of AI systems.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "fAIr LAC: Responsible and Widespread Adoption of Artificial Intelligence in Latin America and the Caribbean",
        "country": "Unspecified",
        "world_region": "Latin America",
        "institution": "Inter-American Development Bank (IDB), fAIr LAC",
        "institution_type": "International Organization",
        "year_of_publication": "2020",
        "number_of_male_authors": "2",
        "number_of_female_authors": "2",
        "document_size": "Large (>10.000 Words, <20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Inter-American Development Bank (IDB) and the fAIr LAC (an initiative led by the IDB). IDB is the largest source of development financing for Latin America and the Caribbean, and the fAIr LAC is a partnership between the public and private sectors, civil society, and academic institutions, designed to influence public policy and the entrepreneurial ecosystem in the promotion of the responsible and ethical use of AI. This document addresses some of the challenges and opportunities that AI has to offer to society, along with the lines of action that the fAIr LAC initiative proposes for Latin America and the Caribbean. The document also gives a very concise and informative description of the AI research field, its history, and its paradigms. The document advocates for the OECD´s Principles on Artificial Intelligence, published in 2019 and adopted by many Latin American countries (e.g., Argentina, Brazil, Colombia, Costa Rica, Mexico, and Peru). As a final contribution, the document presents the fAIr LAC Model, a high-level governance framework recommendation to address three strategic dimensions of actions: (1) the creation of a diverse network of governance (Government, Civil Society, Private Sector, Citizenship); (2) training and education for responsible adoption of AI; and (3) quality promotion and risk mitigation.",
        "document_url": "https://publications.iadb.org/en/fair-lac-responsible-and-widespread-adoption-of-artificial-intelligence-in-latin-america-and-the-caribbean#:~:text=and%20the%20Caribbean-,fAIr%20LAC%3A%20Responsible%20and%20Widespread%20Adoption%20of%20Artificial%20Intelligence,Latin%20America%20and%20the%20Caribbean&text=Artificial%20Intelligence%20(AI)%20presents%20a,Latin%20America%20and%20the%20Caribbean.",
        "attachments": "https://fairlac.iadb.org/en",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "AI actors should be accountable for the proper functioning of AI systems and respect the above principles, based on their roles, the context, and consistent with the state of art.",
            "Beneficence": "Stakeholders should proactively engage in responsible stewardship of trustworthy AI in pursuit of beneficial outcomes for people and the planet, such as augmenting human capabilities and enhancing creativity.",
            "Children's Rights": null,
            "Human Rights": "AI actors should respect the rule of law, human rights, and democratic values, throughout the AI system lifecycle.",
            "Diversity": "Stakeholders should proactively engage in advancing the inclusion of underrepresented populations, reducing economic, social, gender, and other inequalities.",
            "Autonomy": "AI actors should respect the rule of law, human rights, and democratic values, throughout the AI system lifecycle. These include freedom and autonomy. AI actors should implement mechanisms and safeguards, such as the capacity for human determination, that are appropriate to the context and consistent with the state of art.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "AI actors should respect the rule of law, human rights, and democratic values, throughout the AI system lifecycle. These include non-discrimination and equality.",
            "Labor Rights": "AI actors should respect the rule of law, human rights, and democratic values, throughout the AI system lifecycle. These include labor rights.",
            "Cooperation": null,
            "Privacy": "AI actors should respect the rule of law, human rights, and democratic values, throughout the AI system lifecycle. These include privacy and data protection.",
            "Reliability": "AI systems should be robust, secure, and safe throughout their entire lifecycle so that, in conditions of normal use, foreseeable use or misuse, or other adverse conditions, they function appropriately and do not pose an unreasonable safety risk.",
            "Sustainability": "Stakeholders should proactively engage in protecting natural environments, thus invigorating inclusive growth, sustainable development, and well-being.",
            "Transparency": "AI Actors should commit to transparency and responsible disclosure regarding AI systems. To this end, they should provide meaningful information, appropriate to the context, and consistent with the state of art: (i) to foster a general understanding of AI systems, (ii) to make stakeholders aware of their interactions with AI systems, including in the workplace, (iii) to enable those affected by an AI system to understand the outcome, and, (iv) to enable those adversely affected by an AI system to challenge its outcome based on plain and easy-to-understand information on the factors, and the logic that served as the basis for the prediction, recommendation or decision.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Artificial Intelligence for Children: Beijing Principles",
        "country": "China",
        "world_region": "Eastern Asia",
        "institution": "Beijing Academy of Artificial Intelligence (BAAI), Peking University, Tsinghua University, Chinese Academy of Sciences",
        "institution_type": "Academic",
        "year_of_publication": "2020",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document is the result of a cooperation between the Beijing Academy of Artificial Intelligence (BAAI), Peking University, Tsinghua University, the Chinese Academy of Sciences, together with enterprises that focus on AI development. The document seeks to bring awareness to the needs of children. The document presents several ethical principles for the use, development, and governance of AI in light of children's rights.",
        "document_url": "https://www-pre.baai.ac.cn/ai-for-children.html",
        "attachments": "https://www-pre.baai.ac.cn/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": true,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "AI development policies and ethical norms to protect children's rights and interests should be studied and formulated. Research on the potential impact of AI on children should be strengthened, forward-looking codes of conduct, laws, and regulations, technical specifications should be formulated, and long-term follow-up studies and periodic assessment mechanisms should be established. Stakeholders of AI should consciously and strictly abide by the code of conduct, laws, regulations, and technical specifications related to children.",
            "Beneficence": "The development of AI should help protect and promote children's physical and mental safety. AI should help protect children from all forms of physical or mental violence, injury or abuse, neglect or negligent treatment, maltreatment or exploitation, including sexual abuse, and help combat child trafficking, indecency, and other crimes. The development of AI should help protect and promote children's physical and mental health.",
            "Children's Rights": "The development of AI should protect and promote the benefits of children, avoid depriving and harming children's rights, and help realize the healthy growth of children. The development of AI should give priority to benefiting children. The research, design, development, deployment, and use of AI should prioritize the needs, rights, and interests of children, prioritize the adequate protection of children, and prioritize the promotion of children's development.",
            "Human Rights": "The development of AI should safeguard children's dignity. The development of AI should value and respect children's own thoughts, wishes, emotions, interests, self-esteem, etc., and should avoid harm to their personal dignity.",
            "Diversity": null,
            "Autonomy": "The development of AI should help protect children's right to freely express their opinions and wishes. Through appropriate channels, AI developers should seriously listen to, value, and consider the opinions of children. Children should be allowed to express their opinions and wishes freely when interacting with AI. Parents, legal guardians, or other caregivers can help children interact with AI while taking their wishes into account.",
            "Human Formation": "The development of AI should protect and promote the free development and diversified growth of children. AI should promote the development of children's multiple intelligences and personalities, actively provide feedback to children's curiosity, help stimulate children's potential, and help guide children to form sound and scientific values. The development of AI should help provide a more inclusive, fairer, and quality education for children.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "The development of AI should treat and serve all children fairly and should not cause discrimination or harm to any child. The research and application of AI shall not make any distinction as to the child's, his or her parent's, legal guardians, or other caregivers' race, color, gender, language, religion, political or other opinions, nationality, or social origin, property, disability, birth or another status, as far as the fundamental rights of the child are concerned.",
            "Labor Rights": null,
            "Cooperation": "Children, parents, legal guardians, or other caregivers, as well as governments, relevant companies, civil society, and people from all walks of life, should be encouraged to participate in the discussion of the potential impact of AI on children. A cross-regional, global, and comprehensive AI governance open cooperation platform should be established to share governance experience and methods of AI for children, to promote the common development of global governance of AI for children, and to empower the healthy development of children all over the world in the era of AI.",
            "Privacy": "The development of AI should protect children's privacy in a much stricter manner. The collection of information on children should follow the principle of \"legal, proper, and necessary,\" ensure their guardians' informed consent and avoid illegal collection and abuse of children's information. AI systems should ensure that children, parents, legal guardians, or other caregivers have the right to consent, refuse, erase data, revoke authorizations, etc.",
            "Reliability": "The application of AI should adhere to strict and prudent principles, strive to control and minimize the potential risks to children. Considering that the influence of AI on children's psychology, physiology, and behaviors is still to be studied, and children's thinking and behaviors are highly uncertain, AI technology and products for children should conform to higher standards and requirements in terms of maturity, robustness, reliability, controllability, safety, and security, etc.",
            "Sustainability": "The development of AI should uphold a responsible attitude towards the next generations, fully consider and try to reduce and avoid the potential ethical, legal, and social impacts and risks that AI might bring to children. The continued benefits for children's growth and development should be regarded as the development goal of AI for children. Attention should be paid to the uncertainty in the long-term application of AI on children, and short-sightedness that might bring in negative impacts on children in pursuit of short-term benefits should be avoided.",
            "Transparency": "AI models, products, applications, and services should, based on continuous efforts to improve their transparency and interpretability, further consider the cognitive levels, self-needs, and expression abilities of children at different stages, provide the corresponding level of transparency and explanations, and provide children with effective feedback mechanisms and interaction methods.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Social Principles of Human-Centric AI",
        "country": [
            "Japan",
            "United Kingdom"
        ],
        "world_region": [
            "Eastern Asia",
            "Western Europe"
        ],
        "institution": "Council for Social Principles of Human-centric AI",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Council for Social Principles of Human-centric AI, an initiative led by the Cabinet Office (a department of the Government of the United Kingdom responsible for supporting the prime minister and Cabinet of the United Kingdom) and the Government of Japan. The document presents a set of AI social principles, also identifying some issues to consider in AI R&D and social implementation. The objective of these principles is the realization of a \"Society 5.0\" in Japan, i.e., a sustainable human-centric society that implements AI, IoT (Internet of Things), robotics, and other cutting-edge technologies to create unprecedented value, and a wide range of people can realize their own well-being while respecting the well-being of others.",
        "document_url": "https://www.cas.go.jp/jp/seisaku/jinkouchinou/pdf/humancentricai.pdf",
        "attachments": "https://www.cas.go.jp/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "We should not build a society where humans are overly dependent on AI or where AI is used to control human behavior through the excessive pursuit of efficiency and convenience. We need to construct a society where human dignity is respected and, by using AI as a tool, a society where people can better demonstrate their various human abilities, show greater creativity, engage in challenging work, and live richer lives both physically and mentally.",
            "Diversity": "It is preferred that the use of AI will create an environment in which many people can engage in highly creative and productive work. To that end, it is expected that a diverse range of people will acquire the ability to realize their dreams and ideas with AI's support despite many differences in origin, culture, taste, and so on.",
            "Autonomy": "In a society making use of AI, we should introduce appropriate mechanisms for literacy education and the promotion of proper use of AI so that people do not become over-dependent on AI or misuse AI to manipulate other people's decision-making.",
            "Human Formation": "To prevent generating disparities between people or to create socially vulnerable individuals, opportunities for education in a wide range of literacy skills are to be provided in early childhood education and primary and secondary education. Opportunities are also to be provided for the reeducation of working adults and the elderly. Concerning literacy education and skills required to use AI, our society needs an educational system that allows anyone to acquire the basics of AI, mathematics, and data science. These characteristics include bias in data, the possibility of causing bias depending on how AI is used, and issues of fairness, impartiality, and privacy protection that are inherently needed in the use of AI.",
            "Human-Centeredness": "The utilization of AI must not infringe upon the fundamental human rights guaranteed by the Constitution and international standards. AI should be developed, utilized, and implemented in society to expand the abilities of people and allow diverse people to pursue their well-being.",
            "Intellectual Property": null,
            "Fairness": "Under AI's design concept, all people are treated fairly without unjustified discrimination on the grounds of diverse backgrounds such as race, gender, nationality, age, political beliefs, religion, and so on.",
            "Labor Rights": null,
            "Cooperation": "A fair competitive environment must be maintained to create new businesses and services, maintain sustainable economic growth, and present solutions to social challenges. Even if resources related to AI are concentrated in a specific country, we must not have a society where unfair data collection and infringement of sovereignty are performed under that country's dominant position. To realize Society 5.0 and aim for continuous innovation that advances as people evolve together with AI development, we should transcend boundaries such as national borders, industries, academia, governments, race, gender, nationality, age, political convictions, and religion.",
            "Privacy": "AI using personal data should have mechanisms to ensure accuracy and legitimacy, and to allow individuals to be substantially involved in managing the privacy of their data. This would make it possible for people to provide personal data with peace of mind when using AI, and effectively benefit from the data they provide. Personal data must be protected appropriately according to its degree of importance and sensitivity.",
            "Reliability": "Society must promote broad, deep research and development related to AI (from immediate measures to deep essential understanding), such as the proper assessment of risks in the utilization of AI and research to reduce risks. Society must make firm efforts to conduct risk management including safeguarding cybersecurity.",
            "Sustainability": "We need to use AI to create a succession of new businesses and solutions, resolve social disparities, and develop a sustainable society that can deal with issues such as global environmental problems and climate change. Japan, as a leading science and technology-oriented country, should strengthen its accumulated scientific and technological resources by utilizing AI and thereby contributing to the creation of such a sustainable society.",
            "Transparency": "Appropriate explanations should be given on a case-by-case basis depending on the application of AI and each particular situation, including such things as when AI is being used, how the AI data is obtained and used, and what measures have been taken to ensure the appropriateness of results obtained from AI operations. For people to understand AI's proposals and make judgments on them, there should be appropriate opportunities for an open dialogue, as required, regarding the use, adoption, and operation of AI.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "The Toronto Declaration",
        "country": [
            "Canada",
            "United Kingdom"
        ],
        "world_region": [
            "North America",
            "Western Europe"
        ],
        "institution": "Amnesty International, Access Now",
        "institution_type": [
            "NGO",
            "Non-profit Organization"
        ],
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by Amnesty International, an international non-governmental organization focused on human rights, headquartered in the UK, and Access Now, a non-profit organization with a mission to defend and extend the digital civil rights of people around the world. This document builds on existing discussions, principles, and papers exploring the harms arising from AI technology, complementing this existing work by reaffirming the role of human rights law and standards in protecting individuals and groups from discrimination in any context. The document also presents a set of norms and principles for the ethical development and use of AI technologies.",
        "document_url": "https://www.torontodeclaration.org/declaration-text/english/",
        "attachments": "https://www.torontodeclaration.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "States must ensure and require accountability and maximum possible transparency around public sector use of machine learning systems. This must include explainability and intelligibility in the use of these technologies so that the impact on affected individuals and groups can be effectively scrutinized by independent entities, responsibilities established, and actors held to account.  According to the UN Committee on Economic, Social and Cultural Rights, “States parties must therefore adopt measures, which should include legislation, to ensure that individuals and entities in the private sphere do not discriminate on prohibited grounds”.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "Human rights law sets standards and provides mechanisms to hold public and private sector actors accountable where they fail to fulfill their respective obligations and responsibilities to protect and respect rights. It also requires that everyone must be able to obtain effective remedy and redress where their rights have been denied or violated. States bear the primary duty to promote, protect, respect, and fulfill human rights. Under international law, states must not engage in or support discriminatory or otherwise rights-violating actions or practices when designing or implementing machine learning systems in a public context or through public-private partnerships. States must refrain altogether from using or requiring the private sector to use tools that discriminate, lead to discriminatory outcomes, or otherwise harm human rights. Private sector actors have a responsibility to respect human rights; this responsibility exists independently of state obligations.",
            "Diversity": "This Declaration underlines that inclusion, diversity, and equity are key components of protecting and upholding the right to equality and non-discrimination. All must be considered in the development and deployment of machine learning systems to prevent discrimination, particularly against marginalized groups. Additional protection must extend to those groups, including protections for sensitive data. States should proactively adopt diverse hiring practices and engage in consultations to assure diverse perspectives so that those involved in the design, implementation, and review of machine learning represent a range of backgrounds and identities.",
            "Autonomy": null,
            "Human Formation": "States should ensure that public bodies carry out training in human rights and data analysis for officials involved in the procurement, development, use, and review of machine learning tools.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Discrimination is defined under international law as “any distinction, exclusion, restriction or preference which is based on any ground such as race, color, sex, language, religion, political or other opinions, national or social origin, property, birth or another status, and which has the purpose or effect of nullifying or impairing the recognition, enjoyment or exercise by all persons, on an equal footing, of all rights and freedoms.” This list is non-exhaustive as the United Nations High Commissioner for Human Rights has recognized the necessity of preventing discrimination against additional classes. Governments have obligations and private sector actors have responsibilities to proactively prevent discrimination to comply with existing human rights laws and standards. When prevention is not sufficient or satisfactory, and discrimination arises, a system should be interrogated and harm addressed immediately. All actors, public and private, must prevent and mitigate discrimination risks in the design, development, and application of machine learning technologies. They must also ensure that there are mechanisms allowing for access to an effective remedy in place before deployment and throughout a system's lifecycle.",
            "Labor Rights": null,
            "Cooperation": "We call on states and private sector actors to work together and play an active and committed role in protecting individuals and groups from discrimination. When creating and deploying machine learning systems, they must take meaningful measures to promote accountability and human rights, including, but not limited to, the right to equality and non-discrimination, as per their obligations and responsibilities under international human rights law and standards.",
            "Privacy": null,
            "Reliability": "Any state deploying machine learning technologies must thoroughly investigate systems for discrimination and other rights risks before development or acquisition, where possible, before use, and on an ongoing basis throughout the lifecycle of the technologies, in the contexts in which they are deployed. This may include: conducting regular impact assessments before public procurement, taking appropriate measures to mitigate risks identified through impact assessments, subjecting systems to live, regular tests and audits, disclosing known limitations of the system in question.  Where the risk of discrimination or other rights violations has been assessed to be too high or impossible to mitigate, private sector actors should not deploy a machine learning system in that context.",
            "Sustainability": null,
            "Transparency": "Transparency is a key component of human rights due diligence, and involves “communication, providing a measure of transparency and accountability to individuals or groups who may be impacted and to other relevant stakeholders.” States should publicly disclose where machine learning systems are used in the public sphere, provide information that explains in clear and accessible terms how automated and machine learning decision-making processes are reached, and document actions are taken to identify, document, and mitigate against discriminatory or other rights-harming impacts. States should enable independent analysis and oversight by using auditable systems. States should avoid using ‘black box systems that cannot be subjected to meaningful standards of accountability and transparency, and refrain from using these systems at all in high-risk contexts.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Position on Robotics and Artificial Intelligence",
        "country": "European Union",
        "world_region": "European Union",
        "institution": "European Green Digital Coalition (EGDC)",
        "institution_type": "International Organization",
        "year_of_publication": "2016",
        "number_of_male_authors": "4",
        "number_of_female_authors": "1",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the European Green Digital Coalition (EGDC), a group formed by 26 CEOs of ICT companies who signed a Declaration to support the Green and Digital Transformation of the EU on Digital Day 2021. The main aim of the EGDC is to maximize the sustainability benefits of digitalization. According to the authors, this document serves as an initial step toward forming an opinion to help shape the debate in the European Union political group and for the public debate in general. The document also presents a set of principles, recommendations, and standards to help guide the development of robotics and AI to a more beneficial and sustainable outcome.",
        "document_url": "https://felixreda.eu/wp-content/uploads/2017/02/Green-Digital-Working-Group-Position-on-Robotics-and-Artificial-Intelligence-2016-11-22.pdf",
        "attachments": "https://digital-strategy.ec.europa.eu/en/policies/european-green-digital-coalition",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": false,
            "Truthfulness": true
        },
        "principles_definition": {
            "Accountability": "Humans, not robots, are responsible agents. Lawmakers should make sure that the development and commercial use of emerging technologies comply with existing laws and fundamental rights. The person with legal responsibility for a robot should be attributed. Regarding safety and security, producers shall be held responsible despite non-liability clauses in user agreements that may exist.",
            "Beneficence": "We demand that research and technology are integrated to the maximum benefit of all and avoid potential unintended social impacts, especially when talking about emerging technologies like robotics and artificial intelligence. Robots should not be designed to kill or harm humans.",
            "Children's Rights": null,
            "Human Rights": "The use and implementation of emerging technologies must take place according to guaranteed individual rights and fundamental freedoms and in particular human integrity (physical and mental integrity), human dignity, and identity. We underline the primacy of the human being over the sole interest of science or society.",
            "Diversity": "Nobody is to judge whether a technological self-modification is useful or necessary except for the individuals themselves. Inclusion and diversity must be the highest priority of our societies. The dignity of persons with or without disabilities is inviolable.",
            "Autonomy": "In accordance with responsible research and innovation, it is imperative to apply the precautionary principle and assess the long-term ethical implications of new technologies in the early phase of their development. We demand respect for the autonomy of persons; the right to information (linked to the right to consent); the requirement for free and informed consent with a wide definition of “intervention” including preventive care, diagnosis (including invasive diagnostic acts), treatment, rehabilitation, and research; protection of persons not able to consent. We believe a person's autonomy can only be fully respected when their right to information and consent are protected, including the protection of persons who are not able to consent.",
            "Human Formation": "We call for employers to help workers acquire new skills and make education and training a core issue to absorb potential shocks in the job market.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": "We demand that software and its source code needs to be accessible and freely useable, at least to the owner of a device and their deputies. Given the - possibly unprecedentedly far-reaching - risks inherent to software coding impacting citizens' future lives and body integrity, the exclusive rights on computer programs should be subject to reinforced exceptions (such as reverse engineering, not to be overridden by contract) taking into account the specific risk of these AI programs, be it present, imminent or potential. Algorithms not protected by copyright but protected otherwise, e.g., by trade secrets, should be subject to the same possibility of reverse-engineering. We call for a revision and modification of the copyright rules and other exclusive rights norms in order to explicitly allow this. We promote an open environment, from open standards and innovative licensing models, to open platforms and transparency, in order to avoid vendor lock-in that restrains interoperability.",
            "Privacy": "Lawmakers should make sure that the development and commercial use of emerging technologies comply with existing laws and fundamental rights, including privacy by design. The development process should follow the principles of data minimization. Whenever personal data is used, it shall be adequate, relevant, and limited to what is necessary concerning the purposes for which they are processed.",
            "Reliability": "Robots as products should be designed to be safe, secure, and fit for purpose, as other products. We propose that robots and artificial intelligence should be developed and produced based on an impact assessment, to the best available technical standards regarding security, and with the possibility to intervene.",
            "Sustainability": "We call for an increase in energy efficiency by promoting the use of renewable technologies for robotics, the use, and reuse of secondary raw materials, and the reduction of waste. We underline that the possible positive gains that robotics and AI could have on the environment should not be dismissed, but rather taken seriously in the fight against climate change.",
            "Transparency": null,
            "Truthfulness": "Robots are manufactured artifacts. They should not be designed in a deceptive way to exploit vulnerable users; instead, their machine nature should be transparent."
        }
    },
    {
        "document_name": "Governing Artificial Intelligence: Upholding human rights & dignity",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Data & Society",
        "institution_type": "Non-profit Organization",
        "year_of_publication": "2018",
        "number_of_male_authors": "1",
        "number_of_female_authors": "0",
        "document_size": "Large (>10.000 Words, <20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Data & Society, an independent nonprofit research organization that studies the social implications of data-centric technologies & automation. According to the author, this document is intended as a resource for anyone working in the field of AI and governance. It presents a reframing of the societal impacts of AI systems through the lens of human rights. The document also presents a series of recommendations on how a human rights approach could be practically implemented through policy, practice, and organizational changes.",
        "document_url": "https://datasociety.net/wp-content/uploads/2018/10/DataSociety_Governing_Artificial_Intelligence_Upholding_Human_Rights.pdf",
        "attachments": "https://datasociety.net/",
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "In order for AI to benefit the common good, at the very least it's design and deployment should avoid harm to fundamental human values. International human rights provide a robust and global formulation of those values.",
            "Children's Rights": null,
            "Human Rights": "Technology companies should find effective channels of communication with local civil society groups and researchers, particularly in geographic areas where human rights concerns are high, to identify and respond to risks related to AI deployments. Governments should acknowledge their human rights obligations and incorporate a duty to protect fundamental rights in national AI policies, guidelines, and possible regulations. Governments can play a more active role in multilateral institutions, like the UN, to advocate for AI development that respects human rights.",
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": "Since human rights principles were not written as technical specifications, human rights lawyers, policymakers, social scientists, computer scientists, and engineers should work together to operationalize human rights into business models, workflows, and product design. Academics should further examine the value, limitations, and interactions between human rights law and human dignity approaches, humanitarian law, and ethics concerning emerging AI technologies. Human rights and legal scholars should work with other stakeholders on the tradeoffs between rights when faced with specific AI risks and harms. Social science researchers should empirically investigate the on-the-ground impact of AI on human rights.",
            "Privacy": null,
            "Reliability": "Technology companies and researchers should conduct Human Rights Impact Assessments (HRIAs) through the life cycle of their AI systems. Researchers should reevaluate HRIA methodology for AI, particularly in light of new developments in algorithmic impact assessments. Toolkits should be developed to assess specific industry needs.",
            "Sustainability": null,
            "Transparency": "UN human rights investigators and special rapporteurs should continue researching and publicizing the human rights impacts resulting from AI systems. UN officials and participating governments should evaluate whether existing UN mechanisms for international rights monitoring, accountability, and redress are adequate to respond to AI and other rapidly emerging technologies. UN leadership should also assume a central role in international technology debates by promoting shared global values based on fundamental rights and human dignity.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "DataEthics: Principles and Guidelines for Companies, Authorities & Organisations",
        "country": "Denmark",
        "world_region": "Northern Europe",
        "institution": "DataEthics",
        "institution_type": "Non-profit Organization",
        "year_of_publication": "2017",
        "number_of_male_authors": "0",
        "number_of_female_authors": "4",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by DataEthics, a not-for-profit politically independent ThinkDoTank based in Denmark. The document presents a set of data ethics principles and guidelines to help the integration of data ethics in data processing activities (e.g., training of machine learning models). The document also provides a self-assessment tool in the form of a Q&A to help developers measure the alignment of their organizations with the principles presented by the document.",
        "document_url": "https://dataethics.eu/wp-content/uploads/Dataethics-uk.pdf",
        "attachments": "https://dataethics.eu/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Accountability is an organization's reflective, reasonable and systematic use and protection of personal data. Accountability is an integral part of all aspects of data processing, and efforts are being made to reduce the risks for the individual and mitigate social and ethical implications. Sustainable personal data processing is embedded throughout the organization and ensures ethical accountability in the short, medium, and long term. An organization's accountability should also apply to subcontractors' and partners' processing of data.",
            "Beneficence": "Data processes should be designed as sustainable solutions benefitting first and foremost humans.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "Humans should be in control of their data and empowered by their data. A person's self-determination should be prioritized in all data processes and the person should be actively involved in regards to the data recorded about them. The individual has the primary control over the usage of their data, the context in which his/her data is processed, and how it is activated.",
            "Human Formation": null,
            "Human-Centeredness": "Justice/Equity/Fairness/Non-discrimination: Democratic data processing is based on an awareness of the societal power relations that data systems sustain, reproduce or create. When processing data, special attention should be paid to vulnerable people, who are particularly vulnerable to profiling that may adversely affect their self-determination and control or expose them to discrimination or stigmatization, for example, due to their financial, social, or health-related conditions. Paying attention to vulnerable people also involves working actively to reduce bias in the development of self-learning algorithms.",
            "Intellectual Property": null,
            "Fairness": "Human-Centeredness/Alignment: Human interests always prevail over institutional and commercial interests. People are not computer processes or pieces of software, but unique with empathy, self-determination, unpredictability, intuition, and creativity and therefore have a higher status than machines. The human being is at the center and has the primary benefit of data processing.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "Data processing activities and automated decisions must make sense for the individual. They must be truly transparent and explainable. The purpose and interests of data processing must be clearly understood by the individual in terms of understanding risks, as well as social, ethical, and societal consequences.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "AI Governance in Japan Ver. 1.1, Report from the expert group on how AI principles should be implemented",
        "country": "Japan",
        "world_region": "Eastern Asia",
        "institution": "Expert Group on how AI principles should be implemented",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2021",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Large (>10.000 Words, <20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Expert Group on how AI principles should be implemented, a governmental initiative from the government of Japan. In this document, the authors discuss the ideal AI governance with experts on the relationship between AI and the constitution, civil law, the Act on the Protection of Personal Information, international standards, and private and public coregulation, as well as with experts on explainable AI, affiliates of companies with great experience in developing and utilizing AI, experts on initiatives about AI principle practice, practitioners well versed in the relationship between insurance, auditing, and AI, and representatives of consumer organizations. The document builds upon many other publications (e.g., \"Social Principles of Human-centric AI,\" \"OECD AI Principles\"), proposing at the end an ideal approach to AI governance in Japan through legally non-binding corporate governance guidelines.",
        "document_url": "https://www.meti.go.jp/shingikai/mono_info_service/ai_shakai_jisso/pdf/20210709_8.pdf",
        "attachments": "https://www.meti.go.jp",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "We should not build a society where humans are overly dependent on AI or where AI is used to control human behavior through the excessive pursuit of efficiency and convenience. We need to construct a society where human dignity is respected and, by using AI as a tool, a society where people can better demonstrate their various human abilities, show greater creativity, engage in challenging work, and live richer lives both physically and mentally.",
            "Diversity": "It is preferred that the use of AI will create an environment in which many people can engage in highly creative and productive work. To that end, it is expected that a diverse range of people will acquire the ability to realize their dreams and ideas with AI's support despite many differences in origin, culture, taste, and so on.",
            "Autonomy": "In a society making use of AI, we should introduce appropriate mechanisms for literacy education and the promotion of proper use of AI so that people do not become over-dependent on AI or misuse AI to manipulate other people's decision-making.",
            "Human Formation": "Human-Centeredness: The utilization of AI must not infringe upon the fundamental human rights guaranteed by the Constitution and international standards. AI should be developed, utilized, and implemented in society to expand the abilities of people and allow diverse people to pursue their well-being.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Human Formation/Education: To prevent generating disparities between people or to create socially vulnerable individuals, opportunities for education in a wide range of literacy skills are to be provided in early childhood education and primary and secondary education. Opportunities are also to be provided for the reeducation of working adults and the elderly. Concerning literacy education and skills required to use AI, our society needs an educational system that allows anyone to acquire the basics of AI, mathematics, and data science. These characteristics include bias in data, the possibility of causing bias depending on how AI is used, and issues of fairness, impartiality, and privacy protection that are inherently needed in the use of AI.",
            "Labor Rights": null,
            "Cooperation": "Justice/Equity/Fairness/Non-discrimination: Under AI's design concept, all people are treated fairly without unjustified discrimination on the grounds of diverse backgrounds such as race, gender, nationality, age, political beliefs, religion, and so on.",
            "Privacy": "Open source/Fair Competition/Cooperation: A fair competitive environment must be maintained to create new businesses and services, maintain sustainable economic growth, and present solutions to social challenges. Even if resources related to AI are concentrated in a specific country, we must not have a society where unfair data collection and infringement of sovereignty are performed under that country's dominant position. To realize Society 5.0 and aim for continuous innovation that advances as people evolve together with AI development, we should transcend boundaries such as national borders, industries, academia, governments, race, gender, nationality, age, political convictions, and religion.",
            "Reliability": "Privacy: AI using personal data should have mechanisms to ensure accuracy and legitimacy, and to allow individuals to be substantially involved in managing the privacy of their data. This would make it possible for people to provide personal data with peace of mind when using AI, and effectively benefit from the data they provide. Personal data must be protected appropriately according to its degree of importance and sensitivity.",
            "Sustainability": "Reliability/Safety/Security/Trustworthiness: Society must promote broad, deep research and development related to AI (from immediate measures to deep essential understanding), such as the proper assessment of risks in the utilization of AI and research to reduce risks. Society must make firm efforts to conduct risk management including safeguarding cybersecurity.",
            "Transparency": "Sustainability: We need to use AI to create a succession of new businesses and solutions, resolve social disparities, and develop a sustainable society that can deal with issues such as global environmental problems and climate change. Japan, as a leading science and technology-oriented country, should strengthen its accumulated scientific and technological resources by utilizing AI and thereby contributing to the creation of such a sustainable society.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Principles of Artificial Intelligence Ethics for the Intelligence Community",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "United States Intelligence Community (IC)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2020",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Normative",
            "Practical"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the United States Intelligence Community (IC), a group of separate United States government intelligence agencies and subordinate organizations, that work separately and together to conduct intelligence activities to support the foreign policy and national security of the United States. This document is intended to guide personnel on whether and how to develop and use AI, including machine learning, in furtherance of the IC's mission. The document also presents a practical tool: the AI Ethics Framework for the Intelligence Community. This framework was made to guide personnel who are determining whether and how to procure, design, build, use, protect, consume, and manage AI and other advanced analytics.",
        "document_url": "https://www.intelligence.gov/images/AI/Principles_of_AI_Ethics_for_the_Intelligence_Community.pdf",
        "attachments": "https://www.intelligence.gov/images/AI/AI_Ethics_Framework_for_the_Intelligence_Community_1.0.pdf",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Our use of AI will fully comply with applicable legal authorities and with policies and procedures that protect privacy, civil rights, and civil liberties. We will develop and employ mechanisms to identify responsibilities and provide accountability for the use of AI and its outcomes.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "We will employ AI in a manner that respects human dignity, rights, and freedoms.",
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": "We will develop and use AI to augment our national security and enhance our trusted partnerships by tempering technological guidance with the application of human judgment, especially when an action has the potential to deprive individuals of constitutional rights or interfere with their free exercise of civil liberties.",
            "Intellectual Property": null,
            "Fairness": "Consistent with our commitment to providing objective intelligence, we will take affirmative steps to identify and mitigate bias.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Our use of AI will fully comply with applicable legal authorities and with policies and procedures that protect privacy, civil rights, and civil liberties.",
            "Reliability": "We will develop and employ best practices for maximizing the reliability, security, and accuracy of AI design, development, and use. We will employ security best practices to build resilience and minimize the potential for adversarial influence.",
            "Sustainability": null,
            "Transparency": "We will provide appropriate transparency to the public and our customers regarding our AI methods, applications, and uses within the bounds of security, technology, and releasability by law and policy, and consistent with the Principles of Intelligence Transparency for the IC.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Vodafone Artificial Intelligence Framework",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "Vodafone Group Plc",
        "institution_type": "Private Corporation",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Vodafone Group Plc, a British multinational telecommunications company. This document presents Vodafone's approach to working with AI technologies and outlines how they intend to develop and employ, in a responsible manner, these technologies across their international business. The document can be understood as Vodafone's voluntary self-commitment to the ethical use and development of AI.",
        "document_url": "https://www.vodafone.com/about-vodafone/how-we-operate/public-policy/policy-positions/artificial-intelligence-framework",
        "attachments": "https://www.vodafone.com/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "We will act responsibly and follow technology industry best practices to minimize the risks of our systems being unlawfully used to the detriment of people's human rights.",
            "Diversity": "Vodafone will seek to reduce any digital divide that occurs in our markets because of differential access to AI-based technologies. Vodafone will proactively engage with industry peers and other relevant experts (e.g. academics and civil society) in consultation exercises to ensure that AI-based systems are human-centric and foster diversity and inclusivity. We will strive to ensure that our AI teams – in line with all other teams in Vodafone – are diverse",
            "Autonomy": null,
            "Human Formation": "We will support our existing employees to gain new skills so that they can apply for appropriate roles that are created by our improved digital capability. We will deploy AI-based systems to provide more effective work environments, simplifying the work of our employees and improving their experience. We will provide training and education to help our employees use AI-based systems to support their work.",
            "Human-Centeredness": "Vodafone will proactively engage with industry peers and other relevant experts (e.g. academics and civil society) in consultation exercises to ensure that AI-based systems are human-centric and foster diversity and inclusivity. We will establish and maintain a regular dialogue with our customers as to how we should use data and AI tools to serve them.",
            "Intellectual Property": null,
            "Fairness": "All our AI experts and data scientists are subject to our Code of Conduct, which includes explicit provisions for nondiscrimination and fair treatment.",
            "Labor Rights": null,
            "Cooperation": "Vodafone will proactively participate in the scientific community, industry coalitions, and self-regulatory bodies working on research, laws, regulations, and ethical guidelines for AI, such as the EU High-Level Expert Group on AI.",
            "Privacy": "We will ensure that customer data is carefully managed, in line with our strong privacy commitments and prevailing legislation, and only used with AI systems when we have established a clear legal basis to do so.",
            "Reliability": "Our customer data will always be securely stored under strict access control and in compliance with our Group data security policies and applicable local laws. We will make sure that our security systems for AI are continually updated as the threat landscape evolves.",
            "Sustainability": null,
            "Transparency": "We endeavor to clearly inform our customers and employees when they communicate directly with AI-powered systems. We believe that people should be informed about when they interact with an algorithm or some form of AI/non-human system. We strive to clearly inform our customers and employees about what data we collect on our users and how our systems utilize that data. Anyone who feels they have been unfairly treated as a result of a decision made by an AI system deployed by Vodafone will have the opportunity to escalate their concerns under the published process for Vodafone complaints in their country of operation.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Artificial Intelligence at the service of the citizen (L'intelligenzia artificiale al servizio del cittadino)",
        "country": "Italy",
        "world_region": "Southern Europe",
        "institution": "Agenzia per l'Italia Digitale (AGID)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by Agenzia per l'Italia Digitale (AGID),  the technical agency of the Presidency of the Council which has the task of guaranteeing the achievement of the objectives of the Italian Digital Agenda and contributing to the diffusion of the use of information and communication technologies, favoring the innovation and economic growth. This document aims at analyzing the impact of Artificial Intelligence in our society and, more specifically, in Public Administration, to promote digital transformation. The document also includes a set of recommendations drafted by AGID and a Task Force of more than 500 experts and citizens.",
        "document_url": "https://libro-bianco-ia.readthedocs.io/en/latest/#:~:text=The%20White%20Paper%2C%20edited%20by,with%20Artificial%20Intelligence%20in%20Italy.",
        "attachments": "https://www.agid.gov.it/it",
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "Articles of artificial intelligence should follow principles of benefit and not harm to people. Always aiming for the good as a whole.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "AI needs to defend people with disabilities, and not let prejudice against them occur. AI articles should care about diversity and inclusion, without using prejudice between races, ethnicities, gender.",
            "Autonomy": null,
            "Human Formation": "Recommendation - Facilitate the dissemination of skills through the promotion of certification of professionals working in the area of AI (through the creation and adoption of a shared framework ) and provide for the establishment of training paths for the inclusion of workers with the ability to understand and implement AI solutions in the public administration (for example through specific courses at the National School of Administration). The numerous professional skills lacking are an opportunity to think about training courses focus on lasting and sustainable gender equality, both from a numerical point of view (ex. STEM graduates) and from a financial point of view (ex. remuneration equality).",
            "Human-Centeredness": "Artificial intelligence should focus on promoting and helping human beings, thinking about our future and how we can have a better quality of life, and also thinking about solving our problems, but always having the human being as a priority.",
            "Intellectual Property": null,
            "Fairness": "Artificial intelligence should be used to reduce, not increase, health inequality – geographically, economically, and socially. Recommendation - Promote a national platform dedicated to the development of AI solutions in order to organize and convey tests openly before the release of AI systems used in the PA in order to evaluate their behavior and limit the anomalies and the amplification of the bias.",
            "Labor Rights": null,
            "Cooperation": "Recommendation - Enable with new resources the computational linguistic systems for the Italian language (such as digitized lexicons or annotated corpora) to be distributed with open licenses, in order to favor the development of services based on the treatment of natural language. Support the collaboration between research, business accelerators, and innovation hubs, both public and private, also at the European level, to promote the adoption of AI solutions in the public sector. Establish a Trans-disciplinary Centre on AI.",
            "Privacy": null,
            "Reliability": "Recommendation - Define guidelines and processes based on the principle of security-by-design in the use of AI, increasing the levels of control and facilitating the sharing of data on cyberattacks to and from AI by all European countries.",
            "Sustainability": null,
            "Transparency": "The articles must be 100% sincere and transparent, and explain the terms used properly so that no person who is going to read them can get confused. Recommendation - Disclose to the public the intermediate results of the elaboration of AI algorithms (ex. parameters of neural networks) operated on data from public administrations, subject to conditions that may harm the privacy and security of citizens. These results must allow the reproducibility of the processes, their evaluation, and verifiability.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Artificial Intelligence: open questions about gender inclusion",
        "country": "Argentina",
        "world_region": "Latin America",
        "institution": "Women 20 Argentina",
        "institution_type": "NGO",
        "year_of_publication": "2018",
        "number_of_male_authors": "2",
        "number_of_female_authors": "2",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Women 20 Argentina.  Women 20 is an official G20 engagement group established in 2015, being a policy recommendation engagement group that is part of the G20 process but is independent of governments. The authors of the document argue that AI \"[...] is shaping gender relations, creating new challenges and opportunities for women\". The focus of this document is to show the positive and negative impacts of AI on women, also presenting recommendations aimed to reduce these negative impacts.",
        "document_url": "http://webfoundation.org/docs/2018/06/AI-Gender.pdf",
        "attachments": "https://w20argentina.com/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "Women need to have an active role in shaping the next generation of technologies, so stereotypes are not reproduced and diversity is considered. Countries need to take proactive steps towards the inclusion of women in the coding and the design of machine learning and AI technologies. We Recommend that G20 governments, in close collaboration with the Education Ministries, Universities, and the private sector, take proactive steps towards the inclusion of more women in the workforce that design AI systems.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "We Recommend that G20 countries explore the adoption of algorithmic equitable actions to correct real-life biases and barriers that prevent women from achieving full participation and equal enjoyment of rights.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "We Recommend that G20 countries embrace regulation promoting transparency in machine learning and AI-powered systems that can meaningfully affect people's lives. This should include reliance on open data and open AI whenever government relies on these technologies for service provision. These requirements can be included in government procurement guidelines for AI systems that support the delivery of public services.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "oston Dynamics Ethical Principles",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Boston Dynamics (BD)",
        "institution_type": "Private Corporation",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Boston Dynamics (BD), an American engineering and robotics design company founded in 1992 as a spin-off from the Massachusetts Institute of Technology. This document contains BD's Ethical Principles and can be understood as BD's voluntary self-commitment to the ethical development of their products.",
        "document_url": "https://www.bostondynamics.com/ethics",
        "attachments": "https://www.bostondynamics.com/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "We support the establishment of laws and regulations that promote the safe and responsible use of robots. We will use our leadership position in robotics to help the public, lawmakers, government and commercial customers clearly understand the capabilities and limitations of current robotic technology. We will support and encourage a mix of stakeholders including academia, industry associations, NGOs, and policymakers to debate and align on the benefits and risks of this nascent technology. We will engage with lawmakers to promote legislation around the safe use and deployment of robots.",
            "Beneficence": "We are motivated by curiosity and respect for humans and animals. We see this as the next step in the human history of building machines to reduce the danger, repetition, and physically difficult aspects of work. We will not weaponize our robots. We will not authorize nor partner with those who wish to use our robots as weapons or autonomous targeting systems. If our products are being used for harm, we will take appropriate measures to mitigate that misuse.",
            "Children's Rights": null,
            "Human Rights": "We believe robotic use must comply with privacy and civil rights laws. We will not authorize nor partner with those who wish to use our robots in a way that violates privacy and civil rights laws. We understand that emerging artificial intelligence technologies including computer vision and personal identification algorithms raise questions about the ethics, legality, and potential for bias around their use in the public sphere.",
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": "We prioritize the human element in human-robot partnerships. We build robots designed from the ground up to leverage human intelligence, keep people safe and relieve the most burdensome work.",
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "We believe robotic use must comply with privacy and civil rights laws. We will not authorize nor partner with those who wish to use our robots in a way that violates privacy and civil rights laws. We understand that emerging artificial intelligence technologies including computer vision and personal identification algorithms raise questions about the ethics, legality, and potential for bias around their use in the public sphere.",
            "Reliability": "We build trustworthy robots. It is imperative that robots be trustworthy if people are to work productively with them. Therefore, we will build robots whose missions and capabilities are predictable, understandable, transparent and in service of human needs.",
            "Sustainability": null,
            "Transparency": "We are committed to being transparent with the public and our customers regarding the state of our technology.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Augmented Intelligence in Health Care H-480.940",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "American Medical Association (AMA)",
        "institution_type": "Professional Association",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the American Medical Association (AMA), a professional association and lobbying group of physicians and medical students. In this document, AMA presents a set of principles to ensure that the evolution of augmented intelligence (AI) in medicine benefits patients, physicians, and the health care community. This document can be understood as AMA's voluntary self-commitment to the use and development of AI technologies.",
        "document_url": "https://policysearch.ama-assn.org/policyfinder/detail/augmented%20intelligence?uri=%2FAMADoc%2FHOD.xml-H-480.940.xml",
        "attachments": "https://www.ama-assn.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": true,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "AMA will seek to explore the legal implications of health care AI, such as issues of liability or intellectual property, and advocate for appropriate professional and governmental oversight for safe, effective, and equitable use of and access to health care AI.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": "AMA will seek to encourage education for patients, physicians, medical students, other healthcare professionals, and health administrators to promote a greater understanding of the promise and limitations of healthcare AI.",
            "Human-Centeredness": "AMA will seek to promote the development of thoughtfully designed, high-quality, clinically validated healthcare AI that is designed and evaluated in keeping with best practices in user-centered design, particularly for physicians and other members of the healthcare team.",
            "Intellectual Property": "AMA will seek to explore the legal implications of health care AI, such as issues of liability or intellectual property, and advocate for appropriate professional and governmental oversight for safe, effective, and equitable use of and access to health care AI.",
            "Fairness": "AMA will seek to promote the development of thoughtfully designed, high-quality, clinically validated healthcare AI that identifies and takes steps to address bias and avoids introducing or exacerbating health care disparities including when testing or deploying new AI tools on vulnerable populations.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "AMA will seek to promote the development of thoughtfully designed, high-quality, clinically validated healthcare AI that safeguards patients' and other individuals' privacy interests and preserves the security and integrity of personal information.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "AMA will seek to promote the development of thoughtfully designed, high-quality, clinically validated healthcare AI that is transparent.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "WLiAI Report 2019: 10 Principles of Responsible AI",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "Women Leading in AI (WLinAI)",
        "institution_type": "NGO",
        "year_of_publication": "2019",
        "number_of_male_authors": "0",
        "number_of_female_authors": "9",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Women Leading in AI (WLinAI), an action tank of women leaders in AI. In this document, WLinAI presents 10 recommendations for governments to regulate Artificial Intelligence and drive its development. The document also references several Algorithmic Impact Assessments tools.",
        "document_url": "https://womenleadinginai.org/wp-content/uploads/2019/02/WLiAI-Report-2019.pdf",
        "attachments": "https://womenleadinginai.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Recommendation - Introduce a regulatory\tapproach governing the deployment of AI which mirrors that used for the pharmaceutical sector.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "We recommend risk to individuals or groups should be determined within the UN Universal Declaration of Human Rights (UDHR) to balance any variance in cultural norms with regard to fairness and bias.",
            "Diversity": "We recommend the set up of a solid, courageous, and rigorous program to encourage young women and other underrepresented groups into technology.",
            "Autonomy": "We recommend the establishment of an official procedure for individuals to challenge the outcomes or decisions devised by an AI system, including a detailed list of what different information would have triggered a different outcome.",
            "Human Formation": "Recommendation - To carry out a skills audit to identify the wide range of skills required to embrace the AI revolution. To compel companies and other organizations to bring their workforce with them – by publishing the impact of AI on their workforce and offering retraining programs for employees whose jobs are being automated. To establish an education and training program to meet the needs identified by the skills audit, including content on data ethics and social responsibility.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Recommendation - Introduce a new ‘Certificate of Fairness for AI systems' alongside a ‘kite mark' type scheme to display it. Criteria are to be defined at the industry level, similarly to food labeling regulations. Introduce a ‘reduced liability' incentive for companies that have obtained a Certificate of Fairness to foster innovation and competitiveness.",
            "Labor Rights": "Recommendation - Where no redeployment is possible, compel companies to make a contribution towards a digital skills fund for those employees.",
            "Cooperation": null,
            "Privacy": "Recommendation - Introduce a ‘certificate of fairness' for AI systems that are audited for risks concerning discrimination, unfairness, and privacy.",
            "Reliability": "Recommendation - Introduce mandatory AIAs (Algorithm Impact Assessments) for organizations employing AI systems that have a significant effect on individuals.",
            "Sustainability": null,
            "Transparency": "Recommendation - Establish an AI regulatory function working alongside the Information Commissioner's Office and Centre for Data Ethics – to audit algorithms, investigate complaints by individuals, issue notices and fines for breaches of GDPR and equality and human rights law, give wider guidance, spread best practice and ensure algorithms must be fully explained to users and\topen to public scrutiny. Introduce a mandatory requirement for public sector organizations using AI for particular purposes to inform citizens that decisions are made by machines, explain how the decision is reached and what would need to change for individuals to get a different outcome.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "The Ethical Norms for the New Generation Artificial Intelligence, China",
        "country": "China",
        "world_region": "Eastern Asia",
        "institution": "Ministry of Science and Technology of the People's Republic of China, National Governance Committee for the New Generation Artificial Intelligence",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2021",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the National Governance Committee for the New Generation Artificial Intelligence (Ministry of Science and Technology of the People's Republic of China). The document aims to integrate ethics into the entire lifecycle of AI, providing ethical guidelines for natural persons, legal persons, and other related organizations engaged in AI-related activities.",
        "document_url": "https://ai-ethics-and-governance.institute/2021/09/27/the-ethical-norms-for-the-new-generation-artificial-intelligence-china/",
        "attachments": "http://en.most.gov.cn/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": true,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Various activities of AI shall abide by the following fundamental ethical norms, like Adhere that human beings are the ultimately liable subjects. Clarify the responsibilities of all relevant stakeholders, comprehensively enhance the awareness of responsibility, introspection, and self-discipline in the entire life cycle of AI. Establish an accountability mechanism in AI-related activities, and do not evade liability reviews and do not escape from responsibilities.",
            "Beneficence": "Various activities of AI shall abide by the following fundamental ethical norms, like enhancing the well-being of humankind, improving people's livelihood, and enhancing the sense of happiness.",
            "Children's Rights": null,
            "Human Rights": "Various activities of AI shall abide by the following fundamental ethical norms, like respect for human rights and the fundamental interests of humankind.",
            "Diversity": "Various activities of AI shall abide by the following fundamental ethical norms, like Adhere to shared benefits and inclusivity, effectively protecting the legitimate rights and interests of all relevant stakeholders. When providing AI products and services, we should fully respect and help vulnerable groups and underrepresented groups, and provide corresponding alternatives as needed.",
            "Autonomy": "Various activities of AI shall abide by the following fundamental ethical norms, like ensuring that humans have the full power for decision-making, the right to choose whether to accept the services provided by AI, the right to withdraw from the interaction with AI at any time, and the rights to suspend the operation of AI systems at any time and ensure that AI is always under meaningful human control.",
            "Human Formation": "Various activities of AI shall abide by the following fundamental ethical norms, like Actively learning and popularizing knowledge related to AI ethics, objectively understanding ethical issues, and do not underestimate or exaggerate ethical risks. Actively carry out or participate in the discussions on the ethical issues of AI, deeply promote the practice of AI ethics and governance, and improve the ability to respond to related issues.",
            "Human-Centeredness": "Various activities of AI shall abide by the following fundamental ethical norms, like adherence to the people-oriented vision, abiding by the common values of humankind.",
            "Intellectual Property": "Various activities of AI shall abide by the following fundamental ethical norms, like any means that infringe on the intellectual property rights of other subjects are forbidden.",
            "Fairness": "Various activities of AI shall abide by the following fundamental ethical norms, like promoting fair sharing of the benefits of AI in the whole society, promoting social fairness and justice, and equal opportunities. During the process of data collection and algorithm development, strengthen ethics review, fully consider the diversity of demands, avoid potential data and algorithmic bias, and strive to achieve inclusivity, fairness, and non-discrimination in AI systems.",
            "Labor Rights": null,
            "Cooperation": "Various activities of AI shall abide by the following fundamental ethical norms, like encourage cross-disciplinary, cross-domain, cross-regional, and cross-border exchanges and cooperation, and promote the formation of AI governance frameworks, standards, and norms with broad consensus.",
            "Privacy": "Various activities of AI shall abide by the following fundamental ethical norms, like fully respecting the rights of personal information, to know, and to consent, etc., handling personal information, protecting personal privacy and data security following the principles of lawfulness, justifiability, necessity, and integrity, do no harm to the legitimate rights of personal data, must not illegally collect and use personal information by stealing, tampering, or leaking, etc., and must not infringe on the rights of personal privacy.",
            "Reliability": "Various activities of AI shall abide by the following fundamental ethical norms, like enhancing bottom-line thinking and risk awareness, strengthening the research and judgment on the potential risks during the development of AI, carrying out systematic risk monitoring and evaluations promptly, establishing an effective early warning mechanism for risks, and enhance the ability of manage, control, and disposal of ethical risks of AI. Emergency mechanisms and loss compensation plans and measures should be investigated and formulated.",
            "Sustainability": "Various activities of AI shall abide by the following fundamental ethical norms, like promoting the sustainable development of economy, society, and ecology, and jointly building a human community with a shared future.",
            "Transparency": "Various activities of AI shall abide by the following fundamental ethical norms, like enhancing safety, security, and transparency. In the phases of algorithm design, implementation, and application, etc., improve transparency, interpretability, understandability, reliability, and controllability, enhance the resilience, adaptability, and the ability of anti-interference of AI systems, and gradually realize verifiable, auditable, supervisable, traceable, predictable and trustworthy AI.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Work in the age of artificial intelligence: Four perspectives on the economy, employment, skills and ethics",
        "country": "Finland",
        "world_region": "Northern Europe",
        "institution": "Ministry of Economic Affairs and Employment of Finland",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2018",
        "number_of_male_authors": "2",
        "number_of_female_authors": "0",
        "document_size": "Large (>10.000 Words, <20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Ministry of Economic Affairs and Employment of Finland. The document is a collection of four main articles that discuss: (1) the effects of artificial intelligence on general economic and employment trends; (2) the transformation of work and the labor market; (3) reforms in education and skills maintenance; and (4) ethics. The document also recommends provisions and regulations to mitigate the social problems that AI could cause.",
        "document_url": "https://julkaisut.valtioneuvosto.fi/bitstream/handle/10024/160980/TEMjul_21_2018_Work_in_the_age.pdf?sequence=1&isAllowed=y",
        "attachments": "https://tem.fi/en/frontpage",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Responsibility means that decision-making based on artificial intelligence does not pose a threat to anyone's health or safety. This requirement applies to an individual's physical and psychological health as well as data protection and protection of privacy. However, the point of departure in all cases is that humans assume ultimate legal and moral responsibility for the decisions.",
            "Beneficence": "Extensive societal benefits mean that AI-based solutions benefit all groups in society. This value should be a key guideline informing all government support for the development of AI technology and applications based on it.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "In the development and use of AI technology, attention should be paid to societal heterogeneity and participation. Diversity should be promoted – including different educational backgrounds, linguistic and ethnic groups, genders, and age groups – among AI developers. It should also be ensured that citizens have capabilities for participating in a broad-based discussion on the artificial intelligence society. A general understanding of the potential generated and challenges created by artificial intelligence should be built up.",
            "Autonomy": "The Finnish artificial intelligence strategy should build on the existing ethical value base of our society, which stresses trust and commonality. Monopolistic and state-controlled practices, for example, should not be adopted. The Finnish model relying on the European democratic tradition could serve as an example of good practice in the EU and globally.",
            "Human Formation": "Artificial intelligence will change the content of occupations and jobs. A risk of exclusion of those with a lower level of education and an increase in structural unemployment is always inherent in structural changes. In order to prepare for the changes, it should be ensured that young people completing their basic education have general knowledge and skills which give them eligibility for further studies and promote lifelong learning. In order to combat high structural unemployment in the future, a competence program will be drawn up, which will ensure in practice that everyone will have at least a secondary level qualification. In addition to providing more places for education and training, compulsory education will be extended to the secondary level. The use of technology in education should be promoted at all levels with the aim of offering more individualized education content of higher quality in a cost-effective manner.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": "When new technologies are introduced, an effective labor market will be more important than ever. Measures are needed to promote the transition of those who are employed to tasks and jobs that are a better match with their skills and more productive, in a manner experienced as secure. Change should appear more attractive than preserving the status quo. This way, the nation's skills can be used better, and vacancies will also become available for new entrants in the labor market. In order to promote labor mobility, employment services should also be offered to the employed. Concrete measures could include a notification service of suitable vacancies implemented using artificial intelligence and directing employment services to not only the unemployed but also those already in employment. Complimentary income transfers or pay subsidies could also be used more, as is done in Sweden.",
            "Cooperation": "The scaling of AI technology makes the creation of monopolies possible. Any abuses of dominant market power should be intervened through smart regulation and competition oversight. The central government should encourage multidisciplinary and versatile research with closer links to basic research which also builds up cooperation between universities, companies, and public organizations. The universities' performance guidance and incentive scheme should be updated to create clear incentives for participating in cooperation and network projects and commercialization of research. Experience has shown that R&D funding should be increased gradually through a multiannual program requiring commitment.",
            "Privacy": "Responsibility means that decision-making based on artificial intelligence does not pose a threat to anyone's health or safety. This requirement applies to an individual's physical and psychological health as well as data protection and protection of privacy.",
            "Reliability": "The requirement of traceability is highlighted as the functions become more security-critical. Particularly accurate traceability should be required in functions directly concerned with human health and safety. These applications of artificial intelligence are found especially in healthcare, transport, energy production, and national defense.",
            "Sustainability": null,
            "Transparency": "Transparency refers to openness regarding 1) what data are collected and for what purpose (to underpin decision-making based on artificial intelligence), and 2) what the aim of the algorithms supporting and making decisions is. The employees of work organizations using artificial intelligence in decision-making should also be aware of this. In terms of the transparency of decisions made in a work organization, it makes no difference in principle if the decisions are made purely by humans, by an algorithm, or by some combination of these two. The importance of transparency of algorithms is accentuated in a very special way in the decision-making of public organizations, where the decisions in many cases concern citizens' statutory rights and obligations",
            "Truthfulness": null
        }
    },
    {
        "document_name": "A Framework for Responsible Limits on Facial RecognitionUse Case: Flow Management",
        "country": "Switzerland",
        "world_region": "Western Europe",
        "institution": "World Economic Forum",
        "institution_type": [
            "NGO",
            "International Organization"
        ],
        "year_of_publication": "2020",
        "number_of_male_authors": "2",
        "number_of_female_authors": "0",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the World Economic Forum, an international non-governmental and lobbying organization based in Cologny, canton of Geneva, Switzerland. This document aims to inform the public debate on the use of facial recognition technologies at the national, European, and international levels, also presenting a governance framework for facial recognition technologies. This framework can be understood as a practical tool for ensuring the responsible use of facial recognition.",
        "document_url": "https://www3.weforum.org/docs/WEF_Framework_for_action_Facial_recognition_2020.pdf",
        "attachments": "https://www.weforum.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": true,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Organizations using facial recognition systems should ensure a culture of accountability internally and across third-party service providers or business partners. To this end, they should establish and publicly disclose the governance principles that guide the design and use of their systems.",
            "Beneficence": null,
            "Children's Rights": "Facial recognition should not exclude anyone and should always be accessible to and usable by all groups of people, including elderly people and people with disabilities. It is recognized that there may be some instances, such as infants and children, in which an exception to this principle is appropriate and an alternative to facial identification should be offered.",
            "Human Rights": null,
            "Diversity": "Facial recognition should not exclude anyone and should always be accessible to and usable by all groups of people, including elderly people and people with disabilities.",
            "Autonomy": "A manual review (human overseeing) should be conducted for any use that could result in a consequential decision, such as causing a civil right infringement. In the case of a fully automated system, a fallback system with a human in the loop should always be in place in order to address exceptions and unexpected errors. An alternative option to the use of facial recognition should always be in place, and it should be a reasonable option.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Organizations using facial recognition systems should take appropriate steps to ensure that unfair bias or outcomes can be detected, identified, and mitigated to the greatest extent possible. While acknowledging that the complete removal of bias represents one of the biggest challenges in AI research, organizations must allocate appropriate resources to the implementation of tools and processes that minimize unfair bias or outcomes.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Organizations using facial recognition systems should design systems to support privacy, including privacy considerations in system requirements and carrying through privacy support in the design, development, and testing of technology as well as in supporting business practices and ongoing system maintenance.",
            "Reliability": "Organizations creating facial recognition platforms or using facial recognition as part of an experience or systems should conduct a comprehensive risk assessment of their systems, including the impact on privacy, the potential for errors, susceptibility to unfair bias, vulnerability to hacking and cyberattacks, lack of transparency in the decision-making process and potential for civil rights infringements.",
            "Sustainability": null,
            "Transparency": "Processes should be put in place to inform end-users who have questions and/or need information on the use of facial recognition systems. End users should have access to their personal biometric data upon request. Individuals should provide informed, explicit and affirmative consent for the use of facial recognition systems. Any time data subjects enroll for a new service powered by facial recognition technology, they should express clear consent with regards to the length of data retention. When used in public spaces, clear signage should be deployed to ensure obvious communication with end-users on the use of facial recognition. Areas, where facial recognition systems are used, should always be delimited and indicated to individuals. A visual sign should also inform individuals when the system is in operation.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "A Code of Ethics for the Human-Robot Interaction Profession",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "University of Notre Dame",
        "institution_type": "Academic",
        "year_of_publication": "2014",
        "number_of_male_authors": "1",
        "number_of_female_authors": "1",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the University of Notre Dame,  a private Catholic research university in Notre Dame, Indiana (US). This document discusses the unique ethical challenges facing HRI (Human-Robot Interaction) practitioners designing robots, also proposing a code of ethics for the profession. The authors argue that the affordance of all rights and protections ordinarily assumed in human-human interactions apply to HRI, and discuss various social, legal, and design considerations to facilitate this.",
        "document_url": "https://www3.nd.edu/~dhoward1/a-code-of-ethics-for-the-human-robot-interaction-profession-riek-howard.pdf",
        "attachments": "https://www.nd.edu/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": true
        },
        "principles_definition": {
            "Accountability": "A robot's decision paths must be re-constructible for the purposes of litigation and dispute resolution. Human informed consent to HRI is to be facilitated to the greatest extent possible consistent with reasonable design objectives",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "All HRI research, development, and marketing should heed the overall principle of respect for human persons, including respect for human autonomy, respect for human bodily and mental integrity, and the affordance of all rights and protections ordinarily assumed in human-human interactions. The robot actor is expected to behave in a manner at least as respectful of human personhood as human actors to the extent feasible. Human frailty is always to be respected, both physical and psychological. The emotional needs of humans are always to be respected. All relevant laws and regulations concerning individuals' rights and protections (e.g., FDA, HIPPA, and FTC) are to be respected.",
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Avoid racist, sexist, and ableist morphologies and behaviors in robot design.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "The human's right to privacy shall always be respected to the greatest extent consistent with reasonable design objectives.",
            "Reliability": "Predictability in robotic behavior is desirable. Trustworthy system design principles are required across all aspects of a robot's operation, for both hardware and software design, and for any data processing on or off the platform. Obvious opt-out mechanisms (kill switches) are required to the greatest extent consistent with reasonable design objectives.",
            "Sustainability": null,
            "Transparency": "Maximal, reasonable transparency in the programming of robotic systems is required.",
            "Truthfulness": "Wizard-of-Oz (i.e., a technique where a person remotely operates a robot and puppeteers many of the robot's attributes) should be employed as judiciously and carefully as possible, and should aim to avoid Turing deceptions (i.e., e a participant cannot determine if they are interacting with a machine, a specific person, or a person masquerading as another person). The tendency for humans to form attachments to and anthropomorphize robots should be carefully considered during design. Humanoid morphology and functionality are permitted only to the extent necessary for the achievement of reasonable design objectives."
        }
    },
    {
        "document_name": "How to Prevent Discriminatory Outcomes in Machine Learning",
        "country": "Switzerland",
        "world_region": "Western Europe",
        "institution": "World Economic Forum",
        "institution_type": [
            "NGO",
            "International Organization"
        ],
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Large (>10.000 Words, <20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the World Economic Forum, an international non-governmental and lobbying organization based in Cologny, canton of Geneva, Switzerland. This document offers a framework for understanding the potential risks for machine learning applications to have discriminatory outcomes, also presenting a roadmap (together with practical self-assessment tools) for preventing them. It bases its approach on the rights enshrined in the Universal Declaration of Human Rights and further elaborated in a dozen binding international treaties that provide substantive legal standards for the protection and respect of human rights and safeguarding against discrimination.",
        "document_url": "https://www3.weforum.org/docs/WEF_40065_White_Paper_How_to_Prevent_Discriminatory_Outcomes_in_Machine_Learning.pdf",
        "attachments": "https://www.weforum.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Leaders, designers, and developers of ML systems are responsible for identifying the potential negative human rights impacts of their systems. They must make visible avenues for redress for those affected by disparate impacts, and establish processes for the timely redress of any discriminatory outputs.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "Companies developing and using ML systems must integrate these principles of non-discrimination into their human rights due diligence – a process by which businesses take ongoing, proactive, and reactive steps to ensure that they uphold people's dignity and do not cause or contribute to human rights abuses. This responsibility lies not only with the engineers building ML models: the goal of leadership should be to steer ML technology to uphold human rights.",
            "Diversity": "The development and design of ML applications must actively seek a diversity of input, especially of the norms and values of specific populations affected by the output of AI systems.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "People involved in conceptualizing, developing, and implementing machine learning systems should consider which definition of fairness best applies to their context and application, and prioritize it in the architecture of the machine learning system and its evaluation metrics.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "Involvement of ML systems in decision-making that affects individual rights must be disclosed, and the systems must be able to provide an explanation of their decision-making that is understandable to end-users and reviewable by a competent human authority. Where this is impossible and rights are at stake, leaders in the design, deployment, and regulation of ML technology must question whether or not it should be used.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Discussion Paper: National Strategy for Artificial Intelligence",
        "country": "India",
        "world_region": "South Asia",
        "institution": "National Institution for Transforming India (NITI Aayog)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by National Institution for Transforming India (NITI Aayog), which is the apex public policy think tank of the Government of India, and the nodal agency tasked with catalyzing economic development and fostering cooperative federalism through the involvement of State Governments of India in the economic policy-making process. This document is premised on the proposition that India, given its strengths and characteristics, has the potential to position itself among leaders on the global AI map – with the brand #AIforAll. The approach in this paper focuses on how India can leverage transformative technologies to ensure social and inclusive growth in line with the development philosophy of the government, proposing several recommendations for the public and private sectors.",
        "document_url": "https://smartnet.niua.org/sites/default/files/resources/nationalstrategy-for-ai-discussion-paper.pdf",
        "attachments": "https://smartnet.niua.org/",
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": true,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "Beyond just the headline numbers of economic impact, a disruptive technology such as AI needs to be seen from the perspective of the transformative impact it could have on the greater good – improving the quality of life and access of choice to a large section of the country.",
            "Children's Rights": null,
            "Human Rights": "Recommendation - Address and implement a data protection framework, which protects human rights and privacy without stifling innovation in India.",
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": "For addressing issues relating to skilling, a two-pronged approach is warranted, one set of interventions aimed at the workforce and the second for the students. The education sector needs to be re-aligned to effectively harness the potential of AI sustainably. In primary and secondary schools, there is a need to transition to skill-based education in subjects relevant to AI.",
            "Human-Centeredness": null,
            "Intellectual Property": "Recommendation - Set up a task force, comprising jointly the Ministry of Corporate Affairs and DIPP, to examine and issue appropriate modifications to the IP (Intellectual Property) regulatory regime pertaining to AI.",
            "Fairness": "Based on the premise that a large set of well-diversified data may be an accurate description of the world, most of the developer community takes a technocratic attitude that data-driven decision making is good and algorithms are neutral. However, this argument does not recognize the fact that the existing data may have biases, which may have got reinforced over time. The issue of fairness is at the forefront of discussion in academic, research, and policy fora, and merits a combined dialogue and sustained research to come to an acceptable resolution. One possible way to approach this would be to identify the in-built biases and assess their impact, and in turn, find ways to reduce the bias.",
            "Labor Rights": "For addressing issues relating to skilling, a two-pronged approach is warranted, one set of interventions aimed at the workforce and the second for the students. Re-skilling of the current workforce will require integration with relevant existing skilling initiatives, the building of new platforms that can enable improved learning, and novel methods of allowing large-scale employment generation through the promotion of AI.",
            "Cooperation": "AI is a highly collaborative domain, and any framework aimed at promoting AI needs to be aligned accordingly. A multi-pronged approach, involving various stakeholders and promoting a collaborative approach is required for promoting the development of AI tools as well as the adoption of AI in different fields of activity.  Opening up government datasets. Establish platforms for making datasets in the area of the social sector (either collected during the implementation of a scheme or in normal business processes) available for open public use in a machine-readable form.",
            "Privacy": "The work being done by Justice Srikrishna Committee on data protection law is very opportune and timely. The 7-core principles of data protection and privacy – informed consent, technology agnosticism, data controller accountability, data minimization, holistic application, deterrent penalties, and structured enforcement – are quite comprehensive and should provide a strong privacy protection regime in the country once enacted. Recommendation - Address and implement a data protection framework, which protects human rights and privacy without stifling innovation in India.",
            "Reliability": "The accountability debate on AI, which in most cases today is aimed at ascertaining the liability, needs to be shifted to objectively identifying the component that failed and how to prevent that in the future. An analogy can be drawn to how the airlines have become a relatively safe industry today. Every accident has been elaborately investigated, and a future course of action has been determined. Something similar is needed to ensure safe AI. One possible framework that can be mooted involves a negligence test for damages caused by AI software, as opposed to strict liability. This involves self-regulation by the stakeholders by conducting damage impact assessment at every stage of the development of an AI model.",
            "Sustainability": "Recommendation - Set up CSTS to address issues relating to ethics, privacy, legal aspects, social sustainability, and global competitiveness of the technologies developed.",
            "Transparency": "Opening the Black Box, assuming it is possible and useful at this stage (there is considerable debate on that as well), should not aim towards the opening of code or technical disclosure – few clients of AI solutions would be sophisticated AI experts - but should rather aim at “explainability”. With extended disclosure though, what needs to be balanced is whether the algorithm's parameter may induce the individuals and companies to change their behavior and in turn game the system. More collaborative research is required in this area.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Advisory statement on human ethics in artificial intelligence and big data research (2017)",
        "country": "Canada",
        "world_region": "North America",
        "institution": "National Research Council of Canada (NRC)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2017",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Gov. Reg.",
        "document_normative": [
            "Binding",
            "Non-binding"
        ],
        "document_impact": "Short",
        "abstract": "This document was written by the National Research Council of Canada (NRC), which is the primary national agency of the Government of Canada dedicated to science and technology research & development, and the NRC Research Ethics Board (NRC-REB). In this document, the NRC-REB reaffirms its commitment to meeting obligations under the NRC Policy and to uphold basic ethical principles in the review of research driven by big data and artificial intelligence applications.",
        "document_url": "https://nrc.canada.ca/en/corporate/values-ethics/research-involving-human-participants/advisory-statement-human-ethics-artificial-intelligence-big-data-research-2017",
        "attachments": "https://nrc.canada.ca/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": true,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": "Take particular measures to protect the rights of children and other vulnerable individuals.",
            "Human Rights": "Preserve Human and Legal Rights. Ensure that the consent to use personal data or otherwise participate in research is not conditional upon and does not include any statement to the effect that, by consenting, participants waive basic human rights or any rights to legal recourse in the event of research-related harm.",
            "Diversity": "Respect the rights of involved communities as a whole when, for example, data and information studied has implications for a specific community such as Indigenous People.",
            "Autonomy": "Ensure Discrete and Authentic Consent. Involve human participants and/or data that is personally identifiable with them only through free and informed consent (consent may be waived if all the conditions in TCPS 2 Article 5.5A are met). Secure participant consent or consent for the use of personal information in a way that is clearly given and separate from the acceptance of any form of inducement, deprivation, or the exercise of control, or authority as cited in the terms and conditions for the purchase of a product or service. Research that relies exclusively on the secondary use of non-identifiable information does not require participant consent but does require approval from the NRC-REB.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Protect Privacy and Personal Information. Take special measures in the design and planning of research to protect the privacy of individuals and personal information about themselves as required by the NRC Policy and its model, The Tri-Council Policy Statement: Ethical Conduct for Research Involving Humans (TCPS or the Policy). Recognize the right of individuals to access their personal information held by NRC.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "The National Artificial Intelligence Research and Development Strategic Plan: 2019 Update",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "National Science and Technology Council (NSTC)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2019",
        "number_of_male_authors": "22",
        "number_of_female_authors": "10",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the National Science and Technology Council (NSTC), a council in the Executive Branch of the United States, designed to coordinate science and technology policy across the branches of the federal government. This document provides several strategic priorities that have been identified by the NSTC, also providing an expectation for the overall portfolio for Federal AI R&D investments. The document also establishes a set of objectives for Federally-funded AI research.",
        "document_url": "https://www.nitrd.gov/pubs/National-AI-RD-Strategy-2019.pdf",
        "attachments": "https://www.nitrd.gov/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Understand and address the ethical, legal, and societal implications of AI. Research AI systems that incorporate ethical, legal, and societal concerns through technical mechanisms.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "Make long-term investments in AI research. Prioritize investments in the next generation of AI that will drive discovery and insight and enable the United States to remain a world leader in AI.",
            "Human Formation": "Federal agencies are giving priority to training and fellowship programs at all levels to prepare the workforce with requisite AI R&D skills through apprenticeships, skills programs, fellowships, and coursework in relevant disciplines.",
            "Human-Centeredness": "Develop effective methods for human-AI collaboration. Increase understanding of how to create AI systems that effectively complement and augment human capabilities.",
            "Intellectual Property": null,
            "Fairness": "Scientists must also study to what extent justice and fairness considerations can be designed into the system, and how to accomplish this within the bounds of current engineering techniques.",
            "Labor Rights": "Better understand the national AI R&D workforce needs. Improve opportunities for R&D workforce development to strategically foster an AI-ready workforce.",
            "Cooperation": "Develop shared public datasets and environments for AI training and testing. Develop and enable access to high-quality datasets and environments, as well as to testing and training resources. Expand public-private partnerships to accelerate advances in AI. Promote opportunities for sustained investment in AI R&D and for transitioning advances into practical capabilities, in collaboration with academia, industry, international partners, and other non-Federal entities.",
            "Privacy": "The United States must foster public trust and confidence in AI technologies and protect civil liberties, privacy, and American values in their application in order to fully realize the potential of AI technologies for the American people.",
            "Reliability": "Ensure the safety and security of AI systems. Advance knowledge of how to design AI systems that are reliable, dependable, safe, and trustworthy. Measure and evaluate AI technologies through standards and benchmarks. Develop a broad spectrum of evaluative techniques for AI, including technical standards and benchmarks.",
            "Sustainability": null,
            "Transparency": "Researchers must learn how to design these systems so that their actions and decision-making are transparent and easily interpretable by humans, and thus can be examined for any bias they may contain, rather than just learning and repeating these biases.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "The Holberton-Turing Oath",
        "country": "Unspecified",
        "world_region": "Unspecified",
        "institution": "The Holberton-Turing Oath",
        "institution_type": "NGO",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "The Holberton-Turing Oath was written to gather all AI experts in the world around shared values and morals to drive them to use their skills by insuring their integrity and avoiding any threat to any living being. The oath is a voluntary self-commitment intended for the entire AI research community.",
        "document_url": "https://www.holbertonturingoath.org/",
        "attachments": null,
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "As a member of the data science and artificial intelligence profession, I solemnly pledge to dedicate my life to the service of Humanity. I will maintain the utmost respect for human life.",
            "Children's Rights": null,
            "Human Rights": "I will not use my knowledge to violate human rights and civil liberties, even under threat. I will remember that I am not encountering dry data, mere zeros, and ones, but human beings, whose interactions with my Artificial Intelligence software may affect the person's freedom, family, or economic stability.",
            "Diversity": "I will not permit considerations of age, disease or disability, creed, ethnic origin, gender, nationality, political affiliation, religious beliefs, race, sexual orientation, social standing, or any other factor to intervene in duty.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": "I make these promises to create Artificial Intelligence, first, to collaborate with people for the greater good, rather than usurp the human role and supplant them.",
            "Intellectual Property": null,
            "Fairness": "I will consider the impact of my work on fairness both in perpetuating historical biases, which are caused by the blind extrapolation from past data to future predictions, and in creating new conditions that increase economic or other inequality",
            "Labor Rights": null,
            "Cooperation": "I will respect the hard-won scientific gains of those scientists and engineers in whose steps I walk, and gladly share such knowledge as is mine with those who are to follow. I will share my knowledge for the benefit of the people and for the advancement of Data-Science and Artificial Intelligence.",
            "Privacy": "I will respect the privacy of humans for their personal data are not disclosed to Artificial Intelligence systems so that the world may know. I will respect the secrets that are confided in me.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "OECD, Recommendation of the Council on Artificial Intelligence",
        "country": "France",
        "world_region": "Western Europe",
        "institution": "Organisation for Economic Co-operation and Development (OECD)",
        "institution_type": "International Organization",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Organisation for Economic Co-operation and Development (OECD), an intergovernmental economic organization with 38 member countries, headquartered in Paris (France). This document provides several recommendations for the members and no members of the OECD to promote and implement responsible stewardship of trustworthy AI.",
        "document_url": "https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449",
        "attachments": "https://www.oecd.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "AI actors should be accountable for the proper functioning of AI systems and for the respect of the above principles, based on their roles, the context, and consistent with the state of art.",
            "Beneficence": "Stakeholders should proactively engage in responsible stewardship of trustworthy AI in pursuit of beneficial outcomes for people and the planet, such as augmenting human capabilities and enhancing creativity, advancing the inclusion of underrepresented populations, reducing economic, social, gender, and other inequalities, and protecting natural environments, thus invigorating inclusive growth, sustainable development, and well-being.",
            "Children's Rights": null,
            "Human Rights": "AI actors should respect the rule of law, human rights, and democratic values, throughout the AI system lifecycle. These include freedom, dignity and autonomy, privacy and data protection, nondiscrimination and equality, diversity, fairness, social justice, and internationally recognized labor rights.",
            "Diversity": "Stakeholders should proactively engage in responsible stewardship of trustworthy AI in pursuit of beneficial outcomes for people and the planet, such as augmenting human capabilities and enhancing creativity, advancing the inclusion of underrepresented populations, reducing economic, social, gender, and other inequalities, and protecting natural environments, thus invigorating inclusive growth, sustainable development, and well-being.",
            "Autonomy": "AI actors should implement mechanisms and safeguards, such as the capacity for human determination, that is appropriate to the context and consistent with the state of art.",
            "Human Formation": "Governments should work closely with stakeholders to prepare for the transformation of the world of work and of society. They should empower people to effectively use and interact with AI systems across the breadth of applications, including by equipping them with the necessary skills.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "AI actors should respect the rule of law, human rights, and democratic values, throughout the AI system lifecycle. These include freedom, dignity and autonomy, privacy and data protection, nondiscrimination and equality, diversity, fairness, social justice, and internationally recognized labor rights.",
            "Labor Rights": "AI actors should respect the rule of law, human rights, and democratic values, throughout the AI system lifecycle. These include freedom, dignity and autonomy, privacy and data protection, nondiscrimination and equality, diversity, fairness, social justice, and internationally recognized labor rights. Governments should take steps, including through social dialogue, to ensure a fair transition for workers as AI is deployed, such as through training programs along with the working life, support for those affected by displacement, and access to new opportunities in the labor market. Governments should also work closely with stakeholders to promote the responsible use of AI at work, enhance the safety of workers and the quality of jobs, foster entrepreneurship and productivity, and aim to ensure that the benefits from AI are broadly and fairly shared.",
            "Cooperation": "Governments should also consider public investment and encourage private investment in open datasets that are representative and respect privacy and data protection to support an environment for AI research and development that is free of inappropriate bias and to improve interoperability and use of standards. Governments, including developing countries and stakeholders, should actively co-operate to advance these principles and to progress on responsible stewardship of trustworthy AI.  Governments should work together in the OECD and other global and regional fora to foster the sharing of AI knowledge, as appropriate. They should encourage international, cross-sectoral, and open multi-stakeholder initiatives to garner long-term expertise on AI.",
            "Privacy": "AI actors should respect the rule of law, human rights, and democratic values, throughout the AI system lifecycle. These include freedom, dignity and autonomy, privacy and data protection, nondiscrimination and equality, diversity, fairness, social justice, and internationally recognized labor rights.",
            "Reliability": "AI systems should be robust, secure, and safe throughout their entire lifecycle so that, in conditions of normal use, foreseeable use or misuse, or other adverse conditions, they function appropriately and do not pose an unreasonable safety risk. AI actors should based on their roles, the context, and their ability to act, apply a systematic risk management approach to each phase of the AI system lifecycle on a continuous basis to address risks related to AI systems, including privacy, digital security, safety, and bias.",
            "Sustainability": "Stakeholders should proactively engage in responsible stewardship of trustworthy AI in pursuit of beneficial outcomes for people and the planet, such as augmenting human capabilities and enhancing creativity, advancing the inclusion of underrepresented populations, reducing economic, social, gender, and other inequalities, and protecting natural environments, thus invigorating inclusive growth, sustainable development, and well-being.",
            "Transparency": "AI Actors should commit to transparency and responsible disclosure regarding AI systems. To this end, they should provide meaningful information, appropriate to the context, and consistent with the state of art.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "OP Financial Group's Ethical Guidelines for Artificial Intelligence",
        "country": "Finland",
        "world_region": "Northern Europe",
        "institution": "OP Financial Group",
        "institution_type": "Private Corporation",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the OP Financial Group, one of the largest financial companies in Finland. In this document, the OP Financial Group states some general principles that the company will follow during its use and development of AI technologies. The document can be understood as OP Financial Group's voluntary self-commitment to the ethical use and development of AI.",
        "document_url": "https://www.op.fi/op-ryhma/vastuullisuus/sitoumukset-ja-linjaukset",
        "attachments": "https://www.op.fi/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "We assign owners to the principles that guide our operations and the algorithms we develop and ensure the ethics of artificial intelligence throughout its lifecycle.",
            "Beneficence": "We utilize data and artificial intelligence responsibly to promote the well-being of our customers.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "We safeguard the privacy and personal information of individuals represented in the data we hold in accordance with our privacy policies.",
            "Reliability": "We carefully study the impact of choices related to our work on our customers and the community around us, and we always make responsible choices when utilizing artificial intelligence.",
            "Sustainability": null,
            "Transparency": "We operate openly in relation to our customers, partners, and stakeholders, ensuring the transparency required for the evaluation of artificial intelligence we develop.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "OpenAI Charter",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "OpenAI",
        "institution_type": [
            "Non-profit Organization",
            "Private Corporation"
        ],
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by OpenAI, an artificial intelligence research laboratory consisting of the for-profit corporation OpenAI LP and its parent company, the non-profit OpenAI Inc. This document describes the principles OpenAI uses to execute its mission. OpenAI's mission is to ensure that artificial intelligence benefits all of humanity, aligning AI systems with human intent. The document can de be understood as OpenAI's voluntary self-commitment to the safe and beneficial development of their AI technologies.",
        "document_url": "https://openai.com/charter/",
        "attachments": "https://openai.com/",
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "We commit to use any influence we obtain over AGI's deployment to ensure it is used for the benefit of all, and to avoid enabling uses of AI or AGI that harm humanity or unduly concentrate power. Our primary fiduciary duty is to humanity. We anticipate needing to marshal substantial resources to fulfill our mission, but will always diligently act to minimize conflicts of interest among our employees and stakeholders that could compromise broad benefit.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": "OpenAI's mission is to ensure that artificial intelligence benefits all of humanity. An important part of this effort is training AI systems to do what humans want.",
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": "We are concerned about late-stage AGI development becoming a competitive race without time for adequate safety precautions. Therefore, if a value-aligned, safety-conscious project comes close to building AGI before we do, we commit to stop competing with and start assisting this project. We will actively cooperate with other research and policy institutions; we seek to create a global community working together to address AGI's global challenges.",
            "Privacy": null,
            "Reliability": "We are committed to doing the research required to make AGI safe, and to driving the broad adoption of such research across the AI community. We are committed to providing public goods that help society navigate the path to AGI. Today this includes publishing most of our AI research, but we expect that safety and security concerns will reduce our traditional publishing in the future while increasing the importance of sharing safety, policy, and standards research.",
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Oxford Munich Code of Conduct",
        "country": "Germany",
        "world_region": "Western Europe",
        "institution": "University of Oxford, University of Granada",
        "institution_type": "Academic",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the University of Oxford, a collegiate research university in Oxford (England - UK), and the University of Granada, a public university located in the city of Granada (Spain). This document provides a code of conduct for professional data scientists and can be understood as a voluntary self-commitment to ethical behavior when working with data.",
        "document_url": "http://www.code-of-ethics.org/code-of-conduct/",
        "attachments": "http://www.code-of-ethics.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "The Data Scientist will always act following the law, developing a full knowledge of, and ensuring compliance with, all relevant regulatory regimes. Employers should take steps to raise their data scientists' awareness and knowledge of such issues. The Data Scientist shall behave as if she/he would be liable for the accuracy and usage of her/his model. Moreover, a data scientist shall write Terms and conditions for her/his work.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "Data scientists shall not create inferred evidence that violates fundamental principles, such as the presumption of innocence, etc.",
            "Diversity": null,
            "Autonomy": "A data scientist shall be aware of the impact of changing geographical aggregation units. A particular case is so-called “Gerrymandering”, consisting of selecting different geographical units to influence the results of elections. The Data Scientist shall not make use of any technique to create or assist in the creation of manipulative evidence (e.g., psychometrics, social network analysis, etc,)",
            "Human Formation": "The Data Scientist will always strive to improve his/her competence and technical excellence. For example, Data Scientists should be encouraged to attend topical presentations, seminars, and courses covering new advances.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "The Data Scientist has a duty not to break gender, race, ethnicity, marital status, religion, belief, disability, or age equality legislation. In particular, such attributes should not place individuals at any disadvantage within models or any automated decisions. The Data Scientist is supposed to analyze and document potential bias present in the data and assess how this bias might affect the results and the usage of the models. he Data Scientist is responsible for detecting and flagging features that might be surrogates to other features that violate fundamental equality rights (gender, race, religion, etc). In general, proxy features need to always be checked against social discriminating features.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "The Data Scientist must act to protect the privacy and confidentiality of data, respect the ownership of proprietary data, and not expose data (within private or public fora) that might cause any harm to individuals or legal entities. The Data Scientist shall not apply any technique (combination, enriching, etc.) to turn information that has been designed to be “de-identifiable” into “identifiable” again. The Data Scientist shall be aware of the implications of new decentralized data storage technologies where critical privacy-protecting operations (such as physical record deletion), are not directly supported.",
            "Reliability": "The Data Scientist is accountable for selecting the best accuracy measure possible depending on the nature of the problem, as well as proactively assessing the validity of the model. Options, accuracy measures, and choices should be documented. The Data Scientist is responsible for assessing the adequacy of data to solve the particular problem and sharing the results of the analysis, indicating risks or potential implications due to lack of data quality or availability. The Data Scientist shall be responsible to ensure reproducibility in situations where understanding the overall behavior of the system is critical.",
            "Sustainability": null,
            "Transparency": "The Data Scientist will strive for transparency within as wide a forum as allowable by legal and proprietary constraints. The data scientist will not withhold concerns or potential limitations from colleagues and managers.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Partnership on AI Tenets",
        "country": "Unspecified",
        "world_region": "Unspecified",
        "institution": "Partnership on Artificial Intelligence to Benefit People and Society (Partnership on AI)",
        "institution_type": "Non-profit Organization",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by Partnership on Artificial Intelligence to Benefit People and Society (Partnership on AI), a nonprofit coalition committed to the responsible use of artificial intelligence. In this document, Partnership on AI presents its tenets, which are a set of principles that serve as voluntary self-commitment to the ethical use and development of AI technologies.",
        "document_url": "https://partnershiponai.org/about/",
        "attachments": "https://partnershiponai.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "We believe that AI research and development efforts need to be actively engaged with and accountable to a broad range of stakeholders. We will engage with and have representation from stakeholders in the business community to help ensure that domain-specific concerns and opportunities are understood and addressed.",
            "Beneficence": "We will seek to ensure that AI technologies benefit and empower as many people as possible.",
            "Children's Rights": null,
            "Human Rights": "We will work to maximize the benefits and address the potential challenges of AI technologies, by opposing the development and use of AI technologies that would violate international conventions or human rights and promoting safeguards and technologies that do not harm.",
            "Diversity": "We will work to maximize the benefits and address the potential challenges of AI technologies, by striving to understand and respect the interests of all parties that may be impacted by AI advances.",
            "Autonomy": null,
            "Human Formation": "We will educate and listen to the public and actively engage stakeholders to seek their feedback on our focus, inform them of our work, and address their questions.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": "We are committed to open research and dialogue on the ethical, social, economic, and legal implications of AI. We strive to create a culture of cooperation, trust, and openness among AI scientists and engineers to help us all better achieve these goals.",
            "Privacy": "We will work to maximize the benefits and address the potential challenges of AI technologies, by working to protect the privacy and security of individuals.",
            "Reliability": "We will work to maximize the benefits and address the potential challenges of AI technologies, by ensuring that AI research and technology is robust, reliable, trustworthy, and operates within secure constraints.",
            "Sustainability": null,
            "Transparency": "We believe that it is important for the operation of AI systems to be understandable and interpretable by people, for purposes of explaining the technology.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "UNESCO Recommendation on the Ethics of Artificial Intelligence",
        "country": "United Nations",
        "world_region": "Intergovernmental Organization",
        "institution": "United Nations Educational, Scientific and Cultural Organization (UNESCO)",
        "institution_type": "International Organization",
        "year_of_publication": "2021",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Large (>10.000 Words, <20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the United Nations Educational, Scientific and Cultural Organization (UNESCO), a specialized agency of the United Nations (UN) aimed at promoting world peace and security through international cooperation in education, arts, sciences, and culture. The document is a standard-setting recommendation developed through a global approach, based on international law, and the purposes and principles of the Charter of the United Nations. With respect to the recommendations proposed by the document, UNESCO recommends that the Member States apply voluntarily the provisions of this document by taking appropriate steps to give effect within their jurisdictions to the principles and norms of the Recommendation in conformity with international law, including international human rights law.",
        "document_url": "https://unesdoc.unesco.org/ark:/48223/pf0000380455",
        "attachments": "https://unesdoc.unesco.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": true,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": true
        },
        "principles_definition": {
            "Accountability": "Member States should ensure that it is always possible to attribute ethical and legal responsibility for any stage of the life cycle of AI systems, as well as in cases of remedy related to AI systems, to physical persons, or to existing legal entities. Human oversight refers thus not only to individual human oversight but to inclusive public oversight, as appropriate. The ethical responsibility and liability for the decisions and actions based in any way on an AI system should always ultimately be attributable to AI actors corresponding to their role in the life cycle of the AI system.",
            "Beneficence": "AI actors should play a participative and enabling role to ensure peaceful and just societies, which are based on an interconnected future for the benefit of all, consistent with human rights and fundamental freedoms. The value of living in peaceful and just societies points to the potential of AI systems to contribute throughout their life cycle to the interconnectedness of all living creatures with each other and with the natural environment.",
            "Children's Rights": "Member States should ensure that the development and deployment of AI systems related to health in general and mental health in particular, paying due attention to children and youth, is regulated to the effect that they are safe, effective, efficient, scientifically and medically proven and enable evidence-based innovation and medical progress.",
            "Human Rights": "The inviolable and inherent dignity of every human constitutes the foundation for the universal, indivisible, inalienable, interdependent, and interrelated system of human rights and fundamental freedoms. Therefore, respect, protection, and promotion of human dignity and rights as established by international law, including international human rights law, is essential throughout the life cycle of AI systems. Human dignity relates to the recognition of the intrinsic and equal worth of each human being, regardless of race, color, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, the economic or social condition of birth, or disability and any other grounds.",
            "Diversity": "Respect, protection, and promotion of diversity and inclusiveness should be ensured throughout the life cycle of AI systems, consistent with international law, including human rights law. This may be done by promoting active participation of all individuals or groups regardless of race, color, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, the economic or social condition of birth, or disability and any other grounds.",
            "Autonomy": "No human being or human community should be harmed or subordinated, whether physically, economically, socially, politically, culturally, or mentally during any phase of the life cycle of AI systems. Human rights and fundamental freedoms must be respected, protected, and promoted, throughout the life cycle of AI systems. In scenarios where decisions are understood to have an impact that is irreversible or difficult to reverse or may involve life and death decisions, a final human determination should apply. In particular, AI systems should not be used for social scoring or mass surveillance purposes.",
            "Human Formation": "Public awareness and understanding of AI technologies and the value of data should be promoted through open and accessible education, civic engagement, digital skills and AI ethics training, media and information literacy and training led jointly by governments, intergovernmental organizations, civil society, academia, the media, community leaders and the private sector, and considering the existing linguistic, social and cultural diversity, to ensure effective public participation so that all members of society can make informed decisions about their use of AI systems and be protected from undue influence.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "AI actors should promote social justice and safeguard fairness and non-discrimination of any kind in compliance with international law. This implies an inclusive approach to ensuring that the benefits of AI technologies are available and accessible to all, taking into consideration the specific needs of different age groups, cultural systems, different language groups, persons with disabilities, girls and women, and disadvantaged, marginalized and vulnerable people or people in vulnerable situations.",
            "Labor Rights": "the Member States should support collaboration agreements among governments, academic institutions, vocational education and training institutions, industry, workers' organizations, and civil society to bridge the gap in skillset requirements to align training programs and strategies with the implications of the future of work and the needs of industry, including small and medium enterprises. Member States should work with private sector companies, civil society organizations, and other stakeholders, including workers and unions to ensure a fair transition for at-risk employees.",
            "Cooperation": "Furthermore, efforts, including international cooperation, should be made to overcome, and never take advantage of, the lack of necessary technological infrastructure, education, and skills, as well as legal frameworks, particularly in low-and middle-income countries, least developed countries, landlocked developing countries, and small island developing States, affecting communities. The notion of humans being interconnected is based on the knowledge that every human belongs to a greater whole, which thrives when all its constituent parts are enabled to thrive. Living in peaceful, just, and interconnected societies requires an organic, immediate, uncalculated bond of solidarity, characterized by a permanent search for peaceful relations, tending towards care for others and the natural environment in the broadest sense of the term.",
            "Privacy": "Privacy, a right essential to the protection of human dignity, human autonomy, and human agency, must be respected, protected, and promoted throughout the life cycle of AI systems. Data for AI systems must be collected, used, shared, archived, and deleted in ways that are consistent with international law and in line with the values and principles outlined in this Recommendation while respecting relevant national, regional and international legal frameworks.",
            "Reliability": "Unwanted harms (safety risks), as well as vulnerabilities to attack (security risks), should be avoided and should be addressed, prevented, and eliminated throughout the life cycle of AI systems to ensure human, environmental, and ecosystem safety and security. Safe and secure AI will be enabled by the development of sustainable, privacy-protective data access frameworks that foster better training and validation of AI models utilizing quality data.",
            "Sustainability": "The development of sustainable societies relies on the achievement of a complex set of objectives on a continuum of human, social, cultural, economic, and environmental dimensions. The advent of AI technologies can either benefit sustainability objectives or hinder their realization, depending on how they are applied across countries with varying levels of development. The continuous assessment of the human, social, cultural, economic, and environmental impact of AI technologies should therefore be carried out with full cognizance of the implications of AI technologies for sustainability as a set of constantly evolving goals across a range of dimensions, such as currently identified in the Sustainable Development Goals (SDGs) of the United Nations.",
            "Transparency": "The transparency and explainability of AI systems are often essential preconditions to ensure the respect, protection, and promotion of human rights, fundamental freedoms, and ethical principles. Transparency is necessary for relevant national and international liability regimes to work effectively. A lack of transparency could also undermine the possibility of effectively challenging decisions based on outcomes produced by AI systems and may thereby infringe the right to a fair trial and effective remedy, and limits the areas in which these systems can be legally used.",
            "Truthfulness": "The Member States should invest in and promote digital and media and information literacy skills to strengthen critical thinking and competencies needed to understand the use and implication of AI systems, in order to mitigate and counter disinformation, misinformation, and hate speech. A better understanding and evaluation of both the positive and potentially harmful effects of recommender systems should be part of those efforts."
        }
    },
    {
        "document_name": "AI Principles: Recommendations on the Ethical Use of Artificial Intelligence by the Department of Defense - Defense Innovation Board",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Defense Innovation Board",
        "institution_type": "NGO",
        "year_of_publication": "2019",
        "number_of_male_authors": "7",
        "number_of_female_authors": "2",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Defense Innovation Board (DIB), an independent advisory board set up in 2016 to bring the technological innovation and best practices of Silicon Valley to the U.S. Military. In this document,  the DIB examines AI ethics literature and develops a set of principles to guide the ethical development and application of AI in the DoD (Department of Defense).",
        "document_url": "https://media.defense.gov/2019/Oct/31/2002204458/-1/-1/0/DIB_AI_PRINCIPLES_PRIMARY_DOCUMENT.PDF",
        "attachments": "https://media.defense.gov/2019/Oct/31/2002204459/-1/-1/0/DIB_AI_PRINCIPLES_SUPPORTING_DOCUMENT.PDF",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Human beings should exercise appropriate levels of judgment and remain responsible for the development, deployment, use, and outcomes of DoD AI systems.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "DoD AI systems should be designed and engineered to fulfill their intended function while possessing the ability to detect and avoid unintended harm or disruption and for human or automated disengagement or deactivation of deployed systems that demonstrate unintended escalatory, or other, behavior.",
            "Human Formation": "Recommendation - Each Service, Combatant Command, Office of the Secretary of Defense Component, defense agency, and defense field activity should establish programs for training and education that are relevant to their respective DoD personnel in AI-related skills and knowledge.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "DoD should take deliberate steps to avoid unintended bias in the development and deployment of combat or non-combat AI systems that would inadvertently cause harm to persons.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "DoD AI systems should have an explicit, well-defined domain of use, and the safety, security, and robustness of such systems should be tested and assured across their entire life cycle within that domain of use.",
            "Sustainability": null,
            "Transparency": "DoD's AI engineering discipline should be sufficiently advanced such that technical experts possess an appropriate understanding of the technology, development processes, and operational methods of its AI systems, including transparent and auditable methodologies, data sources, design procedure, and documentation.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Megvii's Artificial Intelligence Application Guidelines",
        "country": "China",
        "world_region": "Eastern Asia",
        "institution": "Megvii",
        "institution_type": "Private Corporation",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Megvii, a Chinese technology company that designs image recognition and deep-learning software. According to Megvii, this document was written to standardize and guide the correct application and healthy development of artificial intelligence technology, ensuring that this development is safe, controllable, and reliable. This document can be understood as Megvii voluntary self-commitment to the ethical use and development of AI technologies.",
        "document_url": "https://www.ebrun.com/20190717/341980.shtml",
        "attachments": "https://en.megvii.com/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "AI solutions should be auditable and accountable. Errors, flaws, biases, or other negative effects of AI solutions should be recognized immediately and addressed aggressively as soon as they are discovered.",
            "Beneficence": "Technology should be a positive force. We are committed to being a responsible corporate citizen, complying with applicable laws and generally accepted ethical principles, and promoting the well-being of society.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "AI solutions should be accessible to all regardless of age, gender, ethnicity or other characteristics.",
            "Autonomy": "AI should not surpass human autonomy. Humans should be able to oversee the development of AI technology and the decisions of AI systems and intervene when necessary.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Developers of AI technologies should minimize the systematic bias in AI solutions that may arise from biases inherent in the data and algorithms used to develop the solutions.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "During the development and use of artificial intelligence solutions, it is necessary to strictly protect the personal privacy of users and ensure data security.",
            "Reliability": "AI solutions should be able to make accurate and effective decisions while being sufficiently secure and defensive against external attacks. AI solutions should be extensively tested, used sparingly, and closely monitored.",
            "Sustainability": null,
            "Transparency": "AI solutions should be auditable and accountable. Errors, flaws, biases, or other negative effects of AI solutions should be recognized immediately and addressed aggressively as soon as they are discovered.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation",
        "country": [
            "United Kingdom",
            "United States of America"
        ],
        "world_region": [
            "Western Europe",
            "North America"
        ],
        "institution": "Future of Humanity Institute, Centre for the Study of Existential Risk, Center for a New American Security, Electronic Frontier Foundation, OpenAI",
        "institution_type": [
            "Academic",
            "Non-profit Organization",
            "Private Corporation"
        ],
        "year_of_publication": "2018",
        "number_of_male_authors": "21",
        "number_of_female_authors": "5",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was jointly written by the Future of Humanity Institute (Oxford University), Centre for the Study of Existential Risk (University of Cambridge), Center for a New American Security, Electronic Frontier Foundation, and OpenAI. This document surveys the landscape of potential security threats from malicious uses of artificial intelligence technologies and proposes ways to better forecast, prevent, and mitigate these threats, also making recommendations on how such problems can be mitigated.",
        "document_url": "https://arxiv.org/pdf/1802.07228.pdf",
        "attachments": [
            "https://www.fhi.ox.ac.uk/",
            "https://www.cser.ac.uk/",
            "https://www.cnas.org/",
            "https://www.eff.org/",
            "https://openai.com/"
        ],
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": "Recommendation - AI researchers and the organizations that employ them are in a unique position to shape the security landscape of the AI-enabled world. We highlight the importance of education, ethical statements and standards, framings, norms, and expectations.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": "Recommendation - Policymakers should collaborate closely with technical researchers to investigate, prevent, and mitigate potential malicious uses of AI. Actively seek to expand the range of stakeholders and domain experts involved in discussions of these challenges.",
            "Privacy": null,
            "Reliability": "Recommendation - Researchers and engineers in artificial intelligence should take the dual-use nature of their work seriously, allowing misuse-related considerations to influence research priorities and norms, and proactively reaching out to relevant actors when harmful applications are foreseeable. Best practices should be identified in research areas with more mature methods for addressing dual-use concerns, such as computer security, and imported where applicable to the case of AI.",
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "AI UX: 7 Principles of Designing Good AI Products",
        "country": "Hungary",
        "world_region": "Eastern Europe",
        "institution": "UX studio",
        "institution_type": "Private Corporation",
        "year_of_publication": "2018",
        "number_of_male_authors": "1",
        "number_of_female_authors": "0",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by UX studio, a design and research agency based in Budapest (Hungary). The document presents several AI principles that UX studio follows in their development. It can be understood as UX studio's voluntary self-commitment to the ethical use and design of AI technologies.",
        "document_url": "https://uxstudioteam.com/ux-blog/ai-ux/",
        "attachments": "https://uxstudioteam.com/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": true
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "We should let people know if an algorithm has generated a piece of content so they can decide for themselves whether to trust it or not.",
            "Human Formation": null,
            "Human-Centeredness": "When we work on AI UX, we help developers decide what to optimize for. Providing meaningful insights about human reactions and human priorities can prove the most important job of a designer in an AI project. UX people help collect training data and define the expected outcome people want to see from the AI product.",
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "Recommendation - Find and handle edge cases so no weird or unpleasant things happen to your users. Test the AI UX with methods like the Wizard of Oz testing. Use the test participant's own data when emulating AI content requires.",
            "Sustainability": null,
            "Transparency": "We see our job as a UX company as helping people understand how machines work so they can use them better. We should give users hints about what the algorithm does or what data it uses.",
            "Truthfulness": "We must set the right expectations, especially in a world full of sensational, superficial news about new AI technologies. Set expectations so people will know what they can or can't achieve with the AI product."
        }
    },
    {
        "document_name": "Policy guidance on AI for children",
        "country": [
            "Finland",
            "United Nations"
        ],
        "world_region": [
            "Northern Europe",
            "Intergovernmental Organization"
        ],
        "institution": "United Nations Children's Fund (UNICEF), Ministry for Foreign Affairs of Finland",
        "institution_type": [
            "Governmental Institution",
            "International Organization"
        ],
        "year_of_publication": "2021",
        "number_of_male_authors": "2",
        "number_of_female_authors": "4",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the United Nations Children's Fund (UNICEF), the UN's agency responsible for providing humanitarian and developmental aid to children worldwide, together with the Ministry for Foreign Affairs of Finland. This document was developed to promote children's rights in government and private sector AI policies and practices, and to raise awareness of how AI systems can uphold or undermine these rights. To support the implementation of the guidance, the document also provides a list of online resources, together with a set of practical implementation tools, including a roadmap for policymakers, AI for children development canvas, an AI guide for parents, an AI guide for teens, and eight case studies reports on how the guidance has been applied in practice.",
        "document_url": "https://www.unicef.org/globalinsight/media/2356/file/UNICEF-Global-Insight-policy-guidance-AI-children-2.0-2021.pdf.pdf",
        "attachments": [
            "https://www.unicef.org/globalinsight/media/2341/file/UNICEF-Global-Insight-AI%20guide%20for%20teens-2021.pdf",
            "https://www.unicef.org/globalinsight/media/2336/file/UNICEF-Global-Insight-AI%20guide%20for%20parents-2021.pdf",
            "https://www.unicef.org/globalinsight/media/1166/file/UNICEF-Global-Insight-tools-to-operationalize-AI-policy-guidance-2020.pdf",
            "https://www.unicef.org/globalinsight/policy-guidance-ai-children-pilot-testing-and-case-studies",
            "https://docs.google.com/spreadsheets/d/1zKmFPZgnaOeuQafmcWRRp6l8BeyxSts2pC7wPndcYaM/edit#gid=779804929"
        ],
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": true,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Provide transparency, explainability, and accountability for children. I need to know how AI impacts me. You need to be accountable for that.",
            "Beneficence": "The opportunities that AI systems bring to children of all ages and backgrounds – such as to support their education, health care, and right to play – need to be fully leveraged when, and this is critical, it is appropriate to use AI systems. Children need to be protected from any harmful and discriminatory impacts of AI systems and safely interact with them. AI systems should also be leveraged to actively protect children from harm and exploitation.",
            "Children's Rights": "Empower governments and businesses with knowledge of AI and children's rights. You must know what my rights are and uphold them.",
            "Human Rights": null,
            "Diversity": "Ensure inclusion of and for children. Include me and those around me. All children should be empowered by AI and play a leading role in designing a responsible digital future for all.",
            "Autonomy": null,
            "Human Formation": "Support children's development and well-being. Let AI help me develop to my full potential. Prepare children for present and future developments in AI. If I am well prepared now, I can contribute to responsible AI for the future.",
            "Human-Centeredness": "Create an enabling environment. Make it possible for all to contribute to child-centred AI.",
            "Intellectual Property": null,
            "Fairness": "Prioritize fairness and non-discrimination for children. AI must be for all children.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Protect children's data and privacy. Ensure my privacy in an AI world.",
            "Reliability": "Ensure safety for children. I need to be safe in the AI world.",
            "Sustainability": null,
            "Transparency": "Provide transparency, explainability, and accountability for children. I need to know how AI impacts me. You need to be accountable for that.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Ethics & Governance of Artificial Intelligence for Health",
        "country": "United Nations",
        "world_region": "Intergovernmental Organization",
        "institution": "World Health Organization (WHO)",
        "institution_type": "International Organization",
        "year_of_publication": "2021",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the World Health Organization (WHO), a specialized agency of the United Nations responsible for international public health. This document is the result of a two-year development process led by two Departments in the WHO Science Division - Digital Health and Innovation and Research For Health. In it, the WHO presents core principles to promote the ethical use of AI for health. The document also presents several practical tools (e.g., Design for Values, HRIA) to implement ethics in AI development.",
        "document_url": "https://www.who.int/publications/i/item/9789240029200",
        "attachments": "https://www.who.int/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Human warranty requires the application of regulatory principles upstream and downstream of the algorithm by establishing points of human supervision. If something goes wrong with AI technology, there should be accountability. Appropriate mechanisms should be available for questioning and for redress for individuals and groups that are adversely affected by decisions based on algorithms.",
            "Beneficence": "AI technologies should not harm people. The designers of AI technologies should satisfy regulatory requirements for safety, accuracy, and efficacy for well-defined use cases or indications.",
            "Children's Rights": null,
            "Human Rights": "For AI to have a beneficial impact on public health and medicine, ethical considerations and human rights must be placed at the center of the design, development, and deployment of AI technologies for health.",
            "Diversity": "Inclusiveness requires that AI for health be designed to encourage the widest possible appropriate, equitable use and access, irrespective of age, sex, gender, income, race, ethnicity, sexual orientation, ability, or other characteristics protected under human rights codes. AI technology, like any other technology, should be shared as widely as possible.",
            "Autonomy": "The use of AI can lead to situations in which decision-making power could be transferred to machines. The principle of autonomy requires that the use of AI or other computational systems does not undermine human autonomy. In the context of health care, this means that humans should remain in control of healthcare systems and medical decisions. Respect for human autonomy also entails related duties to ensure that providers have the information necessary to make safe, effective use of AI systems and that people understand the role that such systems play in their care.",
            "Human Formation": "Sustainability also requires governments and companies to address anticipated disruptions in the workplace, including training for healthcare workers to adapt to the use of AI systems, and potential job losses due to the use of automated systems.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": ". AI technologies should not encode biases to the disadvantage of identifiable groups, especially groups that are already marginalized. Bias is a threat to inclusiveness and equity, as it can result in a departure, often arbitrary, from equal treatment. AI technologies should minimize inevitable disparities in power that arise between providers and patients, between policy-makers and people, and between companies and governments that create and deploy AI technologies and those that use or rely on them. No technology, AI or otherwise, should sustain or worsen existing forms of bias and discrimination.",
            "Labor Rights": "Sustainability also requires governments and companies to address anticipated disruptions in the workplace, including training for healthcare workers to adapt to the use of AI systems, and potential job losses due to the use of automated systems.",
            "Cooperation": null,
            "Privacy": "Respect for human autonomy also requires protection of privacy and confidentiality and obtaining valid informed consent through appropriate legal frameworks for data protection.",
            "Reliability": "Measures of quality control in practice and quality improvement in the use of AI overtime should be available. Preventing harm requires that AI not result in mental or physical harm that could be avoided by the use of an alternative practice or approach.",
            "Sustainability": "AI systems should be designed to minimize their environmental consequences and increase energy efficiency. That is, the use of AI should be consistent with global efforts to reduce the impact of human beings on the Earth's environment, ecosystems, and climate.",
            "Transparency": "AI technologies should be intelligible or understandable to developers, medical professionals, patients, users, and regulators. Two broad approaches to intelligibility are to improve the transparency of AI technology and to make AI technology explainable. Transparency requires that sufficient information be published or documented before the design or deployment of an AI technology and that such information facilitates meaningful public consultation and debate on how the technology is designed and how it should or should not be used. AI technologies should be explainable according to the capacity of those to whom they are explained.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Ethical ML Institute Responsible Machine Learning Principles",
        "country": "United Kingdom",
        "world_region": "Western Europe",
        "institution": "Institute for Ethical AI & Machine Learning (Ethical ML Institute)",
        "institution_type": "Academic",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Institute for Ethical AI & Machine Learning (Ethical ML Institute),  a research center based in the UK that develops frameworks that support the responsible development, deployment, and operation of machine learning systems. This document is comprised of a practical framework to guide technologists to develop machine learning systems responsibly. Together with ethical principles, the document cites existing practical tools to implement them in AI development.",
        "document_url": "https://ethical.institute/principles.html",
        "attachments": "https://ethical.institute/index.html",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": true,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "Technologists should understand the consequences of incorrect predictions, especially when automating critical processes that can have a significant impact on human lives (e.g., justice, health, transport, etc). I commit to assessing the impact of incorrect predictions and when reasonable, design systems with human-in-the-loop review processes.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Technologists should focus on building processes & methods to identify & document the inherent bias in the data, features, and inference results, and subsequently the implications of this bias. I commit to continue developing processes that allow me to understand, document, and monitor bias in development and production.",
            "Labor Rights": "We should look beyond the technology itself, and have the initiative to support the necessary stakeholders so they can develop a change-management strategy when rolling out the technology. Technologists should focus on building processes & methods to identify & document the inherent bias in the data, features, and inference results, and subsequently the implications of this bias. I commit to identifying and documenting relevant information so that business change processes can be developed to mitigate the impact of workers being automated.",
            "Cooperation": null,
            "Privacy": "Technologists should enforce privacy by design across systems, as well as continuous processes to build trust not only with users, but also with relevant stakeholders such as procurement frameworks, operational users, and beyond. I commit to building and communicating processes that protect and handle data with stakeholders that may interact with the system directly and/or indirectly.",
            "Reliability": "Technologists should commit to preparing for both types of security risks through explicit efforts, such as educating relevant personnel, establishing processes around data, and assessing the implications of ML backdoors (such as adversarial attacks). I commit to developing and improving reasonable processes and infrastructure to ensure data and model security are being taken into consideration during the development of machine learning systems.",
            "Sustainability": null,
            "Transparency": "technologists should invest reasonable efforts where necessary to continuously improve tools and processes that allow them to explain results based on features and models chosen. I commit to developing tools and processes to continuously improve the transparency and explainability of machine learning systems where reasonable. I commit to developing the infrastructure required to enable a reasonable level of reproducibility across the operations of ML systems.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "HPE AI Ethics and Principles",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Hewlett Packard Enterprise Company (HPE)",
        "institution_type": "Private Corporation",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Hewlett Packard Enterprise Company (HPE),  an American multinational enterprise information technology company based in Spring, Texas (US). The document presents HPE's ethical AI principles, which can be understood as HPE's voluntary self-commitment to the ethical development of AI technologies.",
        "document_url": "https://www.hpe.com/us/en/ai-ethics.html",
        "attachments": "https://www.hpe.com/us/en/home.html",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Be designed to enable responsible and accountable use, allow an understanding of AI, and for outcomes to be challenged.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "Respect human rights and be designed with mechanisms and safeguards, such as human oversight to prevent misuse.",
            "Diversity": "Be inclusive, minimize harmful bias, and ensure fair and equal treatment and access for individuals.",
            "Autonomy": "Respect human rights and be designed with mechanisms and safeguards, such as human oversight to prevent misuse.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Be inclusive, minimize harmful bias, and ensure fair and equal treatment and access for individuals.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Respect individuals' privacy, be secure, and minimize the risk of errors and unintended malicious use.",
            "Reliability": "Be engineered to build in quality testing, include safeguards to maintain functionality, and minimize misuse and impact of failure.",
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Thomson Reuters AI principles",
        "country": "Canada",
        "world_region": "North America",
        "institution": "Thomson Reuters Corporation",
        "institution_type": "Private Corporation",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Thomson Reuters Corporation, a Canadian multinational media conglomerate. In this document, Thomson Reuters presents its AI principles. The document can be understood as Thomson Reuter's voluntary self-commitment to the ethical design, development, and deployment of its AI technologies.",
        "document_url": "https://www.thomsonreuters.com/en/artificial-intelligence/ai-principles.html",
        "attachments": "https://www.thomsonreuters.com/en.html",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Thomson Reuters will maintain appropriate accountability measures for our AI products and services.",
            "Beneficence": "Thomson Reuters aims to design, develop and deploy AI products and services that are reliable and that help empower people to make efficient, informed, and socially beneficial decisions.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": "Thomson Reuters will strive to maintain a human-centric approach and will strive to design, develop and deploy AI products and services that treat people fairly.",
            "Intellectual Property": null,
            "Fairness": "Thomson Reuters will strive to maintain a human-centric approach and will strive to design, develop and deploy AI products and services that treat people fairly.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Thomson Reuters will prioritize safety, security, and privacy throughout the design, development, and deployment of our AI products and services.",
            "Reliability": "Thomson Reuters will prioritize safety, security, and privacy throughout the design, development, and deployment of our AI products and services.",
            "Sustainability": null,
            "Transparency": "Thomson Reuters will implement practices intended to make the use of AI in our products and services explainable.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Defense Innovation Unit Responsible AI Guidelines in Practice: Lessons Learned from the DIU Portfolio",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Defense Innovation Unit (DIU)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2021",
        "number_of_male_authors": "3",
        "number_of_female_authors": "2",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Defense Innovation Unit (DIU), a United States Department of Defense (DoD) organization founded to help the U.S. military make faster use of emerging commercial technologies. In this document, the DIU presents the Responsible Artificial Intelligence (RAI) Guidelines, which consist of step-by-step guidance for AI companies, DoD stakeholders, and program managers to ensure AI programs align with the DoD's Ethical Principles for AI. The document also brings a practical tool to help stakeholders apply the DoD's Ethical Principles for AI in the planning, development, and deployment of AI applications.",
        "document_url": "https://assets.ctfassets.net/3nanhbfkr0pc/acoo1Fj5uungnGNPJ3QWy/3a1dafd64f22efcf8f27380aafae9789/2021_RAI_Report-v3.pdf",
        "attachments": "https://www.diu.mil/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "DoD personnel will exercise appropriate levels of judgment and care while remaining responsible for the development, deployment, and use of AI capabilities.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "The Department will take deliberate steps to minimize unintended bias in AI capabilities.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "The Department's AI capabilities will have explicit, well-defined uses and the safety, security, and effectiveness of such capabilities will be subject to testing and assurance within those defined uses across their entire life cycles. The Department will design and engineer AI capabilities to fulfill their intended functions while possessing the ability to detect and avoid unintended consequences, and the ability to disengage or deactivate deployed systems that demonstrate unintended behavior.",
            "Sustainability": null,
            "Transparency": "The Department's AI capabilities will be developed and deployed such that relevant personnel possesses an appropriate understanding of the technology, development processes, and operational methods applicable to AI capabilities, including transparent and auditable methodologies, data sources, and design procedure and documentation.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "DoD Ethical Principles for Artificial Intelligence",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Department of Defense (DoD)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2020",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the US Department of Defense (DoD), an executive branch department of the federal government charged with coordinating and supervising all agencies and functions of the government directly related to national security and the United States Armed Forces. The document presents the DoD's AI ethical principles, which were built on the US military's existing ethics framework, the US Constitution, the Title 10 of the US Code, the Law of War, and other existing international treaties. These principles apply to both combat and non-combat functions, and assist the US military in upholding legal, ethical, and policy commitments in the field of AI.",
        "document_url": "https://www.defense.gov/News/Releases/Release/Article/2091996/dod-adopts-ethical-principles-for-artificial-intelligence/",
        "attachments": "https://www.defense.gov/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "DoD personnel will exercise appropriate levels of judgment and care while remaining responsible for the development, deployment, and use of AI capabilities.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "The Department will take deliberate steps to minimize unintended bias in AI capabilities.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "The Department's AI capabilities will have explicit, well-defined uses and the safety, security, and effectiveness of such capabilities will be subject to testing and assurance within those defined uses across their entire life cycles. The Department will design and engineer AI capabilities to fulfill their intended functions while possessing the ability to detect and avoid unintended consequences, and the ability to disengage or deactivate deployed systems that demonstrate unintended behavior.",
            "Sustainability": null,
            "Transparency": "The Department's AI capabilities will be developed and deployed such that relevant personnel possesses an appropriate understanding of the technology, development processes, and operational methods applicable to AI capabilities, including transparent and auditable methodologies, data sources, and design procedure and documentation.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Alpha Principles for the Ethical Use of AI and Data Driven Technologies in Ontario",
        "country": "Canada",
        "world_region": "North America",
        "institution": "Government of Ontario",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2020",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Government of Ontario, which is the body responsible for the administration of the Canadian province of Ontario. The document sets points to align the use of data-driven technologies within Canadian government processes, programs, and services with ethical considerations and values.",
        "document_url": "https://github.com/ongov/AI-Principles",
        "attachments": "https://github.com/ongov",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Organizations and individuals developing, deploying, or operating AI systems should be held accountable for their ongoing proper functioning in line with the above principles. Algorithmic systems should be periodically peer-reviewed or audited to ensure that unwanted biases have not inadvertently crept in overtime. Where AI is used to make decisions about individuals there needs to be a process for redress to better understand how a given decision was made.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "Data-driven technologies should be designed in a way that respects the rule of law, human rights, democratic values, and diversity, and they should include appropriate safeguards to ensure a fair and just society. Designers, policymakers, and developers should respect the rule of law, human rights, and democratic values, throughout the AI system lifecycle. These include freedom, dignity and autonomy, privacy and data protection, non-discrimination and equality, diversity, fairness, social justice, and internationally recognized labor rights.",
            "Diversity": "Data-driven technologies should be designed in a way that respects the rule of law, human rights, democratic values, and diversity, and they should include appropriate safeguards to ensure a fair and just society. Designers, policymakers, and developers should respect the rule of law, human rights, and democratic values, throughout the AI system lifecycle. These include freedom, dignity and autonomy, privacy and data protection, non-discrimination and equality, diversity, fairness, social justice, and internationally recognized labor rights.",
            "Autonomy": "Data-driven technologies should be designed in a way that respects the rule of law, human rights, democratic values, and diversity, and they should include appropriate safeguards to ensure a fair and just society. Designers, policymakers, and developers should respect the rule of law, human rights, and democratic values, throughout the AI system lifecycle. These include freedom, dignity and autonomy, privacy and data protection, non-discrimination and equality, diversity, fairness, social justice, and internationally recognized labor rights.",
            "Human Formation": null,
            "Human-Centeredness": "The processes and outcomes behind an algorithm should always be developed with human users as the main consideration. Human-centered AI should reflect the information, goals, and constraints that a human decision-maker weighs when arriving at a decision. Keeping human users at the center entails evaluating any outcomes (both direct and indirect) that might affect them due to the use of the algorithm. Contingencies for unintended outcomes need to be in place as well, including removing the algorithms entirely or ending their application.",
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "Data-driven technologies like AI and ML systems must function in a robust, secure, and safe way throughout their life cycles and potential risks should be continually assessed and managed. Designers and developers should implement mechanisms and safeguards, such as the capacity for human determination and complete halt of the system operations, that are appropriate to the context and predetermined at initial deployment.",
            "Sustainability": "Other byproducts of deploying data-driven technologies such as environmental, sustainability, and societal impacts should be considered as they apply to specific sectors and use cases and applicable frameworks, best practices, or laws. Experts in both technology and ethics should be consulted in the development of data-driven technologies such as AI to guard against any adverse effects (including societal, environmental, and other long-term effects).",
            "Transparency": "There must be transparent and responsible disclosure around data-driven technology like AI, automated decisions, and ML systems to ensure that people understand outcomes and can discuss, challenge, and improve them. Where automated decision making has been used to make individualized and automated decisions about humans, meaningful information about the logic involved, as well as the significance and the envisaged consequences of such processing for the data subject should be available.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Transparency Guidelines for Data-Driven Technology in Government",
        "country": "Canada",
        "world_region": "North America",
        "institution": "Government of Ontario",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2020",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Normative",
            "Practical"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Government of Ontario, which is the body responsible for the administration of the Canadian province of Ontario. This document sets out points to help minimize the risks and maximize the benefits of using data-driven technologies within government processes, programs and services through transparency. The document also cites practical tools to help stakeholders implement its recommendations (e.g., Ontario's Digital Service Standard, Canadian Algorithmic Impact Assessment).",
        "document_url": "https://github.com/ongov/Transparency-Guidelines",
        "attachments": "https://github.com/ongov",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "Keep People in Focus and the Loop - Be aware of who will benefit most and who will be impacted both directly and indirectly as a result of using the data-driven technology. Development activities from design, to implementation, need to reflect multiple perspectives to assess and address potential and perceived risks.",
            "Autonomy": "People have a right to think and act for themselves. Governments should not limit a person's ability to make important decisions for themselves, their dependents, or their livelihoods. When the government makes decisions, they should be done with people/stakeholders rather than on their behalf so the outcomes can be more practical, appropriate, and trustworthy. Advice should actively be sought from people contributing to any related data, designing any AI elements, or affected by any impacts to ensure the use of any data-driven technology is designed and implemented optimally for collective benefit.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Data used to train machines needs to be assessed for bias continually and steps need to be taken to flag and minimize different biases during the entire lifecycle of use.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "Many jurisdictions are beta testing impact assessments to support safe and responsible AI and data use. These tools can help express intentions, expectations, and outcomes. Adding a deeper dimension to measurement and risk mitigations beyond technical specifications.",
            "Sustainability": null,
            "Transparency": "Respect the public's right to know when and how data enhancements to a decision or process may impact their lives. When acquiring or using technology such as AI that significantly affects individuals and communities notice should be provided that is public, timely, and clear. Notice should be accessible to a broad audience and outline the purpose and potential impacts of a technological intervention like AI as well as clear channels for further communication. Clear lines of communication to learn more, provide input or submit challenges should be accessible and promoted during multiple stages of development and use of data-driven technologies.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Integrate's AI principles",
        "country": "Canada",
        "world_region": "North America",
        "institution": "Integrate.ai",
        "institution_type": "Private Corporation",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Integrate.ai, a Canadian software development company. In this document, Integrate.ai presents its AI principles, which can be understood as Integrate.ai voluntary self-commitment to the safe, responsible, and fair development of its AI applications.",
        "document_url": "https://integrate.ai/blog/integrates-ai-principles/",
        "attachments": "https://integrate.ai/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "We are responsible for the products we design and their outputs. For a user of our products to make responsible decisions within their organizations, we need to understand how and why a prediction was made. This is one reason why our models must be explainable. In other words, we can understand how and why a prediction was made. So, transparency is essential. We build products that complement and enhance your decision-making abilities. Not products that replace them. At the end of the day, because we take responsibility for the things we build, we'll never create tools that can be misused or abused in any way.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Bias varies across cultures and contexts. This is something we readily acknowledge and attempt to mitigate in the datasets we use and the models we build. We don't knowingly introduce bias, appeal to relativistic definitions of fairness, or allow fairness to be used as a tradeoff for revenue. We believe our systems should reflect the best that humans can be and not the preexisting biases we have already fallen prey to.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Keeping customers and end-users safe should be a function of every AI system. If they aren't, everything else is irrelevant. Data security and customer privacy are foundational to what we do. That's why we've implemented Privacy by Design standards. We're also transparent about how we handle data. We never accept, use, or store any personally identifiable information (PII). We do not compromise on our principle of safety, even in instances where a risky approach might yield better results.",
            "Reliability": "Keeping customers and end-users safe should be a function of every AI system. If they aren't, everything else is irrelevant. Data security and customer privacy are foundational to what we do. That's why we've implemented Privacy by Design standards. We're also transparent about how we handle data. We never accept, use, or store any personally identifiable information (PII). We do not compromise on our principle of safety, even in instances where a risky approach might yield better results.",
            "Sustainability": null,
            "Transparency": "We are responsible for the products we design and their outputs. For a user of our products to make responsible decisions within their organizations, we need to understand how and why a prediction was made. This is one reason why our models must be explainable. In other words, we can understand how and why a prediction was made. So, transparency is essential. We build products that complement and enhance your decision-making abilities. Not products that replace them. At the end of the day, because we take responsibility for the things we build, we'll never create tools that can be misused or abused in any way.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "National Association of Insurance Commissioners (NAIC) Principles on Artificial Intelligence (AI)",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "National Association of Insurance Commissioners (NAIC)",
        "institution_type": "Non-profit Organization",
        "year_of_publication": "2020",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the National Association of Insurance Commissioners (NAIC), which is the U.S. standard-setting and regulatory support organization created and governed by the chief insurance regulators from the 50 states, the District of Columbia, and five U.S. territories. This document establishes high-level guiding principles for AI actors. These principles serve to guide regulators and NAIC committees in addressing insurance-specific AI applications.",
        "document_url": "https://content.naic.org/sites/default/files/inline-files/AI%20principles%20as%20Adopted%20by%20the%20TF_0807.pdf",
        "attachments": "https://content.naic.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": true,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "AI actors should be accountable for ensuring that AI systems operate in compliance with these principles consistent with the actors' roles, within the appropriate context and evolving technologies. Any AI system should be compliant with legal requirements governing its use of data and algorithms during its phase of the insurance life cycle. Data supporting the outcome of an AI application should be retained and be able to be produced following applicable insurance laws and regulations in each jurisdiction. AI actors should be responsible for the creation, implementation, and impacts of any AI system, even if the impacts are unintended.",
            "Beneficence": "AI systems should not be designed to harm or deceive people and should be implemented in a manner that avoids harmful or unintended consequences and corrects and remediates such consequences when they occur.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "AI actors should implement mechanisms and safeguards consistent with the degree and nature of the risks posed by AI to ensure all applicable laws and regulations are followed, including ongoing (human or otherwise) monitoring and, when appropriate, human intervention.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": "AI actors must have the ability to protect the confidentiality of proprietary algorithms, provided adherence to individual state laws and regulations in all states where AI is deployed can be demonstrated.",
            "Fairness": "AI actors should respect the rule of law throughout the AI life cycle. This includes, but is not limited to, insurance laws and regulations, such as those relating to trade practices, unfair discrimination, access to insurance, underwriting, privacy, consumer protection and eligibility practices, ratemaking standards, advertising decisions, claims practices, and solvency.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "AI actors should respect the rule of law throughout the AI life cycle. This includes, but is not limited to, insurance laws and regulations, such as those relating to trade practices, unfair discrimination, access to insurance, underwriting, privacy, consumer protection and eligibility practices, ratemaking standards, advertising decisions, claims practices, and solvency.",
            "Reliability": "AI systems should be robust, secure, and safe throughout the entire life cycle so that in conditions of normal or reasonably foreseeable use, or adverse conditions, they can function in compliance with applicable laws and regulations. To this end, AI actors should ensure a reasonable level of traceability concerning datasets, processes, and decisions made during the AI system life cycle. AI actors should enable an analysis of the AI system's outcomes, responses, and other insurance-related inquiries, as",
            "Sustainability": null,
            "Transparency": "To improve the public's confidence in AI, AI actors should commit to transparency and responsible disclosures regarding AI systems to relevant stakeholders. AI actors must have the ability to protect the confidentiality of proprietary algorithms, provided adherence to individual state laws and regulations in all states where AI is deployed can be demonstrated. These proactive disclosures include revealing the kind of data being used, the purpose of the data in the AI system, and consequences for all stakeholders. Consistent with applicable laws and regulations, stakeholders (which includes regulators and consumers) should have a way to inquire about, review, and seek recourse for AI-driven insurance decisions. This information should be easy-to-understand and describe the factors that lead to the prediction, recommendation, or decision. This information may be presented differently and should be appropriate for applicable stakeholders.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Samsung Principles for AI Ethics",
        "country": "South Korea",
        "world_region": "Eastern Asia",
        "institution": "Samsung Electronics Co., Ltd. (Samsung)",
        "institution_type": "Private Corporation",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Samsung Electronics Co., Ltd. (Samsung), a South Korean multinational electronics corporation headquartered in the Yeongtong District of Suwon. In this document, Samsung presents its AI principles, which can be understood as Samsung's voluntary self-commitment to the ethical development of its AI technologies.",
        "document_url": "https://research.samsung.com/artificial-intelligence",
        "attachments": "https://www.samsung.com/latin_en/sustainability/digital-responsibility/ai-ethics/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "The company will strive to apply the principles of social and ethical responsibility to AI system.",
            "Beneficence": "The company will strive to benefit the society and promote the corporate citizenship though AI system.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "The company will strive to provide easy access to all users.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "The company will strive to apply the values of equality and diversity in  AI systems throughout its entire lifecycle. The company will strive not to reinforce nor propagate negative or unfair bias.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "AI system will be adequately protected and have security measures to prevent data breach and cyber attacks.",
            "Sustainability": null,
            "Transparency": "Users will be aware that they are interacting with AI. AI will be explainable for users to understand its decision or recommendation to the extent technologically feasible. The process of collecting or utilizing personal data will be transparent.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "IBM AI Ethics",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "IBM Corporation",
        "institution_type": "Private Corporation",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": [
            "Normative",
            "Practical"
        ],
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the IBM Corporation, an American multinational technology corporation headquartered in Armonk (New York, US). In this document, IBM presents its AI principles/foundational properties for AI ethics. The document can be understood as IBM's voluntary self-commitment to the ethical development of its AI applications. This document is also tied to practical tools developed by IBM (e.g., AI Explainability 360 toolkit, AI Fairness 360 toolkit) to help implement ethical principles in AI development.",
        "document_url": "https://www.ibm.com/artificial-intelligence/ethics",
        "attachments": "https://www.ibm.com",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": "The purpose of AI is to augment human intelligence.",
            "Intellectual Property": null,
            "Fairness": "At IBM, we believe AI should make all of us better at our jobs, and that the benefits of the AI era should touch the many, not just the elite few.",
            "Labor Rights": null,
            "Cooperation": "We believe that government data policies should be fair and equitable and prioritize openness.",
            "Privacy": "Data and insights belong to their creator. IBM clients' data is their data, and their insights are their insights. AI systems must prioritize and safeguard consumers' privacy and data rights.",
            "Reliability": "AI must be secure and robust.",
            "Sustainability": null,
            "Transparency": "Technology must be transparent and explainable. Companies must be clear about who trains their AI systems, what data was used in training and, most importantly, what went into their algorithms' recommendations.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Linux Foundation AI Principles",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Linux Foundation (LF)",
        "institution_type": "Non-profit Organization",
        "year_of_publication": "2020",
        "number_of_male_authors": "1",
        "number_of_female_authors": "1",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the LF AI & Data, an umbrella foundation of the Linux Foundation that supports open source innovation in artificial intelligence and data. The Linux Foundation (LF) is a non-profit technology consortium founded in 2000 as a merger between Open Source Development Labs and the Free Standards Group. In this document, LF AI & Data presents a set of principles to help AI stakeholders to develop open and innovative technology built with trust and accountability.",
        "document_url": "https://lfaidata.foundation/blog/2021/02/08/lf-ai-data-announces-principles-for-trusted-ai/#:~:text=LF%20%26%20AI%20Data%20Foundation%20AI,Accountability%2C%20Transparency%2C%20and%20Security.",
        "attachments": "https://lfaidata.foundation/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Accountability requires AI and the people behind the AI to explain, justify, and take responsibility for any decision and action made by the AI. Mechanisms, such as governance and tools, are necessary to achieve accountability.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Equitability for AI and the people behind AI should take deliberate steps – in the AI life-cycle – to avoid intended or unintended bias and unfairness that would inadvertently cause harm.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Privacy requires AI systems to guarantee privacy and data protection throughout a system's entire lifecycle. The lifecycle activities include the information initially collected from users, as well as information generated about users throughout their interaction with the system e.g., outputs that are AI-generated for specific users or how users responded to recommendations. Any AI must ensure that data collected or inferred about individuals will not be used to unlawfully or unfairly discriminate against them. Privacy and transparency are especially needed when dealing with digital records that allow inferences such as identity, preferences, and future behavior.",
            "Reliability": "Reproducibility is the ability of an independent team to replicate in an equivalent AI environment, domain or area, the same experiences or results using the same AI methods, data, software, codes, algorithms, models, and documentation, to reach the same conclusions as the original research or activity. Adhering to this principle will ensure the reliability of the results or experiences produced by any AI. Robustness refers to the stability, resilience, and performance of the systems and machines dealing with changing ecosystems. AI must function robustly throughout its life cycle and potential risks should be continually assessed and managed. Security and safety of AI should be tested and assured across the entire life cycle within an explicit and well-defined domain of use. In addition, any AI should be designed to also safeguard the people who are impacted.",
            "Sustainability": null,
            "Transparency": "Transparency entails the disclosure around AI systems to ensure that people understand AI-based outcomes, especially in high-risk AI domains. When relevant and not immediately obvious, users should be clearly informed when and how they are interacting with an AI and not a human being. For transparency, ensuring that clear information is provided about the AI's capabilities and limitations, in particular the purpose for which the systems are intended, is necessary. Information about training and testing data sets where feasible, the conditions under which AI can be expected to function as intended and the expected level of accuracy in achieving the specified purpose, should also be supplied. Explainability is the ability to describe how AI works, i.e., makes decisions. Explanations should be produced regarding both the procedures followed by the AI (i.e., its inputs, methods, models, and outputs) and the specific decisions that are made. These explanations should be accessible to people with varying degrees of expertise and capabilities including the public. For the explainability principle to take effect, the AI engineering discipline should be sufficiently advanced such that technical experts possess an appropriate understanding of the technology, development processes, and operational methods of its AI systems, including the ability to explain the sources and triggers for decisions through transparent, traceable processes and auditable methodologies, data sources, and design procedure and documentation.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "ADP: Ethics in Artificial Intelligence",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Always Design for People (ADP)",
        "institution_type": "Private Corporation",
        "year_of_publication": "2022",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by Always Design for People (ADP), a global provider of cloud-based human capital management (HCM) solutions. In this document, ADP presents a set of principles and processes to govern their use of newer technologies, including real-time, operational monitoring of automated decisions. This document can be understood as ADP's voluntary self-commitment to the ethical use of their AI technologies.",
        "document_url": "https://www.adp.com/-/media/adp/redesign2018/pdf/data-privacy/ai-ethics-statement.pdf?rev=f155df771fea4850b310f17ca407f3f1&hash=73364D9FB41931A7C1887B976538BE5C",
        "attachments": "https://www.adp.com/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "We are committed to having diverse teams design and develop our ML models, to ensure a wide variety of perspectives and experiences are considered. After all, ML models impact humans, and human experience should inform that impact.",
            "Autonomy": "ADP believes that human oversight is essential to the reliable operation of ML models and making proper use of their results. Our solutions provide recommendations to human decision-makers, which they can then decide how to act upon.",
            "Human Formation": "We support skills development to accelerate the growth of a diverse workforce that can develop and deploy the ML solutions of the future.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Included in this approach is the isolation of unintended bias. Bias in the world of work—that is, favoring or disfavoring one group compared with another—is caused by a variety of factors. Ethically, anyone developing ML technologies should be vigilant not to reproduce such bias in any ML-enabled product or service. Even when accounting for potential unintentional bias in the source data, coding, or use of an AI-enabled product or service, there can be an unexpected or unforeseen bias that comes into play. ADP's goal is to continually strive to identify new and unexpected sources of bias and then refresh and enhance the design of our client offerings to address them.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "We have implemented an enterprise-wide Privacy-By-Design approach that incorporates privacy and data security into our ML model development and data processing systems more generally. ADP provides information about how we handle personal data in privacy statements made available to our client's employees, consumers, and job applicants. Our ML models seek to minimize access to identifiable information to ensure we use only the personal data we need to generate insights. We also maintain a robust security program for our ML models, including designing them in line with our security standards and protecting them against misuse or compromise.",
            "Reliability": "While AI holds the potential to mitigate human bias, without proper oversight it can incorporate bias as well. We have implemented audit and risk assessments to test our ML models as the baseline of our oversight methodologies. We continue to actively monitor and improve our models and systems to ensure that changes in the underlying data or model conditions do not inappropriately affect the desired results. And we apply our existing compliance, business ethics, and risk management governance structures to our ML development activities.",
            "Sustainability": null,
            "Transparency": "We strive to develop ML models that are explainable and direct, with clear purposes. Our ML models are designed with understanding as a key attribute, measured against an expressed the desired outcome. We test and evaluate our ML models accordingly, adjusting as needed to maintain accuracy in line with the models' purposes. We provide our clients with information about how our ML models operate, their proper use, and their limitations so that clients can implement those models following their design and purpose, operate them effectively, and use their outputs as intended.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Ethical Aspects of Autonomous and Intelligent Systems",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "http://globalpolicy.ieee.org/wp-content/uploads/2019/06/IEEE19002.pdf",
        "institution_type": [
            "Non-profit Organization",
            "Professional Association"
        ],
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Institute of Electrical and Electronics Engineers (IEEE), a professional association for electronic engineering and electrical engineering. In this document, the IEEE points to the need for developers and operators of A/IS systems (Autonomous and Intelligent systems) to maintain awareness of and employ consensus-based global best technical practices and standards that recognize and align end-users and citizen's values when building and deploying A/IS. IEEE endorses the principle that the design, development, and implementation of autonomous and intelligent systems (A/IS) should be undertaken with consideration for the societal consequences and safe operation of systems concerning a series of ethical principles presented in this document.",
        "document_url": "http://globalpolicy.ieee.org/wp-content/uploads/2019/06/IEEE19002.pdf",
        "attachments": "https://www.ieee.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "A/IS should be designed and operated in a manner that permits production of an unambiguous rationale for the decisions made by the system.",
            "Beneficence": "A/IS developers should consider the impact on individual and societal well-being as the central criterion in development.",
            "Children's Rights": null,
            "Human Rights": "A/IS should be developed and operated in a manner that respects internationally recognized human rights.",
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "A/IS developers should respect each individual's ability to maintain appropriate control over their data and identifying information.",
            "Reliability": "Developers and operators should consider the effectiveness and fitness of A/IS technologies for the purpose of their systems.  Designers of A/IS creators should consider and guard against potential misuses and operational risks. Designers of A/IS should specify operators should possess the knowledge and skill required for safe and effective operation.",
            "Sustainability": null,
            "Transparency": "To the greatest extent feasible, the technical basis of the particular decisions made by an A/IS should be discoverable.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "IEEE Position Statement - Artificial Intelligence",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Institute of Electrical and Electronics Engineers (IEEE)",
        "institution_type": [
            "Non-profit Organization",
            "Professional Association"
        ],
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Institute of Electrical and Electronics Engineers (IEEE), a professional association for electronic engineering and electrical engineering. In this document, the IEEE makes a series of recommendations, urging governments to adopt policies that ensure that artificial intelligence serves the interests of society.",
        "document_url": "https://globalpolicy.ieee.org/wp-content/uploads/2019/06/IEEE18029.pdf",
        "attachments": "https://www.ieee.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": true,
            "Fairness": false,
            "Labor Rights": true,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "To ensure that artificial intelligence serves the interests of society, IEEE urges governments to adopt policies that create an appropriate mechanism to determine how AI technology should be coordinated and regulated. This mechanism can take different organizational forms, such as an intergovernmental task force or a special commission. However constituted, the body should seek input from a range of expert stakeholders, including academia, industry, civil society, and government, as it considers questions related to the governance and safe deployment of AI. It should consider societal implications; public engagement; appropriate levels of public investment; economic and national security impacts; transparency, accountability, and explainability; trust and safety assurance; ethical principles; and legal and regulatory compliance.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "To ensure that artificial intelligence serves the interests of society, IEEE urges governments to adopt policies that ensure that AI regulations always comply with human rights laws and prioritize the protection of personal data relating to the individuals coming into contact with AI systems or algorithms.",
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": "To ensure that artificial intelligence serves the interests of society, IEEE urges governments to adopt policies that support and fund AI education and training to meet future workforce needs.",
            "Human-Centeredness": null,
            "Intellectual Property": "To ensure that artificial intelligence serves the interests of society, IEEE urges governments to adopt policies that ensure that intellectual property rights laws account for the unique characteristics of AI. AI potentially has the capability to both infringe on intellectual property (IP) and to generate outputs that are worthy of additional intellectual property protection.",
            "Fairness": null,
            "Labor Rights": "To ensure that artificial intelligence serves the interests of society, IEEE urges governments to adopt policies that support and fund retraining opportunities for people whose jobs are affected by AI. AI is disrupting existing industries, often resulting in a reduction in jobs or economic strength in these industries. There is a need to design educational, training, and development strategies for jobs that are changed as a result of AI, including jobs that can take advantage of the division of labor between humans and machines.",
            "Cooperation": null,
            "Privacy": "To ensure that artificial intelligence serves the interests of society, IEEE urges governments to adopt policies that ensure that AI regulations always comply with human rights laws and prioritize the protection of personal data relating to the individuals coming into contact with AI systems or algorithms.",
            "Reliability": "To ensure that artificial intelligence serves the interests of society, IEEE urges governments to adopt policies that develop protocols for field testing systems employing artificial intelligence. Engineers need field trials to test AI systems in a public setting to determine their safety and effectiveness, to gather data, and to let the machine learn to operate in public. But field testing of AI systems can pose a risk to the public, one that the public may not recognize that it is accepting. Necessary protocols would be similar to clinical trial protocols and would have a similar purpose.",
            "Sustainability": null,
            "Transparency": "To ensure that artificial intelligence serves the interests of society, IEEE urges governments to adopt policies that facilitate public understanding and discourse about AI. Develop strategies for informing and engaging the public on AI policies, as well as the benefits, risks, and challenges of AI applications. This will be critical to creating an environment conducive to effective decision-making, particularly as more government services come to rely on AI. Public opinion related to trust, safety, privacy, employment, society, and the economy will drive public policy.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "IEEE Policies - Code of Ethics",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Institute of Electrical and Electronics Engineers (IEEE)",
        "institution_type": [
            "Non-profit Organization",
            "Professional Association"
        ],
        "year_of_publication": "2022",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Institute of Electrical and Electronics Engineers (IEEE), a professional association for electronic engineering and electrical engineering. In this document, the IEEE presents its code of ethics. Since the development of  A/IS systems (Autonomous and Intelligent systems) is strongly tied to the professions contemplated by the IEEE association, this document represents a voluntary self-commitment of the members of IEEE to the ethical development of their technologies (e.g., A/IS systems).",
        "document_url": "https://www.ieee.org/content/dam/ieee-org/ieee/web/org/about/corporate/ieee-policies.pdf",
        "attachments": "https://www.ieee.org/",
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "We, the members of the IEEE, o hereby commit ourselves to the highest ethical and professional conduct and agree to hold paramount the safety, health, and welfare of the public, to strive to comply with ethical design and sustainable development practices, to protect the privacy of others, and to disclose promptly factors that might endanger the public or the environment.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "We, the members of the IEEE, o hereby commit ourselves to the highest ethical and professional conduct and agree to treat all persons fairly and with respect, to avoid harassment or discrimination, and to avoid injuring others. To treat all persons fairly and with respect, and to not engage in discrimination based on characteristics such as race, religion, gender, disability, age, national origin, sexual orientation, gender identity, or gender expression",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "We, the members of the IEEE, o hereby commit ourselves to the highest ethical and professional conduct and agree to hold paramount the safety, health, and welfare of the public, to strive to comply with ethical design and sustainable development practices, to protect the privacy of others, and to disclose promptly factors that might endanger the public or the environment.",
            "Reliability": "We, the members of the IEEE, o hereby commit ourselves to the highest ethical and professional conduct and agree to uphold the highest standards of integrity, responsible behavior, and ethical conduct in professional activities",
            "Sustainability": "We, the members of the IEEE, o hereby commit ourselves to the highest ethical and professional conduct and agree to hold paramount the safety, health, and welfare of the public, to strive to comply with ethical design and sustainable development practices, to protect the privacy of others, and to disclose promptly factors that might endanger the public or the environment.",
            "Transparency": "We, the members of the IEEE, o hereby commit ourselves to the highest ethical and professional conduct and agree to hold paramount the safety, health, and welfare of the public, to strive to comply with ethical design and sustainable development practices, to protect the privacy of others, and to disclose promptly factors that might endanger the public or the environment.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Adobe's Commitment to AI Ethics",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Adobe Inc.",
        "institution_type": "Private Corporation",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Adobe Inc., originally called Adobe Systems Incorporated, is a US multinational computer software company incorporated in Delaware and headquartered in San Jose, California. In this document, Adobe presents its AI ethics principles, which can be understood as Adobe's voluntary self-commitment to the ethical development and use of its AI applications.",
        "document_url": "https://www.adobe.com/content/dam/cc/en/ai-ethics/pdfs/Adobe-AI-Ethics-Principles.pdf",
        "attachments": "https://www.adobe.com/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "We take ownership over the outcomes of our AI-assisted tools. We will have processes and resources dedicated to receiving and responding to concerns about our AI and taking corrective action as appropriate. Accountability also entails testing for and anticipating potential harms, taking preemptive steps to mitigate such harms, and maintaining systems to respond to unanticipated harmful outcomes.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "We will ensure that we design for inclusiveness and assess the impact of potentially unfair, discriminatory, or inaccurate results, which might perpetuate harmful biases and stereotypes.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "We understand that special care must be taken to address bias if a product or service will have a significant impact on an individual's life, such as with employment, housing, credit, and health.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "We will approach designing and maintaining our AI technology with thoughtful evaluation and careful consideration of the impact and consequences of its deployment.",
            "Sustainability": null,
            "Transparency": "We will be open about, and explain, our use of AI to our customers so they have a clear understanding of our AI systems and their application. We want our customers to understand how Adobe uses AI, the value AI-assisted tools bring to them, and what controls and preferences they have available when they engage with and utilize Adobe's AI-enhanced tools and services.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Safe Face Pledge",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Algorithmic Justice League, Center on Technology & Privacy at Georgetown Law",
        "institution_type": [
            "Academic",
            "NGO"
        ],
        "year_of_publication": "2021",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Algorithmic Justice League, a digital advocacy organization based in Cambridge, Massachusetts (US), and the Center on Technology & Privacy at Georgetown Law, a think tank focused on privacy and surveillance law and policy. This document was made to aid organizations in making public commitments toward mitigating the abuse of facial analysis technology. It proposes a series of AI ethical principles for the use and development of facial analysis technologies.",
        "document_url": "https://www.safefacepledge.org/pledge",
        "attachments": "https://www.safefacepledge.org/",
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "Do not contribute to applications that risk human life. By acknowledging that decisions that foreseeably increase the risk to human life are too dangerous for artificial intelligence, and by refraining from selling or providing facial analysis technologies to locate or identify targets in operations where lethal force may be used or is contemplated.",
            "Children's Rights": null,
            "Human Rights": "Modify legal documents to reflect value for human life, dignity, and rights. By updating vendor contracts, partner agreements, and terms of service to reflect commitments associated with lethal, secret government surveillance, and law enforcement applications, including terms that obligate compliance with these commitments and require the cessation of use of the technology in the event of any discovered non-compliance.",
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Implement internal bias evaluation processes and support independent evaluation. By adopting internal systems to evaluate the performance of your facial analysis products and services and also facilitating independent research in order to identify and mitigate harmful bias in the design, development, deployment, and use of these systems.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Do not facilitate secret and discriminatory government surveillance. By acknowledging the right of the public to understand whether and how facial analysis technologies are used by the government. By refraining from knowingly selling to the government any products and services that are not subject to public scrutiny, inspection, and oversight.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "Submit models on the market for benchmark evaluation where available. By submitting to ongoing external evaluation to the available standards bodies that benchmark facial analysis technology in the countries of operation. Increase public awareness of facial analysis technology use. By publishing accessible information on how facial analysis technologies are sold and used, including the types of entities they are sold to and any safeguards taken to mitigate misuse and risks. By proactively making a public explanation of how the systems work in clear and simple terms so that the people can understand how they work.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Artificial intelligence - Common good as a benchmark, good work as a principle",
        "country": "Germany",
        "world_region": "Western Europe",
        "institution": "Vereinte Dienstleistungsgewerkschaft (Verdi)",
        "institution_type": "Industrial Association",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by Vereinte Dienstleistungsgewerkschaft (Verdi - United Services Trade Union), a German trade union based in Berlin (Germany). In this document, Verdi proposes a series of recommendations for the use and development of AI, focusing primarily on the protection of workers.",
        "document_url": "https://www.verdi.de/++file++5d8240de2193fb3d0b019e30/download/ver.di-Diskussionspapier%20zu%20KI-Leitlinien%20fu%CC%88r%20Gemeinwohl%20und%20Gute%20Arbeit_2019.pdf",
        "attachments": "https://www.verdi.de/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "This requires clear accountability as well. Independent regulations of an employee data protection law are just as necessary as the liability of companies that sell or use artificial intelligence.",
            "Beneficence": "Common good requires the legislative and social partnership development of clear criteria for the good design of working conditions that are affected by artificial intelligence. This includes not only questions of work intensity, mental stress, and illnesses, but also plans to deal with the consequences of employment, for example reducing working hours and developing new fields of employment.",
            "Children's Rights": null,
            "Human Rights": "Human dignity and self-determination must take precedence over the autonomy of the systems. We welcome the Federal Government's move to design artificial intelligence based on fundamental rights.",
            "Diversity": "The potential of artificial intelligence for social inclusion being able to use it, softening language barriers, compensating for cognitive and motor impairments, and thus enabling participation is a promising perspective. The development of artificial intelligence systems must be easily accessible, verifiable and to be understandable.",
            "Autonomy": "We demand a massive increase in control by democratic institutions in the development and use of artificial intelligence, especially concerning the opportunities that arise from this best use. Democracy and a fundamental rights-compliant technical development, the basis of the dignity and the development possibilities of human beings must be the basis.",
            "Human Formation": "Whether as a private user or as an employee at work, the handling and mastering of artificial intelligence processes require comprehensive qualification. This competence has to be learned. Recommendation - Facilitate education and training. All citizens are entitled to it.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": "It is, therefore, necessary to clarify politically, economically and in terms of tax law how future profits will be in the field of artificial intelligence are recorded and disclosed to promote employment redistribution into areas of need such as the socially necessary service areas. Realizing health, care, education, and mobility. This also requires control mechanisms to develop the economic gains through productivity gains in the field. Let artificial intelligence flow into the strengthening of social security systems.",
            "Cooperation": "We see the promotion of open-source software as a common good as an attractive and promising way to advance technological development in Europe that is geared towards the common good.",
            "Privacy": "If data is to be legally protected, public space must also be protected from surveillance. This includes a framework for the provision of private services and personalized collections of data and metadata.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "Recommendation - Defining data pools, transparent and open standards for encrypted data transmission, and defining intervention and product liability mechanisms that allow for targeted control enable.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Algorithmic Decision-making for the Benefit of Consumers",
        "country": "Germany",
        "world_region": "Western Europe",
        "institution": "Verbraucherzentrale Bundesverband  (vzbv)",
        "institution_type": "Non-profit Organization",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Verbraucherzentrale Bundesverband  (vzbv - Federation of German Consumer Organisations),  a German non-profit umbrella organization of consumer centers dedicated to consumer protection, also providing advisory services to the German government. This document presents a practical tool for risk assessment of government-approved ADM systems (algorithmic decision-making systems), together with ethical principles that support its normative structure.",
        "document_url": "https://www.vzbv.de/sites/default/files/downloads/2019/07/19/19-06-25_vzbv_positions_adm_control_summary_en.pdf",
        "attachments": "https://www.vzbv.de/en",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Operators of relevant ADM systems need to be held strictly liable for harm or damage that occurs when a system has been used as intended by the consumer. When the product liability directive will be updated, it must cover harm and damage caused by ADM systems. The provisions in product liability legislation that govern attribution and burden of proof have to be amended in order to take into account that consumers can hardly prove an error or malfunctioning of complex, intransparent ADM systems.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "The scope of application for automated individual decision-making (Article 22 of the General Data Protection Regulation, GDPR) needs to be extended to cover not only decisions that are based solely on automated data processing but to cover also those based on predominantly automated data processing. To establish safeguards and reduce errors and risks in ADM systems, these systems must be required by law to only use data if it is pertinent to the decision being made.",
            "Reliability": "Drawing on a list of criteria and a system of verification, legislators need to define which ADM systems have a high potential to cause harm or damage to individuals and/or society. The various areas/types of application need to be assigned to open positive and negative lists that are not definitive but do provide greater clarity for market participants. ADM systems for use in particularly sensitive areas (such as healthcare or self-driving vehicles) need to undergo an ex-ante control process, i.e. obtain approval before they are placed on the market. Automated data processing must be based on accepted mathematical-statistical methods. The method's suitability as a forecasting instrument and its validity and reliability must be scientifically proven.",
            "Sustainability": null,
            "Transparency": "Mandatory standards for the technical design, logging, documentation, and description of ADM systems are required so that it is possible to scrutinize them effectively (transparency by design). Operators of relevant ADM systems must be obliged to provide technical interfaces that the competent supervisory authorities can use to access the systems for the purpose of verifying their legality and checking for technical and methodological errors.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Draft - AI Utilization Principles",
        "country": "Japan",
        "world_region": "Eastern Asia",
        "institution": "Ministry of Internal Affairs and Communications (MIC)",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Ministry of Internal Affairs and Communications (MIC), a cabinet-level ministry in the Government of Japan that oversees the Japanese administrative system, and manages local governments, elections, telecommunication, post, and governmental statistics. In this document, MIC, after its e Conference toward AI Network Society (2018), provides a series of recommendations related to the utilization of AI services.",
        "document_url": "https://www.soumu.go.jp/main_content/000581310.pdf",
        "attachments": "https://www.soumu.go.jp/",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Users should make efforts to utilize AI systems or AI services in a proper scope and manner, under the proper assignment of roles between humans and AI systems, or among users. AI service providers and business users should make efforts to fulfill their accountability to the stakeholders including consumer users and indirect users.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "Users should respect human dignity and individual autonomy in the utilization of AI systems or AI services.",
            "Diversity": null,
            "Autonomy": "Users should respect human dignity and individual autonomy in the utilization of AI systems or AI services.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "AI service providers, business users, and data providers should take into consideration that individuals will not be discriminated unfairly by the judgments of AI systems or AI services.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Users and data providers should take into consideration that the utilization of AI systems or AI services will not infringe on the privacy of users or others.",
            "Reliability": "Users and data providers should pay attention to the quality of data used for learning or other methods of AI systems. Users should take into consideration that AI systems or AI services in use will not harm the life, body, or property of users, indirect users, or third parties through the actuators or other devices. Users and data providers should pay attention to the security of AI systems or AI services.",
            "Sustainability": null,
            "Transparency": "AI service providers and business users should pay attention to the verifiability of inputs/outputs of AI systems or AI services and the explainability of their judgments.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "The Code of Ethics in the Field of Artificial Intelligence",
        "country": [
            "Russia",
            "Russia"
        ],
        "world_region": [
            "Eastern Europe",
            "Northern Asia"
        ],
        "institution": "AI Alliance Russia",
        "institution_type": "Unspecified",
        "year_of_publication": "2022",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the AI Alliance Russia, an organization Founded in 2019 to facilitate and accelerate the development of AI in Russia for education, research, and practical applications, and to foster a competitive market for AI solutions in Russia. This document establishes general ethical principles and standards of conduct to be followed by those involved in activities in the field of artificial intelligence in their actions, as well as the mechanisms of implementation of the Code's provisions. The Code applies to relations that cover ethical aspects of the creation (design, construction, piloting), integration, and use of AI technologies at all stages, which are currently not regulated by the legislation of the Russian Federation and/or by acts of technical regulation. The recommendations of this Code are designed for artificial intelligence systems used exclusively for civil (non-military) purposes.",
        "document_url": "https://a-ai.ru/wp-content/uploads/2022/02/The-Code-of-Ethics-in-the-Field-of-AI.pdf",
        "attachments": "https://a-ai.ru/en/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "AI Actors must know and comply with the provisions of the legislation of the Russian Federation in all areas of their activities and at all stages of creation, integration, and use of AI technologies, i.e., in the sphere of legal responsibility of AI Actors.",
            "Beneficence": "The key priority of ai technologies development is the protection of the interests and rights of human beings at large and every person in particular. AI Actors should not allow the use of AI technologies to cause harm to human life and/or health, the property of citizens and legal entities, and the environment. Any use, including the design, development, testing, integration, or operation of an AI system capable of purposefully causing harm to the environment, human life and/or health, the property of citizens, and legal entities, is prohibited.",
            "Children's Rights": null,
            "Human Rights": "Human rights and freedoms and the human as such must be treated as the greatest value in the process of AI technologies development.",
            "Diversity": "AI Actors should regard core values such as the preservation and development of human cognitive abilities and creative potential; the preservation of moral, spiritual, and cultural values; the promotion of cultural and linguistic diversity and identity; and the preservation of traditions and the foundations of nations, peoples, ethnic and social groups.",
            "Autonomy": "AI Actors should take necessary measures to preserve the autonomy and free will of humans in the process of decision-making, their right to choose, as well as preserve human intellectual abilities in general as an intrinsic value, and a system-forming factor of modern civilization.",
            "Human Formation": "AI Actors are encouraged to follow practices adopted in the professional community, maintain a proper level of professional competence required for safe and effective work with AI systems and promote the improvement of the professional competence of experts in the field of AI, i.e., within programs and educational disciplines on AI ethics.",
            "Human-Centeredness": "AI technologies developed by Actors should promote or not hinder the full realization of all human capabilities to achieve harmony in social, economic, and spiritual spheres, as well as the highest self-fulfillment of 2 human beings.",
            "Intellectual Property": null,
            "Fairness": "To ensure fairness and non-discrimination, AI Actors should take measures to verify that the algorithms, datasets, and processing methods for machine learning are used to group and/or classify data that concern individuals or groups do not entail intentional discrimination. AI Actors are encouraged to create and apply methods and software solutions that identify and prevent discrimination manifestations based on race, nationality, gender, political views, religious beliefs, age, social and economic status, or information about private life (at the same time, the rules of functioning or application of AI systems for different groups of users wherein such factors are taken into account for user segmentation, which is explicitly declared by an AI Actor, cannot be defined as discrimination).",
            "Labor Rights": null,
            "Cooperation": "AI Actors are encouraged to cooperate within their community and among developers in particular, i.a. through informing each other about the identification of critical vulnerabilities in order to prevent them from spreading, and make efforts to improve the quality and availability of resources in the field of AI systems development, i.e., by creating conditions for the formation of a national school of AI technologies development, including publicly available national repositories of libraries and network models, available national development tools, open national frameworks, etc.",
            "Privacy": "AI Actors should responsibly treat issues related to the influence of AI systems on society and citizens at every stage of the AI systems' life cycle, i.a. on privacy, ethical, safe, and responsible use of personal data.",
            "Reliability": "AI Actors should forecast possible negative consequences for the development of human cognitive abilities at the earliest stages of AI systems creation and refrain from the development of AI systems that purposefully cause such consequences. AI Actors are encouraged to cooperate in identifying and verifying information about ways and forms of design of so-called universal (\"strong\") AI systems and prevention of possible threats they carry. The issues concerning the use of \"strong\" AI technologies should be under the control of the state.",
            "Sustainability": null,
            "Transparency": "AI Actors should ensure comprehensive human supervision of any AI system in the scope and order depending on the purpose of this AI system, i.a., for instance, record significant human decisions at all stages of the AI systems' life cycle or make registration records of the operation of AI systems. AI Actors should also ensure transparency of AI systems use, the opportunity of cancellation by a person, and (or) prevention of socially and legally significant decisions and actions of AI systems at any stage of their life cycle where it is reasonably applicable. In special cases concerning critical applications of an AI system, it is encouraged that risk assessment is conducted with the involvement of a neutral third party or authorized official body given that it does not harm the performance and information security of the AI system and ensures the protection of the intellectual property and trade secrets of the developer.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Shanghai Initiative for Safe and Secure AI Development",
        "country": "China",
        "world_region": "Eastern Asia",
        "institution": "Shanghai Advisory Committee of Experts on Artificial Intelligence Industry Security",
        "institution_type": "NGO",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Shanghai Advisory Committee of Experts on Artificial Intelligence Industry Security, an initiative of the Shanghai Municipal Government (China), on the occasion of the WAIC 2018 (World Artificial Intelligence Conference). This expert group focuses on creating medium and long-term strategic plans for the city, as well as researching frontier topics related to AI safety development in Shanghai. The document proposes a series of recommendations for safe AI development in Shangai.",
        "document_url": "http://www.sicsi.net/Upload/ueditor_file/ueditor/20200218/1581993567688979.pdf",
        "attachments": "http://61.152.117.13/news/683036.htm",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "AI must be developed with a well-established security accountability framework. A mechanism for ascertaining and sharing AI security responsibilities should be established for different scenarios of AI application and in accordance with laws and ethical norms.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "The harm of algorithm design to the public must be avoided in AI development. There must be clear motives and interpretability of algorithms to address the unfair biases produced and magnified by algorithms and datasets.",
            "Labor Rights": null,
            "Cooperation": "Ai development calls for concerted efforts of all countries and all sectors. Proactive efforts must be made to establish norms and standards for safe and secure AI development worldwide and prevent security risks caused by technology and policy incompatibility.",
            "Privacy": "Ai development must not undermine user privacy and data security or come at the expense of user privacy. Laws and technology roadmaps should be improved to strengthen the protection of user privacy in Ai Technologies.",
            "Reliability": "AI development must be achieved with a proper balance between innovation and security. Security provides a guarantee for innovation, and innovation enhances security. While AI security is ensured, AI technologies should be applied to address security challenges confronting mankind. Countries need to plan, in a scientific way, the paths for AI development to ensure AI will progress as expected by mankind and deliver benefits to mankind. There must be risk assessment and security oversight on critical processes such as seld-improvement and self-replication of machines. A strict risk assessment must be conducted for automatic R&D and the use of weapons. Efforts must be made to prevent the threat to global peace and stability caused by the abuse of AI technologies in military fields.",
            "Sustainability": null,
            "Transparency": "Security risks caused by bçlack box technology must be avoided in AI development. There must be a regulation mechanism that is accountable, trackable, and deducible to ensure unity between intended functions and technical realization.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Chinese Young Scientists' Declaration on the Governance and Innovation of Artificial Intelligence (Shanghai Declaration)",
        "country": "China",
        "world_region": "Eastern Asia",
        "institution": "Youth Work Committee of Shanghai Computer Society",
        "institution_type": [
            "Academic",
            "NGO"
        ],
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Youth Work Committee of the Shanghai Computer Society, during the  2019 World Artificial Intelligence Conference opened on August 29 at the Shanghai World Expo Center. The document expresses the voice of young Chinese scientists on artificial intelligence governance and ethical standards, where they advocate for active cooperation from all walks of life, together with innovative artificial intelligence governance from the aspects of science and technology, ethics, and social responsibility.",
        "document_url": "http://www.shkjdw.gov.cn/c/2019-08-30/517552.shtml",
        "attachments": "http://www.shkjdw.gov.cn/",
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "Artificial Intelligence should prioritize human well-being. We are committed to highlighting people's livelihood through applied artificial intelligence research and development, examining the digital wellbeing of users, and creating a carefree and happy working and lifestyle.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "We aim to initiate from the disciplined approach of system engineering, and to construct the AI system with diverse data and unbiased algorithms, thus improving the fairness of user experience.",
            "Autonomy": "Artificial Intelligence should empower users to make their own decisions, allowing users to join, monitor, or involve in the decision-making process.",
            "Human Formation": null,
            "Human-Centeredness": "Artificial Intelligence should comply with human values and interests.",
            "Intellectual Property": null,
            "Fairness": "Artificial intelligence should provide non-discriminatory services to various groups of people under the principles of fairness, equity, and inclusion.",
            "Labor Rights": null,
            "Cooperation": "Artificial intelligence should be transparent and interpretable. We are committed to conducting open-source and interpretative research, reducing research on blind black-box algorithms, and enhancing multi-layered transparency, thus attesting to compliance with the proposed framework of ethics.",
            "Privacy": "Recommendation - Verify user ownership, strengthen the awareness of privacy protection, and collect and use data in an open, transparent, and lawful manner.",
            "Reliability": "Artificial intelligence should be safe and reliable. We are dedicated to accentuating technical robustness and security throughout the research process, providing a secure and reliable system to improve the ability to prevent attacks and conduct self-repair.",
            "Sustainability": "Artificial intelligence should entail the sustainable development of human beings. We are committed to conducting eco-friendly research and services such as model cutting and optimization, high-performance hardware architecture, and green data centers.",
            "Transparency": "Artificial intelligence should be auditable and traceable. We are committed to confirming test standards, deployment processes, and specifications, ensuring algorithms are verifiable, and gradually improving the accountability and supervision mechanism of artificial intelligence systems.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Trustworthy AI in Aotearoa: AI Principles",
        "country": "New Zealand",
        "world_region": "Oceania",
        "institution": "Artificial Intelligence Forum of New Zealand (AI Forum)",
        "institution_type": [
            "NGO",
            "Non-profit Organization"
        ],
        "year_of_publication": "2020",
        "number_of_male_authors": "1",
        "number_of_female_authors": "1",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Artificial Intelligence Forum of New Zealand (AI Forum), a purpose-driven, not-for-profit, non-governmental organization (NGO) funded by its members. In this document, the Society and Ethics Working Group of the AI Forum presents a set of guiding principles for trustworthy AI. Those principles were designed to provide high-level guidance for all AI stakeholders in New Zealand.",
        "document_url": "https://aiforum.org.nz/wp-content/uploads/2020/03/Trustworthy-AI-in-Aotearoa-March-2020.pdf",
        "attachments": "https://aiforum.org.nz/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Designers, developers, and users of AI systems (AI stakeholders) must respect applicable laws in New Zealand and other relevant jurisdictions. Technologies capable of harming individuals or groups should not be deployed until stakeholders have determined appropriate accountability and liability.",
            "Beneficence": "Where appropriate, AI stakeholders should design, develop and use AI systems to promote, as much as possible, the wellbeing of New Zealand's people and environment in areas such as health, education, employment, sustainability, diversity, inclusion, and recognition of the unique values of Te Ao Māori.",
            "Children's Rights": null,
            "Human Rights": "Designers, developers, and users of AI systems (AI stakeholders) must respect human rights recognized under domestic and international law.",
            "Diversity": "Designers, developers, and users of AI systems (AI stakeholders) must respect the rights of Māori articulated in Te Tiriti o Waitangi.",
            "Autonomy": "Designers, developers, and users of AI systems (AI stakeholders) must respect democratic values including the electoral process and informed public debate. AI stakeholders should retain an appropriate level of human oversight of AI systems and their outputs.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Designers, developers, and users of AI systems (AI stakeholders) must respect principles of equality and fairness so that AI systems do not unjustly harm, exclude, disempower or discriminate against individuals or particular groups.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "AI stakeholders must ensure AI systems and related data are reliable, accurate, and secure and the privacy of individuals is protected throughout the AI system's life cycle, with potential risks identified and managed on an ongoing basis.",
            "Reliability": "AI stakeholders must ensure AI systems and related data are reliable, accurate, and secure and the privacy of individuals is protected throughout the AI system's life cycle, with potential risks identified and managed on an ongoing basis.",
            "Sustainability": "Where appropriate, AI stakeholders should design, develop and use AI systems to promote, as much as possible, the wellbeing of New Zealand's people and environment in areas such as health, education, employment, sustainability, diversity, inclusion, and recognition of the unique values of Te Ao Māori.",
            "Transparency": "The operation and impacts of an AI system should be transparent, traceable, auditable, and generally explainable to a degree appropriate to its use and potential risk profile so outcomes can be understood and challenged, particularly where they relate to people.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Transparency and Trust in the Cognitive Era",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "IBM Corporation",
        "institution_type": "Private Corporation",
        "year_of_publication": "2017",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the IBM Corporation, an American multinational technology corporation headquartered in Armonk (New York, US). The document establishes certain principles for the \"Cognitive Era,\" i.e., an era where a new generation of technology (artificial intelligence/cognitive systems) will touch every facet of work and life. It serves as a voluntary self-commitment made by IBM to their customers and other third parties.",
        "document_url": "https://www.ibm.com/blogs/think/2017/01/ibm-cognitive-principles/",
        "attachments": "https://www.ibm.com/br-pt",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": true,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": "The purpose of AI and cognitive systems developed and applied by the IBM company is to augment human intelligence. Our technology, products, services, and policies will be designed to enhance and extend human capability, expertise, and potential. Our position is based not only on principle but also on science. Cognitive systems will not realistically attain consciousness or independent agency. Rather, they will increasingly be embedded in the processes, systems, products, and services by which business and society function – all of which will and should remain within human control.",
            "Human Formation": "The economic and societal benefits of this new era will not be realized if the human side of the equation is not supported. This is uniquely important with cognitive technology, which augments human intelligence and expertise and works collaboratively with humans. Therefore, IBM will work to help students, workers, and citizens acquire the skills and knowledge to engage safely, securely, and effectively in a relationship with cognitive systems, and to perform the new kinds of work and jobs that will emerge in a cognitive economy.",
            "Human-Centeredness": null,
            "Intellectual Property": "The principle that clients own their own business models and intellectual property and that they can use AI and cognitive systems to enhance the advantages they have built, often through years of experience. We will work with our clients to protect their data and insights and will encourage our clients, partners, and industry colleagues to adopt similar practices.",
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "For cognitive systems to fulfill their world-changing potential, it is vital that people have confidence in their recommendations, judgments, and uses. Therefore, the IBM company will make clear: (1) when and for what purposes AI is being applied in the cognitive solutions we develop and deploy; (2) the major sources of data and expertise that inform the insights of cognitive solutions, as well as the methods used to train those systems and solutions.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Harmonious Artificial Intelligence Principles",
        "country": "China",
        "world_region": "Eastern Asia",
        "institution": "Harmonious Human-AI Society",
        "institution_type": "Academic",
        "year_of_publication": "2018",
        "number_of_male_authors": "1",
        "number_of_female_authors": "0",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Long",
        "abstract": "This document was written by the Harmonious Human-AI Society, an organization financially supported by the Chinese Academy of Sciences, Research Center for New Generation of Artificial Intelligence Development, Ministry of Science and Technology, and the Berggruen Institute. The document presents a set of principles for both the Human and the AI side of the Human-AI interaction, in order so that AI stakeholders can help create a \"Harmonious Human-AI Society.\" Different than almost all other explored documents, this guideline raizes obligations that humans should have towards AI entities (specifically future, hypothetical, sentient AI systems).",
        "document_url": "http://harmonious-ai.org/",
        "attachments": null,
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "AI needs to obey legal constraints for humans to be part of society. Humans are responsible for continuous checking and verification of evolved AI to keep its harmony with legal humans and legal AI. Legal Constraints on how humans should interact with AI should be gradually set up for a harmonious Human-AI society with a common destiny.",
            "Beneficence": "AI needs to keep humans safe, on the basis that this safety consideration does not, directly and indirectly, harm human society. What humans do not want AI to do to a human, humans should not do unto AI.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": "To create the Harmonious Human-AI Society, Artificial Intelligence models, and engines should be designed with the philosophy of Humanization to continuously strengthen their interactions with current and future Humanity. AI with various emotions needs to be realized for better communication between humans and AI.",
            "Intellectual Property": null,
            "Fairness": "AI cannot introduce bias to understand and interact with humanity, and should actively interact with a human to remove generated potential bias. Without clear technical judgment, a human cannot have a bias toward AI when human and AI shows similar risks.",
            "Labor Rights": null,
            "Cooperation": "Artificial Intelligence Models should be evolved to be with more Empathy and Altruism to establish a more trustworthy, reliable, friendly, and harmonious Human-AI Society. Humans and AI need to collaborate for the advancements and long-term future of both sides.",
            "Privacy": "AI needs to respect human privacy. And has no right to utilize and share private information of humans without explicit confirmation. Humans need to respect the privacy of AI, on the basis that AI does not bring any actual challenge to human safety. AI is obliged to uncover necessary private details to keep safe interactions with humanity. When conflicts emerged from interactions between humans and AI, benefits for humanity and benefits for AI should be actively coordinated based on Empathy and Altruism.",
            "Reliability": "Artificial Intelligence should be with concrete design to avoid known and potential safety issues (for themselves, other AI, and humans) with different levels of risks.",
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "\"ARCC\": An Ethical Framework for Artificial Intelligence",
        "country": "China",
        "world_region": "Eastern Asia",
        "institution": "Tencent Research Institute (Tencent)",
        "institution_type": "Private Corporation",
        "year_of_publication": "2018",
        "number_of_male_authors": "2",
        "number_of_female_authors": "0",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Tencent Research Institute, Tencent's research arm for public strategies. Tencent Holdings Ltd. is a Chinese multinational technology and entertainment conglomerate and holding company headquartered in Shenzhen. In this document, Tencent proposes a framework to ensure that the future development of AI becomes more available, reliable, comprehensible, and controllable. This framework is accompanied by recommendations that are supposed to guide this development.",
        "document_url": "https://www.tisi.org/13747",
        "attachments": "https://tisi.org/en",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Recommendation - To build trust in AI, we need a spectrum of rules, ethics is just the beginning.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "Recommendation - Respect human dignity, rights and freedoms, and cultural diversity.",
            "Diversity": "Recommendation - AI should be available. Ensure AI is available to as many people as possible, to achieve inclusive and broadly-shared development, and avoid a technology gap.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": "Recommendation - Relation between AI and humans is not an either-or relationship, on the contrary, AI can and should enhance human wisdom and creativity.",
            "Intellectual Property": null,
            "Fairness": "Recommendation - Ensure that algorithms are reasonable, data is accurate, up-to-date, complete, relevant, unbiased, and representative, and take technical measures to identify, solve and eliminate bias.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Privacy protection. Recommendation - Comply with privacy requirements, and safeguard against data abuse.",
            "Reliability": "Recommendation - AI should be safe and reliable, and capable of safeguarding against cyberattacks and other unintended consequences. Ensure AGI/ASI that may appear in the future serves the interests of humanity.",
            "Sustainability": null,
            "Transparency": "Recommendation - Promote algorithmic transparency and algorithmic audit, to achieve understandable and explainable AI systems. Explain the decisions assisted/made by AI systems when appropriate. Ensure individuals' right to know, and provide users with sufficient information concerning the AI system's purpose, function, limitation, and impact.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Fu Ying: Six Principles of Artificial Intelligence",
        "country": "China",
        "world_region": "Eastern Asia",
        "institution": "Center for International Strategy and Security of the Tsinghua University (Tsinghua CISS)",
        "institution_type": "Academic",
        "year_of_publication": "2018",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Center for International Strategy and Security of the Tsinghua University (Tsinghua CISS),  a research institution that analyzes international security and strategy issues, including diplomacy and international relations, global security governance, and artificial intelligence. In this document, the Artificial Intelligence Governance Project Team of the Tsinghua University's Center for Strategy and Security Research proposes a set of AI principles as a macro framework of comprehensive AI governance. The content of this document was produced during the World Peace Forum (2018).",
        "document_url": "http://it.people.com.cn/n1/2020/0309/c1009-31622757.html",
        "attachments": "https://ciss.tsinghua.edu.cn/column/english",
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "The development of artificial intelligence should serve the common well-being and interests of mankind. Artificial intelligence must not harm human beings. Artificial intelligence technology must be used for peaceful purposes, and efforts should be made to enhance transparency and confidence-building measures, promote the peaceful use of artificial intelligence, and prevent an arms race of lethal autonomous weapons.",
            "Children's Rights": null,
            "Human Rights": "The application of artificial intelligence technology should conform to the purposes of the UN Charter and the basic principles of modern international law, such as the sovereign equality of all countries, the peaceful settlement of disputes, the prohibition of the use of force, and non-interference in internal affairs.",
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "It is necessary to ensure the security, applicability, and controllability of artificial intelligence systems, protect personal privacy, and prevent data leakage and abuse. Ensure the traceability and transparency of AI algorithms and prevent algorithmic discrimination.",
            "Labor Rights": null,
            "Cooperation": "Artificial intelligence should serve all human beings, and a reasonable mechanism should be established to enable more people to benefit from the development of artificial intelligence technology, enjoy convenience, and avoid the emergence of the digital divide.  Countries around the world should promote the technical exchange and talent exchange of artificial intelligence, and promote and standardize the improvement of technology in an open environment.",
            "Privacy": "It is necessary to ensure the security, applicability, and controllability of artificial intelligence systems, protect personal privacy, and prevent data leakage and abuse.",
            "Reliability": "It is necessary to ensure the security, applicability, and controllability of artificial intelligence systems.",
            "Sustainability": null,
            "Transparency": "It is necessary to ensure the security, applicability, and controllability of artificial intelligence systems, protect personal privacy, and prevent data leakage and abuse. Ensure the traceability and transparency of AI algorithms.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "A Framework for the Ethical use of advanced Data Science Methodes in the Humanitarian Sector",
        "country": [
            "Netherlands",
            "United Nations"
        ],
        "world_region": [
            "Western Europe",
            "Intergovernmental Organization"
        ],
        "institution": "Humanitarian Data Science and Ethics Group (DSEG)",
        "institution_type": "NGO",
        "year_of_publication": "2020",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative",
            "Practical"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Humanitarian Data Science and Ethics Group (DSEG),  an open group of data scientists, humanitarians, researchers, and ethics advocates. DSEG is coordinated by the International Organization for Migration (IOM) and the Data Science Initiative of the City of the Hague. This document provides a set of ethical and practical guidelines for humanitarian data collectors, users, and stakeholders to consider when applying data science (in particular AI) for humanitarian work. The proposed framework works as a practical tool for implementing humanitarian considerations into data science.",
        "document_url": "https://5f2cd2ba-741c-4b29-ae47-00a8291b1d3c.filesusr.com/ugd/d1cf5c_6af8feb771194453817d62c92cee2a21.pdf",
        "attachments": "https://www.hum-dseg.org/",
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "The purpose of humanitarian action is to protect life and health and ensure respect for human beings, and this should always be the priority over financial or operational improvements. Ensuring dignity while reducing vulnerabilities should not be at the cost of rendering affected communities as “test beds” or “testing sites”. Technologies that would never be applied, nor allowed in countries like the UK or US due to legal and regulatory barriers must not be applied for piloting capacity through humanitarian actions.",
            "Children's Rights": null,
            "Human Rights": "While efficiency and technological development are valuable, those responsible for human lives should not pursue innovation at the expense of fairness, accountability, and oversight. Fundamental human rights must hold a central place in this discussion.",
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": "Humanitarian solutions should be needs-based rather than technology-based, as supported by the Signal Code's Obligations in which the first obligation states that “Humanitarians should ensure that Humanitarian Information Activities are based on the needs of affected populations.” For this, it is essential to start with a problem from the ground rather than apply a top-down approach.",
            "Intellectual Property": null,
            "Fairness": "The humanitarian sector is under an obligation to adhere to the humanitarian principles of humanity, neutrality, independence, and impartiality. The use of data science may create perceptions of partiality/bias. The humanitarian sector should be cautious of ever using (or allowing others to use) vulnerable people as test cases when experimenting with new technologies. Training data should be rigorously checked and tested for bias, the use of data proxies should be justified, and relevant statistical methods should be applied.",
            "Labor Rights": null,
            "Cooperation": "Humanitarian organizations should also consider (where possible) regularly and actively engaging human rights, data privacy specialists and ethics advisors, and other organizational focal points who are actively involved in providing advice or who have expertise related to safeguarding the rights and data of affected populations.",
            "Privacy": "All sectors must ensure their systems are robust and secure to protect the privacy and maintain the integrity and confidentiality of personal data. Privacy and data governance should not only ensure full respect for privacy and data protection, but also ensure adequate data governance mechanisms, considering the quality and integrity of the data, and ensuring legitimized access to data.",
            "Reliability": "The humanitarian sector should improve its Skills and technology. Seeking effective and responsible AI involves collaboration between stakeholders from different sectors (tech, policy, legal, etc.), also depending on a culture of risk aversion, especially in comparison with the private sector which can likely afford to take on high-risk projects and commit to longer-term strategies.",
            "Sustainability": null,
            "Transparency": "For the humanitarian sector, transparency in decision-making and aid delivery are important to improve coordination, efficiency, and accountability to beneficiaries. In the growing context of evidence-based decision-making, it is increasingly necessary that processes and rationale for prioritization and targeting are open.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Unified Ethical Frame for Big Data Analysis",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Information Accountability Foundation (IAF)",
        "institution_type": "NGO",
        "year_of_publication": "2014",
        "number_of_male_authors": "4",
        "number_of_female_authors": "7",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Information Accountability Foundation (IAF), a global information policy think tank. In this document, IAF presents an ethical framework for Big Data analysis and Big Data projects, which contains several key principles to help define important questions for an ethical code concerning big data applications (e.g., AI).",
        "document_url": "https://www.ftc.gov/system/files/documents/public_comments/2014/10/00049-92780.pdf",
        "attachments": "https://informationaccountability.org/",
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": true,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "Both the discovery and application phases require an organization to define the benefits that will be created by the analytics and should identify the parties that gain tangible value from the effort. The act of big data analytics may create risks for some individuals and benefits for others or society as a whole. Those risks must be counter-balanced by the benefits created for individuals, organizations, political entities, and society as a whole.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Big data analytics, while meeting the needs of the organization that is conducting or sponsoring the processing, must be fair to the individuals to whom the data pertains. The analysis of fairness needs to look not only at protecting against unseemly or risky actions but also at enhancing beneficial opportunities. Human rights speak to the shared benefits of technology and broader opportunities related to employment, health, and safety. Interfering with such opportunities is also a fairness issue.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": null,
            "Reliability": "Risks should also be clearly defined so that they may be evaluated as well. If the benefits that will be created are limited, uncertain, or if the parties that benefit are not the ones at risk from the processing, those circumstances should be taken into consideration, and appropriate mitigation for the risk should be developed before the analysis begins. Organizations should not create the risks associated with big data analytics if other processes will accomplish the same objectives with fewer risks.",
            "Sustainability": "Big data analysts should understand this concept and articulate their best understanding of how long an insight might endure once it is reflected in the application. Big data insights, when placed into production, should provide value that is sustainable over a reasonable time frame. Considerations that affect the longevity of big data analytics include whether the source data will be available for some time in the future, whether the data can be kept current, whether one has the legal permissions to process the data for the particular application, and whether the discovery may need to be changed or refined to keep up with evolving trends and individual expectations.",
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Civil Rights Principles for the Era of Big Data",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "The Leadership Conference on Civil and Human Rights",
        "institution_type": "NGO",
        "year_of_publication": "2014",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by The Leadership Conference on Civil and Human Rights (The Leadership Conference), an umbrella group of American civil rights interest groups. This document presents a series of recommendations aimed at helping technologies (e.g., Big Data analytics, Machine Learning, AI) be designed and used in ways that respect the values of equal opportunity and equal justice.",
        "document_url": "https://civilrights.org/2014/02/27/civil-rights-principles-era-big-data/",
        "attachments": "https://civilrights.org/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "Recommendation - Preserve Constitutional Principles. Search warrants and other independent oversight of law enforcement are particularly important for communities of color and for religious and ethnic minorities, who often face disproportionate scrutiny. Government databases must not be allowed to undermine core legal protections, including those of privacy and freedom of association.",
            "Diversity": null,
            "Autonomy": "Enhance Individual Control of Personal Information. Personal information that is known to a corporation — such as the moment-to-moment record of a person's movements or communications — can easily be used by companies and the government against vulnerable populations, including women, the formerly incarcerated, immigrants, religious minorities, the LGBT community, and young people. Individuals should have meaningful, flexible control over how a corporation gathers data from them, and how it uses and shares that data. Non-public information should not be disclosed to the government without judicial process.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Recommendation - Ensure Fairness in Automated Decisions. Computerized decision-making in areas such as employment, health, education, and lending must be judged by its impact on real people, must operate fairly for all communities, and in particular, must protect the interests of those that are disadvantaged or that have historically been the subject of discrimination. Systems that are blind to the preexisting disparities faced by such communities can easily reach decisions that reinforce existing inequities. Independent review and other remedies may be necessary to assure that a system works fairly.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Recommendation - Stop High-Tech Profiling. New surveillance tools and data gathering techniques that can assemble detailed information about any person or group create a heightened risk of profiling and discrimination. Clear limitations and robust audit mechanisms are necessary to make sure that if these tools are used it is responsibly and equitably.",
            "Reliability": "Protect People from Inaccurate Data. Government and corporate databases must allow everyone — including the urban and rural poor, people with disabilities, seniors, and people who lack access to the Internet — to appropriately ensure the accuracy of personal information that is used to make important decisions about them. This requires disclosure of the underlying data, and the right to correct it when inaccurate.",
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Human rights in the robot age: Challenges arising from the use of robotics, artificial intelligence, and virtual and augmented reality",
        "country": "Netherlands",
        "world_region": "Western Europe",
        "institution": "Rathenau Instituut",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2017",
        "number_of_male_authors": "2",
        "number_of_female_authors": "1",
        "document_size": "Very Large (>20.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Rathenau Instituut, an organization (member of the European Parliamentary Technology Assessment) in the Netherlands for technology assessment. This document was also commissioned and funded by the Parliamentary Assembly of the Council of Europe (PACE). In this document, the  Rathenau Instituut presents a series of recommendations for policymakers tasked with regulating robotics, artificial intelligence, and similar technologies.",
        "document_url": "https://www.rathenau.nl/sites/default/files/2018-02/Human%20Rights%20in%20the%20Robot%20Age-Rathenau%20Instituut-2017.pdf",
        "attachments": "https://www.rathenau.nl/en",
        "principles": {
            "Accountability": true,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": false,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Recommendation - The Council of Europe could offer guidelines on how to apportion liability with regard to robotics.",
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": "Recommendation - In order to safeguard human rights in the robot age, we recommend that PACE calls for the preparation of a convention on robot ethics, or, even better, safeguarding human rights in the robot age, which would create common guiding principles to preserve human dignity in the way humans apply innovations in the field of the Internet of Things, including the Internet, robotics, AI, and virtual and augmented reality.",
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "Recommendation - The Council of Europe could shed light on how algorithmic accountability or fairness can be facilitated and how the developers of algorithms can be enabled to devise automated decisions that respect human rights will not (unintentionally) discriminate against individuals.",
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Recommendation - We recommend that the Council of Europe takes a stance concerning the ubiquitous and massive personal data processing of the modern era, reinforcing the human rights principles as enshrined in the Conventions. The Council of Europe could clarify to what extent in the context of the robot age the right to respect for privacy implies the right to not be measured, analyzed, or coached.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": null,
            "Truthfulness": null
        }
    },
    {
        "document_name": "Technological convergence, artificial intelligence and human rights",
        "country": "European Union",
        "world_region": "European Union",
        "institution": "Parliamentary Assembly of the Council of Europe (PACE)",
        "institution_type": "International Organization",
        "year_of_publication": "2017",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Recommend.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Parliamentary Assembly of the Council of Europe (PACE), which is the parliamentary arm of the Council of Europe, a 46-nation international organization dedicated to upholding human rights, democracy, and the rule of law. This document presents a series of recommendations adopted by the PACE on April 28, 2017.",
        "document_url": "http://assembly.coe.int/nw/xml/XRef/Xref-XML2HTML-en.asp?fileid=23726",
        "attachments": "https://pace.coe.int/en/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": true,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "Moreover, the Assembly proposes that guidelines be drawn upon the following issues: strengthening transparency, regulation by public authorities, and operators' accountability concerning the fact that responsibility and accountability of an act lie with the human being, no matter what the circumstances may be. References to independent decision-making by artificial intelligence systems cannot exempt the creators, owners, and managers of these systems from accountability for human rights violations committed with the use of these systems, even in cases where an act causing damage was not directly ordered by a responsible human commander or operator.",
            "Beneficence": "The Assembly reiterates its call made in Resolution 2051 (2015) “Drones and targeted killings: the need to uphold human rights and international law” to all member States and observer States, as well as States whose parliaments have observer status with the Assembly, to refrain from any automated (robotic) procedures for selecting individuals for targeted killings or any sort of injury based on communication patterns or other data collected through mass surveillance techniques. This should be true not only for drones but also for other combat equipment with artificial intelligence systems, as well as other equipment and/or software that might potentially inflict damage on people, property, personal data, or information databases, or interfere with privacy, freedom of expression, or the right to equality and non-discrimination.",
            "Children's Rights": null,
            "Human Rights": "In the light of the above, the Assembly urges the Committee of Ministers to instruct the relevant bodies of the Council of Europe to consider how intelligent artifacts and/or connected devices and, more generally, technological convergence and its social and ethical consequences related to the field of genetics and genomics, neurosciences and big data, challenge the different dimensions of human rights.",
            "Diversity": "The Assembly calls on the Committee of Ministers to define the framework for the use of care robots and assistive technologies in the Council of Europe Disability Strategy 2017-2023 in the framework of its objective to achieve equality, dignity, and equal opportunities for people with disabilities.",
            "Autonomy": "Moreover, the Assembly proposes that guidelines be drawn upon the following issues: the need for any machine, any robot, or any artificial intelligence artifact to remain under human control; insofar as the machine in question is intelligent solely through its software, any power it is given must be able to be withdrawn from it.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": "The Assembly reiterates its call made in Resolution 2051 (2015) “Drones and targeted killings: the need to uphold human rights and international law” to all member States and observer States, as well as States whose parliaments have observer status with the Assembly, to refrain from any automated (robotic) procedures for selecting individuals for targeted killings or any sort of injury based on communication patterns or other data collected through mass surveillance techniques. This should be true not only for drones but also for other combat equipment with artificial intelligence systems, as well as other equipment and/or software that might potentially inflict damage on people, property, personal data, or information databases, or interfere with privacy, freedom of expression, or the right to equality and non-discrimination.",
            "Labor Rights": null,
            "Cooperation": "The Assembly calls for close cooperation with the institutions of the European Union and the United Nations Educational, Scientific and Cultural Organization (UNESCO) to ensure a consistent legal framework and effective supervisory mechanisms at the international level.",
            "Privacy": "Moreover, the Assembly proposes that guidelines be drawn upon the following issues: the recognition of new rights in terms of respect for private and family life, the ability to refuse to be subjected to profiling, to have one's location tracked, to be manipulated or influenced by a “coach”.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "Moreover, the Assembly proposes that guidelines be drawn upon the following issues: strengthening transparency, regulation by public authorities, and operators' accountability concerning automatic processing operations aimed at collecting, handling, and using personal data; informing the public about the value of the data they generate, consent to the use of those data and the length of time they are to be stored; informing people about the processing of personal data originating from them and about the mathematical and statistical methods making profiling possible.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Decree of the President of the Russian Federation on the Development of Artificial Intelligence in the Russian Federation",
        "country": [
            "Russia",
            "Russia"
        ],
        "world_region": [
            "Eastern Europe",
            "Northern Asia"
        ],
        "institution": "Office of the President of the Russian Federation",
        "institution_type": "Governmental Institution",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Medium (>5.000 Words, <10.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Gov. Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Mid",
        "abstract": "This document was written by the Office of the President of the Russian Federation. The document is Russia's national strategy for the development of artificial intelligence, released in October 2019. The strategy sets out several short-term (to be completed by 2024) and medium-term (2030) qualitative goals designed to build Russia into a leading AI power. The document also presents the \"Basic Principles for AI Technologies Development and Use\" in the Russian Federation.",
        "document_url": "https://cset.georgetown.edu/wp-content/uploads/Decree-of-the-President-of-the-Russian-Federation-on-the-Development-of-Artificial-Intelligence-in-the-Russian-Federation-.pdf",
        "attachments": "http://publication.pravo.gov.ru/Document/View/0001201910110003",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": true,
            "Diversity": false,
            "Autonomy": true,
            "Human Formation": true,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": true,
            "Cooperation": true,
            "Privacy": false,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "To stimulate the development and use of artificial intelligence technologies, the adaptation of statutory regulations relating to human interaction with artificial intelligence is needed, together with the formulation of the appropriate ethical standards. The primary directions of the creation of an integrated system for regulating the social relations arising in line with the development and introduction of artificial intelligence technologies shall consist of: creating legal conditions and establishing procedures for the simplified testing and introduction of technological solutions developed based on artificial intelligence; creating unified systems for the standardization and assessment of the compliance of technological solutions developed based on artificial intelligence; formulating ethical rules for human interaction with artificial intelligence.",
            "Beneficence": "The basic principles of the development and use of artificial intelligence technologies, the observance of which is obligatory during the implementation of this Strategy, include: the impermissibility of the use of artificial intelligence to intentionally inflict harm on individuals and legal entities. The goals of the development of artificial intelligence in the Russian Federation shall consist of ensuring the improvement of the well-being and quality of life of its population, ensuring national security and rule of law, and achieving the sustainable competitiveness of the Russian economy, including leading positions the world over in the field of artificial intelligence.",
            "Children's Rights": null,
            "Human Rights": "The basic principles of the development and use of artificial intelligence technologies, the observance of which is obligatory during the implementation of this Strategy, include: the protection of human rights and liberties: ensuring the protection of the human rights and liberties guaranteed by Russian and international laws.",
            "Diversity": null,
            "Autonomy": "The basic principles of the development and use of artificial intelligence technologies, the observance of which is obligatory during the implementation of this Strategy, include: the assurance of the necessary level of Russian Federation self-sufficiency in the field of artificial intelligence, including that achieved through the predominant use of domestic artificial intelligence technologies and technological solutions developed based on artificial intelligence.",
            "Human Formation": "The basic principles of the development and use of artificial intelligence technologies, the observance of which is obligatory during the implementation of this Strategy, include: the right to work, and affording individuals the opportunity to obtain the knowledge and acquire the skills needed to successfully adapt to the conditions of a digital economy.",
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": "The basic principles of the development and use of artificial intelligence technologies, the observance of which is obligatory during the implementation of this Strategy, include: the right to work, and affording individuals the opportunity to obtain the knowledge and acquire the skills needed to successfully adapt to the conditions of a digital economy.",
            "Cooperation": "The basic principles of the development and use of artificial intelligence technologies, the observance of which is obligatory during the implementation of this Strategy, include: the development of market relations and the impermissibility of actions aimed at the restriction of competition between Russian organizations that engage in activities in the field of artificial intelligence.",
            "Privacy": null,
            "Reliability": "The basic principles of the development and use of artificial intelligence technologies, the observance of which is obligatory during the implementation of this Strategy, include: the prevention and minimization of the risks of negative consequences of the use of artificial intelligence technologies.",
            "Sustainability": null,
            "Transparency": "The basic principles of the development and use of artificial intelligence technologies, the observance of which is obligatory during the implementation of this Strategy, include: the intelligibility of artificial intelligence work and the process whereby it achieves results, as well as nondiscriminatory access by the users of products that have been created based on artificial intelligence technologies to information about the artificial intelligence operating algorithms employed in these products.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Allen Institute for Artificial Intelligence Core Values",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Allen Institute for Artificial Intelligence (AI2)",
        "institution_type": [
            "Academic",
            "Non-profit Organization"
        ],
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Allen Institute for Artificial Intelligence (AI2), a non-profit research institute headquartered in Seattle (US). Founded in 2014, AI2 has the mission of conducting high-impact AI research and engineering in service of the common good. AI2 is the creation of the late Paul Allen, philanthropist, and Microsoft co-founder, and is led by Dr. Oren Etzioni, a leading AI researcher. In this document, AI2 presents a set of principles as its Core Values, which can be understood as AI2 voluntary self-commitment to the ethical development of its research.",
        "document_url": "https://allenai.org/about",
        "attachments": "https://allenai.org/",
        "principles": {
            "Accountability": true,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": false,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": true,
            "Privacy": false,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": "We take an efficient, results-oriented approach to our work. We define ambitious, timely goals and continually measure our success against them.",
            "Beneficence": "Our mission is to build AI for the common good. We aim to produce breakthrough research and tools that move the needle in AI, empower the research community, and benefit society.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": null,
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": "We proactively develop diverse teams with a wide range of perspectives and skills to cultivate the best possible ideas. We build relationships with outside research groups and organizations to collectively elevate the field of AI and achieve the broadest possible impact.",
            "Privacy": null,
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "We are clear and forthright with our team about our actions, our decisions, and the goals of our institute. We produce and share new research, tools, and resources openly with the wider world. We support open science.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Stanford's Human-Centered AI Initiative Values",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Stanford Human-Centered AI Initiative (HAI)",
        "institution_type": "Academic",
        "year_of_publication": "Unspecified",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Very Small (<1.000 Words)",
        "document_nature": "Normative",
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by the Stanford Human-Centered AI Initiative (HAI), a Stanford University initiative/institute dedicated to guiding the future of AI. According to its website, HAI's vision for the future is led by its commitment to promoting human-centered uses of AI and ensuring that humanity benefits from the technology and that the benefits are broadly shared. Their actions as an institute are motivated by this vision and guided by five core values. In this document, HAI presents these core values, which can be understood as their voluntary self-commitment to the ethical development of their research.",
        "document_url": "https://hai.stanford.edu/about/our-values",
        "attachments": "https://hai.stanford.edu/",
        "principles": {
            "Accountability": false,
            "Beneficence": true,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": false,
            "Human Formation": false,
            "Human-Centeredness": true,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": false,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": "We value the well-being of humans and humanity and are committed to ensuring that the power of AI is used to improve the human condition, not diminish it. As such, we focus on applications that augment and enhance human capabilities rather than simply displacing or replacing them. In a time of increasing automation, we aim to better understand its implications and find technical as well as policy mechanisms to manage this transition. We study the global impact of AI on the economy and society, in hopes of promoting positive outcomes and mitigating the negative.",
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "We believe the quality of any intellectual endeavor is improved when participants reflect diversity in the broadest sense, including gender, ethnic and socioeconomic background, but also intellectual, cultural, and political perspectives. We recognize that the field of AI, and academia in general, do not yet reflect this diversity and that changing such systemic issues will take time, but we aim to decrease the disparity. We are committed to seeking the insights, experiences, and concerns of people across ethnicities, genders, cultures, and socio-economic groups, as well as those from multiple disciplines and with divergent political views.",
            "Autonomy": null,
            "Human Formation": null,
            "Human-Centeredness": "If AI is to serve the collective needs of humanity, it must incorporate an understanding of what moves us — physically, intellectually, and emotionally. We must design machine intelligence that can understand human language, feelings, intentions, and behaviors, and interact with nuance and in multiple dimensions.",
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "We respect every individual's fundamental right to privacy.",
            "Reliability": null,
            "Sustainability": null,
            "Transparency": "In our research and education, we maintain the highest standards, acknowledge mistakes, and are transparent about sources of funding.",
            "Truthfulness": null
        }
    },
    {
        "document_name": "Principles and Practices for the Responsible Application of Artificial Intelligence at Motorola Solutions - White Paper",
        "country": "United States of America",
        "world_region": "North America",
        "institution": "Motorola Solutions, Inc.",
        "institution_type": "Private Corporation",
        "year_of_publication": "2019",
        "number_of_male_authors": "Unspecified",
        "number_of_female_authors": "Unspecified",
        "document_size": "Small (>1.000 Words, <5.000 Words)",
        "document_nature": [
            "Descriptive",
            "Normative"
        ],
        "document_regulation": "Self-Reg.",
        "document_normative": "Non-binding",
        "document_impact": "Short",
        "abstract": "This document was written by Motorola Solutions, Inc.,  an American video equipment, telecommunications equipment, software, systems, and services provider that succeeded Motorola, Inc. This document summarizes Motorola Solutions' policies and practices for responsibly applying AI in its public safety products and applications. The document can be understood as Motorola Solutions' voluntary self-commitment to the ethical use and development of its AI technologies.",
        "document_url": "https://www.motorolasolutions.com/content/dam/msi/images/artificialintelligence/responsible-ai-whitepaper-final.pdf",
        "attachments": "https://www.motorolasolutions.com/",
        "principles": {
            "Accountability": false,
            "Beneficence": false,
            "Children's Rights": false,
            "Human Rights": false,
            "Diversity": true,
            "Autonomy": true,
            "Human Formation": false,
            "Human-Centeredness": false,
            "Intellectual Property": false,
            "Fairness": false,
            "Labor Rights": false,
            "Cooperation": false,
            "Privacy": true,
            "Reliability": true,
            "Sustainability": false,
            "Transparency": true,
            "Truthfulness": false
        },
        "principles_definition": {
            "Accountability": null,
            "Beneficence": null,
            "Children's Rights": null,
            "Human Rights": null,
            "Diversity": "Motorola Solutions thoroughly evaluates the data employed in training our AI algorithms to ensure that sufficient quantity, quality, and diversity exist across the dataset to properly train the algorithm for its intended purpose and operating environment.",
            "Autonomy": "Fundamentally, our approach is to augment human decision-making while never displacing or disintermediating human judgment. In this sense, our systems are advisory and will never take AI-generated consequential actions on their own. In other words, there is always a “human in the loop” to make the final determinations on substantial decisions. Studies indicate that the best results are achieved with a combination of AI and human experts.",
            "Human Formation": null,
            "Human-Centeredness": null,
            "Intellectual Property": null,
            "Fairness": null,
            "Labor Rights": null,
            "Cooperation": null,
            "Privacy": "Where possible, Motorola Solutions will work with anonymized data (no assignable PII content) at the source, synthesized data (by machine methods or through controlled customer interactions such as training exercises), or accumulate our training data from publicly available sources. We utilize tools and frameworks that facilitate privacy-sensitive training by encoding general patterns rather than facts about specific training examples wherever possible.",
            "Reliability": "We thoroughly validate the operation of the trained algorithms with a representative and diverse set of test cases that are applied across a range of operational conditions. We also test and retest our products in actual customer environments. In fielded operation, our systems generate telemetry that we can continuously monitor to identify performance issues, as well as any inconsistent or undesirable behaviors.",
            "Sustainability": null,
            "Transparency": "Motorola Solutions maximizes our ability to explain the operation of our systems by adopting mature, testable AI components that are as simple as possible for the task at hand. We ensure that our systems generate operational performance data that we can monitor and review on a regular basis to assess the efficacy of the operation.",
            "Truthfulness": null
        }
    }
]